[{"url": "iswc2011_gruninger_ontology", "desc": "Ontology verification is concerned with the relationship between the intended structures for an ontology and the models of the axiomatization of the ontology. The verification of a particular ontology requires characterization of the models of the ontology up to isomorphism and a proof that these models are\r\nequivalent to the intended structures for the ontology. In this paper we provide the verification of the ontology of time introduced by Hobbs and Pan, which is a first-order axiomatization of OWL-Time. We identify five modules within this ontology and present a complete account of the metatheoretic relationships among the modules and between other time ontologies for points and intervals.", "recorded": "2011-10-26T10:30:49", "title": "Verification of the OWL-Time Ontology"}, {"url": "rease_perez_tmt", "desc": "This is a one-hour video recording of the presentation of Asun Gomez Perez at the KnowledgeWeb summer school 2006. It comprises either the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nOntologies: Theory, methods and tools\r\nTypes of Ontologies\r\nMain Components\r\nRe-use of ontologies is often difficult\r\nOntologies in Ontology Libraries\r\nOntology Libraries\r\nOntology Metadata Repositories\r\nOMV- Ontology Metadata Vocabulary\r\nOyster\r\nQuery Repository\r\nAIFB\r\nIntegration Oyster and Onthology\r\nShort development history\r\nMain Components\r\nOntology lifecycle methodology components\r\nMost relevant methodologies\r\nOntologies are available anywhere in Internet\r\nOntology Development Process\r\nInter-ontology dependencies\r\nOntology Life cycle\r\nMETHONTOLOGY: Specification\r\nGetting terminology using Competency Questions\r\nMETHONTOLOGY: Conceptualization\r\nAn example: Knowledge Web Ontologies\r\nExample: Event Ontology\r\nExample: Documentation Ontology\r\nExample: Relationships between Person, Project and Documentation\r\nLimitations to current methodologies\r\nNext works: NeOn methodology\r\nOntology's crossed life cycles\r\nOntology Life cycle\r\nOntology Languages Evolution\r\nMain Components\r\nOntology Tools\r\nMain criteria for selecting an ontology editor\r\nTypes of Ontology Tools\r\nOverview of ontology tools (II)\r\nOntology merging and integration tools\r\nRDF(S)\r\nOntology tools have translators to different languages\r\nBenchmarking Tools  in Knowledge Web\r\nBENCHMARKING ITERATION", "recorded": "2007-02-13T00:00:00", "title": "Ontologies: Theory, methods and tools"}, {"url": "solomon_soldatova_ofs", "desc": "At Aberystwyth University, we have several projects for formalizing descriptions of scientific investigations:\r An ontology for a robot scientist, An ontology for drug design, An ontology for description of protocols, ...\r In my talk, I will describe the state-of-the-art for ontology development in these projects and prospects\r for ontology applications in science.", "recorded": "2008-04-15T13:00:00", "title": "Formalisation of Science: Ontology Based Projects in Aberystwyth University"}, {"url": "cidu2011_gomez_ontology", "desc": "An analysis of the role that the ontology plays in determining verb meaning and semantic roles is presented. The discussion will contrast the current approaches to semantic role labeling using supervised machine learning methods to semantic approaches that rely on the ontology and verb sub-categorization. The presentation will discuss the issues dealing with the construction of verb meaning and semantic roles for general domains, and for specific domains with their own clearly defined ontologies. It will be indicated that Wordnet can serve as the general ontology on which specific ontologies can be anchored. The semantic-based algorithms will search for concepts beginning with the domain-specific ontology, and then continue up to the WordNet ontology if concepts are not found within the domain dependent ontology. In this way, the domain-specific ontology may override the general ontology.", "recorded": "2011-10-19T13:30:00", "title": "Ontology, Verb Meaning and Semantic Roles"}, {"url": "reasecs_noy_poeup", "desc": "An introduction to ontology engineering issues, including:\r\n* upper-ontologies\r\n* using a reasoner at creation time\r\n   - ontology normalisation\r\n* ontology patterns\r\n   - value partitions and enumerations\r\n   - n-ary relations\r\n* classes as values\r\n* part-whole relationships\r\n* qualified cardinality\r\n\r\nDocuments:\r\n;[[Protege-OWL.pdf]]\r\n;[[Protege-OWL.ppt]]", "recorded": "2005-12-08T00:00:00", "title": "Ontology Design Patterns and Problems: Practical Ontology Engineering using Protege-OWL"}, {"url": "rease_perez_oe", "desc": "This is a one-hour video recording of the presentation of Asun Gomez Perez at the KnowledgeWeb summer school 2007. It comprises the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nOntological Engineering\r\nI want to build my ontology\r\nTable of content\r\nOntologies are available anywhere in Internet\r\nMost relevant methodologies\r\nMETHONTOLOGY identifies three components\r\nTable of content\r\nThe NeOn Glossary of Activities\r\nTable of ?Recommended and If-Applicable? Activities\r\nTable of content\r\nOntology Network Development Process\r\nTable of content\r\nLife Cycle Models and Life Cycles in Ontological Engineering\r\nSeveral Ontology Life Cycle Models are possible\r\nDecission Tree for Selecting your Ontology Life Cycle Model\r\nDecission Tree for Selecting Activities to be mapped in the Ontology Life Cycle Model\r\nWaterfall\r\nIncremental Model\r\nIterative Ontology Network Life Cycle\r\nTable of content\r\nLooking for an European Employment\r\nThe Goal: Helping Job Seekers on their way\r\nSEEMP Ontology Network Life Cycle: Iterative model life cycle\r\nSpecification of the Reference Ontology\r\nSearch and Assess Standards and Taxonomies\r\nSelection of Human Resources Management Standards\r\nKnowledge Resource Reengineering\r\nOntology Searching in Ontology Metadata Repositories\r\nSearching ontologies: Obtain the set of candidate ontologies using Oyster\r\nProcess for assessing Time Ontologies (I)\r\nProcess for assessing Time Ontologies (II)\r\nThe Time Ontology Selection\r\nConceptualization\r\nConceptualization: Modular approach for ontology construction\r\nReference Ontology\r\nLocal Ontologies Building Process\r\nWhich option is the most appropriate for the use case?\r\nApproach followed by SEEMP for building Local Ontologies\r\nOntology Tools\r\nTypes of Ontology Tools\r\nAcknowledgement", "recorded": "2007-11-23T00:00:00", "title": "Ontology Engineering"}, {"url": "iswc07_tran_lsa", "desc": "Ontology-based applications play an increasingly important role in the public and corporate Semantic Web. While today there exist a range of tools and technologies to support specific ontology engineering and management activities, architectural design guidelines for building ontology-based applications are missing. In this paper, we present an architecture for ontology-based applications\u2014covering the complete ontology-lifecycle\u2014that is intended to support software engineers in designing and developing ontology-based applications. We illustrate the use of the architecture in a concrete case study using the NeOn toolkit as one implementation of the architecture.", "recorded": "2007-11-14T16:00:00", "title": "Lifecycle-Support in Architectures for Ontology-Based Information Systems"}, {"url": "rease_basili_nlol", "desc": "This is a one-hour video recording of the presentation of Roberto Basili at the KnowledgeWeb summer school 2005. It comprises either the video synchronized with the slides (but requires Quicktime, hence Windows or MacOS, otherwise the slides have to be switched manually).\r\n\r\nTable of Contents: \r\n\r\nNatural Language and Ontology Learning some perspectives for SW applications\r\nOverview\r\nPreliminaries\r\nThe ART framework\r\nMotivations\r\nOverview\r\nSW Services\r\nOntologies in the SW\r\nDescription Logics and Ontologies\r\nNLS vs. SW reasoning - motivating example\r\nThe Ontology and The Lexicon\r\nConceptual vs. Linguistic Information\r\nNatural Language Learning for the SW\r\nFrame Semantics\r\nFrameNet and Ontology Languages\r\nLexical vs. Conceptual Learning\r\nAn Integrated Learning Framework for Ontology Engineering\r\nA Solution\r\nThe Ontology Model\r\nOntology modeling\r\nThe Ontology model at work\r\nLKB vs. DCH mapping\r\nDCH: Conceptual relations\r\nLKB: verbal predicates\r\nMapping VP to Semantic Relations\r\nOntology Engineering: an architecture\r\nEnabling Technologies\r\nThe FF-Poirot\r\nThe FF-Poirot Consortium\r\nOntology-driven Web Mining\r\nThe FF-Poirot challanges\r\nSemantic Modeling\r\nWorld Model\r\nUses of the Ontological Model\r\nOntology-driven Mining\r\nOntology-driven Retrieval\r\nFF Poirot: the CONSOB use case\r\nA second Example\r\nOverview\r\nConclusions\r\nOpen Problems", "recorded": "2006-12-06T00:00:00", "title": "Natural Languages and Ontology Learning"}, {"url": "rease_vrandecic_swmta", "desc": "This is a one-hour video recording of the tutorial and hands-on session of Peter Haase and Danny Vrandecic at the First Asian Autumn School on the Semantic Web. It comprises two videos synchronized with the slides (requires Flash) or the videos alone.\r\n\r\nTable of Contents: \r\nSemantic Web Methods, Tools and Applications\r\nIntroduction\r\nAgenda\r\nInformation Search Example\r\nSemantic Technologies Provide Dynamic Integration Solutions to EII\r\nLifecycle Activities and Tools\r\nOntology Development with Protege OWL\r\nOntology Development with the NeOn Toolkit\r\nOntology Development Tools\r\nOntology Mapping ? Problem and Scope\r\nOntology Mapping ? Techniques and Tools\r\nOntology Mapping with OntoMap\r\nOntology Learning\r\nText2Onto\r\nOntology Learning Tools\r\nOntology Learning - Conclusions\r\nOntology Evaluation\r\nOntology Evolution\r\nOntology Evolution (Process)\r\nOntology Management Infrastructure\r\nOntology Repositories\r\nStandard Reasoning Tasks\r\nOverview of Reasoners\r\nWhat is the NeOn Toolkit?\r\nNeOn Architecture to Support the Entire Ontology Lifecycle\r\nApplications\r\nScenario (BT Digital Library)\r\nWhy Ontology-Based Digital Libraries?\r\nConceptual Architecture\r\nOntology Model and Knowledge Base\r\nKnowledge Portal\r\nScenario Revisited\r\nThe BT Digital Library\r\nProject Halo\r\nFormalizing questions\r\nBackground knowledge\r\nEvaluation\r\nResult browser\r\nontoworld.org\r\nThe Semantic Web wiki\r\nWhy should the community care?\r\nPiggybank\r\nScrape data\r\nExplore your data\r\neMerges\r\nDefine a region (spatial object)\r\nAssign a type to it\r\nUniform representation: Spatial Object have context-dependent affordances (actions), and features (properties)\r\nHere retrieves the shelters in an area\r\nAll GMaps features are available and retrieved spatial objects can be fields (e.g. chemical cloud over Stansted airport)\r\nAny xml based WS can be integrated, here snow level (grey), and Instant Messaging presence (green/yellow)\r\nApplications ? Conclusion\r\nOntologies and Semantic Technologies\r\nOntology Engineering\r\nOntology Learning, Mapping\r\nApplications\r\n\r\nHands-on session:\r\nHands on exercises: Semantic Web Methods, Tools and Applications\r\nRequired Software (on CD)\r\nWhat we will do\r\nSemantic MediaWiki\r\nAASSWWiki\r\nEditing the wiki\r\nQuick overview of wiki markup\r\nOverview of semantic markup\r\nData values and types\r\nAdd your own information\r\nCollaborative ontology engineering\r\nSocial aspects\r\nQuerying the knowledge\r\nQuery examples\r\nQuerying and social aspects\r\nExporting the data\r\nWhat we will do\r\nNeOn Toolkit: Create new Ontology Project\r\nImport Ontology as OWL File\r\nBrowse Ontology\r\nCreate and Execute a Query\r\nImport Data from Semantic MediaWiki\r\nCreate Mappings between Ontologies\r\nQuery the Integrated Data\r\nWhat we will do\r\nGetting started with Protege\r\nOWL Reasoner: KAON2\r\nThe DIG interface\r\nStart KAON2 Server mode\r\nConnecting to KAON2\r\nReasoning Tasks\r\nKAON2 Demonstrator\r\nSPARQL\r\nSPARQL Syntax for Conjunctive Queries\r\nBack in Protege: Create SWRL Rules\r\nQuery ontology with rules in KAON2", "recorded": "2007-11-26T00:00:00", "title": "Semantic Web Methods, Tools and Applications"}, {"url": "rease_figueroa_oe", "desc": "These are two one-hour video recording of the presentation of Mari Carmen Suarez-Figueroa at the First Asian Autumn School on the Semantic Web. It comprises the videos synchronized with the slides (requires Flash) or the videos alone.\r\n\r\nTable of Contents: \r\n\r\nPart I:\r\nOntology Engineering: How can we build ontologies? Methods, Techniques and Methodologies\r\nMain References\r\nAcknowledgements\r\nOntology Definition\r\nI want to build my ontology\r\nOntology Engineering\r\nThree aspects of ontology development\r\nOutline\r\nThe Framework\r\nOntologies are available anywhere in Internet\r\nThe NeOn Glossary of Activities\r\nTable of ?Required and If-Applicable? Activities\r\nOntology Network Development Process\r\nOntology Life Cycle. Intra-dependencies\r\nOntology Life Cycle. Inter-dependencies\r\nOutline\r\nLife Cycle Models and Life Cycles in Ontological Engineering\r\nSeveral Ontology Life Cycle Models are possible\r\nStep 2: Decision Tree for Selecting the Ontology Network Life Cycle Model\r\nStep 3: Decision Tree for Selecting Activities to be mapped in the Ontology Network Life Cycle Model\r\n?Yes/No? Natural Language Questions\r\nOutline\r\nMost relevant methodologies\r\nUschold?s Methodology\r\nMethodology used on the KACTUS project\r\nSENSUS Method\r\nOn-To-Knowledge\r\nSummary of the Methodologies\r\nOutline\r\nLooking for an European Employment\r\nThe Goal: Helping Job Seekers on their way\r\nSEEMP Ontology Network Life Cycle: Iterative model life cycle\r\nSpecification of the Reference Ontology\r\nSearch and Assess Standards and Taxonomies\r\nSelection of Human Resources Management Standards\r\nKnowledge Resource Reengineering\r\nOntology Searching in Ontology Metadata Repositories\r\nSearching ontologies: Obtain the set of candidate ontologies using Oyster\r\nProcess for Assessing Time Ontologies\r\nThe Time Ontology Selection\r\nConceptualization\r\nConceptualization: Modular approach for ontology construction\r\nReference Ontology\r\nLocal Ontologies Building Process\r\nWhich option is the most appropriate for the use case?\r\nApproach followed by SEEMP for building Local Ontologies\r\nOntology Engineering: How can we build ontologies? Methods, Techniques and Methodologies\r\n\r\nPart II:\r\nOntology Engineering: How can we build ontologies? Methods, Techniques and Methodologies Tutorial\r\nOutline\r\nGetting terminology using Competency Questions\r\nGetting terminology using Competency Questions. Example\r\nIdentify and Group CQs\r\nExercise to be done in the Hands-on Session\r\nElicitation Techniques. Types\r\nCard Sorting. Collect and organise the concepts\r\nCard Sorting. Example\r\nLaddering. Extend the Concepts\r\nLaddering. Choose Some Main Axes\r\nLaddering. Example\r\nTechniques used in different OL approaches\r\nMETHONTOLOGY. Tasks in the conceptualization activity\r\nMETHONTOLOGY. Terms Glossary\r\nMETHONTOLOGY. Primitives for Modelling Taxonomies\r\nExample of a Taxonomy\r\nMETHONTOLOGY. Identify Ad-hoc relations\r\nMETHONTOLOGY. Define a Concept Dictionary\r\nMETHONTOLOGY. Define Instance Attributes\r\nMETHONTOLOGY. Define Formal Axioms\r\nMETHONTOLOGY. Define Rules\r\nMETHONTOLOGY. Define Instances\r\nOntology Design Patterns for Modelling\r\nExamples of Ontology Design Patterns\r\nExercise to be done in the Hands-on Session\r\nOntology Reengineering\r\nReverse Engineering. Example\r\nRestructuring. Example\r\nExercise to be done in Hands-on Session\r\nGomez-Perez approach for taxonomic evaluation\r\nOntology Evolution\r\nConclusions\r\nOntology Engineering: How can we build ontologies? Methods, Techniques and Methodologies Tutorial", "recorded": "2007-11-26T00:00:00", "title": "Ontology Engineering"}, {"url": "eswc08_lewen_oep", "desc": "Our tutorial targets ontology modelers and engineers. The tutorial provides\r guidance for the development of ontologies and ontology-based applications\r with respect to the complete ontology lifecycle.\r \r We will start with an introduction to a variety of use cases for\r applications of ontologies, including information integration and knowledge\r management. Based on these use cases we will illustrate a typical ontology\r lifecycle and discuss specific ontology lifecycle activities, such as\r ontology development, selection and reuse, ontology mapping, and ontology\r evolution. After a short introduction to the NeOn toolkit and its\r functionalities, we will take a closer look at how the lifecycle activities\r are realized using the NeOn toolkit. As an example, we will demonstrate how\r to support ontology selection and reuse with a plug-in that integrates with\r the Watson Semantic Web gateway. In the hands-on exercises, the participants\r will work on practical activities from a real world use case.\r \r In the second half of the tutorial, we will demonstrate how to extend the\r functionalities of the ontology engineering environment by developing a NeOn\r plug-in to support an additional lifecycle activity from the initial use\r case. Therefore, we first provide further insights into the NeOn reference\r architecture, its plug-in concept and APIs. We will then demonstrate how to\r develop a plug-in in an easy-to-follow step-by-step way. After that, the\r participants will create their own working plug-in in a hands-on exercise.", "recorded": "2008-06-01T09:30:00", "title": "Ontology Engineering and Plug-in Development with the NeOn Toolkit - Ontology Lifecycle and Methodology"}, {"url": "eswc2013_santarelli_ontology_classication", "desc": "Ontology classi\fcation is the reasoning service that computes all subsumption relationships inferred in an ontology between concept, role, and attribute names in the ontology signature. OWL 2 QL is a\r\ntractable pro\fle of OWL 2 for which ontology classi\fcation is polynomial in the size of the ontology TBox. However, to date, no e\u000ecient methods and implementations speci\fcally tailored to OWL 2 QL ontologies have been developed. In this paper, we provide a new algorithm for ontology classi\fcation in OWL 2 QL, which is based on the idea of encoding the ontology TBox into a directed graph and reducing core reasoning to computation of the transitive closure of the graph. We have implemented the algorithm in the QuOnto reasoner and extensively evaluated it over very large ontologies. Our experiments show that QuOnto outperforms various popular reasoners in classi\fcation of OWL 2 QL ontologies.", "recorded": "2013-05-28T15:27:17", "title": "Graph-based Ontology Classi"}, {"url": "stisemanticsummit2011_luczak_roesch_ontology", "desc": "", "recorded": "2011-07-08T09:30:00", "title": "The Next Generation of Ontology Development \u2013 Usage-based Ontology Engineering"}, {"url": "eswc08_haase_oep2", "desc": "Our tutorial targets ontology modelers and engineers. The tutorial provides\r guidance for the development of ontologies and ontology-based applications\r with respect to the complete ontology lifecycle.\r \r We will start with an introduction to a variety of use cases for\r applications of ontologies, including information integration and knowledge\r management. Based on these use cases we will illustrate a typical ontology\r lifecycle and discuss specific ontology lifecycle activities, such as\r ontology development, selection and reuse, ontology mapping, and ontology\r evolution. After a short introduction to the NeOn toolkit and its\r functionalities, we will take a closer look at how the lifecycle activities\r are realized using the NeOn toolkit. As an example, we will demonstrate how\r to support ontology selection and reuse with a plug-in that integrates with\r the Watson Semantic Web gateway. In the hands-on exercises, the participants\r will work on practical activities from a real world use case.\r \r In the second half of the tutorial, we will demonstrate how to extend the\r functionalities of the ontology engineering environment by developing a NeOn\r plug-in to support an additional lifecycle activity from the initial use\r case. Therefore, we first provide further insights into the NeOn reference\r architecture, its plug-in concept and APIs. We will then demonstrate how to\r develop a plug-in in an easy-to-follow step-by-step way. After that, the\r participants will create their own working plug-in in a hands-on exercise.", "recorded": "2008-06-01T11:30:00", "title": "Ontology Engineering and Plug-in Development with the NeOn Toolkit"}, {"url": "eswc08_erdman_oep2", "desc": "Our tutorial targets ontology modelers and engineers. The tutorial provides\r guidance for the development of ontologies and ontology-based applications\r with respect to the complete ontology lifecycle.\r \r We will start with an introduction to a variety of use cases for\r applications of ontologies, including information integration and knowledge\r management. Based on these use cases we will illustrate a typical ontology\r lifecycle and discuss specific ontology lifecycle activities, such as\r ontology development, selection and reuse, ontology mapping, and ontology\r evolution. After a short introduction to the NeOn toolkit and its\r functionalities, we will take a closer look at how the lifecycle activities\r are realized using the NeOn toolkit. As an example, we will demonstrate how\r to support ontology selection and reuse with a plug-in that integrates with\r the Watson Semantic Web gateway. In the hands-on exercises, the participants\r will work on practical activities from a real world use case.\r \r In the second half of the tutorial, we will demonstrate how to extend the\r functionalities of the ontology engineering environment by developing a NeOn\r plug-in to support an additional lifecycle activity from the initial use\r case. Therefore, we first provide further insights into the NeOn reference\r architecture, its plug-in concept and APIs. We will then demonstrate how to\r develop a plug-in in an easy-to-follow step-by-step way. After that, the\r participants will create their own working plug-in in a hands-on exercise.", "recorded": "2008-06-01T15:30:00", "title": "Ontology Engineering and Plug-in Development with the NeOn Toolkit"}, {"url": "eswc08_haase_oep3", "desc": "Our tutorial targets ontology modelers and engineers. The tutorial provides\r guidance for the development of ontologies and ontology-based applications\r with respect to the complete ontology lifecycle.\r \r We will start with an introduction to a variety of use cases for\r applications of ontologies, including information integration and knowledge\r management. Based on these use cases we will illustrate a typical ontology\r lifecycle and discuss specific ontology lifecycle activities, such as\r ontology development, selection and reuse, ontology mapping, and ontology\r evolution. After a short introduction to the NeOn toolkit and its\r functionalities, we will take a closer look at how the lifecycle activities\r are realized using the NeOn toolkit. As an example, we will demonstrate how\r to support ontology selection and reuse with a plug-in that integrates with\r the Watson Semantic Web gateway. In the hands-on exercises, the participants\r will work on practical activities from a real world use case.\r \r In the second half of the tutorial, we will demonstrate how to extend the\r functionalities of the ontology engineering environment by developing a NeOn\r plug-in to support an additional lifecycle activity from the initial use\r case. Therefore, we first provide further insights into the NeOn reference\r architecture, its plug-in concept and APIs. We will then demonstrate how to\r develop a plug-in in an easy-to-follow step-by-step way. After that, the\r participants will create their own working plug-in in a hands-on exercise.", "recorded": "2008-06-01T16:30:00", "title": "Ontology Engineering and Plug-in Development with the NeOn Toolkit"}, {"url": "iswc08_tudarache_scodp", "desc": "Ontologies are becoming so large in their coverage that no single person or a small group of people can develop them effectively and ontology development becomes a community-based enterprise. We present Collaborative Prot\u00e9g\u00e9\u2014an extension of the Prot\u00e9g\u00e9 ontology editor that we have designed specifically to support the collaboration process for a community of users. During the ontology-development process, Collaborative Prot\u00e9g\u00e9 allows users to hold discussions about the ontology components and changes using typed annotations; it tracks the change history of the ontology entities; it provides a chat and search functionality. Users edit simultaneously an ontology stored in a common repository. All changes made by a user are seen immediately by other users. Collaborative Prot\u00e9g\u00e9 is open source and distributed with the full installation of Prot\u00e9g\u00e9.\r\n", "recorded": "2008-10-28T10:30:00", "title": "Supporting Collaborative Ontology Development in Protege"}, {"url": "iswc08_davis_rtoa", "desc": "Controlled Language (CL) for Ontology Editing tools offer an attractive alternative for naive users wishing to create ontologies, but they are still required to spend time learning the correct syntactic structures and vocabulary in order to use the Controlled Language properly. This paper extends previous work (CLOnE) which uses standard NLP tools to process the language and manipulate an ontology. Here we also generate text in the CL from an existing ontology using template-based (or shallow) Natural Language Generation (NLG). The text generator and the CLOnE authoring process combine to form a RoundTrip Ontology Authoring environment: one can start with an existing imported ontology or one originally produced using CLOnE, (re)produce the Controlled Language, modify or edit the text as required and then turn the text back into the ontology in the CLOnE environment. Building on previous methodology we undertook an evaluation, comparing the RoundTrip Ontology Authoring process with a well-known ontology editor; where previous work required a CL reference manual with several examples in order to use the controlled language, the use of NLG reduces this learning curve for users and improves on existing results for basic ontology editing tasks.", "recorded": "2008-10-28T11:30:00", "title": "RoundTrip Ontology Authoring"}, {"url": "eswc08_erdman_oep", "desc": "Our tutorial targets ontology modelers and engineers. The tutorial provides\r guidance for the development of ontologies and ontology-based applications\r with respect to the complete ontology lifecycle.\r \r We will start with an introduction to a variety of use cases for\r applications of ontologies, including information integration and knowledge\r management. Based on these use cases we will illustrate a typical ontology\r lifecycle and discuss specific ontology lifecycle activities, such as\r ontology development, selection and reuse, ontology mapping, and ontology\r evolution. After a short introduction to the NeOn toolkit and its\r functionalities, we will take a closer look at how the lifecycle activities\r are realized using the NeOn toolkit. As an example, we will demonstrate how\r to support ontology selection and reuse with a plug-in that integrates with\r the Watson Semantic Web gateway. In the hands-on exercises, the participants\r will work on practical activities from a real world use case.\r \r In the second half of the tutorial, we will demonstrate how to extend the\r functionalities of the ontology engineering environment by developing a NeOn\r plug-in to support an additional lifecycle activity from the initial use\r case. Therefore, we first provide further insights into the NeOn reference\r architecture, its plug-in concept and APIs. We will then demonstrate how to\r develop a plug-in in an easy-to-follow step-by-step way. After that, the\r participants will create their own working plug-in in a hands-on exercise.", "recorded": "2008-06-01T10:15:00", "title": "Ontology Engineering and Plug-in Development with the NeOn Toolkit - Neon toolkit overview"}, {"url": "eswc08_haase_oep", "desc": "Our tutorial targets ontology modelers and engineers. The tutorial provides\r guidance for the development of ontologies and ontology-based applications\r with respect to the complete ontology lifecycle.\r \r We will start with an introduction to a variety of use cases for\r applications of ontologies, including information integration and knowledge\r management. Based on these use cases we will illustrate a typical ontology\r lifecycle and discuss specific ontology lifecycle activities, such as\r ontology development, selection and reuse, ontology mapping, and ontology\r evolution. After a short introduction to the NeOn toolkit and its\r functionalities, we will take a closer look at how the lifecycle activities\r are realized using the NeOn toolkit. As an example, we will demonstrate how\r to support ontology selection and reuse with a plug-in that integrates with\r the Watson Semantic Web gateway. In the hands-on exercises, the participants\r will work on practical activities from a real world use case.\r \r In the second half of the tutorial, we will demonstrate how to extend the\r functionalities of the ontology engineering environment by developing a NeOn\r plug-in to support an additional lifecycle activity from the initial use\r case. Therefore, we first provide further insights into the NeOn reference\r architecture, its plug-in concept and APIs. We will then demonstrate how to\r develop a plug-in in an easy-to-follow step-by-step way. After that, the\r participants will create their own working plug-in in a hands-on exercise.", "recorded": "2008-06-01T09:00:00", "title": "Ontology Engineering and Plug-in Development with the NeOn Toolkit - Introduction"}, {"url": "iswc2011_fokoue_ontology", "desc": "Ontology alignment is an important problem for the linked data web, as more and more ontologies and ontology instances get published for specific domains such as government and healthcare. A number of (semi-)automated alignment systems have been proposed in recent years. Most combine a set of similarity functions on lexical, semantic and structural features to align ontologies. Although these functions work well in many cases of ontology alignments, they fail to capture alignments when terms or structure varies vastly across ontologies. In this case, one is forced to rely on manual alignment. In this paper, we study whether it is feasible to re-use such expert provided ontology alignments for new alignment tasks. We focus in particular on many-to-one alignments, where the opportunity for re-use is feasible if alignments are stable. Specifically, we define the notion of a cluster as being made of multiple entities in the source ontology S that are mapped to the same\r\nentity in the target ontology T . We test the stability hypothesis that the formed clusters of source ontology are stable across alignments to different target ontologies. If this hypothesis is valid, the clusters of an ontology S, built from an existing alignment with an ontology T \"can be effectively exploited to align S with a new ontology T\". Evaluation on both manual and automated high-quality alignments show remarkable stability of clusters across ontology alignments in the financial domain\r\nand the healthcare and life sciences domain. Experimental evaluation also demonstrates the effectiveness of utilizing the stability of clusters in improving the alignment process in terms of precision and recall.", "recorded": "2011-10-27T14:32:00", "title": "A Clustering-based Approach to Ontology Alignment"}, {"url": "eswc08_hyvonen_bn", "desc": "", "recorded": "2008-06-03T11:00:00", "title": "Building a National Semantic Web Ontology and Ontology Service Infrastructure - The FinnONTO Approach"}, {"url": "reasecs_lanzenberger_owol", "desc": "Web Ontology Language: OWL Lite & OWL DL Basics\r\n\r\nDocuments: \r\n;[[OWL.pdf]]", "recorded": "2006-11-10T00:00:00", "title": "OWL - Web Ontology Language"}, {"url": "reasecs_harmelen_womtb", "desc": "Overview of existing approaches for ontology mappings.\n\nDocuments:\n;[[Ontology_mapping.pdf]]", "recorded": "2005-11-30T00:00:00", "title": "Ontology mapping: a way out of the medical tower of Babel?"}, {"url": "reasecs_franconi_dlcdi", "desc": "In the tutorial I will argue that good Conceptual Modelling and Ontology Design is required to support powerful Query Management and to allow for semantic based Information Integration. Therefore, the tutorial has been structured into three parts:\n* In the first part, an extended ontology language and a methodology for conceptual and ontology design will be introduced.\n* In the second part, the query management problem in the presence of the previously devised conceptual model will be considered: a global framework will be introduced, together with various basic tasks involved in information access.\n* In the last part, general issues about ontology integration will be presented.", "recorded": "2004-11-02T00:00:00", "title": "Description Logics for Conceptual Design, Information Access, and Ontology Integration"}, {"url": "eswc2015_ivanova_ontology_alignment", "desc": "Currently one of the challenges for the ontology alignment\r\ncommunity is the user involvement in the alignment process. At the same\r\ntime, the focus of the community has shifted towards large-scale matching\r\nwhich introduces an additional dimension to this issue. This paper\r\naims to provide a set of requirements that foster the user involvement\r\nfor large-scale ontology alignment tasks. Further, we present and discuss\r\nthe results of a literature study for 7 ontology alignments systems\r\nas well as a heuristic evaluation and an observational user study for 3\r\nontology alignment systems to reveal the coverage of the requirements in\r\nthe systems and the support for the requirements in the user interfaces.", "recorded": "2015-06-03T14:30:00", "title": "Requirements for and Evaluation of User Support for Large-Scale Ontology Alignment"}, {"url": "reasecs_sure_oebpb", "desc": "This short tutorial describes how the Ontology 'Semantic Web for Research Communities' has been built, including a set of design considerations and guidlines for (re-)using it. It also includes a set of application examples.\n\nDocuments:\n;[[Best_Practices.pdf]]", "recorded": "2005-12-12T00:00:00", "title": "Ontology Engineering Best Practices - Building and Applying the SWRC Ontology"}, {"url": "iswc08_euzenat_aoar", "desc": "Correspondences in ontology alignments relate two ontology entities with a relation. Typical relations are equivalence or subsumption. However, different systems may need different kinds of relations. We propose to use the concepts of algebra of relations in order to express the relations between ontology entities in a general way. We show the benefits in doing so in expressing disjunctive relations, merging alignments in different ways, amalgamating alignments with relations of different granularity, and composing alignments.", "recorded": "2008-10-29T12:00:00", "title": "Algebras of ontology alignment relations"}, {"url": "solomon_soldatova_taos", "desc": "The talk will present the results of Larisa's collaboration with the Jozef Stefan Institute in  Ljubljana, focusing on her recent visit. These include in the first place OntoDM, an ontology of data mining, developed at JSI. The use cases of OntoDM include QSAR modeling for drug design, which connects OntoDM with DDI, the ontology for drug design investigations developed in Aberystwyth. Finally, she will discuss recent preliminary investigations into ontologies for modeling dynamic systems undertaken jointly, which have led to some directions for developing the next generation of the Systems Biology Ontology. She will conclude by presenting her vision of the Ontology of Science.\r\n\r\n", "recorded": "2010-12-02T13:00:00", "title": "Towards an Ontology of Science"}, {"url": "iswc07_gangemi_oedp", "desc": "Building upon Asun's presentation here Aldo will focus on Ontology Design. In particular, Aldo will apply the software engineering notion of design patterns to the design of ontologies. This session will give attendees a number of insights into the differences between good and bad ontology design.", "recorded": "2007-11-11T11:45:00", "title": "Ontology Engineering Design Patterns"}, {"url": "iswc08_ensan_ibomf", "desc": "In this paper, we present a framework for developing ontologies in a modular manner, which is based on the notions of interfaces and knowledge encapsulation. Within the context of this framework, an ontology can be defined and developed as a set of ontology modules that can access the knowledge bases of the others through their well-defined interfaces. An important implication of the proposed framework is that ontology modules can be developed completely independent of each others\u2019 signature and language. Such modules are free to only utilize the required knowledge segments of the others. We describe the interface-based modular ontology formalism, which theoretically supports this framework and present its distinctive features compared to the exiting modular ontology formalisms. We also describe the real-world design and implementation of the framework for creating modular ontologies by extending OWL-DL and modifying the Swoop interfaces and reasoners.", "recorded": "2008-10-30T11:00:00", "title": "An Interface-Based Ontology Modularization Framework for Knowledge Encapsulation"}, {"url": "rease_perez_oem", "desc": "This is a one-hour video recording of the presentation of Asun Gomez Perez at the KnowledgeWeb summer school 2005. It comprises either the video synchronized with the slides (but requires Quicktime, hence Windows or MacOS, otherwise the slides have to be switched manually).\r\n\r\nThis is a subset of the other Ontology Engineering tutorials available on REASE.\r\n\r\nTable of Contents:\r\nOntological Engineering: Methodologies\r\nDefinitions of Ontology\r\nTypes of Ontologies Lassila and McGuiness Classification\r\nOntology Libraries\r\nKnowledge Representation Ontologies\r\nOne Unique Top-Level Ontology?\r\nDomain Ontologies: e-Commerce Ontologies\r\nApproaches for Modeling Ontologies\r\nUsing UML for Modeling Ontologies\r\nUsing the Entity Relationship Model for Modeling Ontologies\r\nFrames versus Description Logic\r\nUsing Frames and First Order Logic for Modeling Ontologies\r\nUsing Description Logics for Modeling Ontologies\r\nExample of axioms\r\nConclusions on the Different Approaches to Build Ontologies\r\nOntologies are available anywhere in Internet\r\nOntology Development Process\r\nInter-dependencies\r\nOntology Life cycle\r\nMETHONTOLOGY: Specification\r\nGetting terminology using Competency Questions", "recorded": "2006-12-06T00:00:00", "title": "Ontology Engineering Methodologies"}, {"url": "rease_paslaru_om", "desc": "This is a one-hour video recording of the tutorial of Elena Simperl at the First Asian Autumn School on the Semantic Web. It comprises the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nTutorial Ontology Modeling* Elena Simperl, University of Innsbruck\r\nThe Wine ontology\r\nStep 1: Determine the domain and scope of the ontology\r\nCompetency questions\r\nExample: Competency Questions\r\nStep 2: Consider reusing existing ontologies\r\nStep 3: Enumerate important terms in the ontology\r\nEnumerating Terms - The Wine Ontology\r\nStep 4: Define the classes and the class hierarchy\r\nStep 4: Define the classes and the class hierarchy (ii)\r\nExample: Class inheritance\r\nLevels in the Hierarchy\r\nDocumentation\r\nStep 5: Define the properties of classes\r\nProperties and class inheritance\r\nStep 6: Define the restrictions of the properties\r\nCommon Constraints\r\nConstraints and class inheritance\r\nStep 7: Create instances\r\nPractical modeling guidelines\r\nGeneral issues\r\nHigher degree of formality: costs and benefits\r\nPurpose and scope of the ontology\r\nClass hierarchy\r\nClass hierarchy (ii)\r\nDomain and range of properties\r\nInverse properties\r\nThank you for your attention", "recorded": "2007-11-26T00:00:00", "title": "Ontology Modeling"}, {"url": "internal_zakova_kdo", "desc": "Motivation and main objectives of the ontology:\r\n * top level structure: Algorithm, Knowledge, KnowledgeDiscoveryTask\r\n * representing knowledge and data (including relational data, prolog\r\nfacts, association rules)\r\n * representing algorithms\r\n * algorithm annotation examples - RDM algorithms and Orange algorithms\r\n(class definitions and queries will be shown in Prot\u00e9g\u00e9 ontology editor)\r\n", "recorded": "2010-02-09T15:00:00", "title": "Knowledge Discovery Ontology"}, {"url": "iswc07_calvanese_oda", "desc": "In this tutorial we provide a comprehensive understanding of the\r problem of ontology-based data access, from both the theoretical and\r the practical points of view. We address several problems that are\r crucial in this context, such as expressiveness/efficiency tradeoff,\r query processing, impedance mismatch between ontology and data levels,\r and integration of multiple data sources. We present solutions to these\r problems based on recent research results in the area of tractable\r Description Logics, and we provide also a ``hands-on'' experience with\r QuOnto, a state-of-the-art system for ontology-based data access.", "recorded": "2007-11-12T09:00:00", "title": "Ontology-based Data Access"}, {"url": "iswc07_lembo_oda", "desc": "In this tutorial we provide a comprehensive understanding of the\r problem of ontology-based data access, from both the theoretical and\r the practical points of view. We address several problems that are\r crucial in this context, such as expressiveness/efficiency tradeoff,\r query processing, impedance mismatch between ontology and data levels,\r and integration of multiple data sources. We present solutions to these\r problems based on recent research results in the area of tractable\r Description Logics, and we provide also a ``hands-on'' experience with\r QuOnto, a state-of-the-art system for ontology-based data access.", "recorded": "2007-11-12T14:00:00", "title": "Ontology-based Data Access"}, {"url": "iswc2014_solimando_ontology_to_ontology", "desc": "In order to enable interoperability between ontology-based systems, ontology matching techniques have been proposed. However, when the generated mappings suffer from logical flaws, their usefulness may be diminished. In this paper we present an approximate method to detect and correct violations to the so-called conservativity principle where novel subsumption entailments between named concepts in one of the input ontologies are considered as unwanted. We show that this is indeed the case in our application domain based on the EU Optique project. Additionally, our extensive evaluation conducted with both the Optique use case and the data sets from the Ontology Alignment Evaluation Initiative (OAEI) suggests that our method is both useful and feasible in practice.", "recorded": "2014-10-23T10:45:00", "title": "Detecting and Correcting Conservativity Principle Violations in Ontology-to-Ontology Mappings"}, {"url": "iswc07_funk_cloe", "desc": "This paper presents a controlled language for ontology editing\r and a software implementation, based partly on standard NLP tools,\r for processing that language and manipulating an ontology. The input\r sentences are analysed deterministically and compositionally with respect\r to a given ontology, which the software consults in order to interpret\r the input\u2019s semantics; this allows the user to learn fewer syntactic\r structures since some of them can be used to refer to either classes or\r instances, for example. A repeated-measures, task-based evaluation has\r been carried out in comparison with a well-known ontology editor; our\r software received favourable results for basic tasks. The paper also discusses\r work in progress and future plans for developing this language\r and tool.", "recorded": "2007-11-14T14:00:00", "title": "CLOnE: Controlled Language for Ontology Editing "}, {"url": "rease_gangemi_od", "desc": "This is a one-hour video recording of the presentation of Aldo Gangemi at the KnowledgeWeb summer school 2007. It the video synchronized with the slides.\r\n\r\nTable of Contents:\r\nOntology Design (conceptualization and modelling aspects)\r\nOutline\r\nThe motivations for semantic technologies\r\nOpportunities\r\nA hub for web semantics\r\nOntology graphs (here in a UML OWL profile)\r\nWhat is ontology design?\r\nWhat is needed for designing ontologies\r\nThe modular architecture of (collaborative) ontology design\r\nOntology-related data and reengineering\r\nOntology-related data\r\nLinguistic dictionaries and thesauri\r\nWordNets\r\nFrameNets\r\nThesauri: Agrovoc\r\nTags: Flickr\r\nTags: Wikipedia\r\nHow to compare them?\r\nW3C WNET Schema (Lexicon2ABox approach)\r\nAn example of wordnet in owl (Lexicon2ABox approach)\r\nSKOS Vocabulary (KOS2ABox approach)\r\nOntoFrameNet (a different Lexicon2ABox approach)\r\nOntologies and language\r\nAnything in common?\r\nAnything in common?\r\nOntologies = controlled terminologies?\r\nThe modular architecture of (collaborative) ontology design\r\nFrom ?raw? data to patterns\r\nLegacy aquaculture hierarchies from fishery terminology systems\r\nSample data model analysis/conversion (KOS2TBox approach)\r\nConversion: effects on translation (1)\r\nConversion: effects on translation (2)\r\nOntology design patterns: Theory\r\nOntology design patterns\r\nWhat?s a pattern?\r\nPeter Clark?s idea\r\nConceptual (content) vs. logical patterns\r\nClark (2000), more explicit\r\nSignature morphisms\r\nA distinction between logical and content patterns\r\nMore pattern types (ongoing work in NeOn)\r\nPragmatic features of CODePs\r\nLooking for Ontology Design Patterns\r\nOntology design patterns: Types and examples\r\nTypes of ontology design patterns\r\nLogical patterns (LPs). Definition\r\nExamples of LPs\r\nAn application of nAry- and class-reification pattern\r\nReasoning patterns (RPs). Definition\r\nArchitectural patterns (APs). Definition\r\nExamples of APs\r\nModularity and stratification of ontologies\r\nContent Patterns (CPs). Definition\r\nExamples of CPs\r\nGeneric use cases\r\nPart of\r\nBasic participation\r\nCo-participation\r\nTime-indexed participation\r\nRole-based participation\r\nRoles and tasks within a description\r\nDescription and situation example\r\nCollection&lt;-&gt;Entity (vocabulary for ?classes as values? LP)\r\nInformation objects and realizations\r\nIdentity, Resources, and Entities on the web\r\nSpecializing patterns\r\nComposing patterns\r\nMinimal methodology\r\nC-ODO domain stack\r\nData about C-ODO\r\nArgumentation\r\nOngoing work e.g. in NeOn\r\nSome references", "recorded": "2007-11-22T00:00:00", "title": "Ontology Design"}, {"url": "iswc2012_bendadouche_communication_pattern", "desc": "Wireless Sensor Networks (WSN) are designed to collect large amounts of heterogeneous data to monitor environmental phenomenon. Our aim is to adapt WSN nodes communication to their context, in order to optimize the lifetime of the network. Our description of context and WSN characteristics are based on ontologies. Based upon a critical analysis of existing ontologies which formalize the\r\nWSN domain, we determine that the Semantic Sensor Network (SSN) ontology is the most suitable to represent the WSN issues. However, as the communication data policy is not characterized either by SSN or by other ontologies, we propose to enrich the SSN ontology with a new pattern describing communication. In this paper, we will first integrate the different concepts related to WSN in the SSN ontology and then we will use the resulting ontology, called Wireless Semantic Sensor Network ontology, in an agri-environmental scenario to illustrate the interest of our approach.", "recorded": "2012-11-12T11:30:53", "title": "Extension of the Semantic Sensor Network Ontology for Wireless Sensor Network: The Stimulus-WSNnode-Communication Pattern"}, {"url": "eswc2013_zhao_knowledge", "desc": "The Linked Open Data (LOD) cloud contains tremendous amounts of interlinked instances, from where we can retrieve abundant knowledge. However, because of the heterogeneous and big ontologies, it is time consuming to learn all the ontologies manually and it is difficult to observe which properties are important for describing instances of a specific class. In order to construct an ontology that can help users easily access to various data sets, we propose a semi-automatic ontology integration framework that can reduce the heterogeneity of ontologies and retrieve frequently used core properties for each class. The framework consists of three main components: graph-based ontology integration, machine-learning-based ontology schema extraction, and an ontology merger. By analyzing the instances of the linked data sets, this framework acquires ontological knowledge and constructs a high-quality integrated ontology, which is easily understandable and effective in knowledge acquisition from various data sets using simple SPARQL queries.\r\n", "recorded": "2013-05-28T15:30:00", "title": "Instance-based ontological knowledge acquisition"}, {"url": "rease_noy_oma", "desc": "This is a one-hour video recording of the presentation of Natasha Noy at the KnowledgeWeb summer school 2005. It comprises either the video synchronized with the slides (but requires Quicktime, hence Windows or MacOS, otherwise the slides have to be switched manually). It provide a high-level overview on ontology mapping while the presentation of Steffen Staab provides more details and example systems.\r\n\r\nTable of Contents: \r\n\r\nOntology Mapping and Alignment\r\nLots of Overlapping Ontologies on the Semantic Web\r\nExample Definitions of School\r\nCreating Correspondences Between Ontologies\r\nSemantic Integration Tasks\r\nReasons for Mismatches\r\nTypes of Mismatches\r\nLanguage-level Mismatches\r\nOntology-level Mismatches\r\nOntology-level Mismatches: Examples\r\nSome of the Differences\r\nCategories of Mappings\r\nMapping Discovery: Information Sources\r\nUsing a Common Reference Ontology\r\nSolve the problem before it arises\r\nUsing reference ontologies: Problems\r\nUsing Lexical Information\r\nUsing Ontology Structure\r\nUsing External Sources\r\nUser Input\r\nUsing Prior Matches\r\nMapping Composition\r\nUsing Corpus of Matches\r\nMapping Discovery: Information Sources\r\nMapping Methods\r\nRule-Based and Graph-Analysis Methods\r\nGraph-based Methods\r\nAnchorPrompt: Analyzing Graph Structure\r\nMachine Learning Approaches\r\nProbabilistic Approaches\r\nReasoning and Theorem Proving\r\nUsing Mappings\r\nData Transformation\r\nQuery Answering\r\nGeneration of Ontology Extensions\r\nChallenges/Issues", "recorded": "2006-12-06T00:00:00", "title": "Ontology Mapping and Alignment"}, {"url": "planetdata_training_curriculum_semantic_technology", "desc": "The Semantic Technology curriculum has been created following the research done by STI International and\nSTI Innsbruck for the Austrian national project SARID (Service Austria: Research and Industry\nDissemination).\n\n == 1. Semantic Web Foundations\n\n * a. A Short History of Knowledge Systems\n * b. Birth of the Semantic Web\n * c. Semantic Applications\n * d. Core Concepts\n * e. RDF/S\n * f. OWL\n * g. Rules\n * h. SPARQL\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course%201%20Motivation%20for%20the%20paradig.pdf|Semantic Web Foundations - course]]\n\n||[[:eswc2011_hendler_work]]||[[:iswc2011_van_harmelen_universal]]||[[:eswc2012_welty_watson/]]||[[:mitworld_lee_sw/]]||[[:iswc06_lee_itbl/]]||\n ----\n ----\n\n == 2. Ontologies and the Semantic Web\n\n * a. Ontologies: a brief history\n * b. Ontology development process\n * c. Hands-on: use an example and create a requirements document\n * d. Knowledge elicitation\n * e. Hands-on: formulate competency questions, carry out interviews, and make first draft of ontology\n * f. Ontology creation (tools)\n * g. Ontology design\n * h. Hands-on: create ontology in the chosen editor\n\n||[[:eswc2012_franconi_ontologies_databases/]]||[[:eswc2012_simperl_ontologies/]]||[[:sssc2011_simperl_ontology//]]||[[:eswc2012_van_grondelle_complexity_business/]]||[[:iswc06_parsia_uofw/]]||\n ----\n ----\n\n == 3. Application Development\n\n * a. Semantic Web Application Framework\n * b. Development frameworks\n * c. Development methodologies\n * d. Creating the Semantic Web\n * e. Storing the Semantic Web\n * f. Creating Semantic Web clients\n * g. Querying the Semantic Web\n * h. An application example, e.g. a semantic web portal\n ----\n ----\n\n == 4. KR and Reasoning on the Semantic Web\n\n * a. Core concepts in reasoning and logic\n * b. Description Logic-based Knowledge Representation\n * c. RDFS and Taxonomic reasoning\n * d. OWL semantics\n * e. Hands on session: seeing inferences using an ontology editor and a reasoner\n * f. Reasoners for the Semantic Web\n * g. Logic Programming\n * h. Semantic Web and Logic Programming\n ----\n ----\n\n == 5. Ontology Lifecycle\n\n * a. Ontology lifecycle\n * b. Collaboratively developing an ontology\n * c. Finding ontologies\n * d. Ontology modularisation\n * e. Re-using ontologies\n * f. Ontology evaluation\n * g. Ontology refinement\n * h. Ontology evolution and versioning\n ----\n ----\n\n == 6. Semantic Web Services\n\n * a. From Web Services to Semantic Web Services\n * b. Adding Semantics to existing services: SAWSDL\n * c. OWL-S\n * d. The WSM stack\n * e. Semantic Web Service application deployment\n * f. Hands-on: creating a WSMO service with WSMT\n * g. Hands-on: discovering and executing WSMO services with WSMX\n\n||[[:iswc08_feng_eswsi]]||[[:rease_domingue_sws]]||[[:rease_domingue_swsat]]||[[:iswc07_domingue_sws]]||\n ----\n ----\n\n == 7. Semantic Web Services in Depth\n\n * a. SWS matching\n * b. SWS mediation\n * c. SWS orchestration\n * d. SWS choreography\n * e. SWS co-ordination\n * f. Trust and agreement between services\n * g. Capturing business rules\n * h. Capturing business processes\n\n||[[:eswc2011_cabral_evaluatingtools]]||[[:/sws09_hench_soacs/]]||[[:sws09_norton_sexe/]]||[[:sws09_maue_wsigsw/]]||\n\n * back to [[http://videolectures.net/planetdata|PlanetData Open Training Infrastructure]]\n * back to [[http://videolectures.net/planetdata_training_curriculum/|PlanetData Training Curriculum]]", "recorded": "2013-11-24T17:30:35", "title": "Semantic Technology"}, {"url": "iswc2011_motta_navigating", "desc": "Observational studies in the literature have highlighted low levels of\r\nuser satisfaction in relation to the support for ontology visualization and\r\nexploration provided by current ontology engineering tools. These issues are\r\nparticularly problematic for non-expert users, who rely on effective tool support\r\nto abstract from representational details and to be able to make sense of the\r\ncontents and the structure of ontologies. To address these issues, we have\r\ndeveloped a novel solution for visualizing and navigating ontologies, KC-Viz,\r\nwhich exploits an empirically-validated ontology summarization method, both\r\nto provide concise views of large ontologies, and also to support a \u2018middle-out\u2019\r\nontology navigation approach, starting from the most information-rich nodes\r\n(key concepts). In this paper we present the main features of KC-Viz and also\r\ndiscuss the encouraging results derived from a preliminary empirical\r\nevaluation, which suggest that the use of KC-Viz provides performance\r\nadvantages to users tackling realistic browsing and visualization tasks.\r\nSupplementary data gathered through questionnaires also convey additional\r\ninteresting findings, including evidence that prior experience in ontology\r\nengineering affects not just objective performance in ontology engineering\r\ntasks but also subjective views on the usability of ontology engineering tools.", "recorded": "2011-10-27T11:00:00", "title": "A novel aproach to visualizing and navigation ontologies"}, {"url": "iswc07_troncy_dwfm", "desc": "Semantic descriptions of non-textual media available on the web can be used to facilitate retrieval and presentation of media assets and documents containing them. While technologies for multimedia semantic descriptions already exist, there is as yet no formal description of a high quality multimedia ontology that is compatible with existing (semantic) web technologies. We explain the complexity of the problem using an annotation scenario. We then derive a number of requirements for specifying a formal multimedia ontology before we present the developed ontology, COMM, and evaluate it with respect to our requirements. We provide an API for generating multimedia annotations that conform to COMM.", "recorded": "2007-11-14T16:00:00", "title": "COMM: Designing a Well-Founded Multimedia Ontology for the Web"}, {"url": "iswc2012_degbelo_sensor_web", "desc": "Quality is an important aspect of data discovery in the Semantic Sensor Web. This work extends current endeavors to make the Sensor Web more semantic by introducing an ontology design pattern which facilitates the modeling of aspects of spatial data quality. The implementation of a software program over two scenarios demonstrates the usefulness of the ontology design pattern for the Semantic Sensor Web. ", "recorded": "2012-11-12T12:00:53", "title": "An Ontology Design Pattern for Spatial Data Quality Characterization in the Semantic Sensor Web"}, {"url": "single_fortuna_ontology", "desc": "This thesis addresses the task of formalizing and implementing the process of semi-automatic ontology construction. We propose a theoretical framework for formalizing the ontology construction process. The process is described as a sequence of operators applied to the ontology. Several types of common operators are identified and each type is abstracted so it can be discovered by a combination of machine learning algorithms and user interactions. The proposed ontology learning framework is generic and can handle various domains. The requirement is, that domain data can be provided in a format supported by the learning algorithms.\\\\\r\nOperators defined as part of the ontology construction process are implemented using several machine learning algorithms. Clustering, active learning and large-scale classifications are used to learn operators for adding concepts and relations. A novel visualization approach for visualizing instances, concepts and ontologies is developed, using a combination of dimensionality reduction techniques. The ability to incorporate additional background data is implemented using a novel feature weighting schema, and the addition of new instances to the ontology is translated to a standard classification task.\\\\\r\nWe also developed a system, which implements the framework, together with the proposed machine learning algorithms. The system takes domain data on the input, and guides the user through the process of constructing the ontology for the given domain. The developed system was applied in several use-cases, where domain data was provided as a text corpus or a social network, to showcase the capabilities.\\\\\r\nThe system was also evaluated in two user studies, to evaluate the user interface and to compare developed ontologies against manually constructed ones. The results of the users studies show, that the system is user friendly enough to be used by domain experts. The users can construct ontologies that are comparable to manually constructed ontology and can do so in a shorter amount of time.", "recorded": "2011-10-12T13:00:00", "title": "Semi-Automatic Ontology Construction"}, {"url": "eswc2011_kozaki_exploration", "desc": "It is important that the ontology captures the essential conceptual structure of the target world as generally as possible. However, such ontologies are sometimes regarded as weak and shallow by domain experts because they often want to understand the target world from the domain-specific viewpoints in which they are interested. Therefore, it is highly desirable to have not only knowledge structuring from the general perspective but also from the domain-specific and multi-perspective so that concepts are structured for appropriate understanding from the multiple experts. On the basis of this observation, the authors propose a novel approach, called divergent exploration of an ontology, to bridge the gap between ontologies and domain experts. Based on the approach, we developed an ontology exploration tool which allows experts to explore an ontology and visualizes the result in a user-friendly form, i.e. a conceptual map, depending on the viewpoints that they specify. We evaluated the system through its application to an environmental domain and an experimental use by domain experts. As a result, we confirmed that the tool supports experts to obtain meaningful knowledge for them through the divergent exploration and it contributes to integrated understanding of the ontology and its target domain", "recorded": "2011-05-31T16:00:00", "title": "Understanding an Ontology through Divergent Exploration"}, {"url": "sssw05_studer_om", "desc": "", "recorded": "2005-07-07T09:00:00", "title": "Ontology Management"}, {"url": "reasecs_sure_stsw", "desc": "This tutorial briefly introduces Semantic Web & Ontologies, Ontology Engineering support by Learning (automatic ontology generation), and Mining the Semantic Web. It was produced in the context of the SEKT project and is provided on videolectures.net.", "recorded": "2007-02-13T00:00:00", "title": "A Short Tutorial on Semantic Web"}, {"url": "reasecs_novacek_oepa", "desc": "- introduction of the ontology evolution topic:\n  * gives a broader context\n  * presents the field in general\n  * briefly mentions theoretical issues (to be covered in another document in depth)\n  * describe the main existing practical approaches\n  * give an overview of the major implementations\n\n- presentation of a cutting-edge research in the field, originating in the Knowledge Web project:\n  * a specifically tailored ontology lifecycle scenario\n  * dynamic integration of learned ontologies\n  * industrial perspectives of the research\n\nDocuments:\n;[[Ontology_Evolution.pdf]]", "recorded": "2007-06-29T00:00:00", "title": "Ontology Evolution - Practical Approaches"}, {"url": "gbr07_alpcan_aeobeps", "desc": "This paper proposes a novel expert peering system for information exchange. Our objective is to develop a real-time search engine for an online community where users can query experts, who are simply other participating users knowledgeable in that area, for help on various topics.We consider a graph-based scheme consisting of an ontology tree where each node represents a (sub)topic. Consequently, the fields of expertise or profiles of the participating experts correspond to subtrees of this ontology. Since user queries can also be mapped to similar tree structures, assigning queries to relevant experts becomes a problem of graph matching. A serialization of the ontology tree allows us to use simple dot products on the ontology vector space effectively to address this problem. As a demonstrative example, we conduct extensive experiments with different parameterizations. We observe that our approach is efficient and yields promising results.", "recorded": "2007-06-12T15:30:00", "title": "An Efficient Ontology-Based Expert Peering System "}, {"url": "iswc2011_hollink_standards", "desc": "Ontology matching is a task that has attracted considerable attention in recent years. With very few exceptions, however, research in ontology matching has focused primarily on the development of monolingual matching algorithms. As more and more resources become available in more than one language, novel algorithms are required which are capable of matching ontologies which share more than one language, or ontologies which are multilingual but do not share any languages. In this paper, we discuss several approaches to learning a matching function between two ontologies using a small set of manually aligned concepts, and evaluate them on di\u000bfferent pairs of fi\fnancial accounting standards,\r\nshowing that multilingual information can indeed improve the matching quality, even in cross-lingual scenarios. In addition to this, as current research on ontology matching does not make a satisfactory distinction between multilingual and cross-lingual ontology matching, we provide precise defi\fnitions of these terms in relation to monolingual ontology matching, and quantify their e\u000beffcts on di\u000bfferent matching algorithms.", "recorded": "2011-10-27T15:05:00", "title": "Multilingual and Cross-lingual Ontology matching and its Application to Financial Accounting Standards"}, {"url": "eswc06_gangemi_moe", "desc": "", "recorded": "2006-06-13T00:00:00", "title": "Modeling Ontology Evaluation"}, {"url": "sep08_fortuna_oct", "desc": "", "recorded": "2008-09-12T13:00:00", "title": "Ontology construction from text"}, {"url": "sssc2011_simperl_ontology", "desc": "", "recorded": "2011-08-09T00:00:00", "title": "Ontology design and reasoning"}, {"url": "iswc2011_suchanek_watermarking", "desc": "In this paper, we study watermarking methods to prove the\r\nownership of an ontology. Di\u000bfferent from existing approaches, we propose to watermark not by altering existing statements, but by removing\r\nthem. Thereby, our approach does not introduce false statements into\r\nthe ontology. We show how ownership of ontologies can be established\r\nwith provably tight probability bounds, even if only parts of the ontology\r\nare being re-used. We fi\fnally demonstrate the viability of our approach\r\non real-world ontologies.", "recorded": "2011-10-26T11:00:00", "title": "Watermarking for ontologies"}, {"url": "iswc08_fridman_noy_ccbm", "desc": "Several ontology repositories provide access to the growing collection of ontologies on the Semantic Web. Some repositories collect ontologies automatically by crawling the Web; in other repositories, users submit ontologies themselves. In addition to providing search across multiple ontologies, the added value of ontology repositories lies in the metadata that they may contain. This metadata may include information provided by ontology authors, such as ontologies\u2019 scope and intended use; feedback provided by users such as their experiences in using the ontologies or reviews of the content; and mapping metadata that relates concepts from different ontologies. In this paper, we focus on the ontology-mapping metadata and on community-based method to collect ontology mappings. More specifically, we develop a model for representing mappings collected from the user community and the metadata associated with the mapping. We use the model to bring together more than 30,000 mappings from 7 sources. We also validate the model by extending BioPortal\u2013a repository of biomedical ontologies that we have developed\u2014to enable users to create single concept-to-concept mappings in its graphical user interface, to upload and download mappings created with other tools, to comment on the mappings and to discuss them, and to visualize the mappings and the corresponding metadata.", "recorded": "2008-10-29T11:30:00", "title": "Collecting Community-Based Mappings in an Ontology Repository"}, {"url": "eswc2015_pinkel_data_integration", "desc": "A major challenge in information management today is the\r\nintegration of huge amounts of data distributed across multiple data\r\nsources. A suggested approach to this problem is ontology-based data\r\nintegration where legacy data systems are integrated via a common ontology\r\nthat represents a unified global view over all data sources. However,\r\ndata is often not natively born using these ontologies. Instead, much data\r\nresides in legacy relational databases. Therefore, mappings that relate\r\nthe legacy relational data sources to the ontology need to be constructed.\r\nRecent techniques and systems that automatically construct such mappings\r\nhave been developed. The quality metrics of these systems are,\r\nhowever, often only based on self-designed benchmarks. This paper introduces\r\na new publicly available benchmarking suite called RODI, which\r\nis designed to cover a wide range of mapping challenges in Relationalto-\r\nOntology Data I ntegration scenarios. RODI provides a set of different\r\nrelational data sources and ontologies (representing a wide range of\r\nmapping challenges) as well as a scoring function with which the performance\r\nof relational-to-ontology mapping construction systems may be\r\nevaluated.", "recorded": "2015-06-03T16:30:00", "title": "RODI: A Benchmark for Automatic Mapping Generation in Relational-to-Ontology Data Integration"}, {"url": "icwsm08_syed_wodd", "desc": "", "recorded": "2008-04-01T15:45:00", "title": "Wikipedia as an Ontology for Describing Documents"}, {"url": "eswc06_zhdanova_cdom", "desc": "", "recorded": "2006-06-14T00:00:00", "title": "Community-Driven Ontology Matching"}, {"url": "sab04_grobelnik_tmol", "desc": "", "recorded": "2004-05-13T00:00:00", "title": "Text Mining for Ontology Learning"}, {"url": "eswc2011_garcia_castro_evaluatingtools", "desc": "", "recorded": "2011-05-29T11:00:00", "title": "Evaluating Ontology Engineering Tools"}, {"url": "training06_grobelnik_tmol", "desc": "", "recorded": "2004-01-21T12:00:00", "title": "Text Mining for Ontology Learning"}, {"url": "training06_studer_swom", "desc": "", "recorded": "2005-07-06T12:00:00", "title": "Semantic Web and Ontology Management"}, {"url": "eswc2011_meilicke_evaluatingtools", "desc": "", "recorded": "2011-05-29T11:00:00", "title": "Evaluating Ontology Matching Tools"}, {"url": "iesa08_dahlem_osm", "desc": "", "recorded": "2008-03-27T13:30:00", "title": "Ontology-driven Semantic Mapping"}, {"url": "iswc07_perez_oem", "desc": "Using the insights gained in a decade of research Asun will describe the main principles and phases underlying the construction of ontologies, including acquisition, conceptualization, evaluation and integration. By the end of this presentation attendees will have an overview of the main steps involved in creating an industrial strength ontology.", "recorded": "2007-11-11T11:00:00", "title": "Ontology Engineering Methodologies"}, {"url": "eswc2011_fu_mapping", "desc": "While ontologies are widely accepted internationally as knowledge management mechanism across disciplines, the ability to reason over knowledge bases regardless of the natural languages used in them has become a pressing issue in digital content management. To enable knowledge sharing and reuse, ontology mapping techniques must be able to work with otherwise isolated ontologies that are labelled in diverse natural languages. Machine translation techniques are often employed by cross-lingual ontology mapping approaches to turn a cross-lingual mapping problem into a monolingual mapping problem which can then be solved by state of the art monolingual ontology matching tools. However in the process of doing so, complications introduced by machine translation tools can compromise the performance of the subsequent monolingual matching techniques. In this paper, a novel approach to improve the quality of cross-lingual ontology mapping is presented and evaluated. The proposed approach adopts the pseudo feedback technique that is similar to the well understood relevance feedback mechanism used in the field of information retrieval. It is shown through the evaluation that the pseudo feedback feature can enhance the effectiveness of machine translation and monolingual matching techniques in a cross-lingual ontology mapping scenario.", "recorded": "2011-05-31T16:30:00", "title": "Using Pseudo Feedback to Improve Cross-Lingual Ontology Mapping"}, {"url": "reasecs_shvaiko_som", "desc": "We view Matching as one of the key operations for enabling the Semantic Web since it takes two schemas/ontologies, each consisting of a set of discrete entities (e.g., tables, XML elements, classes, properties, rules, predicates), as input and determines as output the relationships (e.g., equivalence, subsumption) holding between those entities. In this tutorial we introduce, via examples, the schema/ontology matching problem and its application domains. We provide a detailed discussion of the techniques used for schema/ontology matching with the help of a classification of matching approaches. We overview state of the art systems in light of the classification presented, indicating which part of the solution space they cover. Finally, we outline future research directions and new scientific challenges arising in schema/ontology matching.", "recorded": "2005-07-18T00:00:00", "title": "Schema and Ontology Matching"}, {"url": "iswc2011_ortmann_ontology", "desc": "Referential qualities are qualities of an entity taken with reference to another entity. For example the vulnerability of a coast to sea level rise. In contrast to most non-relational qualities which only depend\r\non their host, referential qualities require a referent additional to their host, i.e. a quality Q of an entity X taken with reference to another entity R. These qualities occur frequently in ecological systems, which make concepts from these systems challenging to model in formal ontology. In this paper, we discuss exemplary resilience, vulnerability and a\u000bffordance as qualities of an entity taken with reference to an external factor. We suggest an ontology design pattern for referential qualities. The design pattern is anchored in the foundational ontology DOLCE and evaluated using implementations for the notions affordance, resilience and vulnerability.", "recorded": "2011-10-26T11:00:33", "title": "An Ontology Design Pattern for Referential Qualities"}, {"url": "eswc08_pedrinaci_co", "desc": "", "recorded": "2008-06-04T12:40:00", "title": "A Core Ontology for Business Process Analysis"}, {"url": "iswc06_ma_oqad", "desc": "", "recorded": "2006-11-07T00:00:00", "title": "Research 6: Ontology Query Answering on Databases"}, {"url": "sws09_steinmetz_wsmo", "desc": "", "recorded": "2009-03-04T09:00:00", "title": "Web Service Modeling Ontology (WSMO)"}, {"url": "koml04_ehrig_swomt", "desc": "", "recorded": "2004-11-26T10:30:00", "title": "Semantic Web and Ontology Management Technology"}, {"url": "eswc06_ma_tcoob", "desc": "", "recorded": "2006-06-13T00:00:00", "title": "Towards a Complete OWL Ontology Benchmark"}, {"url": "eswc06_dimitrova_iobuk", "desc": "", "recorded": "2006-06-11T00:00:00", "title": "Interactive Ontology-based User Knovledge"}, {"url": "iswc06_wang_swol", "desc": "", "recorded": "2006-11-07T00:00:00", "title": "Research 4: A Survey of the Web Ontology Landscape"}, {"url": "semantic_serafini_ontology_mappings", "desc": "", "recorded": "2012-11-13T17:50:49", "title": "A Formal Semantics for Weighted Ontology Mappings"}, {"url": "training06_ehrig_swomt", "desc": "", "recorded": "2004-11-26T12:00:00", "title": "Semantic Web and Ontology Management Technology"}, {"url": "rease_euzenat_oma1", "desc": "This is a one-hour video recording of the presentation of J\u00e9r\u00f4me Euzenat at the KnowledgeWeb summer school 2007. It comprises only the video not synchronized with the slides \r\n\r\nTable of Contents: \r\n1) The ontology matching problem\r\n2) Classification\r\n3) Basic techniques\r\n4) Matching process\r\n5) Systems\r\n6) Other topics\r\n7) Discussion", "recorded": "2007-11-23T00:00:00", "title": "Ontology Matching and Alignment"}, {"url": "eswc08_damato_qao", "desc": "", "recorded": "2008-06-04T14:30:00", "title": "Query Answering and Ontology Population: an Inductive Approach"}, {"url": "porto05_pinto_dlceo", "desc": "", "recorded": "2005-03-01T12:00:00", "title": "Distributed Loosely - Controlled and Evolving Ontology Engineering"}, {"url": "reasecs_gandon_on2", "desc": "Introduction to ontologies and folksonomies.", "recorded": "2008-05-05T00:00:00", "title": "Ontology In A Nutshell (version 2)"}, {"url": "iswc06_mcdowell_odieo", "desc": "", "recorded": "2006-11-07T00:00:00", "title": "Research 5: Ontology-driven Information Extraction with OntoSyphon"}, {"url": "solomon_bradesko_ontology_learning", "desc": "", "recorded": "2012-09-19T12:00:00", "title": "Challenges in Ontology Learning with Focus on Crowd Sourcing"}, {"url": "eswc2014_ren_competency", "desc": "", "recorded": "2014-05-29T14:25:00", "title": "Towards Competency Question-driven Ontology Authoring"}, {"url": "sws09_siorpaes_onen", "desc": "", "recorded": "2009-03-03T09:00:00", "title": "DISEJBALNO NA ZELJO AVTORICE: Ontology Engineering"}, {"url": "koml04_grobelnik_olkds", "desc": "", "recorded": "2004-11-26T11:30:00", "title": "Ontology Learning - Knowledge Discovery and the Semantic Web"}, {"url": "iswc06_mocan_fmomc", "desc": "", "recorded": "2006-11-07T00:00:00", "title": "Research 3: Formal Model for Ontology Mapping Creation"}, {"url": "training06_grobelnik_olkds", "desc": "", "recorded": "2006-01-01T12:00:00", "title": "Ontology Learning - Knowledge Discovery and the Semantic Web"}, {"url": "eswc08_hollink_tv", "desc": "", "recorded": "2008-06-05T15:30:00", "title": "Two Variations on Ontology Alignment: Methodological Issues"}, {"url": "iiia06_paliouras_boemi", "desc": "", "recorded": "2006-07-07T00:00:00", "title": "Bootstrapping Ontology Evolution with Multimedia Information Extraction"}, {"url": "sssw05_buitelaar_hltsw", "desc": "In this talk I will present an overview of Human Language Technology\r\n (HLT) and its use in Semantic Web development. HLT is concerned with automatic linguistic processing towards the semantic analysis and extraction of information from textual data. In the context of the Semantic Web the use of HLT is in knowledge markup of web documents for ontology population and text mining for ontology evolution (extension and modification of ontology models). The talk will include examples of both as currently developed in the context of the SmartWeb project on \"Mobile Broadband Access to the Semantic Web\" - http://www.smartweb-projekt.de/", "recorded": "2005-06-30T11:00:00", "title": "Human Language technology for the Semantic Web"}, {"url": "iswc08_denaux_idea", "desc": "This demonstration presents ROO, a tool that facilitates domain experts' definition of ontologies in OWL by allowing them to author the ontology in a controlled natural language called Rabbit. ROO guides users through the ontology construction process by following a methodology geared towards domain experts\u2019 involvement in ontology authoring, and exploiting intelligent user interfaces techniques. An experimental study with ROO was conducted to examine the usability and usefulness of the tool, and the quality of the resultant ontologies. The findings of the study will be presented in a full paper at the ISWC08 research track.\r\n", "recorded": "2008-10-28T10:00:00", "title": "Involving Domain Experts in Authoring OWL Ontologies"}, {"url": "eswc2014_kontokostas_nlp", "desc": "", "recorded": "2014-05-27T15:45:00", "title": "NLP data cleansing based on Linguistic Ontology constraints"}, {"url": "koml04_mladenic_olkds2a", "desc": "", "recorded": "2004-11-26T14:30:00", "title": "Ontology Learning - Knowledge Discovery and the Semantic Web - Part 2"}, {"url": "eswc2014_dos_reis_patterns", "desc": "", "recorded": "2014-05-29T14:50:00", "title": "Identifying change patterns of concept attributes in ontology evolution"}, {"url": "iswc06_simperl_cemoe", "desc": "", "recorded": "2006-11-07T00:00:00", "title": "Research 4: ONTOCOM: A Cost Estimation Model for Ontology Engineering"}, {"url": "koml04_mladenic_olkds2", "desc": "", "recorded": "2004-11-26T14:00:00", "title": "Ontology Learning - Knowledge Discovery and the Semantic Web - Part 2"}, {"url": "eswc08_espinoza_onl", "desc": "", "recorded": "2008-06-04T12:30:00", "title": "Ontologies and Natural Language: Enriching an Ontology with Multilingual Information"}, {"url": "iswc2014_horridge_ontologies", "desc": "The Atomic Decomposition of an ontology is a succinct representation of the logic-based modules in that ontology. Ultimately, it reveals the modular structure of the ontology. Atomic Decompositions appear to be useful for both user and non-user facing services. For example, they can be used for ontology comprehension and to facilitate reasoner optimisation. In this article we investigate claims about the practicality of computing Atomic Decompositions for naturally occurring ontologies. We do this by performing a replication study using an off-the-shelf Atomic Decomposition algorithm implementation on three large test corpora of OWL ontologies. Our findings indicate that (a) previously published empirical studies in this area are repeatable and verifiable; (b) computing Atomic Decompositions in the vast majority of cases is practical in that it can be performed in less than 30 seconds in 90% of cases, even for ontologies containing hundreds of thousands of axioms; (c) there are occurrences of extremely large ontologies (<\u20091% in our test corpora) where the polynomial runtime behaviour of the Atomic Decomposition algorithm begins to bite and computations cannot be completed within 12-hours of CPU time; (d) the distribution of number of atoms in the Atomic Decomposition for an ontology appears to be similar for distinct corpora.", "recorded": "2014-10-23T12:05:00", "title": "A Study on the Atomic Decomposition of Ontologies"}, {"url": "sokt08_bruin_edsoa", "desc": "Following lecture is about extending datamining for SOA and workflows. For the introduction we are presented with summary of the last few days at SOKT workshop and explanation of some buzzwords like ontology, service-oriented architecture \u2013 SOA, service, (scientific) workflow and how they all fit together.  Talk continues with OWL (Web Ontology Language) that is an ontology based on XML that has a W3C recommended status, WSDL (Web Services Description Language) and Taverna as an example of front end workflow application. Presentation ends with hands-on demonstration of Taverna in few example cases.", "recorded": "2008-01-18T09:00:00", "title": "Extending Datamining for SOA and Workflows"}, {"url": "iswc07_gomez_odp", "desc": "Design patterns are widely-used software engineering abstractions which define guidelines for modeling common application scenarios. Ontology design patterns are the extension of software patterns for knowledge acquisition in the Semantic Web. In this work we present a design pattern for representing relevance depending on context in OWL ontologies, i.e. to assert which knowledge from the domain ought to be considered in a given scenario. Besides the formal semantics and the features of the pattern, we describe a reasoning procedure to extract relevant knowledge in the resulting ontology and a plug-in for Prot\u00b4eg\u00b4e which assists pattern use.", "recorded": "2007-11-14T16:00:00", "title": "An Ontology Design Pattern for Representing Relevance in OWL"}, {"url": "iswc07_besana_hscs", "desc": "In open and distributed environments ontology mapping provides interoperability between interacting actors. However, conventional mapping systems focus on acquiring static information, and on mapping whole ontologies, which is infeasible in open systems. This paper shows that the interactions themselves between the actors can be used to predict mappings, simplifying dynamic ontology mapping. The intuitive idea is that similar interactions follow similar conventions and patterns, which can be analysed. The computed model can be used to suggest the possible mappings for the exchanged messages in new interactions. The suggestions can be evaluate by any standard ontology matcher: if they are accurate, the matchers avoid evaluating mappings unrelated to the interaction.\nThe minimal requirement in order to use this system is that it is possible to describe and identify the interaction sequences: the OpenKnowledge project has produced an implementation that demonstrates this is possible in a fully peer-to-peer environment.", "recorded": "2007-11-14T16:00:00", "title": "How Service Choreography Statistics Reduce the Ontology Mapping Problem"}, {"url": "iswc07_ungrangsi_aca", "desc": "Automatic knowledge reuse for Semantic Web applications imposes several challenges on ontology search. Existing ontology retrieval systems merely return a lengthy list of relevant single ontologies, which may not completely cover the specified user requirements. Therefore, there arises an increasing demand for a tool or algorithm with a mechanism to check concept adequacy of existing ontologies with respect to a user query, and then recommend a single or combination of ontologies which can entirely fulfill the requirements. Thus, this paper develops an algorithm, namely combiSQORE to determine whether the available collection of ontologies is able to completely satisfy a submitted query and return a single or combinative ontology that guarantees query coverage. In addition, it ranks the returned answers based on their conceptual closeness and query coverage. The experimental results show that the proposed algorithm is simple, efficient and effective.", "recorded": "2007-11-15T11:00:00", "title": "combiSQORE: An Ontology Combination Algorithm "}, {"url": "eswc06_delahousse_uopas", "desc": "", "recorded": "2006-06-12T00:00:00", "title": "Use of Ontology for production of access systems on Legislation Jurisprudence and Comments"}, {"url": "iswc06_wache_irpto", "desc": "", "recorded": "2006-11-06T00:00:00", "title": "Workshop: Improving the recruitment process through ontology-based querying"}, {"url": "iswc06_meza_odaed", "desc": "", "recorded": "2006-11-07T00:00:00", "title": "Research 5: Ontology-Driven Automatic Entity Disambiguation in Unstructured Text"}, {"url": "semseach09_fernandez_utcc", "desc": "The construction of standard datasets and benchmarks to evaluate ontology-based search approaches and to compare then against baseline IR models is a major open problem in the semantic technologies\r\ncommunity. In this paper we propose a novel evaluation benchmark for ontology-based IR models based on an adaptation of the well-known Cranfield paradigm (Cleverdon, 1967) traditionally used by the IR community. The proposed benchmark comprises: 1) a text document collection, 2) a set of queries and their corresponding document relevance judgments and 3) a set of ontologies and Knowledge Bases covering the query topics. The document collection and the set of queries and judgments are taken from one of the most widely used datasets in the IR community,\r\nthe TREC Web track. As a use case example we apply the proposed benchmark to compare a real ontology-based search model (Fernandez, et al., 2008) against the best IR systems of TREC 9 and TREC 2001 competitions. A deep analysis of the strengths and weaknesses of this benchmark and a discussion of how it can be used to evaluate other ontology-based search systems is also included at the end of the paper.", "recorded": "2009-04-21T16:00:00", "title": "Using TREC for cross-comparison between classic IR and ontology-based search models at a Web scale"}, {"url": "www09_suchanek_sofie", "desc": "This paper presents SOFIE, a system that can extend an existing ontology by new facts. SOFIE provides a integrative framework, in which information extraction, word disambiguation and semantic reasoning all become part of one unifying model. SOFIE processes text or Web sources and finds meaningful patterns. It maps the words in the pattern to entities in the ontology. It hypothesizes on the meaning of the pattern, and checks the semantic plausibility of the hypothesis with the existing ontology. Then the new fact is added to the ontology, avoiding inconsistency with the existing facts. The logical model that connects existing facts, new hypotheses, extraction patterns, and consistency constraints is represented as a set of propositional clauses. We use an approximation algorithm for the Weighted MAX SAT problem to compute the most plausible subset of hypotheses. Thereby, the SOFIE framework integrates the paradigms of pattern matching, entity disambiguation, and ontological reasoning into one unified model, and enables the automated growth of large ontologies. Experiments, using the YAGO ontology as existing knowledge and various text and Web corpora as input sources, show that our method yields very good precision around 90 percent or higher. ", "recorded": "2009-04-24T15:30:00", "title": "SOFIE: Self-Organizing Flexible Information Extraction"}, {"url": "reasecs_norheim_kmpi", "desc": "This presentation was given as part of the industrial day at ESWC 2006.\n\nThe AKSIO project is developing a process-enabled knowledge management system to support\noperations of offshore oilfields. The system will provide timely and contextual knowledge for work processes. Experiences will be processed and annotated by experts and linked to various resources and specialist knowledge networks. AKSIO will allow discovery of experiences through the support of a domain ontology. Core functionality of the AKSIO system is provided by careful application of Semantic Web technology, including ontology-based annotation and contextual ontology driven retrieval of content.\n\n;Documents: [[Knowledge_Management_in_the_Petroleum_Industry.pdf]]", "recorded": "2006-12-18T00:00:00", "title": "Knowledge Management in the Petroleum Industry"}, {"url": "iswc08_wu_ipicro", "desc": "More and more ontologies have been published and used widely on the web. In order to make good use of an ontology, especially a new and complex ontology, we need methods to help understand it first. Identifying potentially important concepts and relations in an ontology is an intuitive but challenging method. In this paper, we first define four features for potentially important concepts and relation from the ontological structural point of view. Then a simple yet effective Concept-And-Relation-Ranking (CARRank) algorithm is proposed to simultaneously rank the importance of concepts and relations. Different from the traditional ranking methods, the importance of concepts and the weights of relations reinforce one another in CARRank in an iterative manner. Such an iterative process is proved to be convergent both in principle and by experiments. Our experimental results show that CARRank has a similar convergent speed as the PageRank-like algorithms, but a more reasonable ranking result. ", "recorded": "2008-10-28T11:00:00", "title": "Identfying Potentiallcy Important Conepts and Relations in an Ontology"}, {"url": "reasecs_gandon_on", "desc": "Short introduction to ontologies in knowledge management and semantic web", "recorded": "2004-10-15T00:00:00", "title": "Ontology in a Nutshell"}, {"url": "eswc08_lochman_osm", "desc": "", "recorded": "2008-06-04T12:00:00", "title": "An Ontology for Software Models and its Practical Implications for Semantic Web Reasoning"}, {"url": "reasecs_lanzenberger_oe", "desc": "Some OWL examples and hints for constructing ontologies manually.", "recorded": "2006-11-11T00:00:00", "title": "Ontology Engineering"}, {"url": "iswc06_nakatsuji_idbui", "desc": "", "recorded": "2006-11-07T00:00:00", "title": "Research 1: Innovation Detection based on User-Interest Ontology of Blog Community"}, {"url": "eswc06_castro_bsiri", "desc": "", "recorded": "2006-06-13T00:00:00", "title": "Benchmark Suites for Improving the RDF(S) Importers and Exporters of Ontology Development Tools"}, {"url": "mmdss07_fortuna_osd", "desc": "We address the problem of constructing light-weight ontology from social network data. As an example we use social network of a mid size research institution obtained based on e-mail communication. The main contribution is an architecture consisting from five major steps that enable transformation of the data from a given e-mail transactions recordings to an ontology estimating the structure of the organization. Once having a set of sparse vectors, we apply an approach to semi-automated ontology construction as implemented in the OntoGen tool. The experiments and illustrative evaluation show that our approach is useful and applicable in real life situations where the goal is to model social structures based on communication records.", "recorded": "2007-09-13T12:06:12", "title": "Ontogen Software Demo"}, {"url": "mmdss07_grobelnik_oml", "desc": "We address the problem of constructing light-weight ontology from social network data. As an example we use social network of a mid size research institution obtained based on e-mail communication. The main contribution is an architecture consisting from five major steps that enable transformation of the data from a given e-mail transactions recordings to an ontology estimating the structure of the organization. Once having a set of sparse vectors, we apply an approach to semi-automated ontology construction as implemented in the OntoGen tool. The experiments and illustrative evaluation show that our approach is useful and applicable in real life situations where the goal is to model social structures based on communication records.", "recorded": "2007-09-13T11:15:11", "title": "Ontologies and Machine Learning"}, {"url": "rease_gangemi_ove1", "desc": "This is a one-hour video recording of the presentation of Aldo Gangemi at the KnowledgeWeb summer school 2005. It comprises either the video synchronized with the slides (but requires Quicktime, hence Windows or MacOS, otherwise the slides have to be switched manually).\r\n\r\nTable of Contents: \r\nOntology Validation and Evaluation\r\nRecap on ontology engineering techniques\r\nMain needs\r\nOutline of the tutorial\r\nQuality - 1\r\nThe nature of ontologies\r\nWhat is an ontology - socio-cognitive cut\r\nOntologies? Resources to be reengineered?\r\nAn early model of ontology dimensions\r\nIn the real world\r\nA different perspective: the communication roles of ontologies\r\nOntologies as semiotic objects\r\nThe three realms of evaluation\r\nQuality assessment\r\nA formal characterization of quality assessment\r\nQuality - 2\r\nStructural evaluation - Dimensions, elements, measurement methods\r\nA formal characterization of quality assessment\r\nOntology (structural) measure definition\r\nTypes of structural measures (graph-based)\r\nTypes of structural measures (formal semantics)\r\nTypes of structural measures (reification)\r\nQuality - 3\r\nFunctional evaluation - Coverage, Precision and Accuracy\r\nGuarino\u2019s model\r\nPrecision and coverage\r\nOntologies by precision\r\nAccuracy and precision\r\nApplicability of functional measures\r\nIntended conceptualization as expertise\r\nAn example: the BWO\r\nA state of affairs that maps to M\r\nAnother state of affairs that maps to M\r\nQuality checking of BWO\r\nAnother state of affairs that maps to M\r\nQuality checking of BWO - (cont\u2019d)\r\nQualified expressions of intended conceptualization: some measurement methods for P/R\r\nAgreement assessment\r\nCompetency assessment\r\nThe Oracle HR schema in OWL\r\nA remodelling that tries to catch the intended conceptualization\r\nCompetency assessment\r\nTopic assessment\r\nModularity assessment\r\nFoundational visions vs. topic-based modules\r\nA toy example of stratification\r\nFoundational visions vs. topic-based modules\r\nA more complex library\r\nPractical stratification: Fishery Ontology Service\r\nMinimal case of alignment\r\nCurrent modules in the fishery ontology\r\nQuality - 4\r\nUsability evaluation - Recognition, Efficiency and Interfacing\r\nRecognition\r\nEconomic efficiency\r\nInterfacing\r\nQuality - 5\r\nPrinciples, parameters, and preferential ordering\r\nSome principles\r\nParameters and principles (examples)\r\nPreferential ordering\r\nAn example: patterns vs. cycles\r\nAn example of the pattern/cycle trade-off\r\nBack to the quality model\r\nSome references", "recorded": "2006-12-06T00:00:00", "title": "Ontology Validation and Evaluation"}, {"url": "iswc06_fukazawa_curot", "desc": "", "recorded": "2006-11-09T00:00:00", "title": "In-Use 4: Construction and Use of Role-ontology for Task-based Service Navigation System"}, {"url": "iswc06_dellschaft_hpgsb", "desc": "", "recorded": "2006-11-09T00:00:00", "title": "Research 16: On How to Perform a Gold Standard Based Evaluation of Ontology Learning"}, {"url": "eswc08_isaac_po", "desc": "", "recorded": "2008-06-05T15:00:00", "title": "Putting Ontology Alignment in Context: Usage Scenarios, Deployment and Evaluation in a Library Case"}, {"url": "solomon_corcho_sensor", "desc": "In this talk we will review different approaches used for the generation,\r\npublication and acesss to ontology-based data streams coming from sensor\r\nnetworks. We will briefly describe the work done on the characterisation\r\nof sensor-based data sources and observations in the context of the W3C\r\nSemantic Sensor Network Incubator Group, which has resulted in an ontology\r\nfor describing sensor networks. We will also analyse different\r\nalternatives that can be used for the generation of sensor data in RDF,\r\nincluding the identification of sensors and the transformation into the\r\nSensor Network Ontology model. We will finally describe how sensor data\r\nsources can be accessed by means of SPARQL-STR queries, and the query\r\nrewriting methods used in the query execution process.", "recorded": "2011-09-23T13:00:14", "title": "Ingredients for the \u000bSemantic Sensor Web"}, {"url": "eswc2015_mendel_gleason_linked_data", "desc": "Many large ontologies have been created which make use of OWL's expressiveness for specification. However, tools to ensure that instance data is in compliance with the schema are often not well integrated\r\nwith triple-stores and cannot detect certain classes of schema-instance inconsistency due to the assumptions of the OWL axioms. This can lead to lower quality, inconsistent data. We have developed a simple ontology consistency and instance checking service, SimpleConsist[8]. We also define a number of ontology design best practice constraints on OWL or RDFS schemas. Our implementation allows the user to specify which constraints should be applied to schema and instance data.", "recorded": "2015-06-01T10:40:00", "title": "Ontology Consistency and Instance Checking for Real World Linked Data "}, {"url": "iswc2014_santarelli_ontologies", "desc": "We study the problem of approximating Description Logic (DL) ontologies speci\ufb01ed in a source language LS in terms of a less expressive target languageLT. This problem is getting very relevant in practice: e.g., approximation is often needed in ontology-based data access systems, which are able to deal with ontology languages of a limited expressiveness. We \ufb01rst provide a general, parametric, and semantically well-founded de\ufb01nition of maximal sound approximation of a DLontology. Then, we present an algorithm that is able to effectively compute two different notions of maximal sound approximation according to the above parametric semantics when the source ontology language is OWL 2 and the target ontology language is OWL 2 QL. Finally, we experiment the above algorithm by computing the two OWL 2 QL approximations of a large set of existing OWL 2 ontologies. The experimental results allow us both to evaluate the effectiveness of the proposed notions of approximation and to compare the two different notions of approximation in real cases.", "recorded": "2014-10-21T15:00:00", "title": "Effective computation of maximal sound approximations of Description Logic ontologies"}, {"url": "iswc2012_sarasua_crowdmap", "desc": "The last decade of research in ontology alignment has brought a variety of computational techniques to discover correspondences between ontologies. While the accuracy of automatic approaches has continuously improved, human contributions remain a key ingredient of the process: this input serves as a valuable source of domain knowledge that is used to train the algorithms and to validate and augment automatically computed alignments. In this paper, we introduce CROWDMAP, a model to acquire such human contributions via microtask crowdsourcing. For a given pair of ontologies, CROWDMAP translates the alignment problem into microtasks that address individual alignment questions, publishes the microtasks on an online labor market, and evaluates the quality of the results obtained from the crowd. We evaluated the current implementation of CROWDMAP in a series of experiments using ontologies and reference alignments from the Ontology Alignment Evaluation Initiative and the crowdsourcing platform CrowdFlower. The experiments clearly demonstrated that the overall approach is feasible, and can improve the accuracy of existing ontology alignment\r\nsolutions in a fast, scalable, and cost-effective manner.", "recorded": "2012-11-15T14:30:53", "title": "CROWDMAP: Crowdsourcing Ontology Alignment with Microtasks"}, {"url": "iswc2014_martin_recuerda_hypergraphs", "desc": "In this paper we define the notion of an axiom dependency hypergraph, which explicitly represents how axioms are included into a module by the algorithm for computing locality-based modules. A locality-based module of an ontology corresponds to a set of connected nodes in the hypergraph, and atoms of an ontology to strongly connected components. Collapsing the strongly connected components into single nodes yields a condensed hypergraph that comprises a representation of the atomic decomposition of the ontology. To speed up the condensation of the hypergraph, we first reduce its size by collapsing the strongly connected components of its graph fragment employing a linear time graph algorithm. This approach helps to significantly reduce the time needed for computing the atomic decomposition of an ontology. We provide an experimental evaluation for computing the atomic decomposition of large biomedical ontologies. We also demonstrate a significant improvement in the time needed to extract locality-based modules from an axiom dependency hypergraph and its condensed version.", "recorded": "2014-10-23T11:45:00", "title": "Fast Modularisation and Atomic Decomposition of Ontologies using Axiom Dependency Hypergraphs"}, {"url": "eswc2011_farazi_catalogue", "desc": "Geo-spatial applications need to provide powerful search capabilities to support users in their daily activities. However, discovery services are often limited by only syntactically matching user terminology to metadata describing geographical resources. We report our work on the implementation of a geographical catalogue, and corresponding semantic extension, for the spatial data infrastructure (SDI) of the Autonomous Province of Trento (PAT) in Italy. We focus in particular to the semantic extension which is based on the adoption of the S-Match semantic matching tool and on the use of a faceted ontology codifying geographical domain specific knowledge. We finally report our experience in the integration of the faceted ontology with the multi-lingual geo-spatial ontology GeoWordNet.", "recorded": "2011-06-01T15:30:00", "title": "A semantic geographical catalogue for semantic search"}, {"url": "iswc07_falconer_csf", "desc": "Ontology mapping is the key to data interoperability in the semantic\r web. This problem has received a lot of research attention, however, the research\r emphasis has been mostly devoted to automating the mapping process,\r even though the creation of mappings often involve the user. As industry interest\r in semantic web technologies grows and the number of widely adopted semantic\r web applications increases, we must begin to support the user. In this paper, we\r combine data gathered from background literature, theories of cognitive support\r and decision making, and an observational case study to propose a theoretical\r framework for cognitive support in ontology mapping tools. We also describe a\r tool called COGZ that is based on this framework.", "recorded": "2007-11-13T16:00:00", "title": " A cognitive support framework for ontology mapping"}, {"url": "reasecs_rector_iodpo", "desc": "Extensive OWL tutorial materials", "recorded": "2004-11-17T00:00:00", "title": "OWL Tutorial: Introduction to Ontology Development and Prot\u00e9g\u00e9-OWL"}, {"url": "iswc06_cross_ocati", "desc": "", "recorded": "2006-11-06T00:00:00", "title": "Workshop: OntoCAT: An Ontology Consumer Analysis Tool and Its Use on Product Services Categorization Standards"}, {"url": "reasecs_gandon_omasc", "desc": "This Ph.D. Thesis concerns multi-agents systems for the management of a corporate semantic web based on an ontology. It was carried out in the context of the European project CoMMA focusing on two application scenarios: support technology monitoring activities and assist the integration of a new employee to the organisation. Three aspects were essentially developed in this work:\nthe design of a multi-agents architecture supporting both scenarios, and the organisational top-down approach followed to identify the societies, the roles and the interactions of agents;\nthe construction of the ontology O'CoMMA and the structuring of a corporate memory exploiting semantic Web technologies;\nthe design and implementation of the sub-societies of agents dedicated to the management of the annotations and the ontology and of the protocols underlying these groups of agents, in particular techniques for distributing annotations and queries between the agents.\nKeywords: distributed artificial intelligence, knowledge management, corporate memory, ontology, knowledge representation, multi-agent systems, semantic web, information retrieval.\n\nDocuments:\n;[[Corporate_Semantic_Web.pdf]]", "recorded": "2004-10-18T00:00:00", "title": "Distributed Artificial Intelligence and Knowledge Management: ontologies and multi-agent systems for a corporate semantic web"}, {"url": "sikdd2011_mladenic_assertions", "desc": "We present an early version of a method for open-domain semantic assertion extraction from natural language texts. To combat the shortage of training data for the task, a two-stage pipeline is employed: we first perform semantic role labeling, then map the resulting frames onto predicate-form, ontology-aligned statements. We chose FrameNet and Cyc as the frame database and the ontology, respectively.", "recorded": "2011-10-10T09:40:00", "title": "High-coverage extraction of semantic assertions from text"}, {"url": "reasecs_kiryakov_ht", "desc": "The core of this tutorial covers HLT tools, followed by a number of example Semantic Web applications, built by non-specialist HLT researchers. It covers the use of (1) GATE tools for deriving web service ontologies from text; (2) Text2Onto, an HLT-based paradigm for ontology construction; and (3) research on automatic ontology population from text and massive semantic annotation.\r\n\r\n\r\nDocuments:\r\n;[[HLT_and_Knowledge_Acquisition.pdf]]\r\n;[[HLT_and_Knowledge_Acquisition.ppt]]", "recorded": "2005-06-16T00:00:00", "title": "HLT and Knowledge Acquisition for the Semantic Web: A Hands On Tutorial"}, {"url": "eswc2013_todorov_ontology_matching", "desc": "Due to the high heterogeneity of ontologies, a combination of many methods is necessary in order to discover correctly the semantic correspondences between their elements. An ontology matching tool can be seen as a collection of several matching components, each implementing a specific method dealing with a specific heterogeneity type (terminological, structural or semantic). In addition, a mapping selection module is introduced to filter out the most likely mapping candidates. This paper proposes an empirical study of the interaction between these components working together inside an ontology matching system. By the help of datasets from the Ontology Alignment Evaluation Initiative, we have carried out several experimental studies. In the first place, we have been interested in the impact of the mapping selection module on the performance of terminological\r\nand structural matchers revealing the advantage of using global methods vs. local ones. Further, we have carried an extensive study on the flaw of the performance of a structural matcher in the presence of noisy input coming from a terminological method. Finally, we have analyzed the behavior of a structural and a semantic component with respect to inputs taken from different terminological matchers.", "recorded": "2013-05-28T11:40:17", "title": "Opening the Black Box of Ontology Matching"}, {"url": "reasecs_harmelen_rb", "desc": "An introduction into RDF with a small discussion why the ontology language OWL is needed.\n\n\nDocuments:\n;[[RDF.pdf]]", "recorded": "2005-11-30T00:00:00", "title": "RDF Briefing"}, {"url": "iswc2011_jimenez_ruiz_ontology", "desc": "In this paper, we present LogMap a highly scalable ontology matching system with \"built-in\" reasoning and diagnosis capabilities. To the best of our knowledge, LogMap is the only matching system that\r\ncan deal with semantically rich ontologies containing tens (and even hundreds) of thousands of classes. In contrast to most existing tools, LogMap also implements algorithms for \"on the y\" unsatisfi\fability detection and repair. Our experiments with the ontologies NCI, FMA and SNOMEDCT con\frm that our system can efficiently match even the largest existing bio-medical ontologies. Furthermore, LogMap is able to produce a \"clean\" set of output mappings in many cases, in the sense that the ontology obtained by integrating LogMap's output mappings with the input ontologies is consistent and does not contain unsatisfiable\f classes.", "recorded": "2011-10-27T14:00:00", "title": "LogMap: Logic-based and Scalable Ontology Matching"}, {"url": "iswc2014_kontchakov_sparql_queries", "desc": "We present an extension of the ontology-based data access platform Ontop that supports answering SPARQL queries under the OWL 2 QL direct semantics entailment regime for data instances stored in relational databases. On the theoretical side, we show how any input SPARQL query, OWL 2 QL ontology and R2RML mappings can be rewritten to an equivalent SQL query solely over the data. On the practical side, we present initial experimental results demonstrating that by applying the Ontop technologies\u2014the tree-witness query rewriting, T-mappings compiling R2RML mappings with ontology hierarchies, and T-mapping optimisations using SQL expressivity and database integrity constraints\u2014the system produces scalable SQL queries.", "recorded": "2014-10-22T11:05:00", "title": "Answering SPARQL Queries over Databases under OWL 2 QL Entailment Regime"}, {"url": "iswc08_david_cod", "desc": "There are many reasons for measuring a distance between ontologies. In particular, it is useful to know quickly if two ontologies are close or remote before deciding to match them. To that extent, a distance between ontologies must be quickly computable. We present constraints applying to such measures\r\nand several possible ontology distances. Then we evaluate experimentally some of them in order to assess their accuracy and speed.", "recorded": "2008-10-28T16:00:00", "title": "Comparing ontology distances: preliminary results"}, {"url": "eswc2013_dragoni_multilingual_ontology", "desc": "Evolving complex artifacts as multilingual ontologies is a difficult activity demanding for the involvement of different roles and for guidelines to drive and coordinate them. We present the methodology and the underlying tool that have been used in the context of the Organic. Lingua project for the collaborative\r\nevolution of the multilingual Organic Agriculture ontology. Findings gathered from a quantitative and a qualitative evaluation of the experience are reported, revealing the usefulness of the methodology used in synergy with the tool.", "recorded": "2013-05-30T14:35:03", "title": "Guiding the Evolution of a Multilingual Ontology in a Concrete Setting"}, {"url": "reasecs_smedt_uopas", "desc": "This presentation was given as part of the industrial day at ESWC 2006.\r\n\r\nWolters Kluwer Belgium publishes about specialized areas related to legislation, jurisprudence and doctrine. The paper reports on an effort to transfer knowledge, scattered over a divers set of classification, coding and index generation systems, into a central thesaurus system, modeled and controlled by an ongtoloy.\r\n\r\nDocuments: \r\n;[[Ontology _Legislation_Jurisprudence_Comments.pdf.pdf]]", "recorded": "2006-12-18T00:00:00", "title": "Use of Ontology for production of access systems on Legislation, Jurisprudence and Comments"}, {"url": "sikdd2013_novalija_fashion_collection", "desc": "This paper presents an approach to developing a fashion domain ontology based on inputs from fashion experts and natural language processing (NLP) methods. While many of software solutions for fashion industry are concentrated on the design, manufacturing and trading applications, semantic technologies are just starting to interact with fashion domain. Domain ontologies allow capturing, sharing, analyzing and reusing the important information from the defined field.", "recorded": "2013-10-07T10:04:13", "title": "Applying NLP for building domain ontology: fashion collection"}, {"url": "iswc2014_sequeda_query_rewriting", "desc": "Given a source relational database, a target OWL ontology and a mapping from the source database to the target ontology, Ontology-Based Data Access (OBDA) concerns answering queries over the target ontology using these three components. This paper presents the development of UltrawrapOBDA, an OBDA system comprising bidirectional evaluation; that is, a hybridization of query rewriting and materialization. We observe that by compiling the ontological entailments as mappings, implementing the mappings as SQL views and materializing a subset of the views, the underlying SQL optimizer is able to reduce the execution time of a SPARQL query by rewriting the query in terms of the views specified by the mappings. To the best of our knowledge, this is the first OBDA system supporting ontologies with transitivity by using SQL recursion. Our contributions include: (1) an efficient algorithm to compile ontological entailments as mappings; (2) a proof that every SPARQL query can be rewritten into a SQL query in the context of mappings; (3) a cost model to determine which views to materialize to attain the fastest execution time; and (4) an empirical evaluation comparing with a state-of-the-art OBDA system, which validates the cost model and demonstrates favorable execution times.", "recorded": "2014-10-22T10:45:00", "title": "OBDA: Query Rewriting or Materialization? In Practice, Both!"}, {"url": "eswc2012_allocca_ontology", "desc": "Using semantic web search engines, such as Watson, Swoogle or Sindice, to find ontologies is a complex process as it is often an exploratory activity. It generally requires formulating multiple queries, browsing many pages of results and assessing the returned ontologies against each other to obtain a relevant and adequate subset of ontologies for the intended use. Our hypothesis is that part of the difficulty related to searching ontologies comes from the lack of structure in the search results, where ontologies that are implicitly related to each other are presented as disconnected and shown on different result pages. In a previous work, to overcome this situation, we devised a software framework, Kannel, that detects and makes explicit relationships between ontologies in large ontology repositories. In this paper, we present a study that compares the use of the Watson ontology search engine with the use of its extension, Watson+Kannel, that provides explicit information regarding the various types of relationships between the result ontologies. We evaluate the benefit of Watson+Kannel by measuring through various indicators how these explicit relationships between ontologies are used to improve the user\u2019s efficiency in ontology search, thus validating our hypothesis.", "recorded": "2012-05-31T11:00:00", "title": "Using Relationships Between Ontologies To Enhance Ontology Search"}, {"url": "iswc07_namgoong_obcnl", "desc": "In recent years, CNL (Controlled Natural Language) has received much attention with regard to ontology-based knowledge acquisition systems. CNLs, as subsets of natural languages, can be useful for both humans and computers by eliminating ambiguity of natural languages. Our previous work, OntoPath [10], proposed to edit natural language-like narratives that are structured in RDF (Resource Description Framework) triples, using a domain-specific ontology as their language constituents. However, our previous work and other systems employing CFG for grammar definition have difficulties in enlarging the expression capacity. A newly developed editor, which we propose in this paper, permits grammar definitions through CFG-LD (Context-Free Grammar with Lexical Dependency) that includes sequential and semantic structures of the grammars. With CFG describing the sequential structure of grammar, lexical dependencies between sentence elements can be designated in the definition system. Through the defined grammars, the implemented editor guides users\u2019 narratives in more familiar expressions with a domain-specific ontology and translates the content into RDF triples.", "recorded": "2007-11-14T14:00:00", "title": "Ontology-based Controlled Natural Language Editor Using CFG with Lexical Dependency"}, {"url": "iswc2011_howse_visualizing", "desc": "Concept diagrams were introduced for precisely specifying\r\nontologies in a manner more readily accessible to developers and other\r\nstakeholders than symbolic notations. In this paper, we present a case\r\nstudy on the use of concept diagrams in visually specifying the Semantic\r\nSensor Networks (SSN) ontology. The SSN ontology was originally developed by an Incubator Group of the W3C. In the ontology, a sensor is a\r\nphysical object that implements sensing and an observation is observed\r\nby a single sensor. These, and other, roles and concepts are captured visually, but precisely, by concept diagrams. We consider the lessons learnt\r\nfrom developing this visual model and show how to convert description\r\nlogic axioms into concept diagrams. We also demonstrate how to merge\r\nsimple concept diagram axioms into more complex axioms, whilst ensuring that diagrams remain relatively uncluttered.", "recorded": "2011-10-27T11:00:00", "title": "Visualizing ontologies: a case study"}, {"url": "eswc2013_ritze_interactive_ontology", "desc": "With a growing number of ontologies used in the semantic web, agents can fully make sense of different datasets only if correspondences between those ontologies are known. Ontology matching tools have been proposed to find such correspondences. While the current research focus is mainly on fully automatic matching tools, some approaches have been proposed that involve the user in the\r\nmatching process. However, there are currently no benchmarks and test methods to compare such tools. In this paper, we introduce a number of quality measures for interactive ontology matching tools, and we discuss means to automatically run benchmark tests for such tools. To demonstrate how those evaluation can be designed, we show examples on assessing the quality of interactive matching tools which involve the user in matcher selection and matcher parametrization.", "recorded": "2013-05-28T12:12:17", "title": "Towards Evaluating Interactive Ontology Matching Tools"}, {"url": "iswc2014_carral_boundaries", "desc": "We identify a class of Horn ontologies for which standard reasoning tasks such as instance checking and classi\ufb01cation are tractable. The class is general enough to include the OWL 2 EL, QL, and RL pro\ufb01les. Verifying whether a Horn ontology belongs to the class can be done in polynomial time. We show empirically that the class includes many real-world ontologies that are not included in any OWL 2 pro\ufb01le, and thus that polynomial time reasoning is possible for these ontologies.", "recorded": "2014-10-21T14:40:00", "title": "Pushing the Boundaries of Tractable Ontology Reasoning"}, {"url": "eswc09_losch_tftao", "desc": "Ontologies are used to formally describe domains of interest. As domains change over time, the ontologies have to be updated accordingly. We advocate the introduction of an Ontology Update Language that captures frequent domain changes and hence facilitates regular updates to be made in ontologies. We thoroughly discuss the general design choices for defining such a language and a corresponding update framework. Moreover, we propose a concrete language proposal based on SPARQL Update and provide a reference implementation of the framework.", "recorded": "2009-06-02T11:30:01", "title": "Tempus Fugit - Towards an Ontology Update Language"}, {"url": "iswc2014_sahar_butt_ontology_factorized", "desc": "Much of the recent work in Semantic Search is concerned with\r\naddressing the challenge of finding entities in the growing Web of Data. However, alongside this growth, there is a significant increase in the availability\r\nof ontologies that can be used to describe these entities. Whereas several\r\nmethods have been proposed in Semantic Search to rank entities based on\r\na keyword query, little work has been published on search and ranking of\r\nresources in ontologies. To the best of our knowledge, this work is the first to\r\npropose a benchmark suite for ontology search. The benchmark suite, named\r\nCBRBench3, includes a collection of ontologies that was retrieved by crawling\r\na seed set of ontology URIs derived from prefix.cc and a set of queries derived\r\nfrom a real query log from the Linked Open Vocabularies search engine.\r\nFurther, it includes the results for the ideal ranking of the concepts in the\r\nontology collection for the identified set of query terms which was established\r\nbased on the opinions of ten ontology engineering experts. We compared this ideal ranking with the top-k results retrieved by eight state-of-the-art ranking algorithms that we have implemented and calculated the precision at k, the mean average precision and the discounted cumulative gain to determine the best performing ranking model. Our study shows that content-based ranking models outperform graph-based ranking models for most queries on the task of ranking concepts in ontologies. However, as the performance of the ranking models on ontologies is still far inferior to the performance of state-of-the-art algorithms on the ranking of documents based on a keyword query, we put forward four recommendations that we believe can significantly improve the accuracy of these ranking models when searching for resources in ontologies.\r\n", "recorded": "2014-10-21T11:45:00", "title": "Ontology Search: An Empirical Evaluation "}, {"url": "reasecs_volkel_kmrot", "desc": "Ontology-based knowledge management (6 h),  Topic Maps (1.5) and Knowledge Retrieval (1.5).\r\n\r\nDocuments:\r\n;[[Knowledge_Management.zip]]", "recorded": "2004-10-11T00:00:00", "title": "Knowledge Management and Retrieval with Ontologies and Topic Maps"}, {"url": "reasecs_zhdanova_asotm", "desc": "ftw.'s Tutorial on Semantic Technologies, targeted at Telecommunications industry R&D.\r\nHeld on May 3, 2007 for ftw.'s member companies.", "recorded": "2008-03-26T00:00:00", "title": "Application of Semantic and Ontology Technologies to Mobile Services"}, {"url": "eswc2013_scheglmann_concurrent_transactions", "desc": "Collaborative editing on large-scale ontologies imposes serious demands on concurrent modifi\fcations and con ict resolution. In order to enable robust handling of concurrent modi\fcations, we propose a\r\nlocking-based approach that ensures independent transactions to simultaneously work on an ontology while blocking those transactions that might in uence other transactions. In the logical context of ontologies, dependence and independence of transactions do not only rely on the single data items that are modifi\fed, but also on the inferences drawn from these items. In order to address this issue, we utilize logical modularization of ontologies and lock the parts of the ontology that share inferential dependencies for an ongoing transaction. We compare and evaluate modularization and the naive approach of locking the whole ontology for each transaction and analyze the trade-o\u000b between the time needed for computing locks and the time gained by running transactions concurrently.", "recorded": "2013-05-30T11:08:03", "title": "Locking for Concurrent Transactions on Ontologies"}, {"url": "eswc2013_bischof_sparql_rewriting", "desc": "In addition to taxonomic knowledge about concepts and properties typically expressible in languages such as RDFS and OWL, implicit information in an RDF graph may be likewise determined by arithmetic equations. The main use case here is exploiting knowledge about functional dependencies among numerical attributes expressible by means of such equations. While some of this knowledge can be encoded in rule extensions to ontology languages, we provide an arguably more flexible framework that treats attribute equations as first class citizens in the ontology language. The combination of ontological reasoning and attribute equations is realized by extending query rewriting techniques already uccessfully applied for ontology languages such as (the DL-Lite-fragment of) RDFS or OWL, respectively. We deploy this technique for rewriting SPARQL queries and discuss the feasibility of alternative implementations, such as rule-based approaches.", "recorded": "2013-05-28T16:04:17", "title": "RDFS with Attribute Equations via SPARQL Rewriting"}, {"url": "iswc07_gangemi_cswl", "desc": "This talk introduces a framework to add a semantic web layer to\r legacy organizational information, and describes its application to the use case\r provided by the Italian National Research Council (CNR) intraweb. Building on\r a traditional web-based view of information from different legacy databases, we\r have performed a semantic porting of data into a knowledge base, dependent on\r an OWL domain ontology. We have enriched the knowledge base by means of\r text mining techniques, in order to discover on-topic relations. Several reasoning\r techniques have been applied, in order to infer relevant implicit relationships.\r Finally, the ontology and the knowledge base have been deployed on a semantic\r wiki by means of theWikiFactory tool, which allows users to browse the ontology\r and the knowledge base, to introduce new relations, to revise wrong assertions in\r a collaborative way, and to perform semantic queries. In our experiments, we have\r been able to easily implement several functionalities, such as expert finding, by\r simply formulating ad-hoc queries from either an ontology editor or the semantic\r wiki interface. The result is an intelligent and collaborative front end, which allow\r users to add information, fill gaps, or revise existing information on a semantic\r basis, while keeping the knowledge base automatically updated.", "recorded": "2007-11-14T11:00:00", "title": "A Collaborative Semantic Web Layer to Enhance Legacy Systems "}, {"url": "iswc2014_klinov_interences", "desc": "ELis a family of tractable Description Logics (DLs) that is the basis of the OWL 2 EL pro\ufb01le. Unlike for many expressive DLs, reasoning inELcan be performed by computing a deductively-closed set of logical consequences of some speci\ufb01c form. In some ontology-based applications, e.g., for ontology de- bugging, knowing the logical consequences of the ontology axioms is often not suf\ufb01cient. The user also needs to know from which axioms and how the consequences were derived. Although it is possible to record all inference steps during the application of rules, this is usually not done in practice to avoid the overheads. In this paper, we present a goal-directed method that can generate inferences for selectedconsequencesinthedeductiveclosurewithoutre-applyingallrulesfrom scratch.Weprovideanempiricalevaluationdemonstratingthatthemethodisfast and economical for large ELontologies. Although the main bene\ufb01ts are demonstrated for EL reasoning, the method can be potentially applied to many other procedures based on deductive closure computation using \ufb01xed sets of rules.", "recorded": "2014-10-21T15:40:00", "title": "Goal-Directed Tracing of Inferences in EL Ontologies"}, {"url": "eswc2013_carral_scheider_map_scaling", "desc": "The concepts of scale is at the core of cartographic abstraction and mapping. It de\fnes which geographic phenomena should be displayed, which type of geometry and map symbol to use, which measures can be taken, as well as the degree to which features need to be exaggerated or spatially displaced. In this work, we present an ontology design pattern for map scaling using the Web Ontology Language (OWL) within a particular extension of the OWL RL pro\fle. We explain how it can be used to describe scaling applications, to reason over scale levels, and geometric representations. We propose an axiomatization that allows us to impose meaningful constraints on the pattern, and, thus, to go beyond simple surface semantics. Interestingly, this includes several functional constraints currently not expressible in any of the OWL pro\fles. We show that for this specifi\fc scenario, the addition of such constraints does not increase the reasoning complexity which remains tractable.", "recorded": "2013-05-30T11:07:03", "title": "An Ontology Design Pattern for Cartographic Map Scaling"}, {"url": "sikdd08_novalija_eo", "desc": "Ontologies are commonly used for annotating textual data\nmainly based on human language technologies [1]. This\nresearch focuses on manual extensions of ontologies to\nsupport the annotation of business news. Experiments were\nconducted on a well known Cyc ontology and using Cyc\nannotator on two business news datasets. We show that the\nproposed extensions of ontology results in annotation with\nbetter coverage of terms that are relevant for the business\ndomain. \n\nThe results of identifying financial terms in\nbusiness news using the original Cyc ontology show the\naverage precision of 56% and recall of 41% in case of\nReuters news and the average precision of 69% and the\nrecall of 57% in case of Yahoo financial news. Using the\nproposed extension results with increased performance, the\naverage precision of 82% and average recall of 73% for\nYahoo financial news and average precision of 84% and\naverage recall of 63% for Reuters news.", "recorded": "2008-10-17T14:00:00", "title": "Extending Ontologies for  Annotating Business News"}, {"url": "iswc2014_walter_framework", "desc": "Many tasks in which a system needs to mediate between natural language expressions and elements of a vocabulary in an ontology or dataset require knowledge about how the elements of the vocabulary (i.e. classes, properties, and individuals) are expressed in natural language. In a multilingual setting, such knowledge is needed for each of the supported languages. In this paper we present M-ATOLL, a frame- work for automatically inducing ontology lexica in multiple languages on the basis of a multilingual corpus. The framework exploits a set of language-speci\ufb01c dependency patterns which are formalized as SPARQL queries and run over a parsed corpus. We have instantiated the system for two languages: German and English. We evaluate it in terms of precision, recall and F-measure for English and German by comparing an automatically induced lexicon to manually constructed ontology lexica for DBpedia. In particular, we investigate the contribution of each single dependency pattern and perform an analysis of the impact of di\ufb00erent parameters.", "recorded": "2014-10-21T11:00:00", "title": "M-ATOLL: A Framework for the lexicalization of ontologies in multiple languages "}, {"url": "reasecs_franconi_iswol", "desc": "Tutorial, jointly created with Grigoris Antoniou, at the REWERSE Summer School 2005.\r\n\r\nDocuments:\r\n;[[Ontology_Languages.pdf]]\r\n;[[Formalising_Ontologies.pdf]]\r\n;[[Using_Ontologies.pdf]]\r\n;[[Case_study_with_a_tiny_OWL.pdf]]\r\n;[[Introduction_to\u000b_Semantic_Web_Ontology_Languages.ppt]]", "recorded": "2005-07-28T00:00:00", "title": "Introduction to Semantic Web Ontology Languages"}, {"url": "reasecs_razmerita_obuma", "desc": "PhD defense, Liana Razmerita,\n3rd december 2003\n\nDocuments:\n;[[User_Modeling_Approach.pdf]]", "recorded": "2004-10-18T00:00:00", "title": "User Models and User Modeling for Knowledge Management Systems: An ontology based User Modeling Approach"}, {"url": "iswc07_schlobach_esib", "desc": "Instance-based ontology mapping is a promising family of solutions to a class of ontology alignment problems. It crucially depends on measuring the similarity between sets of annotated instances. In this paper we study how the choice of co-occurrence measures affects the performance of instance-based mapping. To this end, we have implemented a number of different statistical cooccurrence measures. We have prepared an extensive test case using vocabularies of thousands of terms, millions of instances, and hundreds of thousands of co-annotated items. We have obtained a human Gold Standard judgement for part of the mapping-space. We then study how the different co-occurrence measures and a number of algorithmic variations perform on our benchmark dataset as compared against the Gold Standard. Our systematic study shows excellent results of instance-based match- ing in general, where the more simple measures often outperform more sophisticated statistical co-occurrence measures.", "recorded": "2007-11-14T16:00:00", "title": "An empirical study of instance-based ontology matching"}, {"url": "rease_domingue_sws1", "desc": "This is a one-hour video recording of the presentation of John Domingue at the KnowledgeWeb summer school 2005. It comprises either the video synchronized with the slides (but requires Quicktime, hence Windows or MacOS, otherwise the slides have to be switched manually).\r\n\r\nTable of Contents:\r\n\r\nSemantic Web Services: The Web Service Modelling Ontology and IRS-III\r\nContents\r\nWhat's a Web Service?\r\nWeb Services Framework\r\nWhat's the big deal?\r\nProblems with Web Services Today\r\nLarry Says\r\n\"The problem is not in the plumbing - it's in the semantics\"\r\nSWS Vision\r\nSemantic Web Services (is)\r\nSWS Activities\r\nWeb Service Modelling Ontology (WSMO)\r\nWSMO is ..\r\nSDK-Cluster\r\nWSMO Working Groups\r\nWSMO Design Principles\r\nWSMO Top Level Notions\r\nNon-Functional Properties\r\nNon-Functional Properties List\r\nWSMO Ontologies\r\nOntology Usage & Principles\r\nOntology Specification\r\nWSMO Web Services\r\nCapability Specification\r\nWSMO Web Service Description\r\nChoreography and Orchestration\r\nChoreography Aspects\r\nOrchestration Aspects\r\nService Interface Description\r\nService Interface Description Model\r\nWSMO Goals\r\nGoal Specification\r\nWSMO Mediators\r\nMediation\r\nWSMO Mediators Overview\r\nMediator Structure\r\nOWL-S\r\nOWL-S Ontology\r\nOWL-S Upper Ontology\r\nWSMO OWL-S Comparison\r\nIRS-III:\r\nThe Internet Reasoning Service...\r\nDesign Principles\r\nFeatures of IRS-III\r\nIRS-III Framework\r\nIRS-III Architecture\r\nPublishing Platform Architecture\r\nIRS-III/WSMO differences\r\nIRS-III Demo\r\nSUMMARY\r\nSemantic Web Services\r\nHands-On Session with IRS-III\r\nEuropean Travel Scenario\r\nEuropean Travel Demo\r\nIRS-III Hands On Task\r\nTutorial Setup\r\nTravel Related Knowledge Models\r\nKey Classes, Relations, Instances\r\nGoals\r\nServices\r\nService constraints\r\nAvailable Functions\r\nExample: Multiply Goal\r\nExample: Multiply Mediator\r\nExample: Multiply Web Service\r\nExample: Publishing for Multiply\r\nExample: Invocation Multiply Goal\r\nIRS-III Visualizer\r\nSWS Creation & Usage Steps\r\nMultiple WS for goal\r\nDefining a Mediation Service\r\nGoal Based Invocation\r\nValid Relations\r\nEuropean Currency Assumption\r\nTips", "recorded": "2006-12-06T00:00:00", "title": "Semantic Web Services"}, {"url": "iswc2013_horridge_webprotege", "desc": "Ontology engineering is a task that is notorious for its difficulty. As the group that developed Prot\u00e9g\u00e9, the most widely used ontology editor, we are keenly aware of how difficult the users perceive this task to be. In this paper, we present the new version of WebProt\u00e9g\u00e9 that we designed with two main goals in mind: (1) create a tool that will be easy to use while still accounting for commonly used OWL constructs; (2) support collaboration and social interaction around distributed ontology editing as part of the core tool design. We designed this new version of the WebProt\u00e9g\u00e9 user interface empirically, by analysing the use of OWL constructs in a large corpus of publicly available ontologies. Since the beta release of this new WebProt\u00e9g\u00e9 interface in January 2013, our users from around the world have created and uploaded 519 ontologies on our server. In this paper, we describe the key features of the new tool and our empirical design approach. We evaluate language coverage in WebProt\u00e9g\u00e9 by assessing how well it covers the OWL constructs that are present in ontologies that users have uploaded to WebProt\u00e9g\u00e9. We evaluate the usability of WebProt\u00e9g\u00e9 through a usability survey. Our analysis validates our empirical design, suggests additional language constructors to explore, and demonstrates that an easy-to-use web-based tool that covers most of the frequently used OWL constructs is sufficient for many users to start editing their ontologies.", "recorded": "2013-10-23T12:40:01", "title": "Simplified OWL Ontology Editing: Is WebProt\u00e9g\u00e9 Enough?"}, {"url": "reasecs_kifer_rol", "desc": "A brief introduction to F-logic and its use for ontology specification. Slides of  a lecture given at the Reasoning Web summer school, July 2005, Malta.\n\nDocuments:\n;[[F-logic.pdf]]\n;[[F-logic.ppt]]", "recorded": "2005-06-06T00:00:00", "title": "Rules and Ontologies in F-logic"}, {"url": "reasecs_zaremba_wt", "desc": "The tutorial is intended to disseminate the Web Service Modeling Ontology WSMO to worldwide audiences interested in Semantic Web Services. IRS-III is the tool used in the hands-on session", "recorded": "2004-10-15T00:00:00", "title": "WSMO Tutorial"}, {"url": "iswc2011_scherp_strukt", "desc": "Expert-driven business process management is an established means for improving efficiency of organizational knowledge work. Implicit procedural knowledge in the organization is made explicit by de\ffining processes. This approach is not applicable to individual knowledge work due to its high complexity and variability. However, without explicitly described processes there is no analysis and efficient communication of best practices of individual knowledge work within the organization. In\r\naddition, the activities of the individual knowledge work cannot be synchronized with the activities in the organizational knowledge work. Solution to this problem is the semantic integration of individual knowledge work and organizational knowledge work by means of the patternbased core ontology strukt. The ontology allows for de\ffining and managing the dynamic tasks of individual knowledge work in a formal way and to synchronize them with organizational business processes. Using the strukt ontology, we have implemented a prototype application for knowledge workers and have evaluated it at the use case of an architectural office conducting construction projects.", "recorded": "2011-10-26T11:30:33", "title": "strukt - A Pattern System for Integrating Individual and Organizational Knowledge Work"}, {"url": "iswc08_bonino_domide", "desc": "Home automation has recently gained a new momentum thanks to the ever-increasing commercial availability of domotic components. In this context, researchers are working to provide interoperation mechanisms and to add intelligence on top of them. For supporting intelligent behaviors, house modeling is an essential requirement to understand current and future house states and to possibly drive more complex actions. In this paper we propose a new house modeling ontology designed to fit real world domotic system capabilities and to support interoperation between currently available and future solutions. Taking advantage of technologies developed in the context of the Semantic Web, the DogOnt ontology supports device/network independent description of houses, including both \u201ccontrollable\u201d and architectural elements. States and functionalities are automatically associated to the modeled elements through proper inheritance mechanisms and by means of properly defined SWRL auto-completion rules which ease the modeling process, while automatic device recognition is achieved through classification reasoning.", "recorded": "2008-10-28T16:00:00", "title": "DogOnt \u2013 Ontology Modeling for Intelligent Domotic Environments"}, {"url": "iswc2011_knorr_rules", "desc": "Answering (conjunctive) queries is an important reasoning\r\ntask in Description Logics (DL), hence also in highly expressive ontology\r\nlanguages, such as OWL. Extending such ontology languages with rules,\r\nsuch as those expressible in RIF-Core, and further with non-monotonic\r\nrules, integrating default negation as described in the RIF-FLD, yields\r\nan even more expressive language that allows for modeling defaults, exceptions,\r\nand integrity constraints.\r\nHere, we present a top-down procedure for querying knowledge bases\r\n(KB) that combine non-monotonic rules with an ontology in DL-LiteR\r\n- the DL underlying the OWL 2 profi\fle OWL 2 QL. This pro\ffile aims\r\nparticularly at answering queries in an efficient way for KB with large\r\nABoxes. Our procedure extends the query-answering facility to KB that\r\nalso include non-monotonic rules, while maintaining tractability of reasoning\r\n(w.r.t. data complexity). We show that the answers are sound and\r\ncomplete w.r.t. the well-founded MKNF model for hybrid MKNF KB K.", "recorded": "2011-10-26T11:00:00", "title": "Querying OWL 2 QL and non-monotonic rules"}, {"url": "eswc06_budva", "desc": "Topics of interest to the conference include (but are not restricted to):\r\n Ontology Management (e.g. creation, evolution, evaluation)\r\n Ontology Alignment (e.g. mapping, matching, merging, mediation and reconciliation)\r\n Ontology Learning and Metadata Generation (including e.g. HLT and ML approaches)\r\n Multimedia and Semantic Web\r\n Semantic Annotation of Data\r\n Semantic Web Trust, Privacy, Security and Intellectual Property Rights\r\n Semantic Web Rules and Query Languages\r\n Reasoning on the Web (e.g. scalability, fuzziness, distribution)\r\n Searching, Querying, Visualizing, Navigating and Browsing the Semantic Web\r\n Personalization and User Modelling\r\n User Interfaces and Semantic Web\r\n Semantic Grid and Middleware\r\n Semantic Web Services (e.g. description, discovery, invocation, composition)\r\n Semantic Web-based Knowledge Management (e.g. Semantic Desktop, Knowledge Portals)\r\n Semantic Web for e-Business, e-Culture, e-Government, e-Health, e-Learning, e-Science\r\n Database Technologies for the Semantic Web\r\n Data Semantics and Web Semantics\r\n Semantic Interoperability\r\n Semantic Web Mining.", "recorded": "2006-06-12T00:00:00", "title": "3rd Annual European Semantic Web Conference (ESWC), Budva 2006"}, {"url": "iswc07_hasse_plugins", "desc": "The NeOn toolkit is an extensible Ontology Engineering Environment. It is part of the reference implementation of the NeOn architecture. It contains plugins for ontology management and visualization. The core features include:\r \r * Basic Editing: Editing Schemasplash.jpg\r * Visualization/Browsing\r * Import/Export: F-Logic, (subsets of) RDF(S) and OWL\r \r A number of commercial plugins extend the toolkit by various functionalities, including:\r \r * Rule Support: Graphical/Textual editing, debugging\r * Mediation: Graphical Mapping Editor, life-interpretation of mappings\r * Database Integration: Database schema import, database-access\r * Queries: Query-Editor and persistent queries", "recorded": "2007-11-13T00:17:45", "title": "Expected plugins for the new version of NeOn toolkit"}, {"url": "rease_bechhofer_olsw", "desc": "This is a one-hour video recording of the presentation of Sean Bechhofer at the KnowledgeWeb summer school 2005. It comprises either the video synchronized with the slides (but requires Quicktime, hence Windows or MacOS, otherwise the slides have to be switched manually).\r\n\r\nTable of Contents:\r\n\r\nOWL: An Ontology Language for the Web\r\nTutorial Topics\r\nThe Semantic Web Vision\r\nWhat is the Problem?\r\nA Semantic Web - First Steps\r\nTechnologies for the Semantic Web\r\nObject Oriented Models\r\nStructure of an Ontology\r\nOntology Languages\r\nWhy Semantics?\r\nFormal Languages\r\nRDF\r\nThe RDF Data Model\r\nLinking Statements\r\nRDF Syntax\r\nRDF(S): RDF Schema\r\nRDF(S) Examples\r\nRDF/RDF(S) \"Liberality\"\r\nRDF/RDF(S) Semantics\r\nProblems with RDF(S)\r\nSolution\r\nThe OWL Family Tree\r\nA Brief History of OWL\r\nAside: Description Logics\r\nA Brief History of DLs\r\nDL Semantics\r\nOWL Layering\r\nOWL Full\r\nOWL DL\r\nOWL Lite\r\nOWL Syntaxes\r\nOWL Class Constructors\r\nOWL Axioms\r\nOWL Individual Axioms\r\nOWL Property Axioms\r\nSemantics\r\nOWL Property Axioms\r\nSemantics\r\nReasoning\r\nInstance Reasoning\r\nWhy Reasoning?\r\nExample\r\nNecessary and Sufficient Conditions\r\nExample\r\nCommon Misconceptions\r\nDisjointness\r\nDomain and Range\r\nAnd/Or and Quantification\r\nClosed and Open Worlds\r\nExtensions\r\nExtensions: SWRL\r\nRules: SWRL\r\nRules: Reasoning with SWRL\r\nExtensions: Complex Role Axioms\r\nExtensions: Query and Retrieval\r\nExtensions: Query Languages\r\nExtensions: Datatyping\r\nExtensions: Modularity\r\nTools\r\nSummary", "recorded": "2005-12-01T00:00:00", "title": "OWL: An Ontology Language for the Semantic Web"}, {"url": "rease_domingue_wsmoi", "desc": "This is a one-hour video recording of the presentation of John Domingue at the KnowledgeWeb summer school 2006. It comprises either the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nSemantic Web Services: The Web Service Modelling Ontology and IRS-III\r\nContents\r\nWhat's a Web Service?\r\nWeb Services Framework\r\nComputing On Demand\r\nProblems with Web Services Today\r\nSWS Vision\r\nSemantic Web Services (is)\r\nSWS Broker\r\nSWS Activities (1/2)\r\nSWS Activities (2/2)\r\nWeb Service Modelling Ontology  (WSMO)\r\nWSMO is ..\r\nWSMO Working Groups\r\nWSMO Design Principles\r\nWSMO Top Level Notions\r\nNon-Functional Properties\r\nNon-Functional Properties List\r\nWSMO Ontologies\r\nOntology Usage & Principles\r\nOntology Specification\r\nWSMO Web Services\r\nCapability Specification\r\nWSMO Web Service Description\r\nOrchestration Definition\r\nRuntime Orchestration\r\nService Interface Description\r\nService Interface Description Model\r\nService Interface Example\r\nWSMO Goals\r\nGoals\r\nGoal Specification\r\nWSMO Mediators\r\nMediation\r\nWSMO Mediators Overview\r\nMediator Structure\r\nOO Mediator - Example\r\nGG Mediators\r\nWG & WW Mediators\r\nIRS-III:\r\nThe Internet Reasoning Service is an infrastructure for publishing, locating, executing and composin\r\nFeatures of IRS-III\r\nIRS-III Framework\r\nIRS-III/WSMO differences\r\nIRS-III Demo\r\nSUMMARY\r\nReferences WSMO\r\nReferences IRS-III\r\nSemantic Web Services  Hands-On Session  with IRS-III and WSMO Studio\r\nEuropean Travel Scenario\r\nEuropean Travel Demo\r\nGoal Description\r\nGoal Description in Tutorial\r\nWeb Service Description\r\nWeb Service Description in Tutorial\r\nIRS-III Hands On Task\r\nTutorial Setup\r\nTravel Related Knowledge Models\r\nKey Classes, Relations, Instances\r\nGoals\r\nServices\r\nService constraints\r\nAvailable Functions", "recorded": "2007-02-14T00:00:00", "title": "Semantic Web Services: Web Service Modelling Ontology and IRS-III"}, {"url": "iswc2011_stoilos_reasoners", "desc": "The need for scalable query answering often forces Semantic\r\nWeb applications to use incomplete OWL 2 reasoners, which in some\r\ncases fail to derive all answers to a query. This is clearly undesirable,\r\nand in some applications may even be unacceptable. To address this\r\nproblem, we investigate the problem of \"repairing\" an ontology T |that\r\nis, computing an ontology R such that a reasoner that is incomplete for\r\nT becomes complete when used with T [R. We identify conditions on T\r\nand the reasoner that make this possible, present a practical algorithm\r\nfor computing R, and present a preliminary evaluation which shows that,\r\nin some realistic cases, repairs are feasible to compute, reasonable in size,\r\nand do not signifi\fcantly aff\u000bect reasoner performance.", "recorded": "2011-10-25T11:00:00", "title": "Repairing ontologies for incomplete reasoners"}, {"url": "soks2010_teymourian_sodsr", "desc": "Principles from nature-inspired selforganization can help to attack the massive scalability challenges in future internet infrastructures. We researched into ant-like mechanisms for clustering semantic information. We outline algorithms to store related information within clusters to facilitate efficient and scalable retrieval.\r\n\r\nAt the core are similarity measures that cannot consider global information such as a completly shared ontology. Mechanisms for syntax-based URI-similarity and the usage of a dynamic partial view on an ontology for path-length based similarity are described and evaluated. We give an outlook on how to consider application specific relations for clustering with a usecase in geo-information systems.", "recorded": "2010-04-29T15:00:00", "title": "Self-organization in Distributed Semantic Repositories"}, {"url": "w3cworkshop2012_buitelaar_semantic_web", "desc": "Although knowledge processing on the Semantic Web is inherently language-independent, human interaction with semantically structured and linked data will be text or speech based \u2013 in multiple languages. Semantic Web development is therefore increasingly concerned with issues in multilingual querying and rendering of web knowledge and linked data. The Monnet project on 'Multilingual Ontologies for Networked Knowledge' provides solutions for this by offering methods for lexicalising and translating knowledge structures, such as ontologies and linked data vocabularies. The talk will discuss challenges and solutions in ontology lexicalisation and translation (localisation) by way of several use cases that are under development in the context of the Monnet project.", "recorded": "2012-03-15T15:00:00", "title": "Ontology Lexicalisation and Localisation for the Multilingual Semantic Web"}, {"url": "iswc2014_cheatham_conference_benchmark", "desc": "The Ontology Alignment Evaluation Initiative is a set of benchmarks for evaluating the performance of ontology alignment systems. In this paper we re-examine the Conference track of the OAEI, with a focus on the degree of agreement between the reference alignments within this track and the opinion of experts. We propose a new version of this benchmark that more closely corresponds to expert opinion and confidence on the matches. The performance of top alignment systems is compared on both versions of the benchmark. Additionally, a general method for crowdsourcing the development of more benchmarks of this type using Amazon\u2019s Mechanical Turk is introduced and shown to be scalable, cost-effective and to agree well with expert opinion.", "recorded": "2014-10-23T11:25:00", "title": "Conference v2.0: An Uncertain Version of the OAEI Conference Benchmark"}, {"url": "reasecs_gandon_okr", "desc": "Introduction to: problems solved by ontologies in information retrieval, ontoogies, knowledge modelling, ontology life-cycle, knowledge representation formalisms, examples of ontologies, special case of SW, ontologies and multiagent systems.", "recorded": "2004-10-15T00:00:00", "title": "Ontologies and Knowledge representation"}, {"url": "rease_gangemi_ove", "desc": "This is a one-hour video recording of the presentation of Aldo Gangemi at the KnowledgeWeb summer school 2006. It comprises either the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nn.a.", "recorded": "2007-02-13T00:00:00", "title": "Ontology Validation and Evaluation"}, {"url": "rease_euzenat_oma", "desc": "This is a one-hour video recording of the presentation of Jerome Euzenat at the KnowledgeWeb summer school 2006. It comprises either the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nn.a.", "recorded": "2007-02-13T00:00:00", "title": "Ontology Matching and Alignment"}, {"url": "rease_bechhofer_olw", "desc": "This is a one-hour video recording of the presentation of Sean Bechhofer at the KnowledgeWeb summer school 2006. It comprises either the video synchronized with the slides (requires Flash) or the video alone. \r\n\r\nTable of Contents: \r\nOWL: An Ontology Language for the Web\r\nThe Semantic Web Vision\r\nWhat is the Problem?\r\nA Semantic Web - First Steps\r\nTechnologies for the Semantic Web\r\nBuilding a Semantic Web\r\nObject Oriented Models\r\nStructure of an Ontology\r\nOntology Languages\r\nWhy Semantics?\r\nFormal Languages\r\nRDF\r\nThe RDF Data Model\r\nLinking Statements\r\nRDF Syntax\r\nWhat does RDF give us?\r\nRDF(S): RDF Schema\r\nRDF(S) Examples\r\nRDF/RDF(S) 'Liberality'\r\nRDF/RDF(S) Semantics\r\nRDF(S) Inference\r\nWhat does RDF(S) give us?\r\nProblems with RDF(S)\r\nSolution\r\nThe OWL Family Tree\r\nA Brief History of OWL\r\nAside: Description Logics\r\nDL Architecture\r\nA Brief History of DLs\r\nDL Semantics\r\nOWL Layering\r\nOWL Full\r\nOWL DL\r\nOWL Lite\r\nOWL Syntaxes\r\nOWL Class Constructors\r\nOWL Axioms\r\nOWL Individual Axioms\r\nOWL Property Axioms\r\nSemantics\r\nReasoning\r\nInstance Reasoning\r\nWhy Reasoning?\r\nExample\r\nNecessary and Sufficient Conditions\r\nExample\r\nCommon Misconceptions\r\nDisjointness\r\nDomain and Range\r\nAnd/Or and Quantification\r\nClosed and Open Worlds\r\nExtensions\r\nRules\r\nExtensions: SWRL\r\nRules: SWRL\r\nExtensions: Query and Retrieval\r\nExtensions: Query Languages\r\nQuery Languages\r\nExtensions: Datatyping\r\nExtensions: Modularity\r\nExtensions: OWL 1.1\r\nTools\r\nSummary\r\nAcknowledgements\r\nThank you!", "recorded": "2007-02-13T00:00:00", "title": "OWL: an Ontology Language for the Web"}, {"url": "eswc2011_allocca_automatic", "desc": "When different versions of an ontology are published online, the links between them are often lost as the standard mechanisms (such as owl:versionInfo and owl:priorVersion) to expose these links are rarely used. This generates issues in scenarios where people or applications are required to make use of large scale, heterogenous ontology collections, implicitly containing multiple versions of ontologies. In this paper, we propose a method to detect automatically versioning links between ontologies which are available online through a Semantic Web search engine. Our approach is based on two main steps. The first step selects candidate pairs of ontologies by using versioning information expressed in their identifiers. In the second step, these candidate pairs are characterized through a set of features, including similarity measures, and classified by using Machine Learning Techniques, to distinguish the pairs that represent versions from the ones that do not. We discuss the features used, the methodology employed to train the classifiers and the precision obtained when applying this approach on the collection of ontologies of the Watson Semantic Web search engine.", "recorded": "2011-05-31T17:00:00", "title": "Automatic Identi\ufb01cation of Ontology Versions Using Machine Learning Techniques"}, {"url": "iswc2013_matentzoglu_owl_web", "desc": "Tool development for and empirical experimentation in OWL ontology engineering require a wide variety of suitable ontologies as input for testing and evaluation purposes and detailed characterisations of real ontologies. Empirical activities often resort to (somewhat arbitrarily) hand curated corpora available on the web, such as the NCBO BioPortal and the TONES Repository, or manually selected sets of well-known ontologies. Findings of surveys and results of benchmarking activities may be biased, even heavily, towards these datasets. Sampling from a large corpus of ontologies, on the other hand, may lead to more representative results. Current large scale repositories and web crawls are mostly uncurated and suffer from duplication, small and (for many purposes) uninteresting ontology files, and contain large numbers of ontology versions, variants, and facets, and therefore do not lend themselves to random sampling. In this paper, we survey ontologies as they exist on the web and describe the creation of a corpus of OWL DL ontologies using strategies such as web crawling, various forms of de-duplications and manual cleaning, which allows random sampling of ontologies for a variety of empirical applications.", "recorded": "2013-10-23T11:24:01", "title": "A snapshot of the OWL Web"}, {"url": "iswc2011_mikroyannidi_clustering", "desc": "We propose a novel application of clustering analysis to identify regularities in the usage of entities in axioms within an ontology. We argue that such regularities will be able to help to identify parts of\r\nthe schemas and guidelines upon which ontologies are often built, especially in the absence of explicit documentation. Such analysis can also isolate irregular entities, thus highlighting possible deviations from the initial design. The clusters we obtain can be fully described in terms of generalised axioms that o\u000ber a synthetic representation of the detected regularity. In this paper we discuss the results of the application of our analysis to di\u000bfferent ontologies and we discuss the potential advantages of incorporating it into future authoring tools", "recorded": "2011-10-27T11:35:00", "title": "Inspecting regularities in ontology design using clustering"}, {"url": "reasecs_henze_swlbb", "desc": "This second module of the Semantic Web Lecture describes the Semantic Web components RDF, RDF Schema, OWL and gives a brief introduction to ontology enigneering.\r\n\r\n\r\nDocuments:\r\n;[[Basic_building_blocks.pdf]]\r\n;[[Basic_building_blocks.zip]]", "recorded": "2004-09-23T00:00:00", "title": "Semantic Web Lecture - Basic building blocks"}, {"url": "interoperability_course_syllabus", "desc": "Links pointing to [[http://elearning.interop-vlab.eu/|INTEROP-VLab web courses and tutorials]]\n\n==[[http://elearning.interop-vlab.eu/course/view.php?id=9|ENTERPRISE MODELLING ]]\nIntroduction to Enterprise Modelling\n*Introduction\n*Modelling of enterprises\n*Development of Information Systems\n*ARIS \u2013 Phases and Views\n\nIn this tutorial, we give an introduction to Enterprise Modelling. Enterprise modeling expresses the symbolic illustration of information, which is supported by editing and documenting real-world structures of an enterprise and their meaning, so that they are comprehensible to the user. After describing the overall goals and essential terms for the modeling of enterprises, principles, methods and benefits of enterprise modeling are explained. In the next section the Development of (Business) Information Systems, one of the main goals of enterprise modeling, is explained and related to enterprise modeling. The last part introduces an example of an enterprise modeling methodology: The Architecture of Integrated Information Systems (ARIS), its phases and its views are described.\n ||[[left:iesa08_wings_csit/]]||\n\n----\n ==Unified Enterprise Modelling Language (UEML)\n*Preliminary information\n*What is UEML?\n*Why develop UEML?\n*UEML History\n*The UEML Project\n*The UEML Language\no State of the art. The need to relate Enterprise Modelling Languages\no Requirements of the Language\no Definition of the language\no How Enterprise Modelling with UEML can provide added value\no Example on Models interoperability\n*Conclusions. The future of UEML\n*Other information sources\n*References\n\nThis tutorial is an introduction of the Unified Enterprise Modelling Language, also called, UEML. First, we will define the language and will explain why UEML is crucial. Then, we will show how this new language was conceived and the basic principles of the UEML Project. Thirdly, we will explain the process of defining the language and will give some examples of its application. Finally, the conclusions will explain the future of this new language.\n----\n ==Business Process Modelling Introduction\n*Why is business process (BP) modelling needed?\n*What is a BP?\n*BP classification\n*Techniques and tools to model a BP\n*When to use what?\n*Main BP techniques\n*Examples of BP models\n\nA Business Process is the combination of a set of activities within an enterprise with a structure describing their logical order and dependence whose objective is to produce a desired result. Business Process modelling enables a common understanding and analysis of a business process. A process model can provide a comprehensive understanding of a process. An enterprise can be analysed and integrated through its business processes. Hence, the importance of correctly modelling its business processes.\nUsing the right model involves taking into account the purpose of the analysis and, knowledge of the available process modelling techniques and tools. The number of references on business modelling is huge, thus making it very time consuming to get an overview and understand many of the concepts and vocabulary involved. The primary concern of this tutorial is to make that job easier, i.e. review business process modelling literature and describe the main process modelling techniques. In addition, a framework for classifying business process-modelling techniques according to their purpose is presented.\n ||[[left:eswc08_feldcamp_sb/]]||\n\n----\n ==CIMOSA Computer Integrated Manufacturing Open System Architecture\n*CIMOSA Association\n*Enterprise Modelling - Reasons and Benefits\n*CIMOSA Modelling Framework, Modelling Language\n*CIMOSA Enterprise Modelling - Business Process Modelling\n*Standardisation in Enterprise Modelling\n*Conclusion\n\nThe tutorial presents a structured report about Computer Integrated Manufacturing Open System Architecture. First, it is explained what enterprise modelling is, the goals, reasons and the benefits achieved with enterprise modelling. The tutorial tries to answer the reasons of enterprise engineering and integration. CIMOSA Modelling Framework, Modelling Language is exposed, by means these sections: GERAM Framework, CIMOSA Modelling Framework and CIMOSA Modelling Language.\nThe enterprise modelling based on CIMOSA, focuses on function view, information view, resource view and organisation view.\nThe tutorial explains two Case studies: Business Re-Engineering at FIAT and Paper manufacturer KOEHLER. It makes a relevant standards overview, including ISO/CEN (15704, 19439, 19440, \u2026); ISO/IEC (15414, 62264) and OMG (MDA, BPML, UML, \u2026).\n----\n ==The GRAI Method - Global Modelling\n\n*Introduction\n*The GRAI Model\no Introduction\no Decision in the GRAI Model\no Functional Decomposition\no Systemic Decomposition\no Hierarchy\no The three Modelling Domains\n* The GRAI Grid\no Concepts of the GRAI Grid\no Grid Functions\no Links between Functional and Control Grids\no Multi-Grids Modelling (Co-ordination Grid)\no Possible Extensions of the Grid\n\nThis tutorial generally presents the GRAI method. From an operational point of view, are presented here the GRAI model as a consistent set of concepts in order to model production systems and the GRAI grid that uses the concepts of the GRAI model to propose a global model of the decisional system.\n----\n ==The GRAI Method - Detailed Modelling and Methodological Issues\n*Introduction\n*The GRAI nets\n*The structured approach\n*The rules of inconsistencies\n*The GRAI methodology\n\nThis tutorial follows the previous one. This tutorial presents the GRAI nets that aims at a detail model of the decisional system and the structured approach that organises (steps, actors, etc.) the study.\n----\n==General Standards Life Cycle\n*Introduction\n*Interoperability and Standardisation\n*Enterprise Integration and Engineering Standards\n*Enterprise Interoperability Standards\n*B2B Standards\n*INTEROP \u2013 Interoperability Standards\n*Conclusions\n*Credits\n\nThe tutorial presents interoperability in terms of it driving the need for standardization. It covers aspects such as the concepts of interoperability and standardization, enterprise integration and engineering standards, enterprise interoperability standards, B2B standards, and interoperability standards in INTEROP. It provides a useful insight into the complexity and importance of the standardization area in interoperability, important areas where harmonization is needed, as well as how standards affect organizations and their way of working.\n----\n ==Business Process Modelling Language (BPML)\n* BPML History\n* BPML Components\no Activities\no Process\no Contexts\no Properties\no Signals\n* Activities\n* Communication Patterns\no Synchronous Communication - Examples\no Asynchronous Communication\n* The Web Service Choreography Interface (WSCI)\n* Comparison\n* Business Process Management Notation\no What is BPMN?\no Why develop BPMN?\no BPMN Elements\n* Flow Objects\n* Connecting Objects\n* Swimlanes\n* Artifacts\n* Example - BPMN\n* Conclusions\n* References\n* Credit\n\nThis tutorial is a summary about Business Process Modelling Language, called BPML. There is a detailed explanation of what is BPML, its origins and its main components, focussing on activities. A comparison between others modelling languages is shown. Finally, it is depicted Business Process Modelling Notation as a graphical language that can be mapped onto languages such as BPML.\n----\n ==Use of the Event-driven Process Chain (EPC) to Model Business Processes\n* Introduction\no Introducing business processes\no Business process modeling\n* The event-driven process chain as a modeling method\no Development and intention of the EPC\no Advantages of the EPC\no Basic elements of the EPC\no Modeling principles of the EPC\no Enhanced event-driven process chain (eEPC)\no General modeling rules for EPCs\n* Practical examples\n* Guidelines for modeling EPCs\n* Conslusions and outlook\n\nThis tutorial describes the event-driven process chain (EPC) as a method to model business processes, which has found a high degree of acceptance and dissemination in practice because of its practical focus and intuitive comprehensibility. After introducing business processes, the tutorial continues with sections about business process modelling in general and various methods for business process modelling. The second section focuses on the method of the EPC, giving a short description of its development and intention, naming advantages of the EPC, introducing and explaining its basic elements, modelling principles, the enhancement of the EPC by elements of other views of the ARIS concept as well as general modelling rules for EPCs. As next, some examples are given to practically illustrate the method of the EPC and eEPC, followed by general guidelines for modelling EPCs.\n----\n----\n ==[[http://elearning.interop-vlab.eu/course/view.php?id=23|ONTOLOGIES]]\nIntroduction to Ontologies\n* What is the Semantic Web\n* Semantic Web and Ontologies\n* Knowledge and Ontologies dimensions\n* Ontology modelling\n* Conclusions\n\nThis tutorial explains that the Semantic Web is an extension of the current web in which information is given well-defined meaning, better enabling computers and people to work in cooperation. This concept is related to ontologies and ontology building is also characterized by some dimensions. For a deeper focus on ontology modelling, the tutorial explains onto (meta) model, onto modelling formalism, ontology content and onto system. Finally, conclusions summarize the main ideas.\n----\n ==Methodologies to build Ontologies\n* Ontology Building: Basic Concepts\n* Ontological Building Methodologies\n* Ontological Building Methodologies: UPON\n* Ontological Building: Tools\n* Conclusions\n* References\n\nThis tutorial starts with some basic elements of the Ontology Building (concepts, relationships and facets). In Ontological Building Methodologies, the tutorial shows the most known approaches to build an ontology. Then, UPON is described as a methodology for ontology building based on the Unified Software Development Process and supported by UML. Finally, there is a classification of different tools according to some criteria.\n----\n ==Ontology Languages\n* What is an Ontology?\n* What can we do with an ontology?\n* Ontology language\n\nThe tutorial presents an introduction to ontology representation formalisms, treating general concepts and then analyzing the main features of many existing ontology languages.\nAfter a general introduction to ontologies, that includes an analysis of what an ontology is, what are its intended uses and a how the degree of formality used in representation affects the way an ontology can be used, the tutorial gives a wide-range survey of the languages. The analysis is not limited to the most widely known languages proposed for semantic web applications, but covers various knowledge representation languages, programming languages, essentially graphical formalisms like Semantic Networks and UML, and languages initially designed as knowledge interchange formats. Languages are classified in families according to various dimensions, including their degree of formality, and their main features are reviewed.\nThe tutorial is intended for an advanced audience, that already has familiarity with the concept of ontology and basic notions of logics, and it is suitable for use in PhD courses.\n----\n ==Uses of Ontologies\n* What is the Semantic Web\n* Semantic Web and Ontologies\n* Knowledge and Ontologies dimensions\n* Focus on Semantic Annotation\n* Focus on Semantic Mismatches\n\nThe Semantic Web requires that web information is \u201cmachine understandable\u201d, so this tutorial explains the semantic annotation to achieve this goal. Semantic annotation expresses in a formal way the meaning associated to a web resource or to a part of it. Then there is an identification of semantic mismatches and an analysis of the different kinds of mismatches.\n ||[[left:eswc08_pedrinaci_co/]]||\n----\n ==What is the Semantic Web?\nThe general vision\n* What is the Semantic Web?\n* What the Semantic Web is not\n* What can be achieved by the Semantic Web?\n* Interoperability and the Semantic Web\n* Why do we need the Semantic Web?\n\nThis tutorial explains the Semantic Web, a Web where computers will \u201cunderstand\u201d the meaning of semantic data on a web page by following hyperlinks to definitions of key terms and rules for reasoning about them logically. Currently, the Web uses the computer as a device for rendering information for the human reader but neither for information processing nor computing. The tutorial shows how the Semantic Web is aiming on bringing back the computer as an information processing device\n ||[[left:iswc06_gruber_wswms/]]||\n----\n ==Semantic Web Technologies\n* What is the Semantic Web?\n* What is the Semantic Web good for?\n* What lies beneath the Semantic Web?\n* Unicode\n* URI: Uniform Resource Identifier\n* XML: eXtensible Markup Language\n* XML Schemas\n* Is XML enough for the Semantic Web\n* RDF: Resource Description Framework\n* RDF Schema\n* Ontologies\n* Logic and proofs\n* Logical languages for the Semantic Web\n* Trust and credibility\n* Conclusions\n\nThis tutorial is a brief introduction to the technologies beneath the Semantic Web: Unicode,URI (Uniform Resource Identifiers), XML (eXtensible Markup Language), XML Schemas, RDF (Resource Description Framework), RDF Schema, Ontologies and Logic. All these technologies will work together to achieve the Semantic Web goals.\n ||[[left:eswc08_lochman_osm//]]||\n----\n ==Ontology Tools\n* What is an ontology?\n* What is an ontology in Computer Science?\n* Key use of ontologies\n* Ontology based reasoning\n* Building ontologies\n* About ontology development\n* Ontology engineering vs. Object-Oriented modelling\n* Types of ontologies tools\n* An ontology tools survey on the Web\n* Tools for ontology engineering\n* Tools analysed here\n* Prot\u00e9g\u00e9\n* OilEd\n* Conclusions\n\nThis tutorial is an overview of the current ontology tools. After given a general explanation about what an ontology is and about its applications, the tutorial describes different kinds of ontology tools (editors & browswers, translators, merge and integration tools, etc.). Finally, it focuses on two tools: Prot\u00e9g\u00e9 and OilEd, giving many examples of how to use these tools.\n----\n----\n ==[[http://elearning.interop-vlab.eu/course/view.php?id=18|ARCHITECTURES & PLATFORMS]]\n ==Enterprise Architectures and Enterprise Modelling\nIntroduction\n* Basic terms\n* Examples of enterprise architectures\n* Introduction to ARIS\n* ARIS views on enterprises\n* Function view\n* Organization view\n* Data view\n* Output view\n* Control view\n* ARIS Phase Model\n* ARIS House of Business Engineering\n\nThe tutorial presents different enterprise architectures and describes methods and concepts to model enterprise. Examples of various ways to structure and model enterprises are given. It is shown how an enterprise can be divided into various layers to reduce model complexity. Additionally, a framework to transform the abstract models to IT-models is introduced. The Architecture of Integrated Information Systems (ARIS) including the ARIS views as a concept to model different aspects of an enterprise, the ARIS phase model as a concept to create the relation between industrial situation and IT as well as the ARIS house of business engineering (HOBE) as a framework for managing business processes will be explained in detail in this tutorial.\n----\n ==Introduction to Data Quality in Cooperative Information Systems\n* Introduction\n* Dimensions\n* References\n\nThis tutorial introduces to the problem of data quality in multi-organizational environments. The overlapping of data sources in such environments can be an opportunity to improve data quality, but it is also an issue if conflicting copies of the same data are stored.\n----\n ==Data Quality Models in Cooperative Information Systems\n* Models\no Use of models\no Extension of DB models\no Models for management information systems\n- Process models\n- Data models\no Cost models\n* References\n\nThe tutorial describes exitisting data-oriented models for data quality, like extensions of conceptual and logical models for data representation to include also quality. It also describes process-oriented models, useful for data quality improvement.\n----\n ==Methodologies for data quality in CISs and an Example of a Framework\n* Methodologies\no Types of Strategies\no Types of Methodologies\no General Overview of 4 Methodologies\no Relevant Steps in Methodologies\no Comparison of Methodologies\n* Frameworks and Services for CISs\no Data Quality Broker\no Rating Service\no Quality Notification Service\no Data Quality Factory\n* References\n\nThe tutorial it describes several existing methodologies for assessing and improving quality of data. The methodologies are described in terms of the steps composing them and a comparison framework is also illustrated.\n----\n ==The COMET Methodology - Business and Requirements Modelling\n* Part 1a: Methodology Overview\no Motivation\n- Why system development methodology?\no Software system development methodologies\no COMET\n- A medium-sized methodology for developing Web services in a Service-Oriented Architecture (SOA)\no References\n* Part 1b: Business Modelling\n* Part 1c: Requirements Modelling\n\nThis tutorial presents the COMET Web services modelling which provides guidelines for the design and implementation of Web services based on the COMET business, requirements and architecture models. The tutorial covers the following Web services technologies: XML (eXtensible Markup Language), XSD (XML Schema Definition), WSDL (Web Services Description Language), SOAP (Simple Object Access Protocol), UDDI (Universal Description, Discovery and Invocation) and BPEL (Business Process Execution Language).\n----\n----\n ==[[http://elearning.interop-vlab.eu/course/view.php?id=26|INTEROPERABILITY ]]\nEnterprise Modelling for Interoperability\n* Introduction: Concepts\n* Enterprise modelling supports interoperability\no Enterprise Architectures Aligning Processes with IT\no Business Process Models Integration\n- Unified Approach\n- Interoperability Aspects\n- UEML\n\nIn this tutorial, we are going to define a series of concepts, which will be followed by the explanation of the enterprise architectures aligning processes with IT and the business process models integration.\n----\n ==Ontology for Interoperability\n* Introduction to interoperability\n* Ontology-based solution\no Semantic mismatch analysis\no Semantic annotation\no Reconciliation\n* Three levels of interoperability\no Information interoperability\no Process Interoperability\no Service Interoperability\n* Ontology based architectures for interoperability\n\nIn this tutorial, we will give an overview of the way ontologies can be used to support the interoperability of enterprise software applications. We will therefore expose what the interoperability problem is.\n----\n ==Introduction to Architecture and Platforms for Enterprise system Interoperability\n* Introduction to Software Architecture\n* Architectural styles for interoperability\n* Existing platforms Special Issues:\n* Process Brokers & Integration\n* Design of Processes for Integration\n* Service Oriented Architecture\n\nIn this tutorial, we will introduce you to some of the underlying technical architecture in interoperable systems. First, we will define software architecture. Then, we will see different styles of interoperability architecture. These styles will be Process brokers and Service Oriented Architecture. You will also see some examples of existing platforms.\n----\n ==Ontology Interoperability\n* Ontology Interoperability Pitfalls\n* Solutions for Interoperability among ontologies\no Ontology merging\no Ontology alignment\no Ontology mapping\no Ontology transformation\n* Some solutions in the State of the Art\no Methods for ontology mapping/merging\no A brief overview of some existing systems\n- Mapping Frameworks/tools\n- Similarity reasoning approaches/ solutions\no Summary table of the collected material\n* Conclusions\n\nThe objective of this tutorial is to give an overview of the problem of Ontology Interoperability. We will therefore see what the common problems encountered are when comparing two or more ontologies describing the same domain, ontology pitfalls, then what the basic operations used to solve the differences among such ontologies are and will give some details about a number of State of the Art solutions, methods and tools.\n----\n ==Model Driven Architecture: General Overview\n* Problem\n* MDA Framework\n* MDA Development Life Cycle\n* MDA Benefits\n* Inside the MDA Framework\n* Model Transformation\n\nThis tutorial gives an overview on the Model Driven Architecture (MDA) proposed by the Object Management Group (OMG). It presents the general framework of MDA in terms of development life cycle and abstraction levels.After presenting the benefits of this approach a focus is performed on model transformations.", "recorded": "2009-02-13T10:11:05", "title": "Course Syllabus - Interoperability"}, {"url": "iswc2011_bohm_ontology", "desc": "As Linked Open Data originates from various sources, lever-\r\naging well-de\ffined ontologies aids integration. However, oftentimes the\r\nutilization of RDF vocabularies by data publishers di\u000bffers from the in-\r\ntended application envisioned by ontology engineers. Especially in large-\r\nscale datasets as presented in the Billion Triple Challenge a signi\fficant\r\ndivergence between vocabulary specification and usage patterns can be\r\nobserved. This may impede the goals of the Web of Data in terms of dis-\r\ncovering domain-specifi\fc information in the Semantic Web. In this work,\r\nwe identify common misusage patterns by employing frequency analysis\r\nand rule mining and propose re-engineering suggestions.", "recorded": "2011-10-26T15:05:00", "title": "RDF Ontology (Re-)Engineering through Large-scale Data Mining"}, {"url": "iswc08_hepp_oosniesd", "desc": "The documentation of Enterprise Research Planning (ERP) systems is usually (1) extremely large and (2) combines various views from the business and the technical implementation perspective. Also, a very specific vocabulary has evolved, in particular in the SAP domain (e.g. SAP Solution Maps or SAP software module names). This vocabulary is not clearly mapped to business management terminology and concepts. It is a well-known problem in practice that searching in SAP ERP documentation is difficult, because it requires in-depth knowledge of a large and proprietary terminology. We propose to use ontologies and automatic annotation of such large HTML software documentation in order to improve the usability and accessibility, namely of ERP help files. In order to achieve that, we have developed an ontology and prototype for SAP ERP 6.0. Our approach integrates concepts and lexical resources from (1) business management terminology, (2) SAP business terminology, (3) SAP system terminology, and (4) Wordnet synsets. We use standard GATE/KIM technology to annotate SAP help documentation with respective references to our ontology. Eventually, our approach consolidates the knowledge contained in the SAP help functionality at a conceptual level. This allows users to express their queries using a terminology they are familiar with, e.g. referring to general management terms. Despite a widely automated ontology construction process and a simplistic annotation strategy with minimal human intervention, we experienced convincing results. For an average query linked to an action and a topic, our technology returns more than 3 relevant resources, while a na\u00efve term-based search returns on average only about 0.2 relevant resources.", "recorded": "2008-10-28T14:00:00", "title": "OntoNaviERP: Ontology-supported Navigation in ERP Software Documentation"}, {"url": "rease_bechhofer_olsw1", "desc": "This is a one-hour video recording of the presentation of Sean Bechhofer at the KnowledgeWeb summer school 2007. It comprises the video synchronized with the slides (requires Flash) or the video alone (Flash format).\r\n\r\nTable of Contents: \r\nOntology Languages for the Semantic Web\r\nThe Semantic Web Vision\r\nWhat is the Problem?\r\nA Semantic Web ? First Steps\r\nTechnologies for the Semantic Web\r\nBuilding a Semantic Web\r\nLanguages\r\nObject Oriented Models\r\nStructure of an Ontology\r\nOntology Languages\r\nWhy Semantics?\r\nFormal Languages\r\nRDF\r\nThe RDF Data Model\r\nLinking Statements\r\nRDF Syntax\r\nWhat does RDF give us?\r\nRDF(S): RDF Schema\r\nRDF(S) Examples\r\nRDF/RDF(S) ?Liberality?\r\nRDF/RDF(S) Semantics\r\nRDF(S) Inference\r\nWhat does RDF(S) give us?\r\nProblems with RDF(S)\r\nSolution\r\nThe OWL Family Tree\r\nA Brief History of OWL\r\nAside: Description Logics\r\nA Brief History of DLs\r\nDL Semantics\r\nOWL Layering\r\nOWL Full\r\nOWL DL\r\nOWL Lite\r\nOWL Syntaxes\r\nOWL Class Constructors\r\nOWL Axioms\r\nOWL Individual Axioms\r\nOWL Property Axioms\r\nSemantics\r\nReasoning\r\nInstance Reasoning\r\nWhy Reasoning?\r\nExample\r\nNecessary and Sufficient Conditions\r\nExample\r\nCommon Misconceptions\r\nDisjointness\r\nDomain and Range\r\nAnd/Or and Quantification\r\nClosed and Open Worlds\r\nExtensions\r\nRules\r\nDifferent Semantics\r\nnull\r\nExtensions: OWL1.1\r\nExtensions: OWL 1.1\r\nOWL1.1: Role Axioms\r\nOWL1.1: Metamodelling\r\nOWL1.1: Fragments\r\nExtensions: Query and Retrieval\r\nQuery Languages\r\nSPARQL\r\nSPARQL for OWL\r\nLightweight Vocabularies\r\nConcept Schemes\r\nSKOS: Simple Knowledge Organisation System\r\nSKOS Example\r\nSKOS Use Cases\r\nTools\r\nSummary\r\nAcknowledgements\r\nThank you!", "recorded": "2007-11-23T00:00:00", "title": "Ontology Languages for the Semantic Web"}, {"url": "reasecs_giboin_keasw", "desc": "Complete course on knowledge engineering techniques and formalisms including:\n- ergonomics and scenario-based specifications;\n- ontology life cycles;\n- knowledge representation formalisms;\n- semantic web formalisms;\n- evaluation techniques;\n- semantic search engines;", "recorded": "2004-10-15T00:00:00", "title": "Knowledge Engineering applied to Semantic Web"}, {"url": "eswc06_kerrigan_swss2", "desc": "The proposed tutorial presents the Web Service Execution Environment WSMX and the Internet Reasoning Server IRS as an integrated environment for development and execution of Semantic Web Services on basis of the Web Service Modeling Ontology WSMO.", "recorded": "2006-06-11T00:00:00", "title": "Semantic Web Service Systems - Part 2"}, {"url": "eswc06_cabral_swss1", "desc": "The proposed tutorial presents the Web Service Execution Environment WSMX and the Internet Reasoning Server IRS as an integrated environment for development and execution of Semantic Web Services on basis of the Web Service Modeling Ontology WSMO.", "recorded": "2006-06-11T00:00:00", "title": "Semantic Web Service Systems - Part 1"}, {"url": "rease_domingue_sws", "desc": "This is a one-hour video recording of the presentation of John Domingue at the KnowledgeWeb summer school 2007. It comprises he video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nSemantic Web Services: Approaches and Applications\r\nWeb Services\r\nWhat?s a Web Service?\r\nWeb Services Framework\r\nClickWorkers\r\nArtificial Artificial Intelligence\r\nProblems with Web Services Today\r\nSWS Vision\r\nSemantic Web Services (is)\r\nSemantic Web Service Broker\r\nWeb Service Modelling Ontology (WSMO)\r\nWSMO Top Level Notions\r\nGoals\r\nWSMO Top Level Notions\r\nWSMO Web Service Description\r\nOrchestration Definition\r\nRuntime Orchestration\r\nWSMO Top Level Notions\r\nMediation\r\nWSMO Mediators Overview\r\nMediator Structure\r\nSupporting Emergency Planning for Essex County Council\r\nEssex County Council\r\nEmergency Planning Context\r\nEmergency planning scenario\r\neMerges Ontologies\r\nGeneric Application Structure\r\nDemonstration of Emergency Planning (GIS) Prototype V1\r\nEMerges Prototype Architecture\r\nOWL-S\r\nOWL-S Ontology\r\nOWL-S Upper Ontology\r\nWSMO OWL-S Comparison\r\nSemantic Annotations for WSDL (SAWSDL)\r\nSAWSDL Scope\r\nSummary\r\nOngoing and Future Work\r\nRelevant URLs", "recorded": "2007-11-23T00:00:00", "title": "Semantic Web Services"}, {"url": "iswc07_funk_obie", "desc": "Business Intelligence (BI) requires the acquisition and aggregation\r of key pieces of knowledge from multiple sources in order to\r provide valuable information to customers or feed statistical BI models\r and tools. The massive amount of information available to business\r analysts makes information extraction and other natural language processing\r tools key enablers for the acquisition and use of that semantic\r information. We describe the application of ontology-based extraction\r and merging in the context of a practical e-business application for the\r EU MUSING Project where the goal is to gather international company\r intelligence and country/region information. The results of our experiments\r so far are very promising and we are now in the process of building\r a complete end-to-end solution.", "recorded": "2007-11-14T11:00:00", "title": "Ontology-based Information Extraction for Business Intelligence "}, {"url": "iswc07_bechhofer_iowl", "desc": "Starting with an overview of the requirements for defining and using ontologies on the Web Sean will then outline the main concepts and issues associated with the Web ontology languaages, RDF, RDFS and OWL. By the end of this presentation attendees will have gained a basic understanding of the principles underlying OWL.", "recorded": "2007-11-11T09:45:00", "title": "An Introduction to OWL"}, {"url": "rease_domingue_swsat", "desc": "This is a one-hour video recording of the presentation of John Domingue at the First Asian Autumn School on the Semantic Web. It comprises one video synchronized with the slides (requires Flash) or the videos alone.\r\n\r\nTable of Contents: \r\nSemantic Web Services: Approaches and Technologies\r\nContents\r\nMotivation\r\n'The Internet has ?'\r\n'The Web has ?'\r\n7.2 billion Web searches/month (3.9 billion by Google) far exceed the world population\r\n161 exabytes (10&lt;sup&gt;8 &lt;/sup&gt;TB) of information was created or replicated worldwide in 2006.\r\nThat?s more than in the previous 5,000 years.\r\nIDC estimates 6X growth by 2010 to 988 exabytes (a zetabyte) / year\r\nNew technical information doubles every 2 years.\r\n? every 72 hours by 2010.\r\nAchieving Web Scale\r\nSemantic Web\r\nSW = A Conceptual Layer over the web\r\nSW is Heterogeneous!\r\nWeb Services\r\nWhat?s a Web Service?\r\nWeb Services Framework\r\nProblems with Web Services Today\r\nSWS Vision\r\nSemantic Web Services (is)\r\nSemantic Web Service Broker\r\nWeb Service Modelling Ontology (WSMO)\r\nWSMO Design Principles\r\nWSMO Top Level Notions\r\nNon-Functional Properties\r\nNon-Functional Properties List\r\nWSMO Top Level Notions\r\nOntology Description and Usage\r\nWSMO Ontology Design\r\nOntology Specification\r\nWSMO Top Level Notions\r\nGoals\r\nGoal Specification (1/2)\r\nGoal Specification (2/2)\r\nWSMO Top Level Notions\r\nWSMO Web Service Description\r\nCapability Specification (1/2)\r\nCapability Specification (2/2)\r\nWSMO Web Service Description\r\nChoreography & Orchestration\r\nChoreography Aspects (1/2)\r\nChoreography Aspects (2/2)\r\nWSMO Web Service Description\r\nOrchestration Aspects\r\nCommon requirements for service interface description\r\nOrchestration Definition\r\nRuntime Orchestration\r\nWSMO Top Level Notions\r\nMediation (Wiederhold, 94)\r\nMediation\r\nLevels of Mediation within Semantic Web Services\r\nWSMO Mediators Overview\r\nMediator Structure\r\nOO Mediator - Example\r\nGG Mediators\r\nGG Mediator Example\r\nWG Mediators\r\nWW Mediators\r\nWW Mediator Example\r\nData Level Mediation (1/2)\r\nData Level Mediation (2/2)\r\nFunctional Level Mediation (1/2)\r\nFunctional Level Mediation (2/2)\r\nProcess Level Mediation (1/2)\r\nProcess Level Mediation (2/2)\r\nOther Semantic Web Service Initiatives\r\nOWL-S\r\nOWL-S Ontology\r\nOWL-S Upper Ontology\r\nWSMO OWL-S Comparison\r\nSemantic Annotations for WSDL (SAWSDL)\r\nSAWSDL Scope\r\nIRS-III\r\nDesign Principles\r\nFeatures of IRS-III (1/3)\r\nFeatures of IRS-III (2/3)\r\nFeatures of IRS-III (3/3)\r\nIRS-III Overall Architecture\r\nIRS-III Server\r\nIRS-III Demo Context\r\nEuropean Travel Scenario\r\nEuropean Travel Demo\r\nIRS-III Demo\r\nSummary (1/2)\r\nSummary (2/2)\r\nRelevant URLs\r\nAcknowledgements\r\nThanks", "recorded": "2007-11-26T00:00:00", "title": "Semantic Web Services Approaches and Technologies"}, {"url": "rease_staab_som", "desc": "This is a one-hour video recording of the presentation of Steffen Staab at the KnowledgeWeb summer school 2005. It comprises either the video synchronized with the slides (but requires Quicktime, hence Windows or MacOS, otherwise the slides have to be switched manually). It provides an in-depth view with concrete example mappings while the presentation of Natasha Noy provides the general overview.\r\n\r\nTable of Contents: \r\nSatisficing Ontology Mapping - Step 1\r\nThe Semantic Web - Welcome on board the Voyager\r\nLet's talk\r\nOptimize vs. Satisfice\r\nSWAP Use Case: Virtual Organization\r\nKnowledge exchange P2P style\r\nIndividual Situation\r\n...so we have a problem...\r\nP2P\r\nGeneric Problem Description\r\nMapping Definition\r\nGeneric Process\r\nFeatures\r\nGeneric Process\r\nEntity Pair Selection\r\nGeneric Process\r\nSimilarity Measure\r\nSimilarity Rules\r\nGeneric Process\r\nAggregation\r\nGeneric Process\r\nInterpretation\r\nGeneric Process\r\nExample\r\nCritical Operations\r\nGeneric Process\r\nComplexity\r\nReduction of Comparisons\r\nRemoval of Complex Features\r\nComplexity\r\nScenarios\r\nEvaluation - Scenario\r\nResults for I3CON Ontology Alignment Experiment\r\nMore recently: Select rather than integrate\r\nExemplary Result\r\nEvaluation\r\nLessons Learned about QOM\r\nLessons Learned about Evaluation\r\nReasoning the fast and frugal way?\r\nConclusion\r\nSome references", "recorded": "2006-12-06T00:00:00", "title": "Satisficing Ontology Mapping"}, {"url": "eswc2013_gangemi_web", "desc": "In the last years, basic NLP tasks: NER, WSD, relation extraction, etc. have been configured for Semantic Web tasks including ontology learning, linked data population, entity resolution, NL querying to linked data, etc. Some assessment of the state of art of existing Knowledge Extraction (KE) tools when applied to the Semantic Web is then desirable. In this paper we describe a landscape analysis of several tools, either conceived specifically for KE on the Semantic Web, or adaptable to it, or even acting as aggregators of extracted data from other tools. Our aim is to assess the currently available capabilities against a rich palette of ontology design constructs, focusing specifically on the actual semantic reusability of KE output.", "recorded": "2013-05-28T11:00:00", "title": "A Comparison of Knowledge Extraction Tools for the Semantic Web"}, {"url": "iswc08_qi_krot", "desc": "Revision of a description logic-based ontology deals with the problem of incorporating newly received information consistently. In this paper, we propose a general operator for revising terminologies in description logic-based ontologies. Our revision operator relies on a reformulation of the kernel contraction operator in belief revision. We first define our revision operator for terminologies and show that it satisfies some desirable logical properties. Second, two algorithms are developed to instantiate the revision operator. Since in general, these two algorithms are computationally too hard, we propose a third algorithm as a more efficient alternative. We implemented the algorithms and provide evaluation results on their efficiency, effectiveness and meaningfulness in the context of two application scenarios: Incremental ontology learning and mapping revision.", "recorded": "2008-10-29T14:30:00", "title": "A Kernel Revision Operator for Terminologies - Algorithms and Evaluation"}, {"url": "eswc2015_troullinou_rdf_digest", "desc": "The exponential growth of the web and the extended use of semantic\r\nweb technologies has brought to the fore the need for quick understanding,\r\nflexible exploration and selection of complex web documents and schemas. To\r\nthis direction, ontology summarization aspires to produce an abridged version of\r\nthe original ontology that highlights its most representative concepts. In this\r\npaper, we present RDF Digest, a novel platform that automatically produces\r\nsummaries of RDF/S Knowledge Bases (KBs). A summary is a valid RDFS\r\ndocument/graph that includes the most representative concepts of the schema\r\nadapted to the corresponding instances. To construct this graph, our algorithm\r\nexploits the semantics and the structure of the schema and the distribution of the\r\ncorresponding data/instances. The performed preliminary evaluation demonstrates\r\nthe benefits of our approach and the considerable advantages gained.", "recorded": "2015-06-03T15:00:00", "title": "RDF Digest: Efficient Summarization of RDF/S KBs"}, {"url": "iswc08_horridge_lpjowl", "desc": "A justification for an entailment in an OWL ontology is a minimal subset of the ontology that is sufficient for that entailment to hold. Since justifications respect the syntactic form of axioms in an ontology, they are usually neither syntactically nor semantically minimal. This paper presents two new subclasses of justifications\u2014laconic justifications and precise justifications. Laconic justifications only consist of axioms that do not contain any superfluous \u201cparts\u201d. Precise justifications can be derived from laconic justifications and are characterised by the fact that they consist of flat, small axioms, which facilitate the generation of semantically minimal repairs. Formal definitions for both types of justification are presented. In contrast to previous work in this area, these definitions make it clear as to what exactly \u201cparts of axioms\u201d are. In order to demonstrate the practicability of computing laconic, and hence precise justifications, an algorithm is provided and results from an empirical evaluation carried out on several published ontologies are presented. The evaluation showed that laconic/precise justifications can be computed in a reasonable time for entailments in a range of ontologies that vary in size and complexity. It was found that in half of the ontologies sampled there were entailments that had more laconic/precise justifications than regular justifications. More surprisingly it was observed that for some ontologies there were fewer laconic justifications than regular justifications.", "recorded": "2008-10-29T12:00:00", "title": "Laconic and Precise Justifications in OWL"}, {"url": "aaai2010_stoilos_hiw", "desc": "Conjunctive query answering is a key reasoning service for\r\nmany ontology-based applications. In order to improve scalability,\r\nmany SemanticWeb query answering systems give up\r\ncompleteness (i.e., they do not guarantee to return all query\r\nanswers). It may be useful or even critical to the designers\r\nand users of such systems to understand how much and what\r\nkind of information is (potentially) being lost. We present a\r\nmethod for generating test data that can be used to provide at\r\nleast partial answers to these questions, a purpose for which\r\nexisting benchmarks are not well suited. In addition to developing\r\na general framework that formalises the problem, we\r\ndescribe practical data generation algorithms for some popular\r\nontology languages, and present some very encouraging\r\nresults from our preliminary evaluation.", "recorded": "2010-07-15T14:30:00", "title": "How Incomplete Is Your Semantic Web Reasoner?"}, {"url": "iswc08_mazuel_srmuo", "desc": "This paper presents a new semantic relatedness measure on ontologies which considers especially the object properties between the concepts. Our approach relies on two hypotheses. Firstly, using only concept hierarchy and object properties, only a few paths can be considered as \u201csemantically corrects\u201d and these paths obey to a given set of rules. Secondly, following a given edge in a path has a cost (represented as a weight), which depends on its type (  $is\\mbox{-}a$  ,  $part\\mbox{-}of$ , etc.), its context in the ontology and its position in this path. We propose an evaluation of our measure on the lexical base WordNet using  $part\\mbox{-}of$ relation with two different benchmarks. We show that, in this context, our measure outperforms the classical semantic measures.", "recorded": "2008-10-30T15:00:00", "title": "Semantic Relatedness Measure Using Object Properties in an Ontology"}, {"url": "iswc07_tran_obi", "desc": "Current information retrieval (IR) approaches do not formally capture the explicit meaning of a keyword query but provide a comfortable way for the user to specify information needs on the basis of keywords. Ontology-based approaches allow for sophisticated semantic search but impose a query syntax more difficult to handle. In this paper, we present an approach for translating keyword queries to DL conjunctive queries using background knowledge available in ontologies. We present an implementation which shows that this interpretation of keywords can then be used for both exploration of asserted knowledge and for a semantics-based declarative query answering process.We also present an evaluation of our system and a discussion of the limitations of the approach with respect to our underlying assumptions which directly points to issues for future work.", "recorded": "2007-11-13T16:00:00", "title": "Ontology-based Interpretation of Keywords for Semantic Search"}, {"url": "eswc2014_stoilos_data_access", "desc": "n previous work it has been shown how an OWL 2 DL ontology O can be `repaired' for an OWL 2 RL system ans that is, how we can compute a set of axioms R that is independent from the data\r\nand such that ans that is generally incomplete for O becomes complete for all SPARQL queries when used with O [ R. However, the initial implementation and experiments were very preliminary and hence it is currently unclear whether the approach can be applied to large and complex ontologies. Moreover, the approach so far can only support instance queries. In the current paper we thoroughly investigate repairing as an approach to scalable (and complete) ontology-based data access. First, we present several non-trivial optimisations to the \frst prototype. Second, we show how (arbitrary) conjunctive queries can be supported by integrating well-known query rewriting techniques with OWL 2 RL systems via repairing. Third, we perform an extensive experimental evaluation obtaining encouraging results. In more detail, our results show that we can compute repairs even for very large real-world ontologies in a reasonable amount of time, that the performance overhead introduced by\r\nrepairing is negligible in small to medium sized ontologies and noticeable but manageable in large and complex one, and that the hybrid reasoning approach can very e\u000efficiently compute the correct answers for real-world challenging scenarios", "recorded": "2014-05-28T12:15:00", "title": "Ontology-Based Data Access Using Rewriting, OWL 2 RL Systems and Repairing"}, {"url": "iswc2014_kien_tran_ontology", "desc": "We present a new procedure for ontology materialization (computing all entailed instances of every atomic concept) in which reasoning over a large ABox is reduced to reasoning over a smaller \u201cabstract\u201d ABox. The abstract ABoxisobtainedastheresultofa\ufb01xed-pointcomputationinvolvingtwostages: 1) abstraction: partition the individuals into equivalence classes based on told information and use one representative individual per equivalence class, and 2) re\ufb01nement: iteratively split (re\ufb01ne) the equivalence classes, when new assertions are derived that distinguish individuals within the same class. We prove that the method Is complete for Horn ALCHOI ontologies, that is, all entailed instances will be derived once the \ufb01xed-point is reached. We implement the procedure in a new database-backed reasoning system and evaluate it empirically on existing ontologieswithlargeABoxes.WedemonstratethattheobtainedabstractABoxes are signi\ufb01cantly smaller than the original ones and can be computed with few re\ufb01nement steps.", "recorded": "2014-10-21T15:20:00", "title": "Abstraction Refinement for Ontology Materialization"}, {"url": "reasecs_corcho_oe", "desc": "This tutorial presents the theoretical foundations of Ontological Engineering, describes the most outstanding ontologies that are currently available, and covers the practical aspects of selecting and applying methodologies, languages, and tools for building ontologies. This tutorial also aims at presenting commercial-oriented and research-oriented ontology-based applications.\n\nDocuments:\n;[[Ontological_Engineering.pdf]]", "recorded": "2004-11-02T00:00:00", "title": "Ontological Engineering"}, {"url": "kdd09_hu_ewaek", "desc": "In traditional text clustering methods, documents are represented as \u001cbags of words\u001d without considering the semantic information of each document. For instance, if two documents use different collections of core words to represent the same topic, they may be falsely assigned to different clusters due to the lack of shared core words, although the core words they use are probably synonyms or semantically associated in other forms. The most common way to solve this problem is to enrich document representation with the background knowledge in an ontology. There are two major issues for this approach: (1) the coverage of the ontology is limited, even for WordNet or Mesh, (2) using ontology terms as replacement or additional features may cause information loss, or introduce noise. In this paper, we present a novel text clustering method to address these two issues by enriching document representation with Wikipedia concept and category information. We develop two approaches, exact match and relatedness-match, to map text documents to Wikipedia concepts, and further to Wikipedia categories. Then the text documents are clustered based on a similarity metric which combines document content information, concept information as well as category information. The experimental results using the proposed clustering framework on three datasets (20-newsgroup, TDT2, and LA Times) show that clustering performance improves significantly by enriching document representation with Wikipedia concepts and categories.\r\n", "recorded": "2009-07-08T14:23:46", "title": "Exploiting Wikipedia as External Knowledge for Document Clustering"}, {"url": "eswc09_hepp_hausenblass_wdec", "desc": "In this tutorial, we will\n\n(1) explain the immediate business benefits of joining the Web of Data for Web shops, manufacturers of commodities, and service providers of any kind,\n\n(2) show how any commercial Web site can embed details of its business and offerings as RDFa metadata using the GoodRelations ontology (http://purl.org/goodrelations/), and\n\n(3) demonstrate the usage of the resulting data in multiple applications, namely Yahoo! SearchMonkey, queries on Semantic Web data repositories, Mashups, and the import from and export to popular Web shop software.\n\nParticipants will learn how to use the GoodRelations ontology to augment Web shops and other Web applications with metadata on business entities, products and services, prices, warranty, shop locations, terms and conditions, etc. This will improve the visibility of an offering in next generation Web search engines, allow more precise search, and support partners in the value chain to extract and reuse product model data easily. At the same time, the tutorial will explain the modeling of more complex RDF patterns in RDFa.\nThe tutorial will also serve as a self-contained introduction of what the Web of Data is, which benefits it will provide for businesses, and why now is the time to get involved.\n\n----\nThe tutorial homepage can be found at: http://www.ebusiness-unibw.org/wiki/Web_of_Data_for_E-Commerce_Tutorial_ESWC2009\n----\n**//Disclaimer:// Videolectures.Net emphasises that some slides on lecture part #5 are missing and therefore are not synchronized with video #5.**", "recorded": "2009-05-31T09:00:00", "title": "The Web of Data for E-Commerce in One Day: A Hands-on Introduction to the GoodRelations Ontology, RDFa, and Yahoo! SearchMonkey"}, {"url": "kdd07_dou_donem", "desc": "Event-related potentials (ERP) are brain electrophysiological patterns created by averaging electroencephalographic (EEG) data, time-locking to events of interest (e.g., stimulus or response onset). In this paper, we propose a generic framework for mining and developing domain ontologies and apply it to mine brainwave (ERP) ontologies. The concepts and relationships in ERP ontologies can be mined according to the following steps: pattern decomposition, extraction of summary metrics for concept candidates, hierarchical clustering of patterns for classes and class taxonomies, and clustering-based classification and association rules mining for relationships (axioms) of concepts. We have applied this process to several dense-array (128-channel) ERP datasets. Results suggest good correspondence between mined concepts and rules, on the one hand, and patterns and rules that were independently formulated by domain experts, on the other. Data mining results also suggest ways in which expert-defined rules might be refined to improve ontology representation and classification results. The next goal of our ERP ontology mining framework is to address some long-standing challenges in conducting large-scale comparison and integration of results across ERP paradigms and laboratories. In a more general context, this work illustrates the promise of an interdisciplinary research program, which combines data mining, neuroinformatics and ontology engineering to address real-world problems.", "recorded": "2007-09-14T15:44:21", "title": "Development of NeuroElectroMagnetic Ontologies (NEMO): A Framework for Mining Brain Wave Ontologies "}, {"url": "rease_motta_rpsw", "desc": "This is a one-hour video recording of the presentation of Enrico Motta at the KnowledgeWeb summer school 2007. \r\nIt comprises the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents:\r\nA Research Programme for the Semantic Web\r\nIntroduction\r\nOrganization of the Talk\r\nThe Semantic Web\r\nCharting the web\r\nIncreasing Semantic Content\r\nThe Rise of Semantics\r\nThesis #1\r\nThesis #2\r\nKnowledge Representation Hypothesis in AI\r\nIntelligence as a function of possessing domain knowledge\r\nThe Knowledge Acquisition Bottleneck\r\nSW as Enabler of Intelligent Behaviour\r\nOverall Goal\r\nArchitecture of NGSW Apps\r\nIssue: Semantic Web Infrastructure\r\nCurrent Gateway to the Semantic Web\r\nLimitations of Swoogle\r\nA New Gateway to the Semantic Web\r\n'Sophisticated quality control mechanism'\r\nExamples of Next Generation Semantic Web Applications\r\nExample #1: Ontology Matching\r\nOntology Matching\r\nNew paradigm: use of background knowledge\r\nExternal Source = One Ontology\r\nExternal Source = Web\r\nExternal Source = SW\r\n'How to combine online ontologies...'\r\nStrategy 1 - Definition\r\nStrategy 1- Examples\r\nStrategy 2 - Definition\r\nStrategy 2 - Examples\r\nLarge Scale Evaluation\r\nChart 2\r\nThesis #3\r\nExample #2: Integrating SW and Web2.0\r\nFeatures of Web2.0 sites\r\nLimitations of tagging\r\nGiving meaning to tags\r\nWhat does it mean to add semantics to tags?\r\nApplications of the approach\r\nExperiments\r\nExamples\r\nLessons Learnt\r\nExample #3: Semantics-Enhanced Web Browsing\r\nConclusions\r\nReferences\r\n'Vision' Papers", "recorded": "2007-11-23T00:00:00", "title": "A Research Program for the Semantic Web"}, {"url": "eswc2010_hazucha_axsa", "desc": "Background (or sometimes referred to as domain) knowledge is extensively used in data mining for data pre-processing and for\r\nnugget-oriented data mining tasks: it is essential for constraining the\r\nsearch space and pruning the results. Despite the costs of eliciting background knowledge from domain experts, there has been so far little effort\r\nto devise a common exchange standard for its representation. This paper proposes the Background Knowledge Exchange Format (BKEF), a\r\nlightweight XML Schema for storing information on features and patterns, and the Background Knowledge Ontology (BKOn), as its semantic abstraction. The purpose of BKOn is to allow reasoning over and\r\nintegration of analysed data with existing domain ontologies. We show\r\nan elicitation interface producing BKEF and discuss the possibilities for\r\nintegration of such background knowledge with domain ontologies.", "recorded": "2010-05-31T16:30:00", "title": "An XML Schema and a Topic Map Ontology for Formalization of Background Knowledge in Data Mining "}, {"url": "rease_ciravegna_adauh", "desc": "This is a one-hour video recording of the presentation of Fabio Ciravegna at the KnowledgeWeb summer school 2006. It comprises either the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nAutomating Document Annotation using HLT and ML\r\nTutorial Outline\r\nInformation searching\r\nSome hard facts\r\nSources of Knowledge\r\nTraditional Approaches\r\nFactors hampering searching\r\nGeneral Requirements\r\nGeneral requirements: Multi-Mediality\r\nJet engine example\r\nRequirements for Large Scale KM\r\nRequirements (ctd)\r\nOntology-based Document Annotation\r\nOntology-based Annotation\r\nWhen/What do we annotate?\r\nOntology-based Annotation\r\nAktiveMedia:  Annotation for text and images and across\r\nText is selected and dropped into a concept in the ontology\r\nContextual Annotation of Images and Text\r\nAnnotating across documents (CREAM, 2001)\r\nIssues in User Centred Document Annotation\r\nAnnotations: Where From?\r\nManual Annotation (1)\r\nAn Example\r\nWhy not including\r\nProblems in the example\r\nProblems with Manual Annotation (2)\r\nAnnotation for use...\r\nDoable?\r\nManual Annotation (2)\r\nAutomating Annotation for the Semantic Web\r\nAnnotation Engines\r\nAdvantages\r\nUsing IE to support annotation: step 1\r\nUsing IE to support annotation: step 2\r\nLearning curve\r\nImpact on Annotation\r\nLarge Scale Annotation\r\nArmadillo\r\nAnnotation as Harvesting\r\nLarge Scale Extraction Strategy\r\nInformation Extraction From Text\r\nNamed Entity Recognition\r\nTraditional approach to NER&C\r\nLarge Scale NER&C\r\nLarge Scale NER: Indexing\r\nKnown Name Recognition\r\nDiscovery of New Names\r\nMore complex IE: event modelling\r\nAn Example of Automatic IE\r\nInformation extraction\r\nUse of Annotated Material: Searching\r\nQuerying the documents\r\nQuerying documents\r\nAccessing Services\r\nStatistics in IPAS\r\nInformation Integration\r\nUse of Integrated Information\r\nGourm-adillo\r\nMartin Dzbor, John B. Domingue, and Enrico Motta. Magpie: - towards a semantic web browser.  ISWC 20\r\nSources\r\nSimMetrics\r\nAnother Type of Annotation: Braindump\r\nA different type of annotation: braindump\r\nConclusions\r\nFuture Work & Challenges\r\nA list of tools for automatic annotation", "recorded": "2007-02-14T00:00:00", "title": "Automating Document Annotation using HLT and ML"}, {"url": "eswc09_lambrix_upra", "desc": "In different areas ontologies have been developed and many of these ontologies contain overlapping information. Often we would therefore want to be able to use multiple ontologies. To obtain good results, we need to find the relationships between terms in the different ontologies, i.e. we need to align them. Currently, there already exist a number of ontology alignment systems. In these systems an alignment is computed from scratch. However, recently, some situations have occurred where a partial reference alignment is available, i.e. some of the correct mappings between terms are given or have been obtained. In this paper we investigate whether and how a partial reference alignment can be used in ontology alignment. We use partial reference alignments to partition ontologies, to compute similarities between terms and to filter alignment suggestions. We test the approaches on previously developed golden standards and discuss the results.", "recorded": "2009-06-03T12:10:40", "title": "Using Partial Reference Alignments to Align Ontologies"}, {"url": "iswc2011_bail_structure", "desc": "Current ontology development tools o\u000ber debugging support\r\nby presenting justi\ffications for entailments of OWL ontologies. While\r\nthese minimal subsets have been shown to support debugging and understanding\r\ntasks, the occurrence of multiple justifications presents a significant\r\ncognitive challenge to users. In many cases even a single entailment\r\nmay have many distinct justi\ffications, and justi\ffications for distinct entailments\r\nmay be critically related. However, it is currently unknown how\r\nprevalent signifi\fcant numbers of multiple justi\ffications per entailment are\r\nin the fi\feld. To address this lack, we examine the justifi\fcations from an\r\nindependently motivated corpus of actively used biomedical ontologies\r\nfrom the NCBO BioPortal. We \fnd that the majority of ontologies contain\r\nmultiple justifi\fcations, while also exhibiting structural features (such\r\nas patterns) which can be exploited in order to reduce user e\u000bffort in the\r\nontology engineering process.", "recorded": "2011-10-26T11:00:00", "title": "The justificatory structure of the NCBO BioPortal ontologies"}, {"url": "iswc08_feng_eswsi", "desc": "Currently proposed Semantic Web Services technologies allow the creation of ontology-based semantic annotations of Web services so that software agents are able to discover, invoke, compose and monitor these services with a high degree of automation. The OWL Services (OWL-S) ontology is an upper ontology in OWL language, providing essential vocabularies to semantically describe Web services. Currently OWL-S services can only be developed independently; if one service is unavailable then finding a suitable alternative would require an expensive and difficult global search/match. It is desirable to have a new OWL-S construct that can systematically support substitution tracing as well as incremental development and reuse of services. Introducing inheritance relationship (IR) into OWL-S is a natural solution. However, OWL-S, as well as most of the other currently discussed formalisms for Semantic Web Services such as WSMO or SAWSDL, has yet to define a concrete and self-contained mechanism of establishing inheritance relationships among services, which we believe is very important for the automated annotation and discovery of Web services as well as human organization of services into a taxonomy-like structure. In this paper, we extend OWL-S with the ability to define and maintain inheritance relationships between services. Through the definition of an additional \u201cinheritance profile\u201d, inheritance relationships can be stated and reasoned about. Two types of IRs are allowed to grant service developers the choice to respect the \u201ccontract\u201d between services or not. The proposed inheritance framework has also been implemented and the prototype will be briefly evaluated as well.", "recorded": "2008-10-28T15:00:00", "title": "Enhancing Semantic Web Services with Inheritance"}, {"url": "iswc08_balby_marinho_fbcl", "desc": "The growing popularity of social tagging systems promises to alleviate the knowledge bottleneck that slows the full materialization of the Semantic Web, as these systems are cheap, extendable, scalable and respond quickly to user needs. However, for the sake of knowledge workflow, one needs to find a compromise between the ungoverned nature of folksonomies and the controlled vocabulary of domain-experts. In this paper, we address this concern by first devising a method that automatically combines folksonomies with domain-expert ontologies resulting in an enriched folksonomy. We then introduce a new algorithm based on frequent itemsets mining that efficiently learns an ontology over the concepts present in the enriched folksonomy. Moreover, we propose a new benchmark for ontology evaluation, which is used in the context of information finding, since this is one of the leading motivations for using ontologies in social tagging systems, to quantitatively assess our method. We conduct experiments on real data and empirically show the effectiveness of our approach.", "recorded": "2008-10-28T17:00:00", "title": "Folksonomy-based collabulary learning"}, {"url": "eswc2013_ivanova_aligning_taxonomies", "desc": "With the increased use of ontologies in semantically-enabled applications, the issues of debugging and aligning ontologies have become increasingly important. The quality of the results of such applications is directly dependent on the quality of the ontologies and mappings between the ontologies they employ. A key step towards achieving high quality ontologies and mappings is discovering and resolving modeling defects, e.g., wrong or missing relations and mappings. In\r\nthis paper we present a unified framework for aligning taxonomies, the most used kind of ontologies, and debugging taxonomies and their alignments, where ontology alignment is treated as a special kind of debugging. Our framework supports the detection and repairing of missing and wrong is-a structure in taxonomies, as well as the detection and repairing of missing (alignment) and wrong mappin gaps between ontologies. Further, we implemented a system based on this frame work\r\nand demonstrate its benefits through experiments with ontologies from the Ontology Alignment Evaluation Initiative.", "recorded": "2013-05-28T11:09:17", "title": "A Unified Approach for Aligning Taxonomies and Debugging Taxonomies and their Alignments"}, {"url": "iswc07_domingue_wsmo", "desc": "In this session John and David will first give an overview of the problem and vision for applying Semantic Web technologies to Web Services, then they will describe a number of the most important approaches and finally Semantic Web Service applications. By the end of this session attendees will gained an understanding of the main issues in Semantic Web Services and an overview of OWL-S, SAWSDL and WSMO.", "recorded": "2007-11-11T15:00:00", "title": "Web Service Modelling Ontology"}, {"url": "acmwebsci2011_gamble_joint", "desc": "In science, quality is paramount. As scientists increasingly\r\nlook to the Web to share and discover scienti\ffic data, there\r\nis a growing need to support the scientist in assessing the\r\nquality of that data. However, quality is an ambiguous and\r\noverloaded term. In order to support the scienti\ffic user in\r\ndiscovering useful data we have systematically examined the\r\nnature of \\quality\" by exploiting three, prevalent properties\r\nof scientifi\fc data sets: (1) that data quality is commonly defi\fned objectively; (2) the provenance and lineage in its production\r\nhas a well understood role; and (3)\"fitness-for-use\"\r\nis a de\ffinition of utility rather than quality or trust, where\r\nthe quality and trust-worthiness of the data and the entities\r\nthat produced that data inform its utility. Our study is presented\r\nin two stages. First we review existing information\r\nquality dimensions and detail an assessment-oriented classiffi\fcation. We introduce de\ffinitions for quality, trust and\r\nutility in terms of the entities required in their assessment;\r\nproducer, provider, consumer, process, artifact and quality\r\nstandard. Next we detail a novel and experimental approach\r\nto assessment by modelling the causal relationships between\r\nquality, trust, and utility dimensions through the construction\r\nof decision networks informed by provenance graphs.\r\nTo ground and motivate our discussion throughout we draw\r\non the European Bioinformatics Institute's Gene Ontology\r\nAnnotations database. We present an initial demonstration\r\nof our approach with an example for ranking results from\r\nthe Gene Ontology Annotation database using an emerging\r\nobjective quality measure, the Gene Ontology Annotation\r\nQuality score.", "recorded": "2011-06-16T16:00:00", "title": "Quality, Trust, and Utility of Scientific Data on the Web: Towards a Joint Model"}, {"url": "eswc2012_rubiera_azcona_telix", "desc": "This paper proposes to apply the RDF framework to the representation of linguistic annotations. We argue that RDF is a suitable data model to capture multiple annotations on the same text segment, and to integrate multiple layers of annotations. Besides the idea of using RDF for this purpose, the main contribution of the paper is an OWL ontology, called TELIX (Text Encoding and Linguistic Information eXchange), which models annotation content. This ontology builds on the SKOS~XL vocabulary, a W3C standard for lexical entities representation as RDF graphs. We extend SKOS in order to capture lexical relations between words (e.g., synonymy), as well as to support word sense disambiguation, morphological features and syntactic analysis, among others. Additionally, a formal mapping of feature structures to RDF graphs is defined, enabling complex composition of linguistic entities. Finally, the paper also suggests the use of RDFa as a convenient syntax that combines source texts and linguistic annotations in the same file.", "recorded": "2012-05-30T16:00:00", "title": "TELIX: An RDF-based Model for Linguistic Annotation"}, {"url": "eswc08_sen_cobs", "desc": "We are currently devoloping an integrated business application\r\nplatform named Corinna3 where the long-term goal is to combine\r\nSemantic Web technologies with Natural Language Processing (NLP) to\r\nincrease the efficiency of the enterprise search process.\r\nIn this paper we consider one of the Corinna use cases, namely the\r\nHuman Resource (HR) use case, which has already reached a prototype\r\nimplementation. While NLP is used for automatic categorization\r\nof an unstructured resource, ontologies represent these resources in a\r\ntaxonomical way with arbitrary properties. On top of the resource ontologies\r\nwe use both the NLP for the information extraction as well as\r\nontology-based similarity in order to get more acceptable similar search\r\nresults. Our implemented approach of contextualized hybrid similarity\r\nsearch within the Corinna platform derives strongly from the defined\r\nbusiness use cases. It combines and extends existing similarity measures\r\nunder consideration of additional context information.", "recorded": "2008-06-03T12:00:00", "title": "Contextualized Ontology-Based Similarity in the Human Resources Domain: A Business Use Case"}, {"url": "iswc07_cumc_mpr", "desc": "This talk describes a large case study that explores the applicability of ontology reasoning to problems in the medical domain. We investigate whether it is possible to use such reasoning to automate com- mon clinical tasks that are currently labor intensive and error prone, and focus our case study on improving cohort selection for clinical trials. An obstacle to automating such clinical tasks is the need to bridge the semantic gulf between raw patient data, such as laboratory tests or specific medications, and the way a clinician interprets this data. Our key insight is that matching patients to clinical trials can be formulated as a problem of semantic retrieval. We describe the technical challenges to building a realistic case study, which include problems related to scalability, the integration of large ontologies, and dealing with noisy, inconsistent data. Our solution is based on the SNOMED CT R&#160; ontology, and scales to one year of patient records (approx. 240,000 patients).", "recorded": "2007-11-13T14:00:00", "title": "Matching Patient Records to Clinical Trials Using Ontologies"}, {"url": "iswc08_troncy_biptc", "desc": "For easing the exchange of news, the International Press Telecommunication Council (IPTC) has developed the NewsML Architecture (NAR), an XML-based model that is specialized into a number of languages such as NewsML G2 and EventsML G2. As part of this architecture, specific controlled vocabularies, such as the IPTC News Codes, are used to categorize news items together with other industry-standard thesauri. While news is still mainly in the form of text-based stories, these are often illustrated with graphics, images and videos. Media-specific metadata formats, such as EXIF, DIG35 and XMP, are used to describe the media. The use of different metadata formats in a single production process leads to interoperability problems within the news production chain itself. It also excludes linking to existing web knowledge resources and impedes the construction of uniform end-user interfaces for searching and browsing news content.\r\nIn order to allow these different metadata standards to interoperate within a single information environment, we design an OWL ontology for the IPTC News Architecture, linked with other multimedia metadata standards. We convert the IPTC NewsCodes into a SKOS thesaurus and we demonstrate how the news metadata can then be enriched using natural language processing and multimedia analysis and integrated with existing knowledge already formalized on the Semantic Web. We discuss the method we used for developing the ontology and give rationale for our design decisions. We provide guidelines for re-engineering schemas into ontologies and formalize their implicit semantics. In order to demonstrate the appropriateness of our ontology infrastructure, we present an exploratory environment for searching and browsing news items.", "recorded": "2008-10-29T15:00:00", "title": "Bringing the IPTC News Architecture into the Semantic Web"}, {"url": "eswc09_stuckenschmidt_iomu", "desc": "Despite serious research efforts, automatic ontology matching still suffers from severe problems with respect to the quality of matching results. Existing matching systems trade-off precision and recall and have their specific strengths and weaknesses. This leads to problems when the right matcher for a given task has to be selected. In this paper, we present a method for improving matching results by not choosing a specific matcher but applying machine learning techniques on an ensemble of matchers. Hereby we learn rules for the correctness of a correspondence based on the output of different matchers and additional information about the nature of the elements to be matched, thus leveraging the weaknesses of an individual matcher. We show that our method always performs significantly better than the median of the matchers used and in most cases outperforms the best matcher with an optimal threshold for a given pair of ontologies. As a side product of our experiments, we discovered that the majority vote is a simple but powerful heuristic for combining matchers that almost reaches the quality of our learning results.", "recorded": "2009-06-03T11:00:00", "title": "Improving Ontology Matching using Meta-level Learning"}, {"url": "iswc2011_haglich_cyber", "desc": "The Cyber Scientific Method (CSM) formalizes experimentation on computer systems, hardware, software, and networks on the U.S. National Cyber Range. This formalism provides rigor to cyber tests to ensure knowledge can be shared and experiment results can be viewed with confidence, knowing exactly what was tested under what conditions. Cyber Scientific Test Language (CSTL) is an ontology-based language for CSM experiments. CSTL describes test objectives, statistical experiment design, test network composition, sensor placement, and data analysis and visualization. CSTL represents CSM experiments throughout their lifecycle, from test design through detailed test network description, instrumentation and control network augmentation, testbed buildout, data collection, and analysis. The representation of this information in a formal ontology has several benefits. It enables use of general-purpose reasoners to query and recombine test specifications for rapidly building an experiment network and testbed on the range. Additionally, it facilitates knowledge\r\nmanagement and retrieval of test procedures and results.", "recorded": "2011-10-25T14:30:00", "title": "Cyber Scientific Test Language"}, {"url": "eswc2013_abedjan_synonym", "desc": "Despite unified data models, such as the Resource Description Framework (Rdf) on structural level and the corresponding query language Sparql, the integration and usage of Linked Open Data faces major heterogeneity challenges on the semantic level. Incorrect use of ontology concepts and class properties impede the goal of machine readability and knowledge discovery. For example, users searching for movies with a certain artist cannot rely on a single given property artist, because some movies may be connected to that artist by the predicate starring. In addition, the information need of a data consumer may not always be clear and her interpretation of given schemata may differ from the intentions of the ontology engineer or data publisher. It is thus necessary to either support users during query formulation or to incorporate implicitly related facts through predicate expansion. To this end, we introduce a data-driven synonym discovery algorithm for predicate expansion. We applied our algorithm to various data sets as shown in a thorough evaluation of different strategies and rule-based techniques for this purpose.\r\n", "recorded": "2013-05-28T15:00:00", "title": "Synonym Analysis for Predicate Expansion"}, {"url": "eswc2011_ji_ontology", "desc": "Ontology matching is one of the key research topics in the field of Semantic Web. In the last few years, many matching methods have been proposed to generate matches between different ontologies either automatically or semi-automatically. To select appropriate ones, users need some measures to judge whether a method can achieve the similar compliance even on one dataset without reference matches and whether such a method is reliable w.r.t. its output result along with the confidence. However, widely-used traditional measures like precision and recall fail to provide sufficient hints on them. In this paper, we design two novel evaluation measures to evaluate stability of matching methods and one measure to evaluate credibility of matching confidence values, which help to answer the above two questions. Additionally, we carry out comparison among several carefully selected methods systematically using our new measures. Besides, we report some interesting findings such as identifying potential defects of our subjects.", "recorded": "2011-05-31T15:30:00", "title": "Evaluating the Stability and Credibility of Ontology Matching Methods"}, {"url": "rease_benjamins_sse", "desc": "This is a one-hour video recording of the presentation of Richard Benjamins at the KnowledgeWeb summer school 2007. It comprises the video synchronized with the slides (requires Flash) ot the video alone. \r\n\r\nTable of Contents: \r\nOverview\r\niSOCO\r\nOverview\r\nEstimated Market Size of Semantic Technologies\r\nEmerging Technologies Hype Cycle 2006\r\nMarket Inhabitants: Technology Adoption Lifecycle\r\nOverview\r\nIntegration of Distributed Heterogeneous Systems\r\nFinding Related Content Based on Concepts\r\nAutomatic Analysis of Client Complaints\r\nUnderstanding FAQs for Recent Judges (Law)\r\nDynamic Integration of Third Party Web Services\r\nIntelligent Search in Databases\r\nFrom Search to Online Self Management in eGovernment\r\nIntelligent Access to Cultural Heritage\r\nSemantic Portal for Cultural Heritage\r\nContext Based Interaction\r\nOverview\r\nOntology Building and Maintenance\r\nBest Breed of Tools and Methods\r\nHow Clients Perceive Ontologies\r\nCost Factors for Constructing an Ontology\r\nChallenge for Semantic Technologies\r\nOverview\r\nConclusions\r\nAnd What about Multimedia Search Engines?\r\nWith Much Precision?\r\nUse Free Brain Cycles (Gaming)\r\nContact Information", "recorded": "2007-11-23T00:00:00", "title": "Semantic Solutions for Enterprises"}, {"url": "eswc09_ruiz_oium", "desc": "We propose a general method and novel algorithmic techniques to facilitate the integration of independently developed ontologies using mappings. Our method and techniques aim at helping users understand and evaluate the semantic consequences of the integration, as well as to detect and fix potential errors. We also present a system that implements our approach, and a preliminary evaluation which suggests that our approach is both useful and feasible in practice.", "recorded": "2009-06-03T09:29:23", "title": "Ontology Integration Using Mappings: Towards Getting the Right Logical Consequences"}, {"url": "iswc07_daquin_watson", "desc": "Watson is a Semantic Web gateway. In a way similar to seacrh engines on the Web, Watson collects, analyses and indexes semantic documents (in RDF, OWL, DAML+OIL) in order to provide a variety of access mechanisms to this semantic data for intelligent applications. The idea is to support applications that requires to dynamically find, select and exploit the increasing amount of knowledge available online (that we call next generation semantic web applications). A more complete description of Watson is available on its website, and the latest development and news concerning Watson are generally announced on the Watson Blog.\r A number of applications have already been developed that dynamically exploit online knowledge thanks to Watson. In particular, I am (with the help of Fouad Zablith) in charge of the development of plugins for ontology editors that allow for a large scale reuse of existing knowledge on the Web. I also (quickly) developed an application called gowgle that suggests additional keywords to a query addressed to Google using the semantic relations linking these terms in online ontologies. I also contributed to the development of Scarlet, a relation discovery engine used in particular in ontology matching, and of PowerMagpie a Semantic browser based on Watson.", "recorded": "2007-11-13T18:15:00", "title": "The Watson plugin for the Neon toolkit"}, {"url": "samt08_santini_cnod", "desc": "This paper is a theoretical analysis of formal annotation and ontology for the expression of the semantics of document. They are found wanting in this respect, not only for technical reasons, but because they embody a fundamentally misunderstood model of the process of signification. I propose an alternative model in which the interpretation context plays a fundamental r\u00f4le in the definition of an _activity game_ that includes all actions performed on a document, including accessing external data. I briefly discuss it and its current technical embodiment.", "recorded": "2008-12-04T14:45:00", "title": "Context as a non-ontological determinant of semantics"}, {"url": "sssw05_maynard_lt", "desc": "This tutorial covers the use of Human Language Technologies for the Semantic Web and Web Services. It includes sections on HLT and Text Mining for the Semantic Web, various forms of Information Extraction, Ontology Population and Semantic Metadata Creation, and Evaluation.\r\n \r\n The tutorial begins with an introduction to Human Language Technology, looking at both its background and development, and then situating it within the context of text mining and other tasks involving knowledge discovery from large collections of unstructured text, which are necessary for the development of the semantic web. The second section concerns information extraction, a major component of text mining. Information extraction involves extracting facts and structured information from unstructured data. We contrast this with Information retrieval, which concerns extracting documents from large text collections, and with data mining, which concerns discoveing patterns in structured data. We introduce GATE, and architecture for language engineering, and its resources for information extraction, and then expand the idea of traditional information extraction to focus on semantic web-enabled technology such as ontology population and semantic metadata creation, both of which involve the use of information extraction based on ontologies. We look at some current state-of-the-art semantic annotation systems such as KIM, Magpie, MnM and OntoMat. In the third section, we discuss evaluation methods for such technology, based on the idea that traditional methods are insufficient when applied to semantic web technology, due to the presence of hierarchical (ontological) information rather than flat structures. We also take a brief look at usability issues of annotation systems. Finally, the tutorial gives demonstrations of two examples of HLT in use for the semantic web. First we present RichNews, which aims to automate the annotation of news programs, segmenting, describing and classifying news broadcasts from transcripts. Second, we present work on ontology-based and mixed initiative information extraction carried out in the context of SEKT.\r\n ", "recorded": "2005-07-06T15:00:00", "title": "Language Technologies"}, {"url": "iswc2011_vescovo_klinov_structure", "desc": "We present the first large scale investigation into the modular structure of a substantial collection of state-of-the-art biomedical ontologies, namely those maintained in the NCBO BioPortal repository.5 Using the notion of Atomic Decomposition, we partition BioPortal ontologies into logically coherent subsets (atoms), which are related to each other by a notion of dependency. We analyze various aspects of the resulting structures, and discuss their implications on applications of ontologies.\r\nIn particular, we describe and investigate the usage of these ontology decompositions to extract modules, for instance, to facilitate matchmaking of semantic Web services in SSWAP (Simple Semantic Web Architecture and Protocol). Descriptions of those services use terms from BioPortal so\r\nservice discovery requires reasoning with respect to relevant fragments of ontologies (i.e., modules). We present a novel algorithm for extracting modules from decomposed BioPortal ontologies which is able to quickly identify atoms that need to be included in a module to ensure logically complete reasoning. Compared to existing module extraction algorithms, it has a number of benefits, including improved performance and the possibility to avoid loading the entire ontology into memory. The algorithm is also evaluated on BioPortal ontologies and the results are presented and discussed.", "recorded": "2011-10-27T12:06:00", "title": "Decomposition and Modular Structure of BioPortal Ontologies"}, {"url": "eswc2011_tuominen_biological", "desc": "Biodiversity management requires the usage of heterogeneous biological information from multiple sources. Indexing, aggregating, and finding such information is based on names and taxonomic knowledge of organisms. However, taxonomies change in time due to evolution, new scientific findings, opinions of authorities, and changes in our conception about life forms. Furthermore, organism names and their meaning change in time, different authorities use different scientific names for the same taxon in different times, and various vernacular names are in use in dif- ferent languages. This makes data integration and information retrieval difficult without detailed biological information. This paper introduces a meta-ontology for managing the names and taxonomies of organisms, and presents three applications for it: 1) publishing biological species lists as ontology services (ca. 20 taxonomies including more than 80,000 names), 2) collaborative management of the vernacular names of vascu- lar plants (ca. 26,000 taxa), and 3) management of individual scientific name changes based on research results, covering a group of beetles. The applications are based on the databases of the Finnish Museum of Natural History and are used in a living lab environment on the web.", "recorded": "2011-06-01T16:35:00", "title": "Biological Names and Taxonomies on the Semantic Web -- Managing the Change in Scientific Conception"}, {"url": "iswc2011_thor_graph", "desc": "Annotation graph datasets are a natural representation of\r\nscientifi\fc knowledge. They are common in the life sciences where genes\r\nor proteins are annotated with controlled vocabulary terms (CV terms)\r\nfrom ontologies. The W3C Linking Open Data (LOD) initiative and\r\nsemantic Web technologies are playing a leading role in making such\r\ndatasets widely available. Scientists can mine these datasets to discover\r\npatterns of annotation. While ontology alignment and integration across\r\ndatasets has been explored in the context of the semantic Web, there is\r\nno current approach to mine such patterns in annotation graph datasets.\r\nIn this paper, we propose a novel approach for link prediction; it is a preliminary task when discovering more complex patterns. Our prediction\r\nis based on a complementary methodology of graph summarization (GS)\r\nand dense subgraphs (DSG). GS can exploit and summarize knowledge\r\ncaptured within the ontologies and in the annotation patterns. DSG uses\r\nthe ontology structure, in particular the distance between CV terms, to\r\n\ffilter the graph, and to \ffind promising subgraphs. We develop a scoring\r\nfunction based on multiple heuristics to rank the predictions. We perform\r\nan extensive evaluation on Arabidopsis thaliana genes.", "recorded": "2011-10-26T11:00:00", "title": "Link prediction for annotation graph datasets using graph summarization"}, {"url": "eswc2013_palmero_aprosio_expansion", "desc": "DBpedia is a project aiming to represent Wikipedia content in RDF triples. It plays a central role in the Semantic Web, due to the large and growing number of resources linked to it. Nowadays, only 1.7M Wikipedia pages are deeply classified in the DBpedia ontology, although the English Wikipedia contains almost 4M pages, showing a clear problem of coverage. In other languages (like French and Spanish) this coverage is even lower. The objective of this paper is to define a methodology to increase the coverage of DBpedia in different languages. The major problems that we have to solve concern the high number of classes involved in the DBpedia ontology and the lack of coverage for some classes in certain languages. In order to deal with these problems, we first extend the population of the classes for the different languages by connecting the corresponding Wikipedia pages through cross-language links. Then, we train a supervised classifier using this extended set as training data. We evaluated our system using a manually annotated test set, demonstrating that our approach can add more than 1M new entities to DBpedia with high precision (90%) and recall (50%). The resulting resource is available through a SPARQL endpoint and a downloadable package.", "recorded": "2013-05-28T12:30:00", "title": "Automatic expansion of DBpedia exploiting Wikipedia cross-language information"}, {"url": "machine_pinter_natural_language", "desc": "We outline a Web-based architecture that serves the construction of\r\ntransdisciplinary knowledge and is supported by machine intelligence. At the\r\nheart of the architecture is the interaction between a repository of concepts\r\nand the machine intelligence. The repository is an ontology integrated with a\r\nWiki; each concept in the ontology is grounded in the natural language text of\r\nthe Wiki. The machine intelligence exploits structured sparse coding and helps\r\nusers interact with the concept repository. Most importantly, it helps\r\npractitioners of different fields understand each other by explaining unknown\r\nterminology in the Wiki, and it facilitates creating and maintaining content.\r\nThese two components evolve together: as the concept repository grows, the\r\nintelligence performs better. Furthermore, extending the concept repository\r\nsemi-automatically becomes easier.\r\n\r\nTo support wide contribution and ensure the high quality of the accumulated\r\nknowledge, content is divided into two types: drafts and articles. Anyone who\r\nregisters can create and edit drafts, but only drafts that pass a voting\r\nprocedure and are approved by an Editorial Board can become articles. Articles\r\nare very similar to scientific papers: they undergo peer-review and contain\r\nverified knowledge. Two communities have already started using these portals in\r\nthe domains of robotic surgery and education.", "recorded": "2013-04-11T14:54:00", "title": "Natural language processing supported transdisciplinary crowdsourcing"}, {"url": "reasecs_reitbauer_wfdeu", "desc": "Als qualifizierendes Vertiefungsangebot zu Modul-06 vermittelt Ihnen dieser Workshop Grundlagen des Ontology-Engineerings und den Gebrauch leistungsf\u00e4higer Editoren. Unter fachkundiger Anleitung f\u00fchrt Sie unser Ontologie-Experte Alois Reitbauer (Profactor, Steyr) durch ein Fallstudien-Projekt und zeigt, wie Strukturmodelle semantischer Netze durch formale Logik erweitert werden k\u00f6nnen.", "recorded": "2007-02-01T00:00:00", "title": "Tool-Workshop Ontologie-Editoren: Werkzeuge f\u00fcr die Entwicklung und Pflege Semantischer Systeme"}, {"url": "iswc08_moller_itsr", "desc": "We will provide a brief introduction to OWL, in fact OWL2, and the underlying Description Logic, clarifying the semantics and providing examples to help the understanding of this admittedly complex formalism. In particular, we will discuss common misunderstandings around OWL and OWL2, explain the open world assumption, inferences, and the functionality of reasoners. We will use the RacerPro reasoner to demonstrate the benefit of using reasoning for query answering over ontologies. Scalability issues with respect to expressive ontologies as well as huge assertional knowledge bases are discussed. ", "recorded": "2008-10-27T09:00:00", "title": "Reasoning for Ontology Engineering and Usage"}, {"url": "iswc06_hodgson_delod", "desc": "Currently, one of the most practical application spaces for Semantic Web technologies is creating an ontological layer over existing legacy databases. Such layering allows flexible applications to be built without the cost of restructuring large amounts of data while maintaining the performance advantages of a relational database. Whereas applications designed to directly query a database encode business logic in specific queries, ontological layer offers a flexible framework whereby dynamically generated queries are resilient to schema changes.\r This same approach can be used to query multiple decentralized databases from a seemingly centralized point of view, allowing access to multiple database schemas via a single interface. In an ontology, Semantic Web technologies such as RDFS, OWL and SWRL can be used to specify composition rules and abstractions, making it possible to answer complex questions without developing complex queries.\r TopQuadrant has applied this approach to develop and deploy a flexible faceted search system over a network of large, decentralized legacy databases. The system uses ontologies in two distinct ways: as an abstraction layer over an underlying relational data model; and as a search interface model driving the system itself. This model-based approach allows dynamic system configuration simply through changes to the model. The model controls what data can be searched, what facets can be used for building queries, and even how data should be displayed.\r The system combines the structured power of ontologies with more conventional keyword-based search over a related unstructured document corpus. The resulting hybrid system provides capabilities beyond what is possible with either approach alone.\r This talk will describe the process used for developing the ontological layer; discuss challenges and technical solutions in integrating the databases and bringing together structured and unstructured search. We will also show the benefits of using ontology to specify the search interface and interaction.", "recorded": "2006-11-08T00:00:00", "title": "Industry 2: Deploying Enterprise Level, Ontology-Driven Faceted Search"}, {"url": "iswc2011_makela_booksampo", "desc": "BookSampo is a semantic portal in use, covering metadata about practically all Finnish \ffiction literature of Finnish public libraries on a work level. The system introduces a variety of semantic web novelties\r\ndeployed into practise: The underlying data model is based on the emerging functional, content-centered metadata indexing paradigm using RDF. Linked Data principles are used for mapping the metadata with tens of interlinked ontologies in the national FinnONTO ontology infrastructure. The contents are also linked with the large Linked Data repository of related cultural heritage content of CultureSampo. BookSampo is actually based on using CultureSampo as a semantic web service,\r\ndemonstrating the idea of re-using semantic content from multiple perspectives without the need for modifications. Most of the content has been transformed automatically from existing databases, with the help of ontologies derived from thesauri in use in Finland, but in addition tens of volunteered librarians have participated in a Web 2.0 fashion in annotating and correcting the metadata, especially regarding older litarature. For this purpose, semantic web editing tools and public ONKI ontology services were created and used. The paper focuses on lessons learned in the process of creating the semantic web basis of BookSampo.", "recorded": "2011-10-27T15:00:00", "title": "BookSampo - Lessons Learned in Creating a Semantic Portal for Fiction Literature"}, {"url": "eswc2015_wohlgenannt_ontology_learning", "desc": "Ontology learning (OL) aims at the (semi-)automatic acquisition\r\nof ontologies from sources of evidence, typically domain text.\r\nRecently, there has been a trend towards the application of multiple\r\nand heterogeneous evidence sources in OL. Heterogeneous sources provide\r\nbenefits, such as higher accuracy by exploiting redundancy across\r\nevidence sources, and including complementary information. When using\r\nevidence sources which are heterogeneous in quality, amount of data provided\r\nand type, then a number of questions arise, for example: How many\r\nsources are needed to see significant benefits from heterogeneity, what is\r\nan appropriate number of evidences per source, is balancing the number\r\nof evidences per source important, and to what degree can the integration\r\nof multiple sources overcome low quality input of individual sources?\r\nThis research presents an extensive evaluation based on an existing OL\r\nsystem. It gives answers and insights on the research questions posed for\r\nthe OL task of concept detection, and provides further hints from experience\r\nmade. Among other things, our results suggest that a moderate\r\nnumber of evidences per source as well as a moderate number of sources\r\nresulting in a few thousand data instances are sufficient to exploit the\r\nbenefits of heterogeneous evidence integration.", "recorded": "2015-06-03T16:00:00", "title": "Leveraging and Balancing Heterogeneous Sources of Evidence in Ontology Learning"}, {"url": "iswc2013_knoblock_data_sources", "desc": "Semantic models of data sources and services provide support to automate many tasks such as source discovery, data integration, and service composition, but writing these semantic descriptions by hand is a tedious and time-consuming task. Most of the related work focuses on automatic annotation with classes or properties of source attributes or input and output parameters. However, constructing a source model that includes the relationships between the attributes in addition to their semantic types remains a largely unsolved problem. In this paper, we present a graph-based approach to hypothesize a rich semantic description of a new target source from a set of known sources that have been modeled over the same domain ontology. We exploit the domain ontology and the known source models to build a graph that represents the space of plausible source descriptions. Then, we compute the top k candidates and suggest to the user a ranked list of the semantic models for the new source. The approach takes into account user corrections to learn more accurate semantic descriptions of future data sources. Our evaluation shows that our method produces models that are twice as accurate than the models produced using a state of the art system that does not learn from prior models.", "recorded": "2013-10-25T12:35:01", "title": "A Graph-Based Approach to Learn Semantic Descriptions of Data Sources"}, {"url": "iswc2013_palmero_aprosio_dbpedia", "desc": "DBpedia is a large-scale knowledge base that exploits Wikipedia as primary data source. The extraction procedure requires to manually map Wikipedia infoboxes into the DBpedia ontology. Thanks to crowdsourcing, a large number of infoboxes has been mapped in the English DBpedia. Consequently, the same procedure has been applied to other languages to create the localized versions of DBpedia. However, the number of accomplished mappings is still small and limited to most frequent infoboxes. Furthermore, mappings need maintenance due to the constant and quick changes of Wikipedia articles. In this paper, we focus on the problem of automatically mapping infobox attributes to properties into the DBpedia ontology for extending the coverage of the existing localized versions or building from scratch versions for languages not covered in the current version. The evaluation has been performed on the Italian mappings. We compared our results with the current mappings on a random sample re-annotated by the authors. We report results comparable to the ones obtained by a human annotator in term of precision, but our approach leads to a significant improvement in recall and speed. Specifically, we mapped 45,978 Wikipedia infobox attributes to DBpedia properties in 14 different languages for which mappings were not yet available. The resource is made available in an open format.", "recorded": "2013-10-24T14:20:01", "title": "Towards an automatic creation of localized versions of DBpedia"}, {"url": "reasecs_hodgson_delod", "desc": "Currently, one of the most practical application spaces for Semantic Web technologies is creating an ontological layer over existing legacy databases. Such layering allows flexible applications to be built without the cost of restructuring large amounts of data while maintaining the performance advantages of a relational database. Whereas applications designed to directly query a database encode business logic in specific queries, ontological layer offers a flexible framework whereby dynamically generated queries are resilient to schema changes. This same approach can be used to query multiple decentralized databases from a seemingly centralized point of view, allowing access to multiple database schemas via a single interface. In an ontology, Semantic Web technologies such as RDFS, OWL and SWRL can be used to specify composition rules and abstractions, making it possible to answer complex questions without developing complex queries. TopQuadrant has applied this approach to develop and deploy a flexible faceted search system over a network of large, decentralized legacy databases. The system uses ontologies in two distinct ways: as an abstraction layer over an underlying relational data model; and as a search interface model driving the system itself. This model-based approach allows dynamic system configuration simply through changes to the model. The model controls what data can be searched, what facets can be used for building queries, and even how data should be displayed. The system combines the structured power of ontologies with more conventional keyword-based search over a related unstructured document corpus. The resulting hybrid system provides capabilities beyond what is possible with either approach alone. This talk will describe the process used for developing the ontological layer; discuss challenges and technical solutions in integrating the databases and bringing together structured and unstructured search. We will also show the benefits of using ontology to specify the search interface and interaction.\n\nThis presentation was held at the industry track of the International Semantic Web Conference 2006 (ISWC 2006), the video is provided by videolectures.net", "recorded": "2007-08-06T00:00:00", "title": "Deploying Enterprise Level, Ontology-Driven Faceted Search"}, {"url": "eswc09_janowicz_sdaanss", "desc": "While semantic similarity plays a crucial role for human categorization and reasoning, computational similarity measures have also been applied to fields such as semantics-based information retrieval or ontology engineering. Several measures have been developed to compare concepts specified in various description logics. In most cases, these measures are either structural or require a populated ontology. Structural measures fail with an increasing expressivity of the used description logic, while several ontologies, e.g., geographic feature type ontologies, are not populated at all. In this paper, we present an approach to reduce inter-concept to inter-instance similarity and thereby avoid the canonization problem of structural  measures. The novel approach, called SIM-DL_A, reuses existing similarity functions  such as co-occurrence or network measures from our previous SIM-DL measure. The required instances for comparison are derived from the completion tree of a slightly modified DL-tableau algorithm as used for satisfiability checking. Instead of trying to find one (clash-free) model, the tableau algorithm generates a set of proxy individuals used for comparison. The paper presents the algorithm, alignment matrix, and similarity functions as well as a detailed example.", "recorded": "2009-06-04T14:30:00", "title": "SIM-DL_A: A Novel Semantic Similarity Measure for Description Logics Reducing Inter-Concept to  Inter-Instance Similarity"}, {"url": "reasecs_reitbauer_wfdeu1", "desc": "Als qualifizierendes Vertiefungsangebot zu Modul-06 (Semantic Models: Informationsintegration und Wissenmodellierung durch Ontologien) vermittelt Ihnen dieser Workshop Grundlagen des Ontology-Engineerings und den Gebrauch leistungsf\u00e4higer Editoren. Unter fachkundiger Anleitung f\u00fchrt Sie unser F&E-Experte Alois Reitbauer (profactor Steyr) durch ein Fallstudien-Projekt und zeigt, wie Strukturmodelle semantischer Netze durch formale Logik erweitert werden k\u00f6nnen.", "recorded": "2006-11-02T00:00:00", "title": "Tool-Workshop Ontologie-Editoren: Werkzeuge f\u00fcr die Entwicklung und Pflege Semantischer Systeme"}, {"url": "iswc06_sattler_uofw7", "desc": "The purpose of this tutorial is to help attendees gain sufficient experience of working with OWL and tools to allow them to fruitfully explore new ontologies that they may encounter. In other words, they should be able to do the equivalent of \u201cview source\u201d on an ontology. Also, they will get better fluency in the use and abuse of OWL by examining features, limitations, and workarounds in real contexts, as well as gaining an understanding of the impact of future extensions of OWL, in particular of rules and the proposed revision of the language called OWL 1.1.", "recorded": "2006-11-05T00:00:00", "title": "Learning from the Masters: Understanding Ontologies found on the Web - Part 7"}, {"url": "single_gw_demo", "desc": "The following video was made to show the benefits of the Euridice the cargo centric approach. The video tells a story from the point of\r\nview of a cargo item that was sent from the consolidation warehouse to\r\nthe customer.\\\\\r\nIt shows a possible transportation chain without disruption of\r\ninformation flow and physical flow of goods, and explains the used\r\nmulti-agent-system technology. With this technology the cargo will be\r\ntransformed into intelligent cargo by adding devices running software\r\nagents.\r\nDuring the transportation process some problems occur and solutions to\r\nsolve them with the agent based system are shown. The problems are:\r\n* An item was overlooked in the warehouse\r\n* The temperature deviate from specification\r\n* A detour create a change in the estimated arrival time (ETA)\r\n\r\nThe main features that are shown:\\\\\r\n* Autonomy: no central control, cargo item watch their own status, decide when to communicate\r\n* Real-time tracking: No check-pointing, up to date information always available\r\n* Cross-organizational processes: No isolated processes at the various actors along supply chain with IT-interaction at boundaries, but single cargo-centric process consuming services from actors\r\n* Ontology reasoning: Intelligent configuration of cargo agents through ontology based deductions of missing parameters\r\n* Local cooperation: Cargo items interact with each other and information providers like trucks for accessing required information / sensors ", "recorded": "2011-02-03T14:01:58", "title": "GW pilot case"}, {"url": "reasecs_rosati_sci", "desc": "We present some recent results on the definition of logic-based\r\nsystems integrating ontologies and rules.  In particular, we take into\r\naccount ontologies expressed in Description Logics and rules expressed\r\nin Datalog (and its nonmonotonic extensions).  We first introduce the\r\nmain issues that arise in the integration of ontologies and rules. In\r\nparticular, we focus on the following aspects: (i) from the semantic\r\nviewpoint, ontologies are based on open-world semantics, while\r\nrules are typically interpreted under closed-world semantics. This\r\nsemantic discrepancy constitutes an important obstacle for the\r\ndefinition of a meaningful combination of ontologies and rules; (ii)\r\nfrom the reasoning viewpoint, the interaction between an ontology and\r\na rule component is very hard to handle, and does not preserve\r\ndecidability and computational properties: e.g., starting from an\r\nontology in which reasoning is decidable and a rule base in which\r\nreasoning is decidable, reasoning in the formal system obtained by\r\nintegrating the two components may not be a decidable problem.  Then,\r\nwe briefly survey the main approaches for the integration of\r\nontologies and rules, with special emphasis on how they deal with the\r\nabove mentioned issues, and present in detail one of such approaches,\r\ni.e., DL+LOG. Finally, we illustrate the main open problems in this\r\nresearch area, pointing out what still prevents us from the\r\ndevelopment of both effective and expressive systems able to integrate\r\nontologies and rules.\r\n\r\nDocuments:\r\n;[[Ontologies.pdf]]", "recorded": "2006-08-24T00:00:00", "title": "Integrating ontologies and rules: semantic and computational issues"}, {"url": "envision", "desc": "The [[http://www.envision-project.eu/|ENVISION project]] is the follow-up of the SWING project, adopting and extending its results. It provides an ENVIronmental Services Infrastructure with ONtologies that aims to support non ICT-skilled users in the process of semantic discovery and adaptive chaining and composition of environmental services. Innovations in ENVISION are: on-the-Web enabling and packaging of technologies for their use by non ICT-skilled users, support for migrating environmental models to be provided as models as a service (Maas), and the use of data streaming information for harvesting information for dynamic building of ontologies and adapting service execution.\r\n\r\nThe ENVISION Environmental Decision Portal supports the creation of web-based applications enabled for dynamic discovery and visual service chaining. The ENVISION Ontology Infrastructure provides support for visual semantic annotation tools and multilingual ontology management. The ENVISION Execution Infrastructure comprises a semantic discovery catalogue and a semantic service mediator based on a generic semantic framework and adaptive service chaining with data-driven adaptability.\r\n\r\nScenario requirements and pilots from the ENVISION user partners focus on landslide hazard assessment and environmental pollution (oil spills) decision support systems. The benefit of ENVISION for the wider community will be better accessibility to modelling tools using the Web and it will provide greater flexibility through improved connections to distributed sources of information.", "recorded": "2010-05-13T13:26:17", "title": "ENVISION - ENVIronmental Services Infrastructure with ONtologies"}, {"url": "iswc2014_qu_camo", "desc": "Metadata is a vital factor for effective management, organization and retrieval of multimedia content. In this paper, we introduce CAMO, a new system developed jointly with Samsung to enrich multimedia metadata by integrating Linked Open Data (LOD). Large-scale, heterogeneous LOD sources, e.g., DBpedia, LinkMDB and MusicBrainz, are integrated using ontology matching and instance linkage techniques. A mobile app for Android devices is built on top of the LOD to improve multimedia content browsing. An empirical evaluation is conducted to demonstrate the effectiveness and accuracy of the system in the multimedia domain.", "recorded": "2014-10-21T14:40:00", "title": "CAMO: Integration of Linked Open Data for Multimedia Metadata Enrichment"}, {"url": "dataforum2014_wecel_linked_data", "desc": "Linked open data about public contracts can be valuable for both enterprises and public bodies. One of the aims of the EU LOD2 project is to make public contract data available as linked data, with the help of a Public Contracts Ontology, and to apply analytic methods on the top of such data. A wide range of analytical (data mining) methods is being applied, currently on Czech and Polish data, including both descriptive and predictive approaches, and both directly on RDF data and on (interlinked) data transformed back to tabular format.", "recorded": "2014-03-19T12:45:00", "title": "Advanced Exploration of Public Procurement Data in Linked Data Paragigm "}, {"url": "rease_zaihrayeu_oma", "desc": "This is a one-hour video recording of the presentation of Ilya Zaihrayeu at the First Asian Autumn School on the Semantic Web. It comprises the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nOntology Matching and Alignment\r\nMatching operation\r\nExample: two XML schemas\r\nExample: two ontologies\r\nStatement of the problem\r\nApplications\r\nApplications: Information integration\r\nApplications: summary\r\nClassification of basic techniques\r\nClassification of techniques (simplified)\r\nBasic techniques\r\nSystems: analytical comparison\r\nSemantic matching in a nutshell\r\nConcept of a label & concept at a node\r\nFour macro steps\r\nStep 1: compute concepts at labels\r\nStep 2: compute concepts at nodes\r\nStep 3: compute relations between (atomic) concepts at labels\r\nStep 3: Element level semantic matchers\r\nStep 4: compute relations between concepts at nodes\r\nStep 4: Example of a node matching task\r\nMotivation: Problem of low recall (incompletness)\r\nOn increasing the recall: an overview\r\nIterative semantic matching (ISM)\r\nISM: Discovering critical points - example\r\nISM: Generating candidate axioms\r\nISM: generating candidate axioms Hierarchy Distance\r\nTest cases\r\nMatching systems\r\nExperimental results, test case #4\r\nExperimental results, test case #5\r\nExperimental results, #6,7,8: incompleteness\r\nExperimental results, #6,7,8: incompleteness (OAEI-2006 comparison)\r\nOutline\r\nSummary\r\nFuture challenges\r\n(Some) references\r\nYou are welcome to attend (11 Nov):\r\n'Thank you'", "recorded": "2007-11-26T00:00:00", "title": "Ontology Matching and Alignment"}, {"url": "rease_goble_lmmc", "desc": "This is a one-hour video recording of the presentation of Carole Goble at the KnowledgeWeb summer school 2005. It comprises either the video synchronized with the slides (but requires Quicktime, hence Windows or MacOS, otherwise the slides have to be switched manually).\r\n\r\nTable of Contents:\r\n\r\nA love match? or A marriage of convenience ?\r\nThe Groom\r\nQuantity explosion\r\nSharing expensive resources more effectively, on demand\r\nCollaboratory\r\nBuilding Global Knowledge Communities\r\nVirtual Organisations\r\nGrid Computing characteristics\r\nAvaki\r\nProperties of VOs\r\nPartnership SLA and VO Life Cycle\r\n50,000 feet!\r\nWhat is a Grid?\r\nBIRN\r\nLots of Grids!\r\nGrid Middleware The Grid discovers Web Services\r\nOpen Grid Services Architecture ongoing since early 2002\r\nWSRF & WS-Notification\r\nWSRF is the instruction set of the Grid Thierry Priol EGEE\r\nOGSA Data Services\r\nMyths and Truths\r\nSo what would the Grid get from a marriage with the Semantic Web?\r\nGrid Middleware Enables Resource Sharing\r\nGrid infrastructure driven by metadata Knowledge permeates the Grid\r\nMetadata - a way to deal with aspects\r\nVirtual Organizations and Semantics\r\nGrid Reality\r\nThe ongoing convergence ...\r\nThe Semantic Grid is ...\r\nProblems\r\nAgreement ? VO Security Policy\r\nGrid Service Discovery and Registries\r\nProvenance and annotation\r\nConsuming Semantic Metadata knowledge advisor integrated with the domain script editor\r\nTranslation Service Unicore&lt;-&gt;GLUE\r\nmapping real time discussions/group sense making\r\nGEON: data annotation\r\nSemantic Annotation\r\nEarthSciencesGrid VO Ontology\r\nSo what gets the Gridders excited?\r\nHow will they live together? What does this mean architecturally?\r\nSemantic Descriptions\r\nOntology as an OGSA-DAI Realization\r\nFrom Grid to Semantic Grid\r\nAn ontology for WSRF Properties for Virtual Organisations\r\nA marriage is a partnership\r\nYolandas comments\r\nRequirements of an Agent Platform\r\nHey! Lets use Grid Services!\r\nRequirements Addressed\r\nIsn't this all Semantic Web Technologies? ...\r\nBioDASH Bridging Chemistry and Molecular Biology\r\nCollaboratory for Multi-Scale Chemical Science\r\nAn engagement?\r\nA perfect couple\r\nThe families\r\nBuilding Bridges\r\nSemantic Grid courtship\r\nThe Engagement Party\r\nThe Engagement Party goes on into the night\r\nA marriage is a VO, and needs negotiation too! Divorce???\r\nIs the bride mature enough for marriage?\r\nSummary", "recorded": "2006-12-06T00:00:00", "title": "Semantic Grid: A love match? or A marriage of convenience?"}, {"url": "semsearch09_mika_itdss", "desc": "In this paper, we propose a method to create aggregated representations of the information needs of Web users when searching for particular types of objects. We suggest this method as a way to investigate the gap between what Web search users are expecting to \u00afnd and the kind of information that is provided by Semantic Web datasets formatted according to a particular ontology. We evaluate our method qualitatively by measuring its power as a query completion mechanism. Last, we perform a qualitative evaluation comparing the information Web users search for with the information available in Dbpedia, the structured data representation of Wikipedia.", "recorded": "2009-04-21T10:15:00", "title": "Investigating the Demand Side of Semantic Search through Query Log Analysis"}, {"url": "semantic_ivanova_taxonomies", "desc": "With the increased use of ontologies in semantically-enabled applications, the issues of debugging and aligning ontologies have become increasingly important. The quality of the results of such applications is directly dependent on the quality of the ontologies and mappings between the ontologies they employ. A key step towards achieving high quality ontologies and mappings is discovering and resolving modeling defects, e.g., wrong or missing relations and mappings. In this video we demonstrate a system for aligning taxonomies, the most used kind of ontologies, and debugging taxonomies and their alignments, where ontology alignment is treated as a special kind of debugging.", "recorded": "2013-06-20T18:09:41", "title": "A System for Aligning Taxonomies and Debugging Taxonomies and Their Alignments"}, {"url": "iswc2013_le_duc_shoiq", "desc": "The Semantic Web makes an extensive use of the OWL DL ontology language, underlied by the SHOIQ description logic, to formalize its resources. In this paper, we propose a decision procedure for this logic extended with the transitive closure of roles in concept axioms, a feature needed in several application domains. The most challenging issue we have to deal with when designing such a decision procedure is to represent infinitely non-tree-shaped models, which are different from those of SHOIQ ontologies. To address this issue, we introduce a new blocking condition for characterizing models which may have an infinite non-tree-shaped part.", "recorded": "2013-10-24T15:15:01", "title": "A decision procedure for SHOIQ with transitive closure of roles"}, {"url": "semsearch09_tummarello_tecsse", "desc": "We illustrate the works toward implementing an Entity Centric Semantic Search Engine (ECSSE). ECSSE leverages the Sindice Semantic Web Index to find and combine together semantically structured data published on the web. With respect to previous Semantic Web Data integrators, ECSSE, uses an holistic approach in which large scale semantic web indexing, logic reasoning, data aggregation heuristics, ad hoc ontology consolidation, external services and user interaction all play together to create rich entity descriptions and live, embeddable data mash ups.", "recorded": "2009-04-21T12:00:00", "title": "Towards ECSSE: live Web of Data search and integration"}, {"url": "mlsb09_juty_mfsb", "desc": "The ease with which modern computational and theoretical tools can be applied to modeling has led to an exponential increase in the size and complexity of computational models in biology. At the same time, the accelerating pace of progress also highlights limitations in current approaches to modeling. One of these limitations is the insufficient degree to which the semantics and qualitative behaviour of models are systematised and expressed formally enough to support unambiguous interpretation by software systems. As a result, human intervention is required to interpret and connect a model's mathematical structures with information about the its meaning (semantics). Often, this critical information is usually communicated through free-text descriptions or non-standard annotations; however, free-text descriptions cannot easily be interpreted by current modeling tools.\r\nWe will describe three efforts to standardize the encoding of missing semantics for kinetic models. The overall approach involves connecting model elements to common, external sources of information that can be extended as existing knowledge is expanded and refined. These external sources are carefully managed public, free, consensus ontologies: the Systems Biology Ontology (SBO), the Kinetic Simulation Algorithm Ontology (KiSAO), and the Terminology for the Description of Dynamics (TeDDy). Together they provide a means for annotating a model with stable and perennial identifiers which reference machine readable regulated terms defining the semantics of the three facets of the modeling process 1) the relationship between the model and the biology it aims to describe, 2) the process used to simulate the model and obtain expected results, and 3) the results themselves.", "recorded": "2009-09-06T11:20:00", "title": "Metadata For Systems Biology"}, {"url": "samt08_rodriguez_doncel_smac", "desc": "Nowadays, users want to be able to access their computing resources and all kind of content using different types of devices, from wireless portable devices to stationary devices connected to local area networks in a way that context-based content adaptation has become essential for Universal Multimedia Access (UMA) scenarios. This content adaptation represents the modification of an object possibly subjected to the Intellectual Property (IP) law, and the original author or rights holder should be able to retain the possibility of vetoing or restricting the operation. Whereas MPEG-21 addresses the adaptation in the part 7 of the standard (DIA, Digital Item Adaptation), and the Rights Expressions Language (REL) in the part 5, it still lacks of an integrated approach of them.\r\nThis paper considers the authorisation of context-aware content adaptation in a generic multimedia scenario based on the integration of two new standard-based ontologies providing a bridge between them at a semantic level. First, it is presented the Context Aware Ontology (CAO), which models the Universal Environment Descriptor (UED) tool contained in the MPEG-21 DIA standard. Then, it is introduced the Adaptation Authoriser based on the RRDOnto (Represent Rights Data) ontology, which grants that IP rights will be respected along the Value Chain while supporting the MPEG-21 License model. Finally, the integration of both is described, providing a joint model that allows the adaptation to be controlled by Content Creators and Content Distributors. ", "recorded": "2008-12-04T15:45:00", "title": "A Semantic Model for the Authorisation of Context-Aware Content Adaptation"}, {"url": "iswc2013_del_vescovo_logic_based_modules", "desc": "For ontology reuse and integration, a number of approaches have been devised that aim at identifying modules, i.e., suitably small sets of \u201crelevant\u201d axioms from ontologies. Here we consider three logically sound notions of modules: MEX modules, only applicable to inexpressive ontologies; modules based on semantic locality, a sound approximation of the first; and modules based on syntactic locality, a sound approximation of the second (and thus the first), widely used since these modules can be extracted from OWL DL ontologies in time polynomial in the size of the ontology.\r\n\r\nIn this paper we investigate the quality of both approximations over a large corpus of ontologies, using our own implementation of semantic locality, which is the first to our knowledge. In particular, we show with statistical significance that, in most cases, there is no difference between the two module notions based on locality; where they differ, the additional axioms can either be easily ruled out or their number is relatively small. We classify the axioms that explain the rare differences into four kinds of \u201cculprits\u201d and discuss which of those can be avoided by extending the definition of syntactic locality. Finally, we show that differences between MEX and locality-based modules occur for a minority of ontologies from our corpus and largely affect (approximations of) expressive ontologies \u2013 this conclusion relies on a much larger and more diverse sample than existing comparisons between MEX and syntactic locality-based modules.", "recorded": "2013-10-24T15:35:01", "title": "Empirical Study of Logic-Based Modules: Cheap Is Cheerful"}, {"url": "rease_kerrigan_wsmt", "desc": "This is a one-hour video recording of the tutorial of Mick Kerrigan at the First Asian Autumn School on the Semantic Web. It comprises the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nThe Web Service Modeling Toolkit (WSMT)\r\nOverview\r\nWeb to Web 2.0\r\nWeb Services\r\nA Web of Applications\r\nThe Semantic Web\r\nWeb 3.0\r\nSemantic Web Services\r\nService Web\r\nWSMO Recap\r\nWSMO, WSML and SEE\r\nWSML\r\nWSML Layering\r\nHuman readable Syntax\r\nReasoning with WSML\r\nSemantic Execution Environments\r\nDiscovery\r\nComposition\r\nRanking and Selection\r\nMediation\r\nInvocation\r\nSemantic Web Service Life Cycle\r\nThe Web Service Modeling Toolkit (WSMT)\r\nWhy Tools?\r\nWhy IDE?\r\nWSMT Functionality\r\nWSML\r\nWSML Text Editor\r\nWSML Form based Editor\r\nWSML Visualizer\r\nOutline View\r\nValidation\r\nValidation & the Problem View\r\nWSML Navigator\r\nTesting\r\nTesting Ontologies\r\nWSML Reasoning View\r\nTesting Web Services and Goals\r\nWSML Discovery View\r\nInterfacing with a SEE\r\nBrowsing WSML in a SEE\r\nRetrieving WSML from a SEE\r\nStoring WSML to a SEE\r\nInvoking a SEE\r\nOntology Mediation\r\nOntology Mediation (WSMX/WSMT)\r\nAbstract Mapping Language\r\nView based Editor\r\nView based Editor (PartOf View)\r\nView based Editor (InstanceOf View)\r\nMapping Views\r\nMapping Views (Concept2Concept)\r\nMapping Views (Attribute2Attribute)\r\nTesting\r\nMapping Unit Test View\r\nQuestions?", "recorded": "2007-11-26T00:00:00", "title": "Web Service Modelling Toolkit (WSMT)"}, {"url": "reasecs_rector_gr", "desc": "The slides cover a lecture \"Ontological and Practical Issues in using\na Description Logic to Represent Medical Concepts: Experience from GALEN\".\nGALEN seeks to provide re-usable terminology resources for clinical systems.\nThe heart of GALEN is the Common Reference Model (CRM) formulated in a\nspecialised description logic. The CRM is based on a set of principles\nthat have evolved over the period of the project and illustrate key issues\nto be addressed by any large medical ontology. The principles on which\nthe CRM is based are discussed followed by a more detailed look at the\nactual mechanisms employed. Finally the structure is compared with\nother biomedical ontologies in use or proposed.\n\n\nDocuments:\n;[[GALEN.pdf]]", "recorded": "2006-11-13T00:00:00", "title": "GALEN Revisited"}, {"url": "eswc2013_dumontier_data", "desc": "Bio2RDF currently provides the largest network of Linked Data for the Life Sciences. Here, we describe a significant update to increase the overall quality of RDFized datasets generated from open scripts powered by an API to generate registry-validated IRIs, dataset provenance and metrics, SPARQL endpoints, downloadable RDF and database files. We demonstrate federated SPARQL queries within and across the Bio2RDF network, including semantic integration using the Semanticscience Integrated Ontology (SIO). This work forms a strong foundation for increased coverage and continuous integration of data in the life sciences.", "recorded": "2013-05-30T11:30:00", "title": "Bio2RDF Release 2: Improved coverage, interoperability and provenance of Life Science Linked Data"}, {"url": "eswc2015_kaempgen_similar_genes", "desc": "Physicians nowadays have to consider a diverse range of data sources when treating a patient. Semantic clinical data warehouses allow to easily add new data and to pro-actively help the physician making sense of the data. In this work-in-progress paper we investigate an approach  of  using  Linked  Data  as  the  access  mechanism  and  a  graph database for storage and query processing. We describe lessons learned from a case study of discovering similar genes where we use an existing similarity metric to derive new information, the Gene Ontology as a data\r\nsource, and SAP HANA as an efficient graph database. ", "recorded": "2015-05-31T09:00:00", "title": "Towards a Semantic Clinical Data Warehouse: A Case Study of Discovering Similar Genes"}, {"url": "solomon_zakova_plkdo", "desc": "Assembly of optimized knowledge discovery workfows requires awareness of and extensive knowledge about the principles and mutual relations between diverse  data processing and mining algorithms.We aim at alleviating this burden  by automatically proposing workfows for the given type of inputs and  required outputs of the discovery process. The methodology adopted in  this study is to define a formal conceptualization of knowledge types and data mining algorithms and design a planning algorithm, which extracts  constraints from this conceptualization for the given user's input-output  requirements. We demonstrate our approach in two use cases, one from  scientific discovery in genomics and another from advanced engineering.", "recorded": "2008-10-21T13:00:00", "title": "Planning to Learn with a Knowledge Discovery Ontology"}, {"url": "single_mladenic_semanticweb", "desc": "Machine Learning and Semantic web are covering conceptually different sides of the same story - Semantic Web\u2019s typical approach is top-down modeling of knowledge and proceeding down towards the data while Machine Learning is almost entirely data-driven bottom-up approach trying to discover the structure in the data and express it in the more abstract ways and rich knowledge formalisms. The talk will discuss possible interaction and usage of Machine Learning and Knowledge discovery for Semantic Web with emphases on ontology construction. In the second half of the talk we will take a look at some research using machine learning for Semantic Web and demos of the corresponding prototype systems.", "recorded": "2011-03-11T10:12:25", "title": "Machine Learning and Knowledge Discovery for Semantic Web"}, {"url": "eswc2011_noyer_measurement", "desc": "Exploration and analysis of vast empirical data is a cornerstone of the development and assessment of driver assistance systems. A common challenge is to apply the domain specific knowledge to the (mechanised) data handling, pre-processing and analysis process. Ontologies can describe domain specific knowledge in a structured way that is manageable for both humans and algorithms. This paper outlines an architecture to support an ontology based analysis process for data stored in databases. Build on these concepts and architecture, a prototype that handles semantic data annotations is presented. Finally, the concept is demonstrated in a realistic example. The usage of exchangeable ontologies generally allows the adaption of presented methods for different domains.", "recorded": "2011-06-01T17:00:00", "title": "Semantic technologies for describing measurement data in databases"}, {"url": "eswc09_munoz_ess", "desc": "The increasing number of functionally similar services requires the existence of a non-functional properties selection process based on the Quality of Service (QoS). Thus, in this article authors focus on the provision of a QoS model, an architecture and an implementation which enhance the selection process by the annotation of Service Level Agreement (SLA) templates with semantic QoS metrics. This QoS model is composed by a specification for annotating SLA templates files, a QoS conceptual model formed as a QoS ontology and selection algorithm. This approach, which is background compatible, provides interoperability among customer-providers and lightweight alternative. Finally, its applicability and benefits are shown by using examples of Infrastructure services.", "recorded": "2009-06-04T12:00:00", "title": "Enhancing Service Selection by Semantic QoS "}, {"url": "iswc2011_sengupta_semantics", "desc": "We present a new approach to adding closed world reasoning\r\nto the Web Ontology Language OWL. It transcends previous work on\r\ncircumscriptive description logics which had the drawback of yielding an\r\nundecidable logic unless severe restrictions were imposed. In particular,\r\nit was not possible, in general, to apply local closure to roles.\r\nIn this paper, we provide a new approach, called grounded circumscription, which is applicable to SROIQ and other description logics around\r\nOWL without these restrictions. We show that the resulting language is\r\ndecidable, and we derive an upper complexity bound. We also provide a\r\ndecision procedure in the form of a tableaux algorithm.", "recorded": "2011-10-26T11:00:00", "title": "Local closed world semantics: Grounded circumscription for OWL"}, {"url": "iswc07_kaufman_hunl", "desc": "Natural language interfaces offer end-users a familiar and\r convenient option for querying ontology-based knowledge bases. Several\r studies have shown that they can achieve high retrieval performance as\r well as domain independence. This paper focuses on usability and investigates\r if NLIs are useful from an end-user\u2019s point of view. To that end,\r we introduce four interfaces each allowing a different query language and\r present a usability study benchmarking these interfaces. The results of\r the study reveal a clear preference for full sentences as query language\r and confirm that NLIs are useful for querying Semantic Web data.", "recorded": "2007-11-14T14:00:00", "title": "How Useful are Natural Language Interfaces to the Semantic Web for Casual End-users? "}, {"url": "iswc09_mitchell_ptsw", "desc": "A key question to the future of the semantic web is \"how will we acquire structured information to populate the semantic web on a vast scale?\" One approach is to enter this information manually. A second approach is to take advantage of the great deal of structured information already present in various databases, and to develop common ontologies, publishing standards, and reward systems to make this data widely accessible. We consider here a third approach: developing software that automatically extracts structured information from unstructured text present on the web.\r\n\r\nThis talk will survey attempts to extract structured knowledge from unstructured text, and will focus on an approach with three characteristics that we hypothesize make it viable. First, in contrast to the very difficult problem of reading information from a single document, we consider the much easier problem of reading hundreds of millions of documents simultaneously, so that our system can extract facts that are stated many times by combining evidence from many documents. Second, our system begins with a given ontology that defines the types of information to be extracted, enabling it to focus its effort and to ignore most of the text which is irrelevant to the target ontology. Third, the system uses a new class of semi-supervised learning algorithms to learn how to extract information from web pages -- algorithms designed to achieve greater accuracy when given more complex ontologies. Our experiments show that this approach can produce knowledge bases containing tens of thousands of facts to populate given ontologies with approximately 90% accuracy, starting with only a handful of labeled training examples and 200 million unlabeled web pages.", "recorded": "2009-10-28T09:00:00", "title": "Populating the Semantic Web by Macro-Reading Internet Text"}, {"url": "iswc08_panel_schneider_owl", "desc": "The definition of OWL, the ontology language underlying the Semantic Web, is based on formal representation methods. This provides benefits, in that tools have a firm definition of what they are supposed to do, but can have problems, due to difficulty or expense of building tools or mismatch with needs. The panel will discuss whether the general idea of designing standard Semantic Web languages with steadily increasing power (e.g., the progression from RDF to RDFS to OWL to OWL 2 to \u2026) all based on formal methods is the right way to support the Semantic Web. What level of expressive power does the Semantic Web need? How should standard Semantic Web languages be designed? Does the Semantic Web even need formality?", "recorded": "2008-10-28T14:00:00", "title": "An OWL 2 Far?"}, {"url": "aaai2011_pangercic_shopping", "desc": "The video shows TUM-James (a PR2 robot) simulating the shopping task by\r\nbringing the groceries home and placing them in accordance to a priori\r\nlearnt organizational patterns\r\nin households.\r\nThe robot uses the 3D perception algorithms from point cloud library in\r\norder to detect object candidates in the\r\nstorage rack and system for textured objects detection in order to\r\nrecognize objects. Grasping and manipulation\r\nof the shopping basket is done using James's haptic capabilities.\r\nFinally, to\r\ninfer where do the objects belong to, TUM-James queries a system for\r\nknowledge modeling\r\nand resoning and computes the similarities (WUP similarity) to the other\r\nobjects in the kitchen's ontology\r\nusing techniques from semantic information retrieval.", "recorded": "2011-08-05T11:42:34", "title": "Shopping for Groceries and Putting Them Away"}, {"url": "yaleengl300s09_fry_lec23", "desc": "In this lecture on queer theory, Professor Paul Fry explores the work of Judith Butler in relation to Michel Foucault's History of Sexuality. Differences in terminology and methods are discussed, including Butler's emphasis on performance and Foucault's reliance on formulations such as \"power-knowledge\" and \"the deployment of alliance.\" Butler's fixation with ontology is explored with reference to Levi-Strauss's concept of the raw and the cooked. At the lecture's conclusion, Butler's interrogation of identity politics is compared with that of post-colonial and African-American theorists.\r\n\r\nReading assignment:\r\n\r\nFoucault, Michel. \"The History of Sexuality.\" In The Critical Tradition, pp. 1627-36\r\n\r\nButler, Judith. \"Imitation and Gender Insubordination.\" In The Critical Tradition, pp. 1707-18\r\n", "recorded": "2009-04-14T10:00:00", "title": "Lecture 23 - Queer Theory and Gender Performativity"}, {"url": "iswc2012_klarman_provenance_records", "desc": "Data provenance is the history of derivation of a data artifact from its original sources. As the real-life provenance records can likely cover thousands of data items and derivation steps, one of the pressing challenges becomes development of formal frameworks for their automated veri\ffication. In this paper, we consider data expressed in standard Semantic Web ontology languages, such as OWL, and de\ffine a novel verifi\fcation formalism called provenance speci\ffication logic, building on dynamic logic. We validate our proposal by modeling the test queries presented in The First Provenance Challenge, and conclude that the logic core of such queries can be successfully captured in our formalism.", "recorded": "2012-11-14T11:00:53", "title": "Formal Veri\fcation of Data Provenance Records"}, {"url": "dataforum2013_haase_user_access", "desc": "Scalable end-user access to Big Data is critical for effective data analysis and value creation: Engineers in industry spend a significant amount of their time searching for data that they require for their core tasks. In the Oil&Gas industry, for instance, 30\u201370% of engineers\u2019 time is spent looking for and assessing the quality of data.\r\n\r\nOptique is a large-scale European project focusing on the comprehensive and timely end-user access to very large data sets. In this presentation we describe how the concepts and technologies developed in Optique bring about a paradigm shift for data access by\r\n\r\n*providing a semantic end-to-end connection between users and data sources,\r\n*enabling users to rapidly formulate intuitive queries using familiar vocabularies and conceptualizations,\r\n*seamlessly accessing data spread across multiple distributed data sources, and thus\r\n*reducing the turnaround time for information requests from days to minutes.\r\n\r\nIn the talk we will discuss the key concepts behind the Optique platform, including\r\n\r\n*the central role of ontologies and declarative mappings to capture user conceptualizations and to transform user queries into highly optimized queries over the data sources,\r\n*integration of distributed heterogeneous data sources, including streams,\r\n*the exploitation of massively parallel technologies and holistic optimizations to maximize performance,\r\n*tools to support query formulation and ontology and mapping management, and\r\n*semi-automatic bootstrapping of ontologies and mappings and query driven ontology construction to minimize implementation overhead.\r\n\r\nWe will illustrate the value of the Optique platform through use cases from the case study partners in the energy domain: Siemens and Statoil.", "recorded": "2013-04-10T15:30:00", "title": "Scalable End-user Access to Big Data"}, {"url": "iswc08_liu_sobdpaciwms", "desc": "Metadata management is an important aspect of today\u2019s enterprise information systems. Metadata management systems are growing from toolspecific repositories to enterprise-wide metadata repositories. In this context, one challenge is the management of the evolving metadata whose schema or meta-model itself may evolve, e.g., dynamically-added properties, which are often hard to predict upfront at the initial meta-model design time; another challenge is to organize the metadata by semantically-rich classification schemes. In this paper, we present a practical system which provides support for users to dynamically manage semantically-rich properties and classifications in the IBM WebSphere Metadata Server (MDS) by integrating an OWL ontology repository. To enable the smooth acceptance of Semantic Web technologies for developers of commercial software which must run 24 hours/day, 7 days/week, the system is designed to consist of integrated modeling paradigms, with an integrated query language and runtime repository. Specifically, we propose the modeling of dynamic properties on structured metadata as OWL properties and the modeling of classification schemes as OWL ontologies for metadata classification. We present a natural extension to OQL (Object Query Language)-like query language to embrace dynamic properties and metadata classification. We also observe that hybrid storage, i.e., horizontal tables for structured metadata and vertical triple tables for dynamic properties and classification, is suitable for the storage and query processing of co-existing structured metadata and semantic metadata. We believe that our study and experience are not specific to MDS, but are valuable for the community trying to apply Semantic Web technologies to the structured data management area.\r\n\r\n", "recorded": "2008-10-28T10:30:00", "title": "Supporting Ontology-based Dynamic Property and Classification in WebSphere Metadata Server"}, {"url": "reasecs_hoppenbrouwers_owcfo", "desc": "The second OOA Workshop at the Human Capital Summit in Maastricht has been a great success. Nearly thirty attendees, some from academia and most from industry, followed the programme which was compiled of two sessions and a wrap-up.\n\nThe first session contained presentations of some relevant competency-oriented models and frameworks. The second session saw a managed, lively discussion centered around a 'linking ontology' which could explicitly show semantic overlaps and differences between the various competency models/frameworks. The third wrap-up session was brief and positioned the OOA workshop inside the HR-XML domain.\n\nhttp://www.ontology-advisory.org/node/72\n\nDocuments:\n;[[Workshop.pdf]]", "recorded": "2007-10-16T00:00:00", "title": "OOA Workshop on Competency Frameworks and Ontologies"}, {"url": "ecmlpkdd09_lavrac_gadcegs", "desc": "The paper present a preliminary study of creative knowledge\r\ndiscovery through bisociative data analysis. Bisociative reasoning is at\r\nthe heart of creative, accidental discovery (serendipity), and is focused on finding unexpected links by crossing different contexts. Contextualization\r\nand linking between highly diverse and distributed data and knowledge\r\nsources is therefore crucial for implementation of bisociative reasoning.\r\nIn the paper we explore these ideas on the problem of analysis of microarray\r\ndata. We show how enriched gene sets are found by using ontology\r\ninformation as background knowledge in semantic subgroup discovery.\r\nThese genes are then contextualized by the computation of probabilistic\r\nlinks to diverse bioinformatics resources. Results of two case studies are used to illustrate the approach.", "recorded": "2009-09-11T12:10:00", "title": "Gene Analytics: Discovery and Contextualization of Enriched Gene Sets"}, {"url": "iswc07_tkk_fhi", "desc": "This talk shows how semantic web techniques can be applied to solving problems of distributed content creation, discovery, linking, aggregation, and reuse in health information portals, both from end-users\u2019 and content publishers\u2019 viewpoints. As a case study, the national semantic health portal HEALTHFINLAND is presented. It provides citizens with intelligent searching and browsing services to reliable and up-to-date health information created by various health organizations in Finland. The system is based on a shared semantic metadata schema, ontologies, and ontology services. The content includes metadata about thousands of web documents such as web pages, articles, reports, campaign information, news, services, and other information related to health.", "recorded": "2007-11-13T14:00:00", "title": "HealthFinland - Finnish Health Information on the Semantic Web"}, {"url": "eswc2015_cherny_russian_heritage", "desc": "In this paper we present an architecture and approach to\r\npublishing open linked data in the cultural heritage domain. We demonstrate\r\nour approach for building a system both for data publishing and\r\nconsumption and show how user benefits can be achieved with semantic\r\ntechnologies. For domain knowledge representation the CIDOC-CRM\r\nontology is used. As a main source of trusted data, we use the data of\r\nthe web portal of the Russian Museum. For data enrichment we selected\r\nDBpedia and the published Linked Data of the British Museum. The\r\nevaluation shows the potential of semantic applications for data publishing\r\nin contextual environment, semantic search, visualization and automated\r\nenrichment according to needs and expectations of art experts\r\nand regular museum visitors.", "recorded": "2015-06-04T13:30:00", "title": "Towards the Russian Linked Culture Cloud: Data Enrichment and Publishing"}, {"url": "eswc08_aleksovski_cs", "desc": "Web 2.0 has introduced new style of information sharing featuring\r mass user participation, social networking, heterogeneity of data\r sources, and a huge scale of information and knowledge, posing\r difficulties in discovering relevant information. The Semantic Web\r may contribute by providing a language basis and ontologies to\r support structuring, or introducing new ways to explore the\r information space. This may be achieved by combining semantics from\r semantic web resources with structure of the sharing platforms\r (tags, social acquaintances etc.) and automatic content analysis\r tools. This workshop targets integration arising from the mining of\r Web 2.0 information, multimedia content and knowledge with help of\r the Semantic Web.", "recorded": "2008-06-02T11:00:00", "title": "Collective Semantics: Collective Intelligence & the Semantic Web - Use of multiple background ontologies in ontology matching"}, {"url": "iswc08_cheng_tdosw", "desc": "A large amount of terms (classes and properties) have been published on the Semantic Web by various parties, to be shared for describing resources. Terms are defined based on other terms, and thus a directed dependence relation is formed. The study of term dependence is a foundation work and is important for many other tasks, such as ontology maintenance, integration, and distributed reasoning on the Web scale. In this paper, we analyze the complex network characteristics of the term dependence graph and the induced vocabulary dependence graph. The graphs analyzed in the experiments are constructed from a large data set that contains 1,278,233 terms in 3,039 vocabularies. The results characterize the current status of schemas on the Semantic Web in many aspects, including degree distributions, reachability, and connectivity.", "recorded": "2008-10-30T14:30:00", "title": "Term Dependence on the Semantic Web"}, {"url": "iswc06_grau_uofwi", "desc": "The purpose of this tutorial is to help attendees gain sufficient experience of working with OWL and tools to allow them to fruitfully explore new ontologies that they may encounter. In other words, they should be able to do the equivalent of \u201cview source\u201d on an ontology. Also, they will get better fluency in the use and abuse of OWL by examining features, limitations, and workarounds in real contexts, as well as gaining an understanding of the impact of future extensions of OWL, in particular of rules and the proposed revision of the language called OWL 1.1. [[rimg:iswc06_parsia_uofw]] ;This lecture given by Bernardo Cuenca Grau is combined with Bijan Parsia and will encopass Part 1, Part 3, Part 4 of the complete lecture. :Part 2, 5, 6 and 7 of this lecture can be found at [[iswc06_parsia_uofw|//Bijan Parsia 's lecture//]]", "recorded": "2006-11-05T00:00:00", "title": "Learning from the Masters: Understanding Ontologies found on the Web"}, {"url": "iswc06_parsia_uofw", "desc": "The purpose of this tutorial is to help attendees gain sufficient experience of working with OWL and tools to allow them to fruitfully explore new ontologies that they may encounter. In other words, they should be able to do the equivalent of \u201cview source\u201d on an ontology. Also, they will get better fluency in the use and abuse of OWL by examining features, limitations, and workarounds in real contexts, as well as gaining an understanding of the impact of future extensions of OWL, in particular of rules and the proposed revision of the language called OWL 1.1. [[rimg:iswc06_grau_uofwi]] ;This lecture given by Bijan Parsia is combined with Bernardo Cuenca Grau and will encopass Part 2, Part 5, Part 6, Part 7 of the complete lecture. :Part 1, 3 and 4 of this lecture can be found at [[iswc06_grau_uofwi|//Bernardo Cuenca Grau's lecture//]]", "recorded": "2006-11-05T00:00:00", "title": "Learning from the Masters: Understanding Ontologies found on the Web"}, {"url": "ecmlpkdd09_rettinger_srl", "desc": "We propose a learning approach for integrating formal knowledge into statistical inference by exploiting ontologies as a semantically rich and fully formal representation of prior knowledge. The logical constraints deduced from ontologies can be utilized to enhance and control the learning task by enforcing description logic satisfiability in a latent multi-relational graphical model. To demonstrate the feasibility of our approach we provide experiments using real world social network data in form of a SHOIN(D) ontology. The results illustrate two main practical advancements: First, entities and entity relationships can be analyzed via the latent model structure. Second, enforcing the ontological constraints guarantees that the learned model does not predict inconsistent relations. In our experiments, this leads to an improved predictive performance.", "recorded": "2009-09-10T14:00:00", "title": "Statistical Relational Learning with Formal Ontologies"}, {"url": "iswc2014_mora_kyrie2", "desc": "In this paper we study query answering and rewriting in ontology-based data access. Specifically, we present an algorithm for computing a perfect rewriting of unions of conjunctive queries posed over ontologies expressed in the description logic ELHIO, which covers the OWL 2 QL and OWL 2 EL profiles. The novelty of our algorithm is the use of a set of ABox dependencies, which are compiled into a so-called EBox, to limit the expansion of the rewriting. So far, EBoxes have only been used in query rewriting in the case of DL-Lite, which is less expressive than ELHIO. We have extensively evaluated our new query rewriting technique, and in this paper we discuss the tradeoff between the reduction of the size of the rewriting and the computational cost of our approach.", "recorded": "2014-10-22T11:25:00", "title": "kyrie2: Query Rewriting under Extensional Constraints in ELHIO"}, {"url": "eswc2012_augenstein_lodifier", "desc": "The automated extraction of information from text and its transformation into a formal description is an important goal of in both Semantic Web research and computational linguistics. The extracted information can be used for a variety of tasks such as ontology generation, question answering and information retrieval. LODifier is an approach that combines deep semantic analysis with named entity recognition, word-sense disambiguation and controlled Semantic Web vocabularies in order to extract named entities and relations between them from text and to convert them into an RDF representation which is linked to DBpedia and WordNet. We present the architecture of our tool and discuss design decisions made. Evaluations of the tool give clear evidence of its potential for tasks like information extraction and computing document similarity.", "recorded": "2012-05-30T17:00:00", "title": "LODifier: Generating Linked Data from Unstructured Text"}, {"url": "iswc07_motta_esw", "desc": "The increased availability of online knowledge has led to the design of several algorithms that solve a variety of tasks by harvesting the Semantic Web, i.e., by dynamically selecting and exploring a multitude of online ontologies. Our hypothesis is that the performance of such novel algorithms implicitly provides an insight into the quality of the used ontologies and thus opens the way to a task-based evaluation of the Semantic Web. We have investigated this hypothesis by studying the lessons learnt about online ontologies when used to solve three tasks: ontology matching, folksonomy enrichment, and word sense disambiguation. Our analysis leads to a suit of conclusions about the status of the Semantic Web, which highlight a number of strengths and weaknesses of the semantic information available online and complement the findings of other analysis of the Semantic Web landscape.", "recorded": "2007-11-14T16:00:00", "title": " Evaluating the Semantic Web: A Task-based Approach"}, {"url": "eswc06_jameson_usw", "desc": "In addition to its technical implications, the semantic web vision gives rise to some challenges concerning usability and interface design. What difficulties can arise when persons with little or no relevant training try to * formulate knowledge (e.g., with ontology editors or annotation tools) in such a way that it can be exploited by semantic web technologies; * leverage semantic information while querying or browsing? What strategies have been applied in an effort to overcome these difficulties, and what are the main open issues that remain? This talk will address these questions, referring to examples and results from a variety of research efforts, including the project SemIPort, which concerns semantic methods and tools for information portals, and Halo 2, in which tools have been developed and evaluated that enable scientists to formalize and query college-level scientific knowledge.", "recorded": "2006-06-14T00:00:00", "title": "Usability and the Semantic Web"}, {"url": "semantic_data_management_video_journal_vol1", "desc": "The Video Journal of Semantic Data Management represents an innovative and multimedial way of publishing and sharing current research in the area of Semantic Data Management. It calls for presentations on original and high-quality research describing the role of Semantic Web technologies, Linked Data, and ontologies for the Data Management.\n\nWe welcome video recordings of research covering a wide range of topics, including presentations on full research papers, application reports, systems and tools, ontology papers, surveys, as well as data set reports as long as they clearly relate to challenges and opportunities arising from processing and managing data with the added value of semantics.\n\nArticles are attached to each video abstract and also available at the [[http://iswc2012.semanticweb.org/program|ISWC2012 Boston main conference website]].", "recorded": "2012-11-11T16:30:00", "title": "Video Journal of Semantic Data Management Abstracts - Volume 1"}, {"url": "iswc2013_zhiltsov_scientific_collections", "desc": "We present our work on developing a software platform for mining mathematical scholarly papers to obtain a Linked Data representation. Currently, the Linking Open Data (LOD) cloud lacks up-to-date and detailed information on professional level mathematics. To our mind, the main reason for that is the absence of appropriate tools that could analyze the underlying semantics in mathematical papers and effectively build their consolidated representation. We have developed a holistic approach to analysis of mathematical documents, including ontology based extraction, conversion of the article body as well as its metadata into RDF, integration with some existing LOD data sets, and semantic search. We argue that the platform may be helpful for enriching user experience on modern online scientific collections.", "recorded": "2013-10-23T15:15:01", "title": "Bringing Math to LOD: A Semantic Publishing Platform Prototype for Scientific Collections in Mathematics"}, {"url": "eswc2015_dragoni_reality_scenarios", "desc": "Serious games with 3D interfaces are Virtual Reality (VR)\r\nsystems that are becoming common for the training of military and emergency\r\nteams. A platform for the development of serious games should\r\nallow the addition of semantics to the virtual environment and the\r\nmodularization of the artificial intelligence controlling the behaviors of\r\nnon-playing characters in order to support a productive end-user development\r\nenvironment. In this paper, we report the ontology design activity\r\nperformed in the context of the PRESTO project aiming to realize\r\na conceptual model able to abstract the developers from the graphical\r\nand geometrical properties of the entities in the virtual reality, as well\r\nas the behavioral models associated to the non-playing characters. The\r\nfeasibility of the proposed solution has been validated through real-world\r\nexamples and discussed with the actors using the modeled ontologies in\r\nevery day practical activities.", "recorded": "2015-06-03T16:30:00", "title": "Using Ontologies For Modeling Virtual Reality Scenarios"}, {"url": "reasecs_johannes_rsoc", "desc": "To master large rule sets in ontologies and other logic-based\n specifications, the ability to divide them into components plays an\n important role. While a naive approach treats the rule sets as black-box\n components and composes them via combinators, their relationships\n are usually so complicated that this approach fails to be useful in many scenarios. Instead, the\n components should be \"opened\" before composition.\n The paper presents several such gray-box composition techniques, namely fragment-based\n genericity and extension, inline template expansions, semantic macros, and\n mixin layers.  All approaches help to structure large ontologies and\n rule-based specifications into fine-grained components, from which\n they can be built up flexibly.\n\nDocuments:\n;[[Rule_Set.pdf]]", "recorded": "2006-08-18T00:00:00", "title": "Rule Set and Ontology Composition"}, {"url": "eswc2013_lambrix_large_ontologies", "desc": "There are a number of challenges that need to be addressed when aligning large ontologies. Previous work has pointed out scalability and efficiency of matching techniques, matching with background knowledge, support for matcher selection, combination and tuning, and user involvement as major requirements. In this paper we address these challenges. Our first contribution is an ontology alignment framework that enables solutions to each of the challenges. This is achieved by introducing different kinds of interruptable sessions. The framework allows partial computations for generating mapping suggestions, partial validations of mappings suggestions and use of validation decisions in (re)computation of mapping suggestions and the recommendation of alignment strategies to use. Further, we describe an implemented system providing solutions to each of the challenges and show through experiments the advantages of the session-based approach.", "recorded": "2013-05-28T12:32:17", "title": "A Session-based Approach for Aligning Large Ontologies"}, {"url": "reasecs_henze_rwss2", "desc": "The Semantic Web is one of the major current endeavors of applied Computer Science. The Semantic Web aims at enriching the existing Web with meta-data and processing methods so as to provide web-based systems with advanced (so-called intelligent) capabilities, in particular with context-awareness and decision support. \n\nThe advanced capabilities required in most Semantic Web application scenarios primarily call for reasoning. Reasoning capabilities are offered by Semantic Web languages that are currently being developed. Most of these languages, however, are developed mainly from functionality-centered perspectives (e.g. ontology reasoning or access validation) or application-centered perspectives (e.g. Web service retrieval and composition). A perspective centered on the reasoning techniques (e.g. forward or backward chaining, tableau-like methods, constraint reasoning, etc.) complementing the above-mentioned activities appears desirable for Semantic Web systems and applications. The Summer School will be devoted to this perspective. \n\nJust as the current Web is inherently heterogeneous in data formats and data semantics, the Semantic Web will be inherently heterogeneous in its reasoning forms. Indeed, any single form of reasoning turns out irrealistic in the Semantic Web. For instance, ontology reasoning in general relies on monotonic negation, while databases, Web databases, and Web-based information systems employ non-monotonic reasoning; constraint reasoning is used in dealing with time, while forward and/or backward chaining is the reasoning of choice in coping with database-like views. \n\nThe objective of the Summer School Reasoning Web 2007 is to provide a coherent introduction into Semantic Web methods and issues with a particular focus on reasoning. \n\nThe \"Reasoning Web\" series of annual Summer Schools started in 2005 and is run on behalf of the work package \"Education and Training (ET)\" of the Network of Excellence REWERSE.", "recorded": "2007-02-23T00:00:00", "title": "Reasoning Web Summer School 2007"}, {"url": "rease_wooldridge_ppf", "desc": "This is a one-hour video recording of the presentation of Mike Wooldridge at the KnowledgeWeb summer school 2005. It comprises either the video synchronized with the slides (but requires Quicktime, hence Windows or MacOS, otherwise the slides have to be switched manually).\r\n\r\nTable of Contents: \r\n\r\nMultiagent Systems: Past, Present, and Future\r\nEvolution: Technology Push/Pull\r\nFive Trends in Computing\r\nUbiquity\r\nInterconnection\r\nIntelligence\r\nDelegation\r\nHuman Orientation\r\nProgramming metaphors\u00ef\u00bf\u00bd\r\nGlobal Computing\r\nWhere does it bring us?\r\nDefinition: Agents\r\nDefinition: Multiagent Systems\r\nThe Two Key Research Issues\r\nThe Research Issues\r\nMultiagent Systems\r\nThe Technology Components\r\nThe State of the Art\r\nAgent Architectures\r\nAgent Communication Languages\r\nOntology Languages & Tools\r\nAgreement Protocols\r\nAgent-based Solutions: When?\r\nApplications: Cooperative Info Systems\r\nAnd the Future...? Evolution, not Revolution", "recorded": "2006-12-06T00:00:00", "title": "Multiagent Systems: Past, Present, and Future"}, {"url": "iswc2014_kontopoulos_knowledge_driven_activity", "desc": "We propose a knowledge-driven activity recognition and seg-\r\nmentation framework introducing the notion of context connections. Given an RDF dataset of primitive observations, our aim is to identify, link and classify meaningful contexts that signify the presence of complex activities, coupling background knowledge pertinent to generic contextual dependencies among activities. To this end, we use the Situation concept of the DOLCE+DnS Ultralite (DUL) ontology to formally capture the context of high-level activities. Moreover, we use context similarity measures to handle the intrinsic characteristics of pervasive environments in real-world conditions, such as missing information, temporal inaccuracies or activities that can be performed in several ways. We illustrate the performance of the proposed framework through its deployment in a hospital for monitoring activities of Alzheimer's disease patients.\r\n", "recorded": "2014-10-21T14:40:00", "title": "Knowledge-driven Activity Recognition and Segmentation Using Context Connections"}, {"url": "iswc06_gruber_wswms", "desc": "The Semantic Web is an ecosystem of interaction among computer systems. The social web is an ecosystem of conversation among people. Both are enabled by conventions for layered services and data exchange. Both are driven by human-generated content and made scalable by machine-readable data. Yet there is a popular misconception that the two worlds are alternative, opposing ideologies about how the web ought to be. Folksonomy vs. ontology. Practical vs. formalistic. Humans vs. machines.\r \r This is nonsense, and it is time to embrace a unified view. I subscribe to the vision of the Semantic Web as a substrate for collective intelligence. The best shot we have of collective intelligence in our lifetimes is large, distributed human-computer systems. The best way to get there is to harness the \"people power\" of the Web with the techniques of the Semantic Web. In this presentation I will show several ways that this can be, and is, happening.", "recorded": "2006-11-07T00:00:00", "title": "Where the Social Web Meets the Semantic Web"}, {"url": "semantic_data_management_video_journal_vol2", "desc": "The Video Journal of Semantic Data Management represents an innovative and multimedial way of publishing and sharing current research in the area of Semantic Data Management. It calls for presentations on original and high-quality research describing the role of Semantic Web technologies, Linked Data, and ontologies for the Data Management.\r\n\r\nIn this issue we welcomed self-made video recordings of research covering a wide range of topics, including presentations on full research papers, application reports, systems and tools, ontology papers, surveys, as well as data set reports as long as they clearly relate to challenges and opportunities arising from processing and managing data with the added value of semantics.\r\n\r\nThe call was published at the [[http://planet-data.eu/semantic-data-management-video-journal/vol2|PlanetData Network of Excellence project website]].", "recorded": "2013-06-23T11:52:39", "title": "Video Journal of Semantic Data Management Abstracts - Volume 2"}, {"url": "iswc07_yuzhong_dsmb", "desc": "Ontologies proliferate with the growth of the Semantic Web. However, most of data on theWeb are still stored in relational databases. Therefore, it is important to establish interoperability between relational databases and ontologies for creating a Web of data. An e\u00aeective way to achieve interoperability is \u00afnding mappings between relational database schemas and ontologies. In this paper, we propose a new approach to discovering simple mappings between a relational database schema and an ontology. It exploits simple mappings based on virtual documents, and eliminates incorrect mappings via validating mapping consistency. Additionally, it also constructs a special type of semantic mappings, called contextual mappings, which is useful for practical applications. Experimental results demonstrate that our approach performs well on several data sets from real world domains.", "recorded": "2007-11-14T16:00:00", "title": "Discovering Simple Mappings Between Relational Database Schemas and Ontologies "}, {"url": "wims2013_jung_social_collaboration", "desc": "Since working environments are dramatically changing, it is difficult to support collaboration among people. In this talk, I will claim that the context should be efficiently synchronized. \r\nTo efficiently support collaborations between people (agents) in real-time, we propose an ontology-based platform for acquainting the most relevant users (e.g., colleagues and classmates), according to their context. \r\nThereby, we have modeled two kinds of contexts with semantic information derived from ontologies; (i) personal context, and (ii) consensual context, integrated from several personal contexts.\r\nMore importantly, we formulate measurement criteria to compare them. Consequently, groups can be dynamically organized with respect to the similarities among several aspects of personal context. In particular, users can engage in complex collaborations related to multiple semantics. For experimentation, a social browsing system has been implemented based on context synchronization.", "recorded": "2013-06-14T10:00:00", "title": "Contextual Synchronization on Social Collaboration"}, {"url": "interoperability_curriculum", "desc": "[[http://videolectures.net/interoperability_course_syllabus/|go to ALL COURSES page]]\r\n\r\n==Dissemination of courses on Interoperability\r\n\r\n===Description\r\nCurrently, in the e-learning platform, there are 24 tutorials developed, 21 tutorials more are coming in next months. They belong to four different domains related to interoperability.\r\n\r\n=== Keywords\r\nEnterprise Modelling, Unified Enterprise Modelling Language, Business Process, Global Modelling, Business Process Modelling Language, Semantic Web, Ontologies, Ontology Tools, Ontology Interoperability.\r\n\r\n=== Goal\r\nOne of the objectives of this tutorial is to increase awareness on Interoperability, to keep you informed on the research results developed within the consortium but also to share knowledge on interoperability directed to internal partners (INTEROP researchers and PhD students) and external stakeholders (enterprises or professionals) by means tutorials and web courses.\r\n\r\n=== Structure\r\n\u2022 Enterprise Modelling: 8 tutorials developed.\r\n\r\nThere have been substantial advances in the development of a viable approach to mapping between models in different enterprise modelling languages. A good foundation has been established for future development. It was noted that the work had some parallels with work\r\nin the OMG on transformations between models based on the MetaObject Facility (MOF).\r\n\r\n\u2022 Ontologies: 7 tutorials developed.\r\n\r\nThe aim of this domain is to explore the potential of ontology-based techniques to tackle the problem of interoperability and to investigate how such techniques can be joined together with the other two fundamental perspectives addressed in INTEROP, enterprise modelling, and architectures and enabling technologies.\r\n\r\n\u2022 Architectures & Platforms: 5 tutorials developed.\r\nThe goal of this domain is to focus on research coordination in the area of Architecture & Platforms and to continuously update the state-of-the-art, but not to perform any research activities directly.\r\n\r\n\u2022 Interoperability: 4 tutorials developed.\r\nThis domain aims at capturing scientific interoperability knowledge developed by other Joint Research work packages and task groups with the objective of constructing a basic knowledge corpus to establish the interoperability domain as a scientific discipline. This is an important objective for the INTEROP NoE and essential for the establishment of the VLab. The domain is also responsible for the identification of interoperability best practices and solutions, and the derivation of design patterns and principles for interoperability. The two aspects of the domain are rather different in nature and it will be important to ensure that both are appropriately resourced and managed.\r\n\r\nThis domain is also invited to address some basic questions underlying the whole enterprise interoperability research field. At present, various large European research projects on enterprise interoperability are conducting valuable research. However, these projects do not always question themselves how they can really advance enterprise interoperability, or whether that should even be the true purpose. Some fundamental questions remain unanswered.\r\n\r\nIn addition, the European enterprise interoperability research domain and INTEROP in particular has been divided since long in three related areas: enterprise modelling, ontologies, and architectures and platforms. Any division of the playing field is welcome, but a true division should not be based on what are perceived as means to achieve or support interoperability, but rather on fundamental types of interoperability.\r\n\r\n === User type\r\n researchers, business decision makers, engineers, students, scholars and general public\r\n\r\n[[http://videolectures.net/interoperability_course_syllabus/|go to ALL COURSES page]]", "recorded": "2009-02-13T10:08:24", "title": "Curriculum - Interoperability"}, {"url": "eswc2014_cure_water_fowl", "desc": "In this paper we present WaterFowl, a novel approach for the storage of RDF triples that addresses scalability issues through compression. The architecture of our prototype, largely based on the use\r\nof succinct data structures, enables the representation of triples in a self-indexed, compact manner without requiring decompression at query answering time. Moreover, it is adapted to e\u000efficiently support RDF and RDFS entailment regimes thanks to an optimized encoding of ontology concepts and properties that does not require a complete inference materialization or query reformulation. This approach implies to make a distinction between the terminological and the assertional components of\r\nthe knowledge base early in the process of data preparation, i:e: preprocessing the data before storing it in our structures. The paper describes our system's architecture and presents some preliminary results obtained from evaluations on di\u000berent datasets.", "recorded": "2014-05-28T11:50:00", "title": "WaterFowl: a Compact, Self-indexed and Inference-enabled immutable RDF Store"}, {"url": "eswc2012_chevalier_servant_product_customization", "desc": "Ranges of customizable products are huge and complex, because of the number of features and options a customer can choose from, and the many constraints that exist between them. It could hinder the publishing of customizable product data on the web of e-business data, because constraints are not tractable by agents lacking reasoning capabilities. But the configuration process, which helps a customer to make her choice, one step at a time, is a traversal of a graph of partially defined products - that is, Linked Data. Reasoning being hosted on the server, its complexity is hidden from clients. This results in a generic configuration API, in use at Renault. As configurations can be completed to valid commercial offers, the corresponding ontology fits nicely with GoodRelations. Benefits in e-business related use cases are presented: sharing configurations between media, devices and applications, range comparison based on customer's interests, ads, SEO.", "recorded": "2012-05-30T10:30:00", "title": "Product customization as Linked Data"}, {"url": "eswc2015_mutharaju_scalable_reasoning", "desc": "OWL 2 EL is one of the tractable profiles of the Web Ontology\r\nLanguage (OWL) which is a W3C-recommended standard. OWL 2\r\nEL provides sufficient expressivity to model large biomedical ontologies\r\nas well as streaming data such as traffic, while at the same time allows\r\nfor efficient reasoning services. Existing reasoners for OWL 2 EL, however,\r\nuse only a single machine and are thus constrained by memory and\r\ncomputational power. At the same time, the automated generation of\r\nontological information from streaming data and text can lead to very\r\nlarge ontologies which can exceed the capacities of these reasoners. We\r\nthus describe a distributed reasoning system that scales well using a cluster\r\nof commodity machines. We also apply our system to a use case on\r\ncity traffic data and show that it can handle volumes which cannot be\r\nhandled by current single machine reasoners.", "recorded": "2015-06-02T12:00:00", "title": "Distributed and Scalable OWL EL Reasoning"}, {"url": "iswc2011_kalyanpur_leveraging", "desc": "Watson, the winner of the Jeopardy! challenge, is a state-of-the-art open-domain Question Answering system that tackles the fundamental issue of answer typing by using a novel type coercion (TyCor) framework, where candidate answers are initially produced without considering type information, and subsequent stages check whether the candidate can be coerced into the expected answer type. In this paper, we provide a high-level overview of the TyCor framework and discuss how it is integrated in Watson, focusing on and evaluating three TyCor components that leverage the community built semi-structured and structured knowledge resources - DBpedia (in conjunction with the YAGO\r\nontology), Wikipedia Categories and Lists. These resources complement each other well in terms of precision and granularity of type information, and through links to Wikipedia, provide coverage for a large set of instances.", "recorded": "2011-10-25T11:00:00", "title": "Leveraging Community-built Knowledge for Type Coercion in Question Answering"}, {"url": "mlsb09_king_asci", "desc": "The basis of science is the hypothetico-deductive method and the recording of experiments in sufficient detail to enable reproducibility. We report the development of the Robot Scientist \"Adam\" which advances the automation of both. Adam has autonomously generated functional genomics hypotheses about the yeast Saccharomyces cerevisiae, and experimentally tested these hypotheses using laboratory automation. We have confirmed Adam's conclusions through manual experiments. To describe Adam's research we have developed an ontology and logical language. The resulting formalization involves over 10,000 different research units in a nested tree-like structure, ten levelsdeep, that relates the 6.6 million biomass measurements to their logical description. This formalization describes how a machine discovered new scientific knowledge. Describing scientific investigations in this way opens up new opportunities to apply machine learning and data-mining to discover new knowledge.", "recorded": "2009-09-06T16:00:00", "title": "Automating Science"}, {"url": "eswc2013_simon_di_mascio_french_library", "desc": "Linked open data tools have been implemented through data.bnf.fr , a project which aims at making the BnF data more useful on the Web. data.bnf.fr gathers data automatically from different databases on pages about authors, works and themes. Online since July 2011, it is still under development and has feedbacks from several users, already. First the article will present the issues linked to our data and stress the importance of useful links and of persistency for archival purposes. We will discuss our solution and methodology, showing their strengths and weaknesses, to create new services for the library. An insight on the ontology and vocabularies will be given, with a \u201cbusiness\u201d view of the interaction between rich RDF ontologies and light HTML embedded data such as schema.org\r\n. The broader question of Libraries on the Semantic Web will be addressed so as to help specify similar projects. ", "recorded": "2013-05-29T11:07:03", "title": "Publishing bibliographic records on the Web of data: opportunities for the BnF"}, {"url": "iswc2011_groza_dysplasia", "desc": "In this paper we report on our on-going e\u000bfforts in building SKELETOME { a community-driven knowledge curation platform for the skeletal dysplasia domain. SKELETOME introduces an ontology-\r\ndriven knowledge engineering cycle that supports the continuous evolution of the domain knowledge. Newly submitted, undiagnosed patient cases undergo a collaborative diagnosis process that transforms them into well-structured case studies, classi\ffied, linked and discoverable based on their likely diagnosis(es). The paper presents the community requirements driving the design of the platform, the underlying implementation details and the results of a preliminary usability study. Because SKELETOME is built on Drupal 7, we discuss the limitations of some of its embedded Semantic Web components and describe a set of new modules, developed to handle these limitations (which will soon be released\r\nas open source to the community).", "recorded": "2011-10-27T11:00:00", "title": "Using Semantic Web Technologies to Build a Community-driven Knowledge Curation Platform for the Skeletal Dysplasia Domain"}, {"url": "eswc2015_fiorelli_metadata_module", "desc": "The OntoLex W3C Community Group has been working for more\r\nthan three years on a shared lexicon model for ontologies, called lemon. The\r\nlemon model consists of a core model that is complemented by a number of\r\nmodules accounting for specific aspects in the modeling of lexical information\r\nwithin ontologies. In many usage scenarios, the discovery and exploitation of\r\nlinguistically grounded ontologies may benefit from summarizing information\r\nabout their linguistic expressivity and lexical coverage by means of metadata.\r\nThat situation is compounded by the fact that lemon allows the independent\r\npublication of ontologies, lexica and lexicalizations linking them. While the\r\nVoID vocabulary already addresses the need for general metadata about interlinked\r\ndatasets, it is unable by itself to represent the more specific metadata\r\nrelevant to lemon. To solve this problem, we developed a module of lemon,\r\nnamed LIME (Linguistic Metadata), which extends VoID with a vocabulary of\r\nmetadata about the ontology-lexicon interface.", "recorded": "2015-06-02T12:00:00", "title": "LIME: the Metadata Module for OntoLex"}, {"url": "iswc2011_seitz_owl", "desc": "Ontologies have been used for formal representation of knowledge for many years now. One possible knowledge representation language for ontologies is the OWL 2 Web Ontology Language, informally OWL 2. The OWL specification includes the definition of variants of OWL, with different levels of expressiveness. OWL DL and OWL Lite are based on Description Logics, for which sound and complete reasoners exits. Unfortunately, all these reasoners are too complex for embedded systems. But since evaluation of ontologies on these resource constrained devices becomes more and more necessary (e.g. for diagnostics) we developed an OWL reasoner for embedded devices. We use the OWL 2 sub language OWL 2 RL, which can be implemented using rule-based reasoning engines. In this paper we present our used embedded hardware, the implemented reasoning component, and results regarding performance and memory consumption.", "recorded": "2011-10-25T14:00:00", "title": "Rule-based OWL Reasoning for specific Embedded Devices"}, {"url": "rease_hendler_swcsf", "desc": "This is a one-hour video recording of the presentation of Jim Hendler at the KnowledgeWeb summer school 2006. It comprises either the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nOutline\r\nSemantic Web @ 5 Current Status and Future Promise of the Semantic Web\r\nBefore We Get Started\r\n1990's: 'Pre-history'\r\n2000-2001: What Did We Believe?\r\n2000-2001: 'Early Years'\r\nOriginal Outline (July 2000)\r\n2001\r\n2003\r\n2005\r\n2006: You Are Here!\r\nSignificant Corporate Activity\r\nSignificant Government Activity\r\nThere's a Lot Out There!\r\nSemantic WEB\r\nSEMANTIC Web\r\n2006: The Gap Is Closing\r\nSEMANTIC Web Lessons\r\nSemantic WEB Lessons\r\nWhere Are the Agents?\r\nLinking Is Power!\r\nOntology Engineering\r\nIt's not all OWL DL\r\nThink beyond the layer cake\r\nMost important of all\r\nCharge for this week", "recorded": "2007-02-13T00:00:00", "title": "Semantic Web@5 - Current Status and Future Promise of the Semantic Web"}, {"url": "eswc2015_knoblock_data_mining", "desc": "As the knowledge discovery process has been widely applied in a variety of domains, there is a growing opportunity to use the Linked Open Data (LOD) cloud as a primary data source for knowledge discovery. The tasks of finding the relevant data from various sources and then using that data for the desired analysis are the key challenges. There is a striking increase on the availability of statistical data and indicators (e.g. social, economic) in the LOD, and the Cube ontology has become the de facto\r\nstandard for their description according to a multi-dimensional model. In this paper we discuss a detailed scenario for using the LOD as a primary source of data for building analysis models in the Peacebuilding domain. Next, we present an approach to finding potentially relevant cube datasets in the LOD cloud, assessing their compatibility, and then integrating the compatible datasets to enable the application of data mining algorithms", "recorded": "2015-05-31T09:25:00", "title": "Finding, Assessing, and Integrating Statistical Sources for Data Mining"}, {"url": "eswc2011_semantic_business_process", "desc": "Ontology-based semantics have shown, as documented in five previous iterations of the SBPM workshop, a high degree of automation in the management of the business process space of single enterprises and whole value chains. A key source of problems in the \"pre-semantic\" BPM domain is in the representational heterogeneities between the various perspectives and the various stages in the life-cycles of business processes. Typical examples are incompatible representations of the managerial vs. the IT perspective, or the gap between normative modeling for compliance purposes and process execution log data.\r\n\r\nIn this workshop, we want to bring together experts from the relevant communities and help reach agreement on a roadmap for SBPM research. We aim at bundling experiences and prototypes from the successful application of Semantic Web technology to BPM in various industries, like automotive, engineering, chemical and pharmaceutical, and services domains. Additionally we encourage visionary papers regarding the future of semantics for BPM.", "recorded": "2011-05-29T09:00:00", "title": "6th International Workshop on Semantic Business Process Management"}, {"url": "taoiw09_grcar_videolectures", "desc": "The task in the VideoLectures case study is to develop a software component that will aid the VideoLectures editors in categorizing recorded lectures (i.e. ontology population). This functionality is required due to the rapid growth of the number of hosted lectures as well as due to the fact that the categorization taxonomy is rather fine-grained (200 categories and growing). In addition to aiding the categorization of new lectures, the software will also be used for re-categorization and additional categorization of lectures already categorized.\n\nWe will show that we were successful in our task as the categorizer is highly accurate \u2013 it achieves accuracies that stretch 12\u201320% above the baseline \u2013 and highly robust in terms of missing data. The latter means that a lecture might be missing textual annotations (such as the description and slide titles) but is still categorized correctly. Furthermore, the categorizer has been successfully integrated into the VideoLectures Web site. Categorization suggestions (termed \"quick links\") are provided to the author in the categorization panel.", "recorded": "2009-01-27T15:45:00", "title": "VideoLectures.net case study"}, {"url": "www09_gracia_lsissw", "desc": "Nowadays, the increasing amount of semantic data available on the Web leads to a new stage in the potential of Semantic Web applications. However, it also introduces new issues due to the heterogeneity of the available semantic resources. One of the most remarkable is redundancy, that is, the excess of different semantic descriptions, coming from different sources, to describe the same intended meaning.\r\nIn this paper, we propose a technique to perform a large scale integration of senses (expressed as ontology terms), in order to cluster the most similar ones, when indexing large amounts of online semantic information. It can dramatically reduce the redundancy problem on the current Semantic Web. In order to make this objective feasible, we have studied the adaptability and scalability of our previous work on sense integration, to be translated to the much larger scenario of the Semantic Web. Our evaluation shows a good behaviour of these techniques when used in large scale experiments, then making feasible the proposed approach. ", "recorded": "2009-04-24T14:30:00", "title": "Large Scale Integration of Senses for the Semantic Web"}, {"url": "iswc2011_kazakov_classification", "desc": "We describe an optimised consequence-based procedure for\r\nclassification of ontologies expressed in a polynomial fragment ELHR+ of\r\nthe OWL 2 EL profile. A distinguishing property of our procedure is that\r\nit can take advantage of multiple processors/cores, which increasingly\r\nprevail in computer systems. Our solution is based on a variant of the\r\n\u2018given clause\u2019 saturation algorithm for first-order theorem proving, where\r\nwe assign derived axioms to \u2018contexts\u2019 within which they can be used and\r\nwhich can be processed independently.We describe an implementation of\r\nour procedure within the Java-based reasoner ELK. Our implementation\r\nis light-weight in the sense that an overhead of managing concurrent\r\ncomputations is minimal. This is achieved by employing lock-free data\r\nstructures and operations such as \u2018compare-and-swap\u2019. We report on\r\npreliminary experimental results demonstrating a substantial speedup\r\nof ontology classification on multi-core systems. In particular, one of\r\nthe largest and widely-used medical ontologies SNOMED CT can be\r\nclassified in as little as 5 seconds.", "recorded": "2011-10-25T11:00:00", "title": "Concurrent classification of EL ontologies"}, {"url": "iswc08_wang_lcm", "desc": "Finding mappings between compatible ontologies is an important but difficult open problem. Instance-based methods for solving this problem have the advantage of focusing on the most active parts of the ontologies and reflect concept semantics as they are actually being used. However such methods have not at present been widely investigated in ontology mapping, compared to linguistic and structural techniques. Furthermore, previous instance-based mapping techniques were only applicable to cases where a substantial set of instances was available that was doubly annotated with both vocabularies. In this paper we approach the mapping problem as a classification problem based on the similarity between instances of concepts. This has the advantage that no doubly annotated instances are required, so that the method can be applied to any two corpora annotated with their own vocabularies. We evaluate the resulting classifiers on two real-world use cases, one with homogeneous and one with heterogeneous instances. The results illustrate the efficiency and generality of this method. ", "recorded": "2008-10-29T10:30:00", "title": "Learning Concept Mappings from Instance Similarity"}, {"url": "iswc2014_faria_bioportal_mappings", "desc": "BioPortal is a repository for biomedical ontologies that also includes mappings between them from various sources. Considered as a whole, these mappings may cause logical errors, due to incompatibilities between the ontologies or even erroneous mappings.\r\n\r\nWe have performed an automatic evaluation of BioPortal mappings between 19 ontology pairs using the mapping repair systems of LogMap and AgreementMakerLight. We found logical errors in 11 of these pairs, which on average involved 22% of the mappings between each pair. Furthermore, we conducted a manual evaluation of the repair results to identify the actual sources of error, verifying that erroneous mappings were behind over 60% of the repairs.\r\n\r\nGiven the results of our analysis, we believe that annotating BioPortal mappings with information about their logical conflicts with other mappings would improve their usability for semantic web applications and facilitate the identification of erroneous mappings. In future work, we aim to collaborate with BioPortal developers in extending BioPortal with these annotations.", "recorded": "2014-10-23T11:05:00", "title": "Towards Annotating Potential Incoherences in BioPortal Mappings"}, {"url": "iswc2014_reforgiato_recupero_sheldon", "desc": "SHELDON is the first true hybridization of NLP machine\r\nreading and Semantic Web. It is a framework that builds upon a ma-\r\nchine reader for extracting RDF graphs from text so that the output is\r\ncompliant to Semantic Web and Linked Data patterns. It extends the\r\ncurrent human-readable web by using Semantic Web practices and technologies in a machine-processable form. Given a sentence in any language, it provides different semantic functionalities (frame detection,\r\ntopic extraction, named entity recognition, resolution and coreference, terminology extraction, sense tagging and disambiguation, taxonomy induction, semantic role labeling, type induction, sentiment analysis, citation inference, relation and event extraction) as well as nice visualization tools which make use of the JavaScript infoVis Toolkit and\r\nRelFinder, as well as a knowledge enrichment component that extends\r\nmachine reading to Semantic Web data. The system can be freely used\r\nat http://wit.istc.cnr.it/stlab-tools/sheldon.", "recorded": "2014-10-22T14:40:00", "title": "SHELDON: Semantic Holistic framEwork for LinkeD ONtology data"}, {"url": "eswc2015_oberkampf_missing_link", "desc": "A wealth of biomedical datasets is meanwhile published as\r\nLinked Open Data. Each of these datasets has a particular focus, such as\r\nproviding information on diseases or symptoms of a certain kind. Hence,\r\na comprehensive view can only be provided by integrating information\r\nfrom various datasets. Although, links between diseases and symptoms\r\ncan be found, these links are far too sparse to enable practical applications\r\nsuch as a disease-centric access to clinical reports that are annotated\r\nwith symptom information. For this purpose, we build a model\r\nof disease-symptom relations. Utilizing existing ontology mappings, we\r\npropagate semantic type information for disease and symptom across\r\nontologies. Then entities of the same semantic type from different ontologies\r\nare clustered and object properties between entities are mapped to\r\ncluster-level relations. The effectiveness of our approach is demonstrated\r\nby integrating all available disease-symptom relations from different biomedical\r\nontologies resulting in a significantly increased linkage between\r\ndatasets.", "recorded": "2015-06-02T16:00:00", "title": "From Symptoms to Diseases - Creating the Missing Link"}, {"url": "solomon_kocev_epso", "desc": "In many real-world domains, such as bioinformatics (functional\r\ngenomics), text classification and image annotation, the goal is to\r\npredict a complex output. For example, in functional genomics, the\r\ngoal is to predict the function of a gene, while the set of functions\r\ncan be organized as tree (FunCat) or graph (GO ontology).\r\nIn this talk, we present an approach for predicting structured outputs\r\nusing ensembles of trees. The proposed approach is scalable to large\r\ndatasets, different types of outputs and it is applicable to wide\r\nrange of domains. First, we describe the types of structured outputs\r\nthat we typically encounter, and then we explain the base classifiers\r\n- predictive clustering trees (PCTs). Next, we discuss the ensemble\r\nmethods that we extended (bagging and random forests) to deal with\r\nstructured outputs and accordingly adapted the voting schemes.\r\nAfterwards, we present experimental evaluation of the proposed\r\napproach on wide range of real-world domains. At the end, we present\r\nan application of the proposed approach in functional genomics and\r\nshow that our approach is competitive with state-of-the-art approaches.", "recorded": "2010-02-02T13:00:00", "title": "Ensembles for predicting structured outputs"}, {"url": "iswc2011_fernandez_videolectures", "desc": "This paper presents our work and experience interlinking educational information across universities through the use of Linked Data principles and technologies. More specifically this paper is focused on selecting, extracting, structuring and interlinking information of video lectures produced by 27 different educational institutions. For this purpose, selected information from several websites and YouTube channels have been scraped and structured according to well-known vocabularies, like FOAF, or the W3C Ontology for Media Resources. To integrate this information, the extracted videos have been categorized under a common classification space, the taxonomy defined by the Open Directory Project. An evaluation of this categorization process has been conducted obtaining a 98% degree of coverage and 89% degree of correctness. As a result of this process a new Linked Data dataset has been released containing more than 14,000 video lectures from 27 different institutions and categorized under a common classification scheme.", "recorded": "2011-10-25T15:30:00", "title": "Linking Data Across Universities: an integrated video lectures dataset"}, {"url": "eswc2015_osenberg_architecture_analysis", "desc": "Enterprise Architecture (EA) models are established means\r\nfor decision makers in organizations. They describe the business processes,\r\nthe application landscape and IT infrastructure as well as the relationships\r\nbetween those layers. Current research focuses merely on frameworks,\r\nmodeling and documentation approaches for EA. But once these models\r\nare established, methods for their analysis are rare. In this paper we propose\r\nthe use of semantic web technologies in order to represent the EA and\r\nperform analyses. We present an approach how to transform an existing\r\nEA model into an ontology. Using this knowledge base, simple questions\r\ncan be answered with the query language SPARQL. The major benefits\r\nof semantic web technologies can be found, when defining and applying\r\nmore complex analyses. Change impact analysis is important to estimate\r\nthe effects and costs of a change to an EA model element. To show the benefits\r\nof semantic web technologies for EA, we implemented an approach to\r\nchange impact analysis and executed it within a case study.", "recorded": "2015-06-03T17:00:00", "title": "Using Semantic Web Technologies for Enterprise Architecture Analysis"}, {"url": "estc08_popov_azsa", "desc": "The rising costs of drug development make it imperative for pharmaceutical companies to quickly learn from knowledge generated in clinical trials. Timely access to successful study designs and trial outcomes can facilitate speed and quality improvements in decision-making at various stages.\r\n\r\nUtilization of information standards for extraction, integration and exploitation of structured and unstructured clinical study information could prove to be critical in this context\r\n\r\nThis talk will describe our implementation of a semantic repository of clinical studies in a global clinical development organization. We will discuss the design of a semantic annotation platform for clinical study reports stored in large clinical document repositories.  The extracted semantic annotations over clinical studies are integrated with structured information from a global trial execution database and stored in an organizational semantic repository. Beside clinical trial models the repository also incorporated and aligned existing thesauri, dictionaries and taxonomies in a syntactically coherent and semantically sound ontology.\r\n\r\n\r\n", "recorded": "2008-09-25T10:36:38", "title": "Semantic Annotation of Clinical Studies for Knowledge-Driven Drug Development"}, {"url": "iswc07_lambrix_mro", "desc": "In different areas ontologies have been developed and many of these ontologies contain overlapping information. Often we would therefore want to be able to use multiple ontologies. To obtain good results, we need to find the relationships between terms in the different ontologies, i.e. we need to align them. Currently, there already exist a number of different alignment strategies. However, it is usually difficult for a user that needs to align two ontologies to decide which of the different available strategies are the most suitable. In this paper we propose a method that provides recommendations on alignment strategies for a given alignment problem. The method is based on the evaluation of the different available alignment strategies on several small selected pieces from the ontologies, and uses the evaluation results to provide recommendations. In the paper we give the basic steps of the method, and then illustrate and discuss the method in the setting of an alignment problem with two well-known biomedical ontologies. We also experiment with different implementations of the steps in the method.", "recorded": "2007-11-14T16:00:00", "title": "A method for recommending ontology alignment strategies"}, {"url": "rease_bouquet_irsw", "desc": "This is a one-hour video recording of the presentation of Paolo Bouquet at the First Asian Autumn School on the Semantic Web. It comprises the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\n'?Knowledge representation is a...'\r\nLecture outline\r\nA few basic definitions\r\nThe Semantic Web: from vision to practice\r\nAn example ?\r\nAn example ?\r\nKey ideas: a summary\r\nAn example of RDF statements\r\nKnowlegde integration in the global space\r\nIssue #1: schema-level heterogeneity\r\nIssue #1: schema-level integration\r\nIsssue #2: entity-level mismatch\r\nIsssue #2: entity-level integration\r\nState-of-the-art\r\nHowever ?.\r\nIdentity and Reference\r\nThree critical issues\r\n1. Identities vs. identifiers: abstract resources\r\n1. Identities vs. Identifiers: individuals\r\n1. Identities vs. identifiers\r\n2. What kind of URIs?\r\n3. Managing reference on the SemWeb\r\nHowever ?\r\n3. ENS: a ?DNS? for the Semantic Web\r\nAn example: creating instances in an ontology\r\nConclusions: Expected advantages\r\nConclusions: A bootstrap for the Semantic Web?\r\nReferences\r\nReferences - II", "recorded": "2007-11-26T00:00:00", "title": "Identity and Reference on the Semantic Web"}, {"url": "iswc08_swcbtc", "desc": "The central idea of the Semantic Web is to extend the current human-readable web by encoding some of the semantics of resources in a machine-processable form. Moving beyond syntax opens the door to more advanced applications and functionality on the Web. Computers will be better able to search, process, integrate and present the content of these resources in a meaningful, intelligent manner.\r\n\r\nThe core technological building blocks are now in place and widely available: ontology languages, flexible storage and querying facilities, reasoning engines, etc. Standards and guidelines for best practice are being formulated and disseminated by the W3C.\r\n\r\nThe Semantic Web Challenge offers participants the chance to show the best of the Semantic Web. The Challenge thus serves several purposes:\r\n\r\n    * Helps us illustrate to society what the Semantic Web can provide\r\n    * Gives researchers an opportunity to showcase their work and compare it to others\r\n    * Stimulates current research to a higher final goal by showing the state-of-the-art every year\r\n", "recorded": "2008-10-29T16:00:00", "title": "Semantic Web Challenge & Billion Triple Challenge "}, {"url": "kdd2014_yang_twitter", "desc": "We are interested in organizing a continuous stream of sparse and noisy texts, known as \"tweets\", in real time into an ontology of hundreds of topics with measurable and stringently high precision. This inference is performed over a full-scale stream of Twitter data, whose statistical distribution evolves rapidly over time. The implementation in an industrial setting with the potential of affecting and being visible to real users made it necessary to overcome a host of practical challenges. We present a spectrum of topic modeling techniques that contribute to a deployed system. These include non-topical tweet detection, automatic labeled data acquisition, evaluation with human computation, diagnostic and corrective learning and, most importantly, high-precision topic inference. The latter represents a novel two-stage training algorithm for tweet text classification and a close-loop inference mechanism for combining texts with additional sources of information. The resulting system achieves 93% precision at substantial overall coverage.", "recorded": "2014-08-25T13:45:00", "title": "Large Scale High-Precision Topic Modeling on Twitter"}, {"url": "eswc2015_krishnamurthy_data_sources", "desc": "There is a huge demand to be able to find and integrate\r\nheterogeneous data sources, which requires mapping the attributes of a\r\nsource to the concepts and relationships defined in a domain ontology. In\r\nthis paper, we present a new approach to find these mappings, which we\r\ncall semantic labeling. Previous approaches map each data value individually,\r\ntypically by learning a model based on features extracted from the\r\ndata using supervised machine-learning techniques. Our approach differs\r\nfrom existing approaches in that we take a holistic view of the data values\r\ncorresponding to a semantic label and use techniques that treat this data\r\ncollectively, which makes it possible to capture characteristic properties\r\nof the values associated with a semantic label as a whole. Our approach\r\nsupports both textual and numeric data and proposes the top k semantic\r\nlabels along with their associated confidence scores. Our experiments\r\nshow that the approach has higher label prediction accuracy, has lower\r\ntime complexity, and is more scalable than existing systems.", "recorded": "2015-06-03T11:30:00", "title": "Assigning Semantic Labels to Data Sources"}, {"url": "eswc09_shamdasanis_smutu", "desc": "Traditional ontology alignment techniques enable equivalence relationships to be established between concepts in two ontologies with some confidence value. With semantic matching, however, it is possible to identify not only equivalence  relationships between concepts, but less general and more general relationships. This is beneficial since more expressive relationships can be discovered between ontologies thus helping us to resolve heterogeneity between differing semantic representations at a finer level of granularity. This work concerns the application of semantic matching to the medical domain. We have extended the SMatch algorithm to function in the medical domain with the use of the UMLS metathesaurus as the background resource, hence removing its previous reliance on WordNet, which does not cover the medical domain in a satisfactory manner. We describe the steps required to extend the SMatch algorithm to the medical domain for use with UMLS. We test the accuracy of our approach on subsets of the FMA and MeSH ontologies, with both precision and recall showing the accuracy and coverage of different versions of our algorithm on each dataset.", "recorded": "2009-06-03T12:30:00", "title": "Semantic Matching using the UMLS"}, {"url": "iswc08_meditskos_cdlrre", "desc": "We introduce the notion of the mixed DL and entailment-based (DLE) OWL reasoning, defining a framework inspired from the hybrid and homogeneous paradigms for integration of rules and ontologies. The idea is to combine the TBox inferencing capabilities of the DL algorithms and the scalability of the rule paradigm over large ABoxes. Towards this end, we define a framework that uses a DL reasoner to reason over the TBox of the ontology (hybrid-like) and a rule engine to apply a domain-specific version of ABox-related entailments (homogeneous-like) that are generated by TBox queries to the DL reasoner. The DLE framework enhances the entailment-based OWL reasoning paradigm in two directions. Firstly, it disengages the manipulation of the TBox semantics from any incomplete entailment-based approach, using the efficient DL algorithms. Secondly, it achieves faster application of the ABox-related entailments and efficient memory usage, comparing it to the conventional entailment-based approaches, due to the low complexity and the domain-specific nature of the entailments. ", "recorded": "2008-10-29T10:30:00", "title": "Combining a DL Reasoner and a Rule Engine for Improving Entailment-Based OWL Reasoning"}, {"url": "eswc2011_probst_soknos", "desc": "Disaster management software deals with supporting staff in large catastrophic incidents such as earthquakes or floods, e.g., by providing relevant information, facilitating task and resource planning, and managing communication with all involved parties. In this paper, we introduce the SoKNOS support system, which is a functional prototype for such software using semantic technologies for various purposes. Ontologies are used for creating a mutual understanding between developers and end users from different organizations. Information sources and services are annotated with ontologies for improving the provision of the right information at the right time, and for connecting existing systems and databases to the SoKNOS system using those annotations. Furthermore, the users' actions are constantly supervised, and errors are avoided by employing ontology-based consistency checking. We show how the pervasive and holistic use of semantic technologies leads to a significant improvement of both the development and the usability of disaster management software, and present some key lessons learned from employing semantic technologies in a large-scale software project.", "recorded": "2011-06-01T16:00:00", "title": "SoKNOS - Using Semantic Technologies in Disaster Management Software"}, {"url": "rease_mika_mws", "desc": "This is a one-hour video recording of the presentation of Peter Mika at the KnowledgeWeb summer school 2007. It comprises he video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\nMaking the Web searchable, or the Future of Web Search\r\nAbout Yahoo!\r\nYahoo! by numbers (April, 2007)\r\nMaking the Web searchable, or the Future of Web Search\r\nOverview\r\nMotivation\r\nHard searches\r\nExample?\r\nThe Semantic Web (1996-?)\r\nProblem: difficulties in deployment\r\nWeb 2.0 (2003-)\r\nMicroformats\r\nExample: hCard\r\nWikipedia infoboxes\r\nProblem: lack of foundations\r\nThesis: making the Web searchable\r\nSemantic Web 2.0\r\nGRDDL: microformats to RDF\r\nExample: openacademia.org and RDFa\r\nRDFa\r\nExample: machine tags\r\nZoneTag project (Yahoo! Research Berkeley)\r\nExample: Freebase\r\nWeb IR 2.0\r\nExample: folksonomies\r\nThe more complete picture\r\nMining and modelling folksonomies\r\nVision: ontology-based search\r\nIdeal world\r\nTechnical challenges\r\nSocial challenges\r\nExample: Technorati and microformats\r\nConclusion\r\nWhat is there to gain?\r\nQuestions?", "recorded": "2007-11-23T00:00:00", "title": "Making the Web Searchable"}, {"url": "eswc2013_kaljurand_semantic", "desc": "We describe a semantic wiki system with an underlying controlled natural language grammar implemented in Grammatical Framework (GF). The grammar restricts the wiki content to a well-defined subset of Attempto Controlled English (ACE), and facilitates a precise bidirectional automatic translation between ACE and language fragments of a number of other natural languages, making the wiki content accessible multilingually. Additionally, our approach allows for automatic translation into the Web Ontology Language (OWL), which enables automatic reasoning over the wiki content. The developed wiki environment thus allows users to build, query and view OWL knowledge bases via a user-friendly multilingual natural language interface. As a further feature, the underlying multilingual grammar is integrated into the wiki and can be collaboratively edited to extend the vocabulary of the wiki or even customize its sentence structures. This work demonstrates the combination of the existing technologies of Attempto Controlled English and Grammatical Framework, and is implemented as an extension of the existing semantic wiki engine AceWiki.", "recorded": "2013-05-30T15:00:00", "title": "A Multilingual semantic wiki based on Attempto Controlled English and Grammatical Framework"}, {"url": "iswc2013_hellmann_linked_data", "desc": "We are currently observing a plethora of Natural Language Processing tools and services being made available. Each of the tools and services has its particular strengths and weaknesses, but exploiting the strengths and synergistically combining different tools is currently an extremely cumbersome and time consuming task. Also, once a particular set of tools is integrated, this integration is not reusable by others. We argue that simplifying the interoperability of different NLP tools performing similar but also complementary tasks will facilitate the comparability of results and the creation of sophisticated NLP applications. In this paper, we present the NLP Interchange Format (NIF). NIF is based on a Linked Data enabled URI scheme for identifying elements in (hyper-)texts and an ontology for describing common NLP terms and concepts. In contrast to more centralized solutions such as UIMA and GATE, NIF enables the creation of heterogeneous, distributed and loosely coupled NLP applications, which use the Web as an integration platform. We present several use cases of the second version of the NIF specification (NIF 2.0) and the result of a developer study.", "recorded": "2013-10-23T15:55:01", "title": "Integrating NLP using Linked Data"}, {"url": "estc08_aquin_neon", "desc": "NeOn  addresses the R&D cycle of semantic applications, in an open environment of  highly contextualized, evolving and networked ontologies.  To this purpose, the project is creating a service-centred reference  architecture that includes methods and tools for ontology evolution,  collaborative development, contextual adaptation of semantic resources, etc.\r\n\r\nThis presentation will primarily demonstrate the use of NeOn technologies in  two case studies in the pharmaceutical sector. First, we aim at cataloguing information about pharmaceutical products in order to provide European  associations of pharmacy professionals with access to homogenized information  repositories. NeOn produces a global vademecum where distributed databases and regulations can be integrated and kept up-to-date.\r\n\r\nSecond, since a European directive in 2002 authorised the use of digitally  signed invoices for commercial transactions, the use of electronic invoices  has grown exponentially, leading to a high level of heterogeneity in formats.  Networked ontologies enable actors involved in a transaction to automatically  process arbitrary invoices by abstracting the underlying information from the  details of their particular encoding and technologies.", "recorded": "2008-09-25T14:23:52", "title": "NeOn \u2502 Lifecycle Support for Networked Ontologies A Case Study in the Pharmaceutical Domain"}, {"url": "rease_benjamins_ca", "desc": "This is a one-hour video recording of the presentation of Richard Benjamins at the KnowledgeWeb summer school 2006. It comprises either the video synchronized with the slides (requires Flash) or the video alone.\r\n\r\nTable of Contents: \r\niSOCO\r\nOverview\r\nMotivation\r\nSome reflections (I)\r\nSome reflections (II)\r\nThe Semantic Web\r\nThe Current Web for People\r\nThe Semantic Web: Ontologies\r\nWave: The Semantic Web and the Lisbon Council\r\nArchitecture: Stack of Languages for the Semantic Web\r\nOverview\r\nWho is Investing in Semantic Web?\r\nWhen Will Semantic Web Take Off?\r\nBut, Remember the Emerging Technology Lifecycle\r\nTypes of Markets and Its Customers\r\nInnovation Funnel\r\nA Business Roadmap for the Semantic Web\r\nOverview\r\nBusinesses Challenges I\r\nBusinesses Challenges II\r\nTwo Types of Businesses Applications\r\nOverview\r\nOntologies\r\nBuilding Ontologies\r\nPractical Experiences\r\nInfo Sources, Ontologies and Applications\r\nCost Factors for Constructing an Ontology\r\nOverview\r\neGovernment: Semantic Search\r\neGovernment: Cultural Heritage\r\nInsurances\r\nIntelligent FAQ System\r\nI have given an injunction of protection and the woman is asking me for a withdrawal of the measure.\r\n3D Visualization of Semantic Content", "recorded": "2007-02-13T00:00:00", "title": "The Semantic Web: Challenges and Applications"}, {"url": "eswc09_ramollari_lsws", "desc": "Recent years have seen the utilisation of Semantic Web Service descriptions for automating a wide range of service-related activities, with a primary focus on service discovery, composition, execution and mediation. An important area which so far has received less attention is service validation, whereby advertised services are proven to conform to required behavioural specifications.  This paper proposes a method for validation of service-oriented systems through automated functional testing. The method leverages ontology-based and rule-based descriptions of service inputs, outputs, preconditions and effects (IOPE) for constructing a stateful EFSM specification. The specification is subsequently utilised for functional testing and validation using the proven Stream X-machine (SXM) testing methodology. Complete functional test sets are generated automatically at an abstract level and are then applied to concrete Web services, using test drivers created from the Web service descriptions.  The testing method comes with completeness guarantees and provides a strong method for validating the behaviour of Web services.", "recorded": "2009-06-04T12:30:00", "title": "Leveraging Semantic Web Service Descriptions for Validation by Automated Functional Testing"}, {"url": "iswc08_parsia_iooor", "desc": "The Web Ontology Language (OWL) provides a modelling paradigm that is especially well suited for developing models of large, structurally complex domains such as those found in Health Care and the Life Sciences. OWL\u2019s declarative nature combined with powerful reasoning tools has effectively supported the development of very large and complex anatomy, disease, and clinical ontologies. OWL, however, is not a programming language, so using these models in applications necessitates both a technical means of integrating OWL models with programs and considerable methodological sophistication in knowing how to integrate them. In this paper, we present an analytical framework for evaluating various OWL-Java combination approaches. We have developed a software framework for what we call hybrid modelling, that is, building models in which part of the model exists and is developed directly in Java and part of the model exists and is developed directly in OWL. We analyse the advantages and disadvantages of hybrid modelling both in comparison to other approaches and by means of a case study of a large medical records system.", "recorded": "2008-10-28T14:00:00", "title": "Integrating Object-Oriented and Ontological Representations: A Case Study in Java and OWL"}, {"url": "iswc07_bloehdorn_kmmi", "desc": "The amount of ontologies and meta data available on the Web is constantly growing. The successful application of machine learning techniques for learning of ontologies from textual data, i.e. mining for the Semantic Web, contributes to this trend. However, no principal approaches exist so far for mining from the Semantic Web. We investigate how machine learning algorithms can be made amenable for directly taking advantage of the rich knowledge expressed in ontologies and associated instance data. Kernel methods have been successfully employed in various learning tasks and provide a clean framework for interfacing between non-vectorial data and machine learning algorithms. In this spirit, we express the problem of mining instances in ontologies as the problem of defining valid corresponding kernels. We present a principled framework for designing such kernels by means of decomposing the kernel computation into specialized kernels for selected characteristics of an ontology which can be flexibly assembled and tuned. Initial experiments on real world Semantic Web data enjoy promising results and show the usefulness of our approach.", "recorded": "2007-11-15T11:00:00", "title": "Kernel Methods for Mining Instance Data in Ontologies"}, {"url": "akbc2010_grenoble", "desc": "Good decision-making is dependent on comprehensive, accurate knowledge. But the information relevant to many important decisions in areas such as business, government, medicine and scientific research is massive, and growing at an accelerating pace. Relevant raw data is widely available on the web and other data sources, but usually in order to be useful it must be gathered, extracted, organized, and normalized into a knowledge base.\r\n\r\nHand-built knowledge bases such as Wikipedia have made us all better decision-makers. However more than human editing will be necessary to create a wide variety of domain-specific, deeply comprehensive, more highly structured knowledge bases.\r\n\r\nA variety of automated methods have begun to reach levels of accuracy and scalability that make them applicable to automatically constructing useful knowledge bases from text and other sources. These capabilities have been enabled by research in areas including natural language processing, information extraction, information integration, databases, search and machine learning. There are substantial scientific and engineering challenges in advancing and integrating such relevant methodologies.\r\n\r\nThis workshop gathered researchers in a variety of fields that contribute to the automated construction of knowledge bases.\r\n\r\nThere has recently been a tremendous amount of new work in this area, some of it in traditionally disconnected communities. In this workshop the organizers aim to bring these communities together.\r\n\r\nTopics of interest include:\r\n\r\n- information extraction; open information extraction, named entity extraction; entity resolution, relation extraction.\\\\\r\n- information integration; schema alignment; ontology alignment; ontology constrution.\\\\\r\n- monolingual alignment, alignment between knowlege bases and text.\\\\\r\n- joint inference between text interpretation and knowledge base\\\\\r\n- pattern analysis, semantic analysis of natural language, reading the web, learning by reading.\\\\\r\n- databases; distributed information systems; probabilistic databases.\\\\\r\n- scalable computation; distributed computation.\\\\\r\n- information retrieval; search on mixtures of structured and unstructured data; querying under uncertainty.\\\\\r\n- machine learning; unsupervised, lightly-supervised and distantly-supervised learning; learning from naturally-available data.\\\\\r\n- human-computer collaboration in knowledge base construction; automated population of wikis.\\\\\r\n- dynamic data, online/on-the-fly adaptation of knowledge.\\\\\r\n- inference; scalable approximate inference.\\\\\r\n- languages, toolkits and systems for automated knowledge base construction.\\\\\r\n- demonstrations of existing automatically-built knowledge bases.\\\\\r\n\r\nMore about the event [[http://akbc.xrce.xerox.com/|here]].", "recorded": "2010-05-17T09:00:00", "title": "1st Workshop on Automated Knowledge Based Construction (AKBC), Grenoble 2010"}, {"url": "ecmlpkdd2011_lavrac_vavpetic_mining", "desc": "The term semantic data mining denotes a data mining approach where domain ontologies are used as background knowledge. Such approach is motivated by large amounts of data that are increasingly becoming openly available and described using real-life ontologies represented in Semantic Web languages, arguably most extensively in the domain of biology. This recently opened up the possibility for interesting large-scale and real-world semantic applications.\r\n\r\nThe availability of semantically annotated data poses requirements for new kinds of approaches for data mining that would be able to deal with the complexity, and expressivity of the semantic representation languages, leverage on availability of ontologies and explicit semantics of the described resources, and account for novel assumptions (e.g., open world) that underlie reasoning services exploiting ontologies.\r\n\r\nThe tutorial addresses the above issues, focusing on the problems of how machine learning techniques can work directly on the richly structured Semantic Web data, exploit ontologies, and the Semantic Web technologies, what is the value added of machine learning methods exploiting ontologies, and what are the challenges for developers of semantic data mining methods. It also contains demonstrations of tools supporting semantic data mining.\r\n\r\nThe tutorial presents the topic of semantic data mining from three complementary perspectives.\r\n\r\nFirstly, it presents a general framework for semantic data mining, following the work [NVTL09]. The first part of the tutorial also discusses a new method for semantic subgroup discovery: g-SEGS. It is accompanied with a presentation of the developed tool, a part of Orange4WS environment.\r\n\r\nThe second part of tutorial covers the topic of learning from description logics (DL-learning), motivated by the fact that the standard Web ontology language, OWL, is theoretically based on description logics. This includes a demo of a tool supporting DL-learning (a plugin to the Rapid Miner system).\r\n\r\nFinally, the third part of the tutorial covers the topic of semantic meta-mining. This approach has three features that distinguish it from its predecessors. First, more than in previous work, it adopts a process-oriented approach where meta-learning is applied to support design choices at different stages of the complete data mining process or workflow. Second, it complements dataset descriptions with an in-depth analysis and characterization of algorithms\u2014their underlying assumptions, optimization goals and strategies, the models and patterns they generate. Finally, it relies on a data mining ontology which distills extensive background knowledge concerning knowledge discovery itself.", "recorded": "2011-09-09T14:00:00", "title": "Semantic Data Mining"}, {"url": "iswc2011_patton_semantic", "desc": "We present a semantic technology-based approach to emerging monitoring systems based on our linked data approach in the Tetherless World Constellation Semantic Ecology and Environment Portal (SemantEco). Our integration scheme uses an upper level monitoring ontology and mid-level monitoring-relevant domain ontologies. The initial domain ontologies focus on water and air quality. We then integrate domain data from different authoritative sources and multiple regulation ontologies (capturing federal as well as state guidelines) to enable pollution detection and monitoring. An OWL-based reasoning scheme identifies pollution events relative to user chosen regulations. Our approach captures and leverages provenance to enable transparency. In addition, SemantEco features provenance-based facet generation, query answering, and validation over the integrated data via SPARQL. We introduce the general SemantEco approach, describe the implementation which has been built out substantially in the water domain creating the SemantAqua portal, and highlight some of the potential impacts for the future of semantically-enabled monitoring systems.", "recorded": "2011-10-26T17:30:37", "title": "A Semantic Portal for Next Generation Monitoring Systems"}, {"url": "nipsworkshops09_computational_biology", "desc": "**Machine Learning in Computational Biology**\r\n\r\nThe field of computational biology has seen dramatic growth over the past few years, both in terms of new available data, new scientific questions, and new challenges for learning and inference. In particular, biological data are often relationally structured and highly diverse, well-suited to approaches that combine multiple weak evidence from heterogeneous sources. These data may include sequenced genomes of a variety of organisms, gene expression data from multiple technologies, protein expression data, protein sequence and 3D structural data, protein interactions, gene ontology and pathway databases, genetic variation data (such as SNPs), and an enormous amount of textual data in the biological and medical literature. New types of scientific and clinical problems require the development of novel supervised and unsupervised learning methods that can use these growing resources. Furthermore, next generation sequencing technologies are yielding terabyte scale data sets that require novel algorithmic solutions. The goal of this workshop is to present emerging problems and machine learning techniques in computational biology.\r\n----\r\nThe Workshop homepage can be found at http://www.mlcb.org/.\r\n----", "recorded": "2009-12-11T07:30:00", "title": "Computational Biology"}, {"url": "www2010_wagner_twt", "desc": "Although one might argue that little wisdom can be conveyed in messages of 140 characters or less, this paper sets out to explore whether the aggregation of messages in social awareness streams, such as Twitter, conveys meaningful information about a given domain. As a research community, we know little about the structural and semantic properties of such streams, and how they can be analyzed, characterized and used. This paper introduces a network-theoretic model of social awareness stream, a so-called \"tweetonomy\", together with a set of stream-based measures that allow researchers to systematically defi\fne and compare diff\u000berent stream aggregations. We apply the model and measures to a dataset acquired from Twitter to study emerging semantics in selected streams. The network-theoretic model and the corresponding measures introduced in this paper are relevant for researchers interested in information retrieval and ontology learning from social awareness streams. Our empirical\r\nfi\fndings demonstrate that di\u000bfferent social awareness stream aggregations exhibit interesting differences, making them amenable for \u000bdifferent applications.", "recorded": "2010-04-26T14:25:00", "title": "The Wisdom in Tweetonomies: Acquiring Latent Conceptual Structures from Social Awareness Streams"}, {"url": "iswc08_wolverton_apcfwg", "desc": "As AI developers increasingly look to work\ufb02ow technologies to perform complex integrations of individual software components, there is a growing need for the work\ufb02ow systems to have expressive descriptions of those components. They must know more than just the types of a component\u2019s inputs and outputs; instead, they need detailed characterizations that allow them to make\r\n\ufb01ne-grained distinctions between candidate components and between candidate work\ufb02ows. This paper describes PROCAT, an implemented ontology-based cata log for components, conceptualized as processes, that captures and communicates this detailed information. PROCAT is built on a layered representation that allows reasoning about processes at varying levels of abstraction, from qualitative con straints re\ufb02ecting preconditions and effects, to quantitative predictions about output data and performance. PROCAT employs Semantic Web technologies RDF,OWL, and SPARQL, and builds on SemanticWeb services research.We describe PROCAT\u2019S approach to representing and answering queries about processes, discuss some early experiments evaluating the quantitative predictions, and report on our experience using PROCAT in a system producing work\ufb02ows for intelligence\r\nanalysis.", "recorded": "2008-10-28T10:30:00", "title": "A Process Catalog for Workflow Generation"}, {"url": "coin_course_syllabus", "desc": "back to [[http://videolectures.net/coin|COIN training project ]]\r\n\r\n == 1. Motivation for the paradigm\r\n * Collaboration and Interoperability\r\n * Practical examples of CNs\r\n * Practices of Interoperability\r\n * Historic overview.\r\n * Technological and organizational trends.\r\n * Discussion of the usefulness / benefits and current limitations\r\n\r\n ||[[:ice09_martinez_ewbom]]||[[:ice08_martinez_future]]||[[:ice08_fernando_cdcw]]||[[:ice08_prinz_web]]||\r\n\r\n ----\r\n ----\r\n\r\n == 2. Basic concepts\r\n * COIN Basic Concepts\r\n * Fundamentals in CN\r\n * Fundamentals in Interoperability\r\n * COIN innovative concepts and models\r\n\r\n ||[[:ice08_conte_coin]]||[[:ice08_gusmeroli_meta]]||[[:ice09_conte_coin]][[||:iesa08_rossiter_lfi]]||\r\n\r\n ----\r\n ----\r\n\r\n == 3. Enterprise Interoperability\r\n * Basic Concepts, Definitions and Approaches.\r\n * Enterprise Modelling for Interoperability\r\n * Ontology for Interoperability\r\n * Introduction to Architecture and Platforms for Enterprise system Interoperability\r\n * Business Interoperability (BI)\r\n\r\n ||[[:ice08_katranuschkov_aigevo]]||[[:ice09_olmo_aabc]]||[[:ice09_debate_qa]]||[[:iswc06_wache_irpto]]\r\n\r\n ----\r\n ----\r\n\r\n == 4. VO Breeding Environment\r\n * Concept and examples.\r\n * Components, structure, actors and roles.\r\n * Competencies and assets.\r\n * Processes and governance principles.\r\n * VBE management system.\r\n * Trust and value systems.\r\n\r\n ||[[:ess07_ferlez_mc]]||[[:akom08_grobelnik_ina]]||[[:brussels06_afsarmanesh_v]]||\r\n\r\n ----\r\n ----\r\n\r\n == 5. Virtual Organizations\r\n * Concepts, organizational models and operational rules.\r\nLife cycle.\r\n * VO creation process and functionalities.\r\n * VO management functionalities and performance measurement.\r\n * VO dissolution and inheritance.\r\n\r\n ||[[:ess07_ollus_vom]]||[[:ess06_ollus_vrvp]]||[[:ess06_seifert_pmv]]||\r\n\r\n ----\r\n ----\r\n\r\n == 6. Virtual Communities\r\n * Concepts and typology.\r\n * Components, structure, and life cycle.\r\n * Professional virtual communities (PVC).\r\n * PVC management system.\r\n * Virtual teams.\r\n * Governance principles and social computing.\r\n\r\n ||[[:ess06_seifert_pmv]]||[[:esocenet07_santoro_ci]]||[[:esocenet07_santoro_ci]]||[[:brussels06_gusmeroli_i]]||\r\n ** recomended lectures:**\r\n *[[http://videolectures.net/ess06_crave_pbct| PVC basic concepts & typologies]]\r\n *[[http://videolectures.net/ess07_crave_pca|PVC and cooperation from AI perspective]]\r\n *[[http://videolectures.net/ess06_picard_sppvc|Social protocols in Professional Virtual Communitie]]\r\n *[[http://videolectures.net/eccs07_chavalarias_sma|Science mapping with asymmetric co-occurence analisys]]\r\n\r\n ----\r\n ----\r\n\r\n == 7. Architectures and Platforms\r\n * Computer networks basics. Base Internet technologies.\r\n * Components of a communication infrastructure.\r\n * Introduction to Service Platforms, Service Oriented Architectures\r\n * Introduction to Distributed systems\r\n * Introduction to Platform virtualisation\r\n * Introduction to Service-Oriented Interoperability (SOI)\r\n * Introduction to Model-Driven Interoperability (MDI)\r\n * Security mechanisms and technologies.\r\n * Data Quality in Cooperative Information Systems\r\n * Emerging computing models and implementation approaches\r\n\r\n ----\r\n ----\r\n\r\n == 8. Background Technologies\r\n * Traditional technologies\r\n * Semantic and knowledge technologies\r\n * Self awareness and cognitive systems\r\n * Agent technologies\r\n\r\n ||[[:kdd07_fayyad_dms]]||[[:ssll09_kotagiri_dami]]||[[:stanfordcs229f08_ng_lec01]]||[[:iswc08_hendler_ittsw]]||\r\n**recomended lectures:**\r\n *[[http://videolectures.net/psm08_cristianini_ieb/|In the Eye of the Beholder? Another look at Cognitive Systems]]\r\n*[[http://videolectures.net/ijcai09_lesser_saitmao/|Scaling AI Through Multi-Agent Organizations]]\r\n*[[http://videolectures.net/ccss09_pietronero_soafse/|Self-Organization and Finite Size Effects in Agent Models for Financial Markets]]\r\n*[[http://videolectures.net/ccss09_steubing_atcf/|Assessing the Critical Factors that Determine the Availability of Wood Fuel in Switzerland with an Agent Based Model]]\r\n ----\r\n ----\r\n\r\n == 9. COIN Solution\r\n * Basic architecture\r\n * Introduction to COIN Service platform\r\n * Transition from a Service Platform to an Utility Platform\r\n * Business-adaptive Service Platform:\r\n * Pervasive, Evolutionary and Scalable Service Platform\r\n * TSD-enabled service Platform for Networked Enterprises\r\n * Agent-based Business Knowledge Interoperability\r\n * Introduction to COIN Enterprise Interoperability services\r\n * Interoperability baseline\r\n * Information Interoperability Services\r\n * Knowledge Interoperability Services\r\n * Business Interoperability Services.\r\n * Introduction to COIN Enterprise Collaboration services\r\n * Collaboration baseline\r\n * Collaborative Product Development c-PD,\r\n * Collaborative Production Planning c-PP,\r\n * Collaborative Project Management c-PM\r\n * Collaborative Human Interaction c-HI.\r\n\r\n ----\r\n ----\r\n\r\n == 10. Practical Examples and COIN prototipes\r\n * use scenarios,\r\n * case studies and best practices,\r\n * demonstrators, demos, prototypes\r\n\r\n ||[[:ice09_olmo_coincpds]]||[[:ice09_doumeingts_vnlab]]||[[:ice09_canepa_isurf]]||[[:ice09_withalm_cdcp]]||\r\n\r\n ----\r\n ----\r\n\r\n == 11. Information Management\r\n * Information management requirements.\r\n * Mechanisms for information sharing and exchange.\r\n * Access rights definition and enforcement.\r\n * Federated /distributed information management.\r\n\r\n ----\r\n ----\r\n\r\n == 12. Information Exchange Standards\r\n * Importance of standards.\r\n * Interaction with legacy systems.\r\n\r\n ----\r\n ----\r\n\r\n == 13. Coordination Mechanisms\r\n * Collaboration modalities.\r\n * Concept of coordination.\r\n * Distributed-business process modeling and planning.\r\n * Distributed scheduling and re-scheduling.\r\n * Languages for business process modeling.\r\n * Workflow and process execution engines.\r\n * Challenges in flexible coordination.\r\n\r\n ||[[:eccs07_stark_cpc]]||[[:eccs07_menczer_wcn]]||[[:eccs07_matteo_gld]]||[[:eccs07_stark_cpc]]||\r\n\r\n ----\r\n ----\r\n\r\n == 14. Management of common Ontologies\r\n * The role of ontologies in collaboration\r\n * Ontology based support to Enterprise Interoperability\r\n * Introduction to Ontologies\r\n * Glossary and specification of base entities and concepts\r\n * COIN Core level common ontology\r\n * Ontology engineering approaches\r\n\r\n ||[[:ess07_grobelnik_twdmI]]||[[:ess07_grobelnik_twdmII]]||[[:mmdss07_grobelnik_oml]]||[[:ess07_obitko_oswve]]||\r\n\r\n ----\r\n ----\r\n\r\n == 15. E-commerce and E-markets\r\n * Concepts of e-Commerce and e-Market.\r\n * Relationships to CN and Interoperability.\r\n * Support institutions.\r\n * Support systems. Portals. Negotiation.\r\n * CRM. Logistics.\r\n\r\n ||[[:ess06_nagellen_soa]]||[[:eccs07_servedio_nsf]]||[[:eccs07_menczer_sws]]||\r\n\r\n ----\r\n ----\r\n\r\n == 16. Non Tecnological Issues\r\n * Social, ethical, legal, and organizational issues.\r\n * Contractual issues.\r\n * New business models.\r\n * Sustainability mechanisms.\r\n * Intellectual property management.\r\n\r\n ||[[:antwerpen04_heath_tbmso]]||[[:antwerpen04_blomqvist_ottbn]]||[[:eccs07_antonelli_fei]]||[[:eccs07_hales_end]]||\r\n\r\n ----\r\n ----\r\n\r\n == 17. Organisation Modeling and Reference Models\r\n * Concept of reference model.\r\n * Modeling frameworks.\r\n * Examples of reference models.\r\n * Organisation Modelling\r\n * Business Process Modelling\r\n * Business Models Overview\r\n * Derivation and evolution methods.\r\n\r\n ||[[:eccs07_stark_cpc]]||[[:eccs07_menczer_wcn]]||[[:eccs07_matteo_gld]]||\r\n\r\n ----\r\n ----\r\n\r\n == 18. Emerging Collaborative Forms\r\n * Summary of studied collaborative forms and interoperability approaches.\r\n * New application examples: collaborative e-government, e-Science, Virtual institutes, Virtual Labs, etc.\r\n * Internet of Things: Networks of machines, networks of sensors.\r\n * Intelligent, self-aware enterprises, Symbiotic models\r\n * Other emerging cases.\r\n\r\n ||[[:eccs07_newman_sdc]]||[[:eccs07_verschure_dac]]||[[:eccs07_stamatiou_dtc]]||[[:eccs07_canright_smn]]||\r\n **recomended lectures:**\r\n *[[http://videolectures.net/porto05_cordeiro_sc| Semiotics in CNOs]]\r\n *[[http://videolectures.net/eccs07_damiani_irb|Interacting Random Boolean Networks]]\r\n *[[http://videolectures.net/eccs07_jiang_pba|Population-based adaptive Systems: An Implementation in NEW TIES]]", "recorded": "2010-01-05T23:41:15", "title": "Course"}, {"url": "classconference2012_di_martino_project", "desc": "Cloud vendor lock-in and interoperability gaps arise (among many reasons) when semantics of resources and services, and of Application Programming Interfaces is not shared. Standards and techniques borrowed from SOA and Semantic Web Services areas might help in gaining shared, machine readable description of Cloud offerings (resources, Services at Platform and Application level, and their API groundings), thus allowing automatic discovery, matchmaking, and thus supporting selection, brokering, interoperability end even composition of Cloud Services among multiple Clouds. The EU funded mOSAIC project (http://www.mosaic-cloud.eu) aims at designing and developing an innovative open-source API and platform that enables applications to be Cloud providers' neutral and to negotiate Cloud services as requested by their users. Using the mOSAIC Cloud ontology and Semantic Engine, cloud applications' developers will be able to specify their services and resources requirements and communicate them to the mOSAIC Platform and Cloud Agency. The mOSAIC Cloud Agency will implement a multi-agent brokering mechanism that will search for Cloud services matching the applications\u2019 request, and possibly compose the requested service.", "recorded": "2012-10-24T12:20:00", "title": "Portability and Interoperability in Clouds: contributions from the mOSAIC Project"}, {"url": "eswc2012_burel_online_enquiry", "desc": "Online communities are prime sources of information. The Web is rich with forums and Question Answering (Q&A) communities where people go to seek answers to all kinds of questions. Most systems employ manual answer-rating procedures to encourage people to provide quality answers and to help users locate the best answers in a given thread. However, in the datasets we collected from three online communities, we found that half their threads lacked best answer markings. This stresses the need for methods to assess the quality of available answers to: 1) provide automated ratings to fill in for, or support, manually assigned ones, and; 2) to assist users when browsing such answers by filtering in potential best answers. In this paper, we collected data from three online communities and converted it to RDF based on the SIOC ontology. We then explored an approach for predicting best answers using a combination of content, user, and thread features. We show how the influence of such features on predicting best answers differs across communities. Further we demonstrate how certain features unique to some of our community systems can boost predictability of best answers.", "recorded": "2012-05-29T11:00:00", "title": "Automatic Identification of Best Answers in Online Enquiry Communities"}, {"url": "iswc2013_gentile_linked_datasets", "desc": "The Web of Data is a rich common resource with billions of triples available in thousands of datasets and individual Web documents created by both expert and non-expert ontologists. A common problem is the imprecision in the use of vocabularies: annotators can misunderstand the semantics of a class or property or may not be able to find the right objects to annotate with. This decreases the quality of data and may eventually hamper its usability over large scale. This paper describes Statistical Knowledge Patterns (SKP) as a means to address this issue. SKPs encapsulate key information about ontology classes, including synonymous properties in (and across) datasets, and are automatically generated based on statistical data analysis. SKPs can be effectively used to automatically normalise data, and hence increase recall in querying. Both pattern extraction and pattern usage are completely automated. The main benefits of SKPs are that: (1) their structure allows for both accurate query expansion and restriction; (2) they are context dependent, hence they describe the usage and meaning of properties in the context of a particular class; and (3) they can be generated offline, hence the equivalence among relations can be used efficiently at run time.", "recorded": "2013-10-25T16:05:01", "title": "Statistical Knowledge Patterns: Identifying Synonymous Relations in Large Linked Datasets"}, {"url": "solomon_rousu_sopef", "desc": "Enzyme function prediction is an important problem in post-genomic\r\nbioinformatics. There are two general methods for solving the problem:\r\ntransfer of annotation from a similar, already annotated protein, and\r\nmachine learning approaches that treat the problem as classification\r\nagainst a fixed taxonomy, such as Gene Ontology or the EC hierarchy.\r\nThese methods are suitable in cases where the function has been\r\npreviously characterized and included in the taxonomy. However, given a\r\nnew function that is not previously described, existing approaches\r\narguably do not offer adequate support for the human expert.\r\n\r\nIn this presentation, we I will present a structured output learning\r\napproach, where the enzyme function, an enzymatic reaction, is described\r\nin fine-grained fashion with so called reaction kernels which allow\r\ninterpolation and extrapolation in the output (reaction) space. A\r\nstructured output model is learned to predict enzymatic reactions from\r\nsequence motifs. We bring forward several choices for constructing\r\nreaction kernels and experiment with them in the remote homology case\r\nwhere the functions in the test set have not been seen in the training\r\nphase. Our experiments demonstrate the viability of our approach.", "recorded": "2009-09-04T10:00:00", "title": "Structured Output Prediction of Enzyme Function via Reaction Kernels"}, {"url": "eswc2014_peters_rule_based", "desc": "Using semantic technologies the materialization of implicit given facts that can be derived from a dataset is an important task performed by a reasoner. With respect to the answering time for queries and the growing amount of available data, scaleable solutions that are able to process large datasets are needed. In previous work we described a rule-based reasoner implementation that uses massively parallel hardware to derive new facts based on a given set of rules. This implementation was limited by the size of processable input data as well as on the number of used parallel hardware devices. In this paper we introduce further concepts for a workload partitioning and distribution to overcome this\r\nlimitations. Based on the introduced concepts, additional levels of parallelization can be proposed that benefi\ft from the use of multiple parallel devices. Furthermore, we introduce a concept to reduce the amount of invalid triple derivations like duplicates. We evaluate our concepts by applying di\u000bfferent rulesets to the real-world DBPedia dataset as well as to the synthetic Lehigh University benchmark ontology (LUBM) with up to 1.1 billion triples. The evaluation shows that our implementation scales in a linear way and outperforms current state of the art reasoner with respect to the throughput achieved on a single computing node", "recorded": "2014-05-28T11:00:00", "title": "Scaling Parallel Rule-based Reasoning"}, {"url": "iswc08_schenk_ostc", "desc": "The Semantic Web is a distributed environment for knowledge representation and reasoning. The distributed nature brings with it failing data sources and inconsistencies between autonomous knowledge bases. To reduce problems resulting from unavailable sources and to improve performance, caching can be used. Caches, however, raise new problems of imprecise or outdated information. We propose to distinguish between certain and cached information when reasoning on the semantic web, by extending the well known  $\\mathcal{FOUR}$  bilattice of truth and knowledge orders to  $\\mathcal{FOUR-C}$  , taking into account cached information. We discuss how users can be offered additional information about the reliability of inferred information, based on the availability of the corresponding information sources. We then extend the framework towards  $\\mathcal{FOUR-T}$  , allowing for multiple levels of trust on data sources. In this extended setting, knowledge about trust in information sources can be used to compute, how well an inferred statement can be trusted and to resolve inconsistencies arising from connecting multiple data sources. We redefine the stable model and well founded semantics on the basis of  $\\mathcal{FOUR-T}$ , and reformalize the Web Ontology Language OWL2 based on logical bilattices, to augment OWL knowledge bases with trust based reasoning. ", "recorded": "2008-10-30T12:00:00", "title": "On the Semantics of Trust and Caching in the Semantic Web"}, {"url": "iswc07_wang_por", "desc": "Extracting semantic relations is of great importance for the creation of the Semantic Web content. It is of great benefit to semi-automatically extract relations from the free text of Wikipedia using the structured content readily available in it. Pattern matching methods that employ information redundancy cannot work well since there is not much redundancy information in Wikipedia, compared to the Web. Multi-class classification methods are not reasonable since no classification of relation types is available in Wikipedia. In this paper, we propose PORE (Positive-Only Relation Extraction), for relation extraction from Wikipedia text. The core algorithm B-POL extends a state-of-the-art positive-only learning algorithm using bootstrapping, strong negative identification, and transductive inference to work with fewer positive training examples. We conducted experiments on several relations with different amount of training data. The experimental results show that B-POL can work effectively given only a small amount of positive training examples and it significantly outperforms the original positive learning approaches and a multi-class SVM. Furthermore, although PORE is applied in the context of Wikipedia, the core algorithm B-POL is a general approach for Ontology Population and can be adapted to other domains.", "recorded": "2007-11-13T14:00:00", "title": "PORE: Positive-Only Relation Extraction from Wikipedia Text"}, {"url": "eswc06_hovy_tlsss", "desc": "Building on the successes of the past decade\u2019s work on statistical methods, there are signs that continued quality improvement for QA, summarization, information extraction, and possibly even machine translation require more-elaborate and possibly even (shallow) semantic representations of text meaning.\r \r But how can one define a large-scale shallow semantic representation system and contents adequate for NLP applications, and how can one create the corpus of shallow semantic representation structures that would be required to train machine learning algorithms? This talk addresses the components required (including a symbol definition ontology and a corpus of (shallow) meaning representations) and the resources and methods one needs to build them (including existing ontologies, human annotation procedures, and a verification methodology). To illustrate these aspects, several existing and recent projects and applicable resources are described, and a research programme for the near future is outlined. Should NLP be willing to face this challenge, we may in the not-too-distant future find ourselves working with a whole new order of knowledge, namely (shallow) and doing so in increasing collaboration (after a 40-years separation) with specialists from the Knowledge Representation and reasoning community.", "recorded": "2006-06-14T00:00:00", "title": "Toward Large-Scale Shallow Semantics for Higher-Quality NLP"}, {"url": "iswc2014_nikitina_annotation", "desc": "In this paper, we present Semano \u2014 a generic framework for annotating natural language texts with entities of OWL 2 DL ontologies. Semano generalizes the mechanism of JAPE transducers that has been introduced within the General Architecture for Text Engineering (GATE) to enable modular development of annotation rule bases. The core of the Semano rule base model are rule templates called japelates and their instantiations. While Semano is generic and does not make assumptions about the document characteristics used within japelates, it provides several generic japelates that can serve as a starting point. Also, Semano provides a tool that can generate an initial rule base from an ontology. The generated rule base can be easily extended to meet the requirements of the application in question. In addition to its JavaAPI,Semano includes two GUI components \u2014 a rule base editor and an annotation viewer. In combination with the default japelates and the rule generator, these GUI components can be used by domain experts that are not familiar with the technical details of the framework to set up a domain-speci\ufb01c annotator. In this paper, we introduce the rule base model of Semano, provide examples of adapting the rule base to meet particular applicationrequirementsandreportourexperiencewithapplyingSemanowithin the domain of nano technology.", "recorded": "2014-10-21T11:40:00", "title": "Semano: Semantic Annotation Framework for NaturalLanguage Resources "}, {"url": "eswc2010_bechhofer_sppf", "desc": "SKOS (Simple Knowledge Organisation System) is a common data model for sharing and linking knowledge organization systems via the Web. Many knowledge organization systems, such as thesauri, taxonomies, classification schemes and subject heading systems, share a similar structure, and are used in similar applications. SKOS captures much of this similarity and makes it explicit, enabling data and technology sharing across diverse applications.\r\nThe SKOS data model provides a standard, low-cost migration path for porting existing knowledge organization systems to the Semantic Web. SKOS also provides a light weight, intuitive language for developing and sharing new knowledge organization systems. It may be used on its own, or in combination with formal knowledge representation languages such as the Web Ontology language (OWL). SKOS was published as a W3C Recommendation in August 2009 and is seeing growing take-up in a number of fields including (among others) cultural heritage, economics, astronomy, and local government. SKOS also looks set to play a key role in providing vocabularies for the Data Web through its use in Open Linked Data.", "recorded": "2010-06-03T09:04:00", "title": "SKOS: Past, Present, Future - and a little bit of history, architecture and engineering "}, {"url": "w3cworkshop2012_melby_data", "desc": "There is currently a \"strong separation\" between the well-established fields of terminology and Linked Data. This presentation describes a proposal to adapt TermBase eXchange (TBX, ISO 30042)\u2014the international standard for representing complex, typically multilingual termbases\u2014for use in the Linked Data and MultilingualWeb-LT communities. This version would be called RDF-TBX and would be isomorphic to the current version TBX. It would help bring the terminology community and the Linked Data community (more generally the Semantic Web community) closer together. Possibile applications include (a) linking terms in data to a termbase that has been converted to RDF-TBX and (b) carrying out automated conversions between existing terminology resources with concept relations and existing Semantic Web ontology resources. I would like to determine though face-to-face interaction at the workshop whether this project, if carried out, is likely to address the separation between terminology and Linked Data. Depending on the reaction to this position by the Dublin workshop participants, an RDF-TBX project could begin immediately at the Brigham Young University Translation Research Group.\r\n\r\n**The transcript of the Q&A session \"Linked Open Data and the Lexicon\" is available [[http://www.w3.org/2012/06/11-mlwDub-minutes#qa_3|here]].**", "recorded": "2012-06-11T11:40:00", "title": "Bringing Terminology to Linked Data through TBX"}, {"url": "newtonschw03s08_li_lias", "desc": "The fast-growing public repertoire of microarray gene expression databases provides individual investigators with unprecedented opportunities to study transcriptional activities for genes of their research interest at no additional cost. Methods such as hierarchical clustering, principal component analysis, gene network and others, have been widely used. They offer biologists valuable genome-wide portraits of how genes are co-regulated in groups. Such approaches have a limitation because it often turns out that the majority of genes do not fall into the detected gene clusters. If one has a gene of primary interest in mind and cannot find any nearby clusters, what additional analysis can be conducted? In this talk, I will show how to address this issue via the statistical notion of liquid association. An online biodata mining system is developed in my lab for aiding biologists to distil information from a web of aggregated genomic knowledgebase and data sources at multi-levels, including gene ontology, protein complexes, genetic markers, drug sensitivity. The computational issue of liquid association and the challenges faced in the context of high p low n problems will be addressed.\r\n\r\n**Homepage Link**\r\n* http://www.newton.ac.uk/programmes/SCH/seminars/062416301.html", "recorded": "2008-06-24T16:30:00", "title": "Liquid association for large scale gene expression and network studies"}, {"url": "eswc09_conroy_ueso", "desc": "A key aspect of semantic interoperability is the semantic mapping process itself. Traditionally, semantic mapping processes conducted by knowledge engineers have been proposed to bridge this gap. However, knowledge engineers alone are unlikely to cope with the ever increasing amount of mapping work required, especially as mappings themselves begin to be specialised for different contexts. One solution is to develop new mapping processes that enable users to participate in the mapping process themselves. In this paper we present an evaluation study of our user-driven tagging approach to the semantic mapping process. In our approach, users actively participate in generating mappings by categorising automatically generated candidate matches presented in natural language over a long time period. In the evaluation study three groups of users generated mappings between their personal ontologies and a sports ontology describing sports news content from RSS feeds. The mapping process was embedded within the users' work environment as a Firefox browser extension. The study is discussed, focusing on whether the mapping process is unintrusive, engaging and simplified for the user. The evaluation results were promising and indicate that people with various levels of expertise could become active in the semantic mapping process.", "recorded": "2009-06-04T11:25:59", "title": "User Evaluation Study of a Tagging Approach to Semantic Mapping"}, {"url": "collaborative_networks_course_syllabus", "desc": "back to [[http://videolectures.net/collaborative_networks_curriculum|Collaborative Networks curriculum]]\n\n == 1. Motivation for the Paradigm\n * Practical examples of collaborative networks\n * Historic overview.\n * Technological and organizational trends.\n * Discussion of the usefulness / benefits and current limitations of CNs.\n\n This first unit aims at creating a motivation for the course through a brief presentation of application areas, illustrated by concrete examples in industry, services, government, etc. A brief historic overview of the industrial organizational paradigms leading to collaborative networks as well as a summary of current technological and organizational trends is presented. For each example an attempt to identify the main involved problems (e.g. organizational forms, processes, cooperation and collaboration forms) is made, calling the attention for the potential contributes from other disciplines. The socioeconomic importance of each case is also briefly highlighted.\n ||[[left:ess06_matos_cbc]]||\n\n ----\n ----\n\n == 2. Basic Concepts of Collaborative Networks\n * Categories of CNs.\n * Actors and roles.\n * Life cycle and related key processes.\n\n After the motivation phase, the base concepts are introduced. Considering the large variety of collaborative networks, a categorization of the various forms is made and a taxonomy is introduced in order to give students a global perspective of the area. The main types of collaborative networks, namely the long term strategic alliance as well as the dynamic (short term) opportunity driven collaborative network is addressed. The various actors involved in a collaborative network as well as the roles they can play are identified. Finally the life cycle of a collaborative network is discussed in terms of its main phases.\n ||[[left:prove04_zwegers_pfcrj]]||\n\n ----\n ----\n\n == 3. Virtual Organization Breeding Environment\n * Concept and examples.\n * Components, structure, actors and roles.\n * Competencies and assets.\n * Processes and governance principles.\n * VBE management system.\n * Trust and value systems.\n\n The concept of Virtual organization Breeding Environment (VBE) is elaborated and justified. Illustrating examples are provided. The components, structure and life cycle of this organizational form as well as its involved actors and roles are identified and characterized. Main processes, working & sharing and governance principles are discussed. The architecture and supporting functionalities for a VBE management system as well as the corresponding information and knowledge bases are introduced in a step by step approach. The issues of trust and value systems are analyzed in terms of modeling, support functionality, and practical use. . The management of competencies, VBE assets, and trust, as well as the value systems is analyzed in terms of modeling, support functionality, and practical use.\n ||[[:brussels06_afsarmanesh_v]]||[[:ess07_ferlez_mc]]||[[:akom08_grobelnik_ina]]||\n\n ----\n ----\n\n == 4. Virtual Organisations\n * Concepts, organizational models and operational rules.\n * Life cycle.\n * VO creation process and functionalities.\n * VO management functionalities and performance measurement.\n * VO dissolution and inheritance.\n\n The concept of Virtual Organization (VO) previously introduced is briefly revisited and the conditions for its emergence are discussed. Particular emphasis is devoted to the creation of dynamic VOs in a VBE context. The life cycle \u2013 creation, operation, evolution, and dissolution \u2013 of the VO is analyzed and the supporting information / knowledge and functionalities are discussed together with the involved actors and roles. Special attention is devoted to the consortia formation, negotiation, distributed business process planning and supervision, performance management, dissolution and inheritance, and business modeling. The relationship to other more classic networks such as supply chains is made. Examples in various domains are analyzed.\n ||[[:ess07_ollus_vom]]||[[:ess06_ollus_vrvp]]||[[:ess06_seifert_pmv]]||\n\n ----\n ----\n\n == 5. Virtual Communities\n * Concepts and typology.\n * Components, structure, and life cycle.\n * Professional virtual communities (PVC).\n * PVC management system.\n * Virtual teams.\n * Governance principles and social computing.\n\n The concept of Virtual Community (VC) previously introduced is briefly revisited and compared with the concept of VO. A typology of VC is introduced and a particular attention is devoted to Professional Virtual Communities. The components, structure, and life cycle of PVCs are discussed and modeling options introduced in comparison with the VBE. Architectural options for a PVC management system and supporting functionalities are introduced. The creation of Virtual Teams within a PVC and their management are studied. Governance principles, main processes, intellectual property issues, and social computing issues are discussed.\n ||[[:esocenet07_santoro_ci]]||[[:fiw05_santoro_pvcce]]||[[:brussels06_gusmeroli_pld]]||[[:brussels06_gusmeroli_i]]||\n ** recomended lectures:**\n *[[http://videolectures.net/ess06_crave_pbct| PVC basic concepts & typologies]]\n *[[http://videolectures.net/ess07_crave_pca|PVC and cooperation from AI perspective]]\n *[[http://videolectures.net/ess06_picard_sppvc|Social protocols in Professional Virtual Communitie]]\n *[[http://videolectures.net/eccs07_chavalarias_sma|Science mapping with asymmetric co-occurence analisys]]\n\n ----\n ----\n\n == 6. Management of Common Ontologies\n * Glossary and specification of base entities and concepts\n * Core level common ontology for collaborative networks\n * Ontology engineering approaches\n * Learning ontology from unstructured sources\n * Semi-automatic customization of common ontology to specific domain/application\n\n Considering the complexity of the collaborative network environments, a number of benefits are gained through provision of the ontology for collaborative networks, e.g. to support common understanding of their related entities and concepts, to classify their knowledge in order to facilitate the knowledge interoperability both among the network participants and among different networks, as well as for development of a management system for collaborative networks, the needed databases and data/knowledge access functionality. Approaches for a common ontology will be presented and mechanisms required for ontology customization and management will be addressed.\n\n ||[[:ess07_grobelnik_twdmI]]||[[:ess07_grobelnik_twdmII]]||[[:mmdss07_grobelnik_oml]]||[[:ess07_obitko_oswve]]||\n\n ----\n ----\n\n == 7. e-Commerce and e-Markets\n * Concepts of e-Commerce and e-Market.\n * Relationships to collaborative networks.\n * Support institutions.\n * Support systems. Portals. Negotiation.\n * CRM. Logistics.\n\n Although these issues are not part of the Collaborative Networks, they share a number of common issues. Therefore the concepts of e-Commerce and e-Market are introduced and the differences and commonalities in relation to collaborative networks highlighted. The involved organizational issues are discussed and supporting architectures and technologies introduced. Finally the contact points between these areas and collaborative networks in a new digital ecosystems context are discussed.\n ||[[:ess06_nagellen_soa]]||[[:eccs07_servedio_nsf]]||[[:eccs07_menczer_sws]]||\n\n ----\n ----\n\n == 8. Non-technological Issues\n * Social, ethical, legal, and organizational issues.\n * Contractual issues.\n * New business models.\n * Collaboration sustainability mechanisms.\n * Intellectual property management.\n\n The success and effectiveness of implementation of the collaborative networks depend on a number of other important issues besides the technological solutions. In this unit social, ethical, legal, and organizational issues are discussed and current trends pointed out. New business models and their applicability are discussed, namely through the introduction of examples. Marketing and sustainability of the network, intellectual property management, systems of incentives, etc. are other relevant issues. Alternatively these topics can each be introduced in parallel and along the other units.\n ||[[:antwerpen04_heath_tbmso]]||[[:antwerpen04_blomqvist_ottbn]]||[[:eccs07_antonelli_fei]]||[[:eccs07_hales_end]]||\n\n ----\n ----\n\n == 9. Base Infrastructures\n * Computer networks basics. Base Internet technologies.\n * Components of a communication infrastructure.\n * Implementation approaches: agent-based, service-oriented, etc.\n * Security mechanisms and technologies.\n * Emerging computing models.\n\n The establishment of adequate communication channels and protocols is a basic pre-requisite for the operation of collaborative networks and interoperation among its components and subsystems. Therefore the main logical components of a communications infrastructure are introduced. Various implementation approaches are discussed, included agent-based and service-oriented approaches. The security issues deserve special attention and the various mechanisms and technologies are discussed in terms of their benefits and limitations. Emerging computing models, mobile and pervasive computing are briefly studied in terms of their contribution to collaborative networks.\n ||[[:ess06_nagellen_soa]]||[[:ess06_rabelo_etcsi]]||[[:ess07_negretto_ii]]||[[:eccs07_iyer_chf]]||\n\n ----\n ----\n\n == 10. Information Management\n * Information management requirements.\n * Mechanisms for information sharing and exchange.\n * Access rights definition and enforcement.\n * Federated /distributed information management.\n\n Information management in a distributed, multi-ownership context is discussed and mechanisms for information sharing, information exchange, and access rights definition and enforcement are introduced. The role of standards is discussed and main standards briefly characterized. Various information management approaches are briefly discussed, with particular emphasis on the federated information management systems. Different implementation approaches are also discussed.\n ||[[:ess06_angelov_c]]||[[:eccs07_huberman_bwe]]||\n\n ----\n ----\n\n == 11. Special Information Exchange Standards\n * Importance of standards in collaborative networks.\n * EDI and EDIFACT.\n * Interaction with legacy systems.\n * XML and its role.\n * STEP and PDM.\n * Other standards.\n\n A number of standards particularly relevant for collaborative networks are introduced and analyzed. Among them: EDI (Electronic Data Interchange), which in historical terms represents one of the first tools for cooperation among enterprises, is introduced and briefly characterized. The interaction between EDI and ERP systems is briefly discussed. The EDIFACT standard is presented and current XML-based implementations mentioned. The STEP standard for the exchange of technical product data is described and its applicability in virtual enterprises is discussed. Support technologies as well as PDM systems are discussed. Other emerging standards for information and knowledge exchange are pointed out.\n\n ----\n ----\n\n == 12. Coordination Mechanisms\n * Collaboration modalities.\n * Concept of coordination.\n * Distributed-business process modeling and planning.\n * Distributed scheduling and re-scheduling.\n * Languages for business process modeling.\n * Workflow and process execution engines.\n * Challenges in flexible coordination.\n\n Various modalities of collaboration are discussed and the corresponding coordination needs introduced. The concept of coordination is highlighted. Process-based coordination and the corresponding distributed business process modeling, planning, scheduling, and execution are particularly focused. Languages for business process modeling are introduced. Workflow / process execution engines are discussed and standard architectures for inter-organization workflow are analyzed. Finally challenges in flexible coordination are raised and the students are motivated to suggest approaches.\n ||[[:eccs07_stark_cpc]]||[[:eccs07_menczer_wcn]]||[[:eccs07_matteo_gld]]||\n\n ----\n ----\n\n == 13. Reference Models\n * Concept of reference model.\n * Modeling frameworks.\n * Examples of reference models.\n * Derivation and evolution methods.\n\n The concept of reference model and its need is introduced. Modeling frameworks are presented and discussed. Example reference models are introduced and methods for models evolution and derivation of particular models are briefly discussed. A reference modeling framework for CNs will be presented, addressing its specific dimensions and elements. Some CN reference models, for example for VBEs and VOs will be presented.\n ||[[:porto05_putnik_ftmc]]||[[:antwerpen04_eijnatten_iccom]]||[[:porto05_pinto_dlceo]]||\n\n ----\n ----\n\n == 14. Emerging Collaborative Forms\n * Summary of studied collaborative forms.\n * New application examples: collaborative e-government, e-Science, Virtual institutes, Virtual Labs, etc.\n * Networks of machines, networks of sensors.\n * Other emerging cases.\n\n In this last unit, and after a brief summary of the various collaborative forms studied in previous units, a discussion of possible new models and generalizations is made. As a starting basis, new forms of collaborative e-government, e-science, virtual institutes, Virtual laboratories, etc, are discussed. Other generalizations include: networks of sensors, networks of machines, etc. Then students are encouraged to suggest other application areas and identify the innovative collaborative forms needed.\n ||[[:eccs07_newman_sdc]]||[[:eccs07_verschure_dac]]||[[:eccs07_stamatiou_dtc]]||[[:eccs07_canright_smn]]||\n **recomended lectures:**\n *[[http://videolectures.net/porto05_cordeiro_sc| Semiotics in CNOs]]\n *[[http://videolectures.net/eccs07_damiani_irb|Interacting Random Boolean Networks]]\n *[[http://videolectures.net/eccs07_jiang_pba|Population-based adaptive Systems: An Implementation in NEW TIES]]", "recorded": "2008-06-19T12:03:37", "title": "Course Syllabus- Collaborative Networks"}, {"url": "nipsworkshops2010_computational_biology", "desc": "The field of computational biology has seen dramatic growth\r\nover the past few years, both in terms of new available data,\r\nnew scientific questions, and new challenges for learning and\r\ninference. In particular, biological data is often relationally\r\nstructured and highly diverse, well-suited to approaches that\r\ncombine multiple weak evidence from heterogeneous sources.\r\nThese data may include sequenced genomes of a variety of\r\norganisms, gene expression data from multiple technologies,\r\nprotein expression data, protein sequence and 3D structural\r\ndata, protein interactions, gene ontology and pathway databases,\r\ngenetic variation data (such as SNPs), and an enormous amount\r\nof textual data in the biological and medical literature. New types\r\nof scientific and clinical problems require the development of\r\nnovel supervised and unsupervised learning methods that can\r\nuse these growing resources. \r\n\r\nThe goal of this workshop is to\r\npresent emerging problems and machine learning techniques\r\nin computational biology. We invited several speakers from\r\nthe biology/bioinformatics community who presented current\r\nresearch problems in bioinformatics, and we invited contributed\r\ntalks on novel learning approaches in computational biology.\r\nWe encouraged contributions describing either progress on\r\nnew bioinformatics problems or work on established problems\r\nusing methods that are substantially different from standard\r\napproaches.\r\n\r\nWorkshop homepage: http://mlcb.org/", "recorded": "2010-12-10T07:30:00", "title": "Machine Learning in Computational Biology"}, {"url": "iswc2011_yu_rdfgraphs", "desc": "Data quality issues arise in the Semantic Web because data\r\nis created by diverse people and/or automated tools. In particular, erroneous\r\ntriples may occur due to factual errors in the original data source,\r\nthe acquisition tools employed, misuse of ontologies, or errors in ontology\r\nalignment. We propose that the degree to which a triple deviates\r\nfrom similar triples can be an important heuristic for identifying errors.\r\nInspired by functional dependency, which has shown promise in database\r\ndata quality research, we introduce value-clustered graph functional dependency to detect abnormal data in RDF graphs. To better deal with\r\nSemantic Web data, this extends the concept of functional dependency\r\non several aspects. First, there is the issue of scale, since we must consider\r\nthe whole data schema instead of being restricted to one database\r\nrelation. Second, it deals with multi-valued properties without explicit\r\nvalue correlations as specified as tuples in databases. Third, it uses clustering\r\nto consider classes of values. Focusing on these characteristics, we\r\npropose a number of heuristics and algorithms to efficiently discover the\r\nextended dependencies and use them to detect abnormal data. Experiments\r\nhave shown that the system is efficient on multiple data sets and\r\nalso detects many quality problems in real world data.", "recorded": "2011-10-26T11:00:00", "title": "Extending functional dependency to detect abnormal data in rdf graphs"}, {"url": "aaai2011_klank_pancakes", "desc": "In this video we show a recent public experiment that shows two\r\nrobots making pancakes using web instructions. In the experiment,\r\nthe robots retrieve instructions for making pancakes from the World\r\nWide Web and generate robot action plans from the instructions.\r\nThis task is jointly performed by two autonomous robots: The first\r\nrobot opens and closes cupboards and drawers, takes a pancake mix\r\nfrom the refrigerator, and hands it to the robot B. The second robot\r\ncooks and flips the pancakes, and then delivers them back to the\r\nfirst robot.\r\nAI-related in the experiment is using of the encyclopedic knowledge base\r\nfor the translation of instructions into robot plans which is performed\r\nby the following sequence of steps. First, the sentences are\r\nparsed using a common natural-language parser to\r\ngenerate a syntax tree of the instructions. The branches of the tree\r\nare then recursively combined into more complex descriptions to create\r\nan internal representation of the instructions describing the actions,\r\nthe objects involved, locations, time constraints, the amount of\r\ningredients to be used etc. The words in the original text are\r\nresolved to concepts in the robot's knowledge base by first looking up\r\ntheir meanings in the WordNet lexical database,\r\nand by then exploiting mappings between WordNet and the\r\nCyc ontology. Our system employs a simple method\r\nbased on the phrase context and on information about object-action\r\npairs obtained from Cyc to disambiguate between possible word\r\nmeanings.", "recorded": "2011-08-05T11:42:34", "title": "Robotic Roommates Making Pancakes"}, {"url": "iswc08_klinov_oerpdl", "desc": "This paper describes the first steps towards developing a methodology for testing and evaluating the performance of reasoners for the probabilistic description logic P-  ${\\ensuremath{\\mathcal{SHIQ}}(D)}$ . Since it is a new formalism for handling uncertainty in DL ontologies, no such methodology has been proposed. There are no sufficiently large probabilistic ontologies to be used as test suites. In addition, since the reasoning services in P-  ${\\ensuremath{\\mathcal{SHIQ}}(D)}$ are mostly query oriented, there is no single problem (like classification or realization in classical DL) that could be an obvious candidate for benchmarking. All these issues make it hard to evaluate the performance of reasoners, reveal the complexity bottlenecks and assess the value of optimization strategies. This paper addresses these important problems by making the following contributions: First, it describes a probabilistic ontology that has been developed for the real-life domain of breast cancer which poses significant challenges for the state-of-art P-  ${\\ensuremath{\\mathcal{SHIQ}}(D)}$ reasoners. Second, it explains a systematic approach to generating a series of probabilistic reasoning problems that enable evaluation of the reasoning performance and shed light on what makes reasoning in P-  ${\\ensuremath{\\mathcal{SHIQ}}(D)}$ hard in practice. Finally, the paper presents an optimized algorithm for the non-monotonic entailment. Its positive impact on performance is demonstrated using our evaluation methodology.", "recorded": "2008-10-28T17:00:00", "title": "Optimization and Evaluation of Reasoning in Probabilistic Description Logic: Towards a Systematic Approach"}, {"url": "kdd09_ahmed_sctm", "desc": "A major source of information (often the most crucial and informative part) in scholarly articles from scientific journals, proceedings and books are the figures that directly provide images and other graphical illustrations of key experimental results and other scientific contents. In biological articles, a typical figure often comprises multiple panels, accompanied by either scoped or global captioned text. Moreover, the text in the caption contains important semantic entities such as protein names, gene ontology, tissues labels, etc., relevant to the images in the figure. Due to the avalanche of biological literature in recent years, and increasing popularity of various bio-imaging techniques, automatic retrieval and summarization of biological information from literature figures has emerged as a major unsolved challenge in computational knowledge extraction and management in the life science. We present a new structured probabilistic topic model built on a realistic figure generation scheme to model the structurally annotated biological figures, and we derive an efficient inference algorithm based on collapsed Gibbs sampling for information retrieval and visualization. The resulting program constitutes one of the key IR engines in our SLIF system that has recently entered the final round (4 out 70 competing systems) of the Elsevier Grand Challenge on Knowledge Enhancement in the Life Science. Here we present various evaluations on a number of data mining tasks to illustrate our method.", "recorded": "2009-06-29T16:18:00", "title": "Structured Correspondence Topic Models for Mining Captioned Figures in Biological Literature"}, {"url": "eswc2012_jiang_relation_prediction", "desc": "The three most common approaches for deriving or predicting instantiated relations, i.e. triple statements (s, p, o), are information extraction, reasoning and relational machine learning. Information extraction uses sensory information, typically in form of text, and extracts statements using various methods ranging from simple classifiers to the most sophisticated NLP approaches. Logical reasoning is based on a set of true statements and derives new statements via inference using higher-order logical axioms. Finally, machine learning exploits regularities in the data to predict the likelihood of new statements. In this paper we combine all three methods to exploit all sources of available information in a modular way, by which we mean that each approach, i.e., information extraction, reasoning, machine learning, can be optimized independently to be combined in an overall system. For relational machine learning, we present a novel approach based on hierarchical Bayesian multi-label learning which also sheds new light on common factorization approaches. We rank the probabilities for statements to be true in the sense that: given that we are forced to make a decision, what is the best option. We consider the fact that an entity can belong to more than one ontological class and discuss aggregation. We extend the approach to modeling nonlinear dependencies between relationships and for personalization. We validate our model using data from the Yago and the DBpedia ontology.", "recorded": "2012-05-31T17:00:00", "title": "Exploiting Information Extraction, Reasoning and Machine Learning for Relation Prediction"}, {"url": "kdd09_ye_dgepausftti", "desc": "The Drosophila gene expression pattern images document the spatial and temporal dynamics of gene expression and they are valuable tools for explicating the gene functions, interaction, and networks during Drosophila embryogenesis. To provide text-based pattern searching, the images in the Berkeley Drosophila Genome Project (BDGP) study are annotated with ontology terms manually by human curators. We present a systematic approach for automating this task, because the number of images needing text descriptions is now rapidly increasing. We consider both improved feature representation and novel learning formulation to boost the annotation performance. For feature representation, we adapt the bag-of-words scheme commonly used in visual recognition problems so that the image group information in the BDGP study is retained. Moreover, images from multiple views can be integrated naturally in this representation. To reduce the quantization error caused by the bag-of-words representation, we propose an improved feature representation scheme based on the sparse learning technique. In the design of learning formulation, we propose a local regularization framework that can incorporate the correlations among terms explicitly. We further show that the resulting optimization problem admits an analytical solution. Experimental results show that the representation based on sparse learning outperforms the bag-of-words representation significantly. Results also show that incorporation of the term-term correlations improves the annotation performance consistently.\r\n", "recorded": "2009-07-01T12:00:00", "title": "Drosophila Gene Expression Pattern Annotation Using Sparse Features and Term-term Interactions"}, {"url": "wapa2011_diethe_mining", "desc": "The British Medical Journal Group (BMJ Group) has a wide and var-\r\nied content set, including a suite of medical journals, online learning materials, best\r\npractice guidelines, clinical evidence summaries, a doc-2-doc online forum, and a port-\r\nfolio system for doctors. There is an emerging need to aggregate accross these content\r\ntypes, providing a uni\fed tagging and linking system, so that related content can eas-\r\nily be retrieved across the group. The main use-cases include an improved search and\r\nbrowse capability, and the (semi-)automatic construction of \\specialty portals\", which\r\nmay be medical in nature (e.g. diabetes) or non-medical (e.g. NHS reform). This pro-\r\nvides a challenge to standard Pattern Analysis algorithms, due in part to the highly\r\ntechnical nature of the documents. Prior work has mainly been focussed on the use\r\nof tools that automatically index against a medical ontology (such as MetaMap and\r\nUMLS), but this approach has drawbacks in terms of computational resources, lack of\r\nuser control, and limitations to medical-only concepts. A hybrid approach based on\r\nstatistiscal and semantic methods appears to have some merit, and may be the way\r\nforward. The presentation will focus on preliminary work taking the two approaches,\r\nand talk about some speci\fc technical issues that have arisen along the way. This is\r\nbased on joint work with Jonathon Peterson, Chris Wroe, and Rob Challen.", "recorded": "2011-10-19T10:15:43", "title": "Medical Text Mining"}, {"url": "www09_markines_esst", "desc": "Social bookmarking systems are becoming increasingly important data sources for bootstrapping and maintaining Semantic Web applications. Their emergent information structures have become known as folksonomies. A key question for harvesting semantics from these systems is how to extend and adapt traditional notions of similarity to folksonomies, and which measures are best suited for applications such as community detection, navigation support, semantic search, user profiling and ontology learning. Here we build an evaluation framework to compare various general folksonomy-based similarity measures, which are derived from several established information-theoretic, statistical, and practical measures. Our framework deals generally and symmetrically with users, tags, and resources. For evaluation purposes we focus on similarity between tags and between resources and consider different methods to aggregate annotations across users. After comparing the ability of several tag similarity measures to predict user-created tag relations, we provide an external grounding by user-validated semantic proxies based on WordNet and the Open Directory Project. We also investigate the issue of scalability. We find that mutual information with distributional micro-aggregation across users yields the highest accuracy, but is not scalable; per-user projection with collaborative aggregation provides the best scalable approach via incremental computations. The results are consistent across resource and tag similarity. ", "recorded": "2009-04-24T16:30:00", "title": "Evaluating Similarity Measures for Emergent Semantics of Social Tagging"}, {"url": "rease_domingue_swsa", "desc": "This is a one-hour video recording of the presentation of John Domingue at the First Asian Autumn School on the Semantic Web. It comprises two videos synchronized with the slides (requires Flash) or the videos alone.\r\n\r\nTable of Contents: \r\nSemantic Web Services: Application Areas\r\nContents\r\nDIP\r\nDIP Consortium\r\nSupporting Emergency Planning for Essex County Council\r\nEssex County Council\r\nEmergency Planning Context\r\nEmergency planning scenario\r\neMerges Ontologies\r\nGeneric Application Structure\r\nDemonstration of Emergency Planning (GIS) Prototype V1\r\nEMerges Prototype Architecture\r\nSWS and Business Process Modelling\r\nSuper Project\r\nSUPER Consortium\r\nMotivation\r\nQuerying the Process Space\r\nThe Critical IT / Process Divide\r\nWhat Are My Services?\r\nWhat are my services?\r\nMatching Activities and Port Types Based on Semantics\r\nSupporting Business Users Better\r\nMatching Model Representations & Semantics\r\nThe SUPER Stack\r\nModelling Stack\r\nTelecommunications Solution Map\r\nContent on Demand\r\nDigital Rights Management & Content Procurement\r\nModelling Stack\r\nBusiness Process Notations\r\nModelling Stack\r\nProgramming Model\r\nDeploying Applications\r\nBusiness Protocols\r\nModelling Stack\r\nWSMO Top Level Notions\r\nThe SUPER Trinity\r\nSUPER Methodology\r\nSUPER Architecture\r\nSUPER Ontology Stack\r\nSuper Demo Context\r\nPrototype Scenario\r\n Digital Asset Management BPMN\r\nService/Process Catalogue\r\nSuper Demo Video", "recorded": "2007-11-26T00:00:00", "title": "Semantic Web Services Applications"}, {"url": "iswc2011_nikitina_revision", "desc": "When ontological knowledge is acquired automatically, quality control\r\nis essential. We consider the tightest possible approach \u2013 an exhaustive manual\r\ninspection of the acquired data. By using automated reasoning, we partially\r\nautomate the process: after each expert decision, axioms that are entailed by the\r\nalready approved statements are automatically approved, whereas axioms that\r\nwould lead to an inconsistency are declined. Adequate axiom ranking strategies\r\nare essential in this setting to minimize the amount of expert decisions.\r\nIn this paper, we present a generalization of the previously proposed ranking techniques\r\nwhich works well for arbitrary validity ratios \u2013 the proportion of valid\r\nstatements within a dataset \u2013 whereas the previously described ranking functions\r\nwere either tailored towards validity ratios of exactly 100% and 0% or were optimizing\r\nthe worst case. The validity ratio \u2013 generally not known a priori \u2013 is\r\ncontinuously estimated over the course of the inspection process. We further employ\r\npartitioning techniques to significantly reduce the computational effort. We\r\nprovide an implementation supporting all these optimizations as well as featuring\r\na user front-end for successive axiom evaluation, thereby making our proposed\r\nstrategy applicable to practical scenarios. This is witnessed by our evaluation\r\nshowing that the novel parameterized ranking function almost achieves the\r\nmaximum possible automation and that the computation time needed for each\r\nreasoning-based, automatic decision is reduced to less than one second on average\r\nfor our test dataset of over 25,000 statements.", "recorded": "2011-10-27T11:00:00", "title": "Wheat or chaff - Practically feasible inferactive ontology revision"}, {"url": "lsoldm2012_diethe_medical_text", "desc": "The British Medical Journal Group (BMJ Group) has a wide and varied content set, including a suite\r\nof medical journals, online learning materials, best practice guidelines, clinical evidence\r\nsummaries, a doc-2-doc online forum, and a portfolio system for doctors. There is an emerging\r\nneed to aggregate accross these content types, providing a unified tagging and I inking system, so\r\nthat related content can easily be retrieved across the group. The main use-cases include an\r\nimproved search and browse capability, and the (semi-)automatic construction of \"specialty\r\nportals\", which may be clinical in nature (e.g. diabetes) or non-clinical (e.g. NHS reform). This\r\nprovides a challenge to standard Pattern Analysis algorithms, due in part to the highly technical\r\nnature of the documents. Prior work has mainly been focussed on the use of tools that\r\nautomatically index against a medical ontology (such as Meta Map and UMLS), but this approach\r\nhas drawbacks in terms of computational resources, lack of user control, and limitations to\r\nmedical-only concepts. A hybrid approach based on statistical and semantic methods appears to\r\nhave some notable advantages. The presentation will focus on the first phase of work taking the\r\ntwo approaches, and talk about some specific technical issues that have arisen along the way. This\r\nis based on joint work with Jonathon Peterson, Keith Marshall, Chris Wroe, and Rob Challen.", "recorded": "2012-09-17T12:00:00", "title": "Large-Scale Mining of Medical Text- a Hybrid Statistical/Semantic Approach"}, {"url": "iswc08_halpin_essn", "desc": "We present Redgraph, the first generic virtual reality visualization program for Semantic Web data. Redgraph is capable of handling large data-sets, as we demonstrate on social network data from the U.S. Patent Trade Office. We develop a Semantic Web vocabulary of virtual reality terms compatible with GraphXML to map graph visualization into the Semantic Web itself. Our approach to visualizing Semantic Web data takes advantage of user-interaction in an immersive environment to bypass a number of difficult issues in 3-dimensional graph visualization layout by relying on users themselves to interactively extrude the nodes and links of a 2-dimensional graph into the third dimension. When users touch nodes in the virtual reality environment, they retrieve data formatted according to the data\u2019s schema or ontology. We applied Redgraph to social network data constructed from patents, inventors, and institutions from the United States Patent and Trademark Office in order to explore networks of innovation in computing. Using this data-set, results of a user study comparing extrusion (3-D) vs. no-extrusion (2-D) are presented. The study showed the use of a 3-D interface by subjects led to significant improvement on answering of fine-grained questions about the data-set, but no significant difference was found for broad questions about the overall structure of the data. Furthermore, inference can be used to improve the visualization, as demonstrated with a data-set of biotechnology patents and researchers.", "recorded": "2008-10-30T14:00:00", "title": "Exploring Semantic Social Networks using Virtual Reality"}, {"url": "eswc2013_schneider_conjunctive_query", "desc": "With the advent of publicly available geospatial data, ontology-based data access (OBDA) over spatial data has gained increasing interest. Spatiorelational DBMSs are used to implement geographic information systems (GIS) and are fit to manage large amounts of data and geographic objects such as points, lines, polygons, etc. In this paper, we extend the Description Logic DL-Lite with spatial objects and show how to answer spatial conjunctive queries (SCQs) over ontologies\u2014that is, conjunctive queries with point-set topological relations such as next and within\r\n\u2014expressed in this language. The goal of this extension is to enable an off-the-shelf use of spatio-relational DBMSs to answer SCQs using rewriting techniques, where data sources and geographic objects are stored in a database and spatial conjunctive queries are rewritten to SQL statements with spatial functions. Furthermore, we consider keyword-based querying over spatial OBDA data\r\nsources, and show how to map queries expressed as simple keyword lists describing objects of interest to SCQs, using a meta-model for completing the SCQs with spatial aspects. We have implemented our lightweight approach to spatial OBDA in a prototype and show initial experimental results using data sources such as Open Street Maps and Open Government Data Vienna from an associated project. We show that for real-world scenarios, practical queries are expressible under\r\nmeta-model completion, and that query answering is computationally feasible. ", "recorded": "2013-05-28T14:32:17", "title": "Lightweight Spatial Conjunctive Query Answering using Keywords"}, {"url": "neon", "desc": "NeOn is a project involving 14 European partners and co-funded by the European Commission\u2019s Sixth Framework Programme under grant number IST-2005-027595. NeOn started in March 2006 and has a duration of 4 years. Our aim is to advance the state of the art in using ontologies for large-scale semantic applications in the distributed organizations. Particularly, we aim at improving the capability to handle multiple networked ontologies that exist in a particular context, are created collaboratively, and might be highly dynamic and constantly evolving.\r\n\r\nThe latest release of the NeOn Toolkit, one of the core outcomes of the NeOn project, is available for download and testing from the \r\n[[http://neon-toolkit.org/wiki/Main_Page|NeOn Toolkit & Community ]] site. \r\n\r\nNeOn includes 14  [[http://www.neon-project.org/nw/Partners| Partners]] from various European countries, various European countries, from both academia and industry. The technologies produced by NeOn have been applied to three different [[http://www.neon-project.org/nw/Case_Studies|case studies]] in two vast, transnational domains (fisheries and the pharmaceutical industry). \r\n\r\n==== Neon related events\r\n\r\n;[[http://videolectures.net/icwsm08_seattle/| International Conference on Weblogs and Social Media  International Conference on Weblogs and Social Media]]\r\n: Seattle, 2008\r\n\r\n;[[http://videolectures.net/semsearch09_madrid/| Semantic Search 2009 Workshop]]\r\n: Madrid, 2009\r\n\r\n==== Neon related talks\r\n\r\n;[[/ijcai09_mladenic_grobelnik_tmala/|Text Mining and Link Analysis - Dunja Mladeni\u0107, Marko Grobelnik]]\r\n: IJCAI tutorial, 2009\r\n\r\n;[[/icwsm08_syed_wodd/|Wikipedia as an Ontology for Describing Documents - Zareen Syed]]\r\n: ICWSM, 2008\r\n\r\n----", "recorded": "2006-03-01T17:39:49", "title": "NeOn - Lifecycle Support for Networked Ontologies"}, {"url": "mlcb08_whistler", "desc": "The field of computational biology has seen dramatic growth over the past few years, both in terms of new available data, new scientific questions, and new challenges for learning and inference. In particular, biological data is often relationally structured and highly diverse, well-suited to approaches that combine multiple weak evidence from heterogeneous sources. These data may include sequenced genomes of a variety of organisms, gene expression data from multiple technologies, protein expression data, protein sequence and 3D structural data, protein interactions, gene ontology and pathway databases, genetic variation data (such as SNPs), and an enormous amount of textual data in the biological and medical literature. New types of scientific and clinical problems require the development of novel supervised and unsupervised learning methods that can use these growing resources.\n\nThe goal of this workshop is to present emerging problems and machine learning techniques in computational biology. We invited several speakers from the biology/bioinformatics community who will present current research problems in bioinformatics, and we invite contributed talks on novel learning approaches in computational biology. We encourage contributions describing either progress on new bioinformatics problems or work on established problems using methods that are substantially different from standard approaches. Kernel methods, graphical models, feature selection and other techniques applied to relevant bioinformatics problems would all be appropriate for the workshop.\n\nMore information about the workshop can be found [[http://www.mlcb.org|here]].", "recorded": "2008-12-12T07:30:00", "title": "NIPS Workshop on Machine Learning in Computational Biology, Whistler 2008"}, {"url": "estc08_franz_etm", "desc": "ROCESSUS as a particular project of the German national funded high-tech-initiative THESEUS has the objective to create an IT-based corporate system that will allow companies to compare products, solutions and details of business associates, as well as locating the complex and sometimes obscure specialist information needed by employees whose work involves high-density knowledge bases.\r\n\r\nThe research teams are also aiming to develop a basic semantic platform that will integrate a company\u2019s internal planning of resources with management of the digital content of agile business processes. One specific scenario taken from the domain of mechanical engineering will demonstrate the requirements of an ontology based intra- and intererenterprise communication for solution and application retrieval in the Engineering domain. A prototypical demonstrator will illustrate the solution approach.\r\n\r\nempolis is a software company specialised in knowledge management and information access technologies. Knowledge based technologies form the basis for empolis\u2019 products. Starting from core Case-Based Reasoning technology, empolis has evolved its tools towards a semantic processing technology. It is a platform for the implementation of hybrid intelligent applications that can make use of a variety of AI technologies, including e.g., the CBR kernel, a rule engine, machine learning and user modelling techniques, to name a few. Today we offer a complete framework for setting up intelligent content management, knowledge management, retrieval and assistance systems. empolis is an arvato AG subsidiary, an international media service company and part of Bertelsmann AG. empolis employs 200 people in Germany and international divisions.", "recorded": "2008-09-26T10:32:05", "title": "empolis/tu munich \u2502 Semantic Enterprise: Unleashing Solution Knowledge in the Area of Mechanical Engineering"}, {"url": "dataforum2012_kaschesky_fusepool", "desc": "The Internet is becoming an integral element of the value chain supporting as well as enabling new business interactions and transactions. However, small and medium enterprises (SMEs) are not yet leveraging the full potential of the Internet for more efficient, digitally supported and data-driven business insights and actions. For example, product and service offerings lack efficient detection and matching with sourcing requirements resulting in significant search costs for potential customers. In research and development, technology intelligence lacks easy detectability of technological opportunities and threats combined with efficient matching to own competences and solutions.\r\n\r\nThe international joint project \"Fusepool\" develops automated tools and intelligent interfaces for efficiently matching data harvested from various sources to internal business needs, be they in research and development, product marketing or areas such as product branding, public opinion, and civil emergency support. The project builds on proven technologies developed by the project partners as well as external providers, such as Semantic Similarity Matching algorithms or the Good Relations Ontology for the publication and quotation of product information. Existing systems of knowledge representation are translated into reusable Semantic Web ontologies. For example, data from multiple, diverse sources are gathered, analyzed, and integrated in a reusable data format RDF (Resource Description Framework) and published as Linked Open Data (LOD).\r\n\r\nThe core benefit of project \"Fusepool\" concerns more efficient and effective detection and matching of data for real-time decision making based on rapid access to timely, context-aware, and needs-oriented information.", "recorded": "2012-06-06T14:00:00", "title": "Fusepool - Fusing and pooling information for product/service development and research"}, {"url": "e4", "desc": "[[video:e4_promo_video]]\r\n\r\nThe ambition of E4 STREP is to be the catalyst of current and past R&D multi-disciplinary efforts (organisational, managerial, psychological, socio-economical, technical) to finally apply cbusiness and extended product paradigms to enlarged EU SMEs, irrespective of the sector they belong to and of their geographical location.\r\n \r\n The method followed will be a holistic multi-dimensional collaborative approach which is able to encompass all stages of collaboration from \u00e2\u20ac\u0153cradle-to-grave\u00e2\u20ac\u009d (initiation, management, operational life and dissolution), all phases of extended products\u00e2\u20ac\u2122 development (conception, design, prototyping), all forms of collaboration (ad-hoc, mediated and planned) and all enterprise assets in any type of business network (people, ICT-systems, processes and knowledge assets).\r\n \r\n This holistic paradigm requires a multi-disciplinary and multi-sector perspective, in which human skills and competencies, heterogeneous knowledge assets, independent business models and proprietary ICT systems have to become cooperative & concurrent working teams, shared & accessible resources, synchronised & interconnected processes, inter-operable & open enterprise applications.\r\n \r\n To obtain all this E4 aims at developing and engineering a platform to support project and process management which integrate the tools and functions required by the networks they belong to in a cost-effective way. It will moreover support a seamless data exchange with the different levels: design constraints, partial BOMs (Bill of Materials) from above; partial drawings,\r\n BOMs and project KPI (Key Performance Indicators) from below.\r\n \r\n The project will rely upon ASP concepts to provide the required resources \u00e2\u20ac\u201c tools or services in a Web based mode to be paid on a use basis \u00e2\u20ac\u201c and will define or complete appropriate ontology.", "recorded": "2008-03-03T21:03:27", "title": "E4 - Extended Enterprise Management in Enlarged Europe"}, {"url": "mlsb2012_stojanova_ppi", "desc": "**Motivation:** Catalogs, such as Gene Ontology (GO) and MIPS-FUN, assume that functional classes\r\nare organized hierarchically (general functions include more specific functions). This has recently\r\nmotivated the development of several machine learning algorithms under the assumption that instances\r\nmay belong to multiple hierarchy organized classes. Besides relationships among classes,\r\nit is also possible to identify relationships among examples. Although such relationships have been\r\nidentified and extensively studied in the in the area of protein-to-protein interaction (PPI)\r\nnetworks, they have not received much attention in hierarchical protein function prediction. The\r\nuse of such relationships between genes introduces autocorrelation and violates the assumption\r\nthat instances are independently and identically distributed, which underlines most machine\r\nlearning algorithms. While this consideration introduces additional complexity to the learning\r\nprocess, we expect it would also carry substantial benefits.\\\\\r\n**Results:** This article demonstrates the benefits (in terms of predictive accuracy) of considering autocorrelation\r\nin multi-class gene function prediction. We develop a tree-based algorithm for considering\r\nnetwork autocorrelation in the setting of Hierarchical Multi-label Classification (HMC). The\r\nempirical evaluation of the proposed algorithm, called NHMC, on 24 yeast datasets using MIPSFUN\r\nand GO annotations and exploiting three different PPI networks, clearly shows that taking\r\nautocorrelation into account improves performance.\\\\\r\n**Conclusions:** Our results suggest that explicitly taking network autocorrelation into account increases\r\nthe predictive capability of the models, especially when the underlying PPI network is\r\ndense. Furthermore, NHMC can be used as a tool to assess network data and the information it\r\nprovides with respect to the gene function.", "recorded": "2012-09-08T16:30:00", "title": "Using PPI Networks in hierarchical multi-label classification trees for gene function prediction"}, {"url": "eswc2011_seals_tutorial", "desc": "Semantic Web technologies have become a well-established area of computer science research. With the increasing number of technologies being developed, the problem of how to compare and evaluate the various approaches gains more and more importance. Such evaluation is critical not only for future scientific progress, but also for the industrial adoption of the developed technologies. A still open challenge in this area is the lack of standard benchmarks and evaluation resources that can be easily reused by the community.\r\n\r\nThe objective of the SEALS (Semantic Evaluation at Large Scale) European project is to create a lasting reference infrastructure for semantic technology evaluation (the SEALS Platform) and enable the continuous benchmarking of semantic technologies at a large scale via public evaluation campaigns. In October 2010 the SEALS project completed its first phase where different evaluation services for semantic technologies were implemented in the SEALS Platform and were used to evaluate several tools in the first set of SEALS Evaluation Campaigns.\r\n\r\nAutomated evaluation of semantic technologies is a challenge in the Semantic Web area. SEALS concentrates on providing an infrastructure for the evaluation of five key areas of semantic technologies: ontology engineering tools, storage and reasoning systems, matching tools, semantic search tools, and semantic web service tools. The SEALS Platform provides an integrated way for evaluating these technologies through a set of evaluation services and test suites. This kind of infrastructure is crucial for researches, developers and industrial adopters of these technologies.\r\n\r\nThis tutorial aims at presenting the SEALS Platform and is targeted at researchers and practitioners interested in learning how to use this platform for evaluating their semantic technologies.\r\n\r\nDetailed information can be found at [[http://www.seals-project.eu/events/details/13-1st-seals-tutorial-eswc| 1st SEALS Tutorial]].", "recorded": "2011-05-29T09:00:00", "title": "1st SEALS Tutorial \u2013 Semantic evaluation at large scale"}, {"url": "sokt08_ljubljana", "desc": "**Integration of data sources and tools, and performing computations on them is one of the key problems for using the data from experimental biology today** (see e.g. CFP of the Workshop on Service Oriented Technologies for Biological Databases and Tools (SOBDAT 2007), **held in conjunction with ICWS/SCC 2007 9-13 July 2007, Salt Lake City, [[http://www.cs.gsu.edu/~hipc/sobdat07/|Utah]])**. These resources are highly diverse in nature in terms of representation, data formats, and computer systems and are distributed across the network. Although this broad spectrum of information is accessible over the Web, each data source comes with its own structure, semantics, data formats, names, concepts, and access methods. Currently, the burden falls on the scientist to manually (via programs) convert between the data formats, resolve conflicts, integrate data, and interpret results in order to make viable use of this information.\r\n\r\n**This workshop intends to bring together JSI and Leiden researches**  with the intention to elaborate a joint service oriented approach to information fusion, for the needs of exploratory data analysis in the framework of inductive databases, enriched with ontology and text information available from the web. The goal of this workshop is to:\r\n\r\n-\t//Present subgroup discovery, as a methodology for exploratory/explanatory data analysis in biomedical applications;//\r\n\r\n-\t//Present an architecture for inductive databases, and an approach to extending this architecture to a service oriented architectures (SoA);//\r\n\r\n-\t//Present details of the background data mining technologies: subgroup discovery and propositionalization approach to relational data mining;//\r\n\r\n-\t//Enable ample brainstorming time on how to implement the SOKT architecture. SEGS workflow in a SoA framework, as a step in a more ambitious SoA approach to implementing workflows for exploratory data analysis;///\r\n\r\n-\t//Presentation of the proposed architecture for the future Service Oriented Knowledge Technologies (SOKT) toolbox;//\r\n\r\n-\t//Wrap-up session: Summary of achievements and plans for future work.//", "recorded": "2008-01-19T09:00:00", "title": "Workshop on Service Oriented Knowledge Technologies "}, {"url": "eswc08_shadbolt_gst", "desc": "In under a decade the internet has changed our lives. Now we can shop, bank, date, research, learn and communicate online and every time we do we leave behind a trail of personal information. Organisations have a wealth of structured information about individuals on large numbers of databases. What does the intersection of this information mean for the individual? How much of your personal data is out there and more importantly, just who has access to it? As stories of identity theft and online fraud fill the media internet users are becoming increasingly nervous about their online data security. Also what opportunities arise for individuals to exploit this information for their own benefit?\r \r Garlik was formed to give individuals and their family's real power over the use of their personal information in the digital world. Garlik's technology base has exploited and extended results from research on the Semantic Web. It has built the world's largest, SPARQL compliant, native format, RDF triple store. The store is implemented on a low-cost network cluster with over 100 servers supporting a 24x7 operation. Garlik has built semantically informed search and harvesting; used industrial strength language engineering technologies across many millions of people-centric Web pages. Methods have been developed for extracting information from structured and semi structured databases. All of this information is organised against a people-centric ontology with facilities to integrate these various fragments.\r \r Garlik has received two substantial rounds of venture capital funding (as of March 2008), has established an active user base of tens of thousands of individuals, and is adding paying customers at an increasing rate. This talk reviews the consumer need, describes the technology and engineering, and discusses the lessons we can draw about the challenges of deploying Semantic Technologies.", "recorded": "2008-06-03T09:00:00", "title": "Garlik: Semantic Technology for the Consumer"}, {"url": "eswc2012_chiarcos_powla", "desc": "This paper describes POWLA, a formalism to formalize linguistic corpora in OWL/DL. POWLA is based on data models currently developed by the NLP community to overcome the heterogeneity of linguistic annotation (Ide and Pustejovsky 2010), in particular, PAULA, an XML standoff format developed out of early sketches of the Linguistic Annotation Framework (LAF, Ide and Romary 2004) which is currently developed within ISO TC37/SC4. These data models are defined as specializations of directed acyclic (hyper)graphs, and it is claimed that every kind of linguistic annotation can be represented as a directed (hyper)graph (Bird and Liberman 2001). Linguistic corpora can thus be naturally linearized in RDF. Unlike earlier approaches to model generic data models for linguistic annotations by means of Semantic Web standards (e.g., Cassidy 2010), POWLA augments the RDF linearization of linguistic data with a data model formalized in an OWL/DL ontology that defines data types for primary data, annotations and linguistic metadata, as well as consistency constraints on linguistic corpora. Unlike other approaches to model linguistic corpora in OWL/DL (e.g., Burchardt et al. 2008), POWLA is not specific to a particular type of annotation, but it implements a generic data model. This genericity is illustrated here for the conversion of GrAF (the XML linearization of the Linguistic Annotation Format, Ide and Suderman 2007) to POWLA. That POWLA preserves the linguistic information conveyed in the original GrAF data as shown by an experient to emulate ANNIS-QL, a query language specifically designed for heterogeneous and richly annotated linguistic corpora (Chiarcos et al. 2008), by means of SPARQL macros on POWLA data. Finally, the paper identifies advantages and disadvantages of OWL/RDF linearizations of generic data models for linguistic corpora (and in particular, POWLA) as compared to traditional XML standoff formats (Ide and Suderman 2007, Chiarcos et al. 2008).", "recorded": "2012-05-30T16:30:00", "title": "POWLA: Modeling Linguistic Corpora in OWL/DL"}, {"url": "eswc2012_summer_school", "desc": "The ESWC Summer School 2012 provides an opportunity for Master\u2019s and Ph.D. students in the area of the Semantic Web to learn the current key topics in the field from the leading researchers in the area. This summer school has been designed using experiences from the following:\r\n\r\n    * Over forty years of experience in distance education, learning and teaching from the Open University, and also the extensive research and teaching experience of the other involved universities (Karlsruhe Institute of Technology, Vrije University of Amsterdam, University of Innsbruck),\r\n    * Previous summer schools run within the OntoWeb, KnowledgeWeb and S-Cube networks of excellence,\r\n    * Events including summer schools run within STI International and SemSphere.\r\n\r\nBased on the above the school follows a number of principles:\r\n\r\n    * The school takes a participatory and hands on approach. That is in addition to theory and methodology within the school students will learn about and use state-of-the-art Semantic Web tools.\r\n    * Motivation is widely acknowledged to be a key component of successful learning and we will ensure that all student learning experiences are rewarding, engaging and fulfilling.\r\n    * Team working, communication and networking are a useful academic skills and the school will enable learning on these topics. We will also facilitate networking between students, tutors and invited speakers.\r\n    * The school is aligned with the ESWC conference ensuring that the emerging and next generation of organizers and contributors to the conference continues to grow and become encultured in the general Semantic Web community. This affects the scientific topics and structure of the summer school as well as the location and date of the event.\r\n    * The school is also synchronised with and leverages from other STI International and SemSphere training activities.\r\n\r\n**Topics**\r\n\r\nThe school covers the topics of:\r\n\r\n    * Web languages and Web scale reasoning\r\n    * Practical ontology engineering including repository alignment\r\n    * Linked Data publication and usage\r\n    * Semantic support for Web APIs and services\r\n    * Semantics and front ends\r\n\r\nFor more information please visit [[http://summerschool2012.eswc-conferences.org/|ESWC 2012 Summer School website]].", "recorded": "2012-05-21T09:00:00", "title": "2nd ESWC Summer School, Kalamaki 2012"}, {"url": "solomon_skunca_pcifa", "desc": "Phylogenetic profiling is a genomic context method that predicts gene function by correlating gene occurrence patterns in selected organisms [1]. The intuition behind phylogenetic profiling is that genes found and lost together (i. e. inherited together) in different genomes are likely to share function, either by 1) being involved in the same biological pathway (which is therefore incomplete without all members in a given genome), or 2) being crucial for survival in a particular environment, so their presence is mandatory throughout the phenotype. \r\nWe have used a recently developed machine learning approach based on decision trees for Hierarchical Multi \u2013 label Classification (HMC) [2] to predict Gene Ontology (GO) assignments of Orthologous Matrix (OMA) groups [3]. The HMC extension of the decision tree classifier takes into account the hierarchical layout of GO and considerably improves computational efficiency and accuracy by taking into account a set of class labels simultaneously when constructing the decision trees, instead of learning each class label separately. A standard decision tree would recursively split the training data into subsets (\u2018branches\u2019) on values of an attribute in such a manner as to decrease a measure of entropy of a class label within the subsets after the split. The HMC approach has to deal with multiple class labels, and would compute a weighted average of decrease in entropy over all labels when deciding on a split point. The weights here are inversely proportional to the depth of a class in the GO, giving more significance to high-level, more general GO terms.\r\nWe have inspected the effects of stepwise addition of putative paralogs on computational learning of orthologous groups\u2019 (and consequentially gene) function. By introducing paralogous genes in the learning process, we substantially increase its success and show that gene function prediction from sequence information alone, when encoded as a paralog-containing phylogenetic profile, is a promising approach in narrowing of possible function space for a particular protein.", "recorded": "2010-02-15T13:00:00", "title": "Paralogs considerably improve accuracy of phylogenetic profiling for in silico functional annotation"}, {"url": "eswc2013_summer_school", "desc": "The ESWC Summer School 2013 will provide an opportunity for Master's and Ph.D. students in the area of the Semantic Web to learn the current key topics in the field from the leading researchers in the area. This summer school has been designed using experiences from the following:\r\n\r\n*Over forty years of experience in distance education, learning and teaching from the Open University, and also the extensive research and teaching experience of the other involved universities (Karlsruhe Institute of Technology, Vrije University of Amsterdam, Southampton, Digital Enterprise Research Institute),\r\n*Previous summer schools run within the OntoWeb, KnowledgeWeb and S-Cube networks of excellence,\r\n*Events including summer schools run within STI International and SemSphere.\r\n\r\nBased on the above the school will follow a number of principles:\r\n\r\n*The school takes a participatory and hands on approach. That is in addition to theory and methodology within the school students will learn about and use state-of-the-art Semantic Web tools.\r\n*Motivation is widely acknowledged to be a key component of successful learning and we will ensure that all student learning experiences are rewarding, engaging and fulfilling.\r\n*Team working, communication and networking are a useful academic skills and the school will enable learning on these topics. We will also facilitate networking between students, tutors and invited speakers.\r\n*The school is aligned with the ESWC conference ensuring that the emerging and next generation of organizers and contributors to the conference continues to grow and become encultured in the general Semantic Web community. This affects the scientific topics and structure of the summer school as well as the location and date of the event.\r\n*The school is also synchronised with and leverages from other STI International and SemSphere training activities.\r\n\r\n**Topics**\r\n\r\nThe school will cover the topics of:\r\n\r\n*Web languages and Web scale reasoning\r\n*Practical ontology engineering including repository alignment\r\n*Linked Data publication and usage\r\n*Semantic support for Web APIs and services\r\n*Semantics and front ends\r\n\r\nFor more information please visit [[http://events.kmi.open.ac.uk/eswc-ss2013/|ESWC 2013 Summer School website]].", "recorded": "2013-09-02T09:00:00", "title": "3rd ESWC Summer School, Crete 2013"}, {"url": "aaai2013_hunter_building_mind", "desc": "Sometimes two hard problems are easier than one. Making sense of the explosion to data about life and human health that arises from exponentially improving DNA sequencing technology is one of the primary scientific challenges of our time. Artificial intelligence is based in the equally profound question of what constitutes a mind and how one could be constructed artificially. These two challenges mutually inform and constrain each other. Computational biology needs tools that relate enormous experimental results to vast amounts of relevant prior knowledge in ways that illuminate the mechanisms underlying the phenomena under study. This is a fundamentally semantic process that requires programs represent complex, incomplete and partially incorrect knowledge, reason about it and its relation to experimental results, and engage in effective, ongoing scientific communication about hypotheses. This is an \"AI-complete\" problem. However, the domain is special in several ways: (1) All the relevant knowledge is explicit, and can be found in the roughly 10,000 textbooks and 20 million journal articles that make up the biomedical literature. (2) The biomedical research community has a long-standing and effective project in ontology development, provide an increasingly comprehensive conceptual foundation of entities, processes, functions, locations, relations and more that are explicitly defined, rigorously organized and maintained by domain experts. These biomedical ontologies underpin several large-scale annotation projects, the results of which are available in standardized semantic formats like RDF and OWL. (3) There is a large community of biomedical research scientists desperate for effective means of explaining and contextualizing their data. Although they are demanding and less interested in the technological means than the scientific ends, a thoughtful human community eager to interact in an extended intellectual partnership with programs is a rare and valuable resource for AI research. This combination of factors suggests that the first wildly acknowledged genuine AI may think about biology. I will talk about progress to date and prospects in building a mind for life.", "recorded": "2013-07-15T08:00:00", "title": "Building a Mind for Life"}, {"url": "planetdata_training_curriculum_data_streams", "desc": "Data streams curriculum has taken ideas from several books, papers, presentations and courses as a basis. It has been adapted for the PlanetData project needs in large-scale data processing. However, we have not generated any material yet and we have not exercised or used this curriculum in any other courses yet.\n\nAs a starting point we are re-using the [[http://streamreasoning.org/sr4ld2013#team|\"Tutorial on Stream Reasoning for Linked Data at ISWC 2013\"]] delivered by PlanetData members: Marco Balduini (Politecnico di Milano), Jean-Paul Calbimonte (Universidad Politcnica de Madrid), Oscar Corcho (Universidad Politcnica de Madrid), Daniele Dell'Aglio (Politecnico di Milano), Emanuele Della Valle (Politecnico di Milano), Jeff Z. Pan (University of Aberdeen)\n\n== 1. Motivation\n\n * a. Comparison with Relational DB storage\n\n ----\n ----\n\n== 2. Streaming data models\n\nMaterials: Stream Reasoning introduction [[http://streamreasoning.org/slides/2013/10/A1_Stream%20Reasoning%20introduction.pdf|slides]]\n\n * a. Unbounded streams\n * b. Tuples, Windows\n * c. Timestamps\n * d. K-constraints\n\n ----\n ----\n\n== 3. Query Languages\n\n * a. Relational operators\n * b. Window operators, temporal operators\n * c. Aggregators\n * d. Joins\n\n||[[:iswc2011_ferre_semantic]]||[[:iswc07_zhou_akqss]]||[[:solomon_bierman_tfuod]]||\n\n ----\n ----\n\n== 4. Semantic streaming data\n\nMaterials: RDF stream processing models [[http://streamreasoning.org/slides/2013/10/sr4ld-a2.pdf|slides]]\nand Naive reasoning on RDF streams [[http://streamreasoning.org/slides/2013/10/A3_Naive%20reasoning%20on%20RDF%20streams.pdf|slides]]\n\n * a. RDF Stream data models\n * b. SPARQL extensions for RDF Streams\n * c. Reasoning with Streams\n * d. Complex event processing\n * e. Linked Streaming Data\n\n||[[:iswc2012_calbimonte_srbench]]||[[:coinplanetdataschool2011_calbimonte_data/]]||[[:iswc2012_calbimonte_raw_measurements]]||[[:wapa2011_bifet_moa]]||[[:eswc2011_calbimonte_observations]]||\n\n ----\n ----\n\n== 5. Query processing\n\nMaterials: C-SPARQL - A Continuous Extension of SPARQL [[http://streamreasoning.org/slides/2013/10/B1_C-SPARQL.pdf|slides]] and SPARQLstream: Ontology-based streaming data access [[http://streamreasoning.org/slides/2013/10/B2_SPARQLstream.pdf|slides]]\n\n * a. Continuous queries\n * b. Window evaluation\n * c. Aggregates evaluation, approximative queries\n * d. Static optimization\n * e. Query optimization, statistics\n * f. Load shedding\n * g. Sampling\n\n||[[:qlm09_madrid]]||[[:iswc06_wache_irpto]]||[[:www2010_liang_lss]]||[[:eswc2013_hogan_linked_data]]||[[:iswc2012_gropengiesser_data_management]]||[[:brownbag_wicker_sindbad]]||\n\n * back to [[http://videolectures.net/planetdata|PlanetData Open Training Infrastructure]]\n * back to [[http://videolectures.net/planetdata_training_curriculum/|PlanetData Training Curriculum]]", "recorded": "2013-11-24T17:38:45", "title": "Data Streams"}, {"url": "reasecs_fuchs_ace", "desc": "Attempto Controlled English (ACE) is a controlled natural language,  \ni.e. a precisely defined subset of English that can automatically and  \nunambiguously be translated into first-order logic. ACE may seem to be  \ncompletely natural, but is actually a formal language, concretely it  \nis  a first-order logic language with an English syntax. Thus ACE is  \nhuman and machine understandable.\n\nACE was originally intended to specify software, but has since been  \nused as a general knowledge representation language in several  \napplication domains, most recently for the semantic web.\n\nACE is supported by a number of tools, predominantly the Attempto  \nParsing Engine (APE). Besides translating an ACE text into discourse  \nrepresentation structures, APE also offers translations into various  \nother forms of first-order logic, into OWL, SWRL, and into RuleML.  \nFurthermore, APE can generate ACE paraphrases of DRSs derived from ACE  \ntexts.\n\nTo support automatic reasoning in ACE, we have developed the Attempto  \nReasoner (RACE). RACE can prove that one ACE text is the logical  \nconsequence of another one, and give a justification for the success  \nor the failure of the proof in ACE.\n\nRecently, ACE has found several applications within the semantic web.  \nTherefore, we have developed translations of ACE into and from  \nsemantic web languages. Concretely, there are the translations ACE &lt;-&gt;  \nOWL/SWRL and ACE -&gt; rules. Also, there are various tools that use  \nthese translations: AceWiki (uses ACE -&gt; OWL/SWRL), ACE View (uses ACE  \n&lt;-&gt; OWL/SWRL), and AceRules (uses ACE -&gt; rules). The tool AceWiki  \ncombines controlled natural language with the ideas and technologies  \nof the semantic web and with the concepts of wikis. AceWiki also  \nincorporates a predictive editor that enables users to construct  \nsyntactically correct ACE sentences from a restricted vocabulary. ACE  \nView is a plug-in for the ontology editor Prot\u00e9g\u00e9. Finally, AceRules  \nis a forward chaining rule system that offers three different semantics.\n\nThe Attempto web-site (attempto.ifi.uzh.ch) contains much more  \ninformation on ACE and its tools: documentation, publications, web- \ninterfaces to the tools, software downloads, demos, talks and screen- \ncasts, and last but not least course material.", "recorded": "2008-05-14T00:00:00", "title": "Attempto Controlled English"}, {"url": "active_multipliers_training", "desc": "back to [[http://videolectures.net/active|ACTIVE training project ]]\r\n\r\n===\r\nThe goal of training activities in ACTIVE is to achieve the transfer of knowledge and best practices within the project as well as (principally) outside the project. ACTIVE training program is aimed at training individuals and groups on the topics that are relevant to the ACTIVE project. Each training program covers a general topic and is generated from several training courses that are focused on specific topics. Furthermore, each training program combines different types and forms of learning: traditional, ICT supported or blended training event. For each training course we provide textual materials, references to the sources used for training module preparation, a list of the topic relevant ACTIVE deliverables, video tutorials and additional materials/suggested readings.\r\n\r\n== 1. Theoretical Foundations and Conceptual Models\r\n\r\nThis course starts with the theoretical foundations on the organisational and collaboration forms, business process modelling, management and collaboration mechanisms, knowledge management and current governance principles in organisations. In contrast it provides basic information about traditional and emerging technologies that influence traditional business organisation and management context. Then it gives motivation for the complete ACTIVE training programme by providing incentives, future trends and business potentials.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse1_TheoreticalFoundations.pdf|Theoretical foundations and conceptual models - course]]\r\n\r\nCourse topics:\r\n\r\n**Collaboration and collaborative knowledge creation**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n*[[http://videolectures.net/semseach09_albakour_mcpse|Managing Collaboration Projects using Semantic Email]]\r\n*[[http://videolectures.net/iswc08_tudarache_scodp|Supporting Collaborative Ontology Development in Protege]]\r\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\r\n*[[http://videolectures.net/ice08_kristensen_pcik|Productivity in Collaboration-intensive Knowledge Work: The Collaboration Management Imperative]]\r\n*[[http://videolectures.net/nano07_gadlin_rsc|Re-thinking scientific teams: competition, conflict and collaboration]]\r\n*[[http://videolectures.net/iswc06_auer_otssc|In-Use 1: OntoWiki - A Tool for Social, Semantic Collaboration]]\r\n\r\n**Knowledge processes and tasks**\r\n*[[http://videolectures.net/active09_tilly_ikp|Informal Knowledge Processes: The Long Tail of Business Processes]]\r\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\r\n\r\n**Process modelling**\r\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\r\n\r\n**Knowledge management**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\r\n*[[http://videolectures.net/training06_davies_ka|Knowledge Access]]\r\n*[[http://videolectures.net/iswc08_bhagdev_cauoswilno|Creating and Using Organisational Semantic Webs in Large Networked Organisations]]\r\n*[[http://videolectures.net/cikm08_feldman_ak|Automating Knowledge]]\r\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\r\n\r\n**Formalisms for (dynamic) aspects of knowledge worker context and enterprises**\r\n*[[http://videolectures.net/iswc06_grobelnik_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_witbrock_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_mozetic_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_haase_cop|Context Sensitivity in Knowledge Rich Systems - Contents of parts 2]]\r\n\r\n ----\r\n ----\r\n\r\n == 2. Knowledge Models and Structures\r\n\r\nThis course deals with the theoretical background on knowledge and semantic technologies and examines them from a technological, historical and scientific perspective. It starts with the basic facts about knowledge structures and models and their role in the knowledge formalisation, modelling, reasoning and adaptation. It provides comparison and contrasting of diverse knowledge models, structures and systems and understanding their participation in industry.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse2_KnowledgeModels.pdf|Knowledge models and structures - course]]\r\n\r\nCourse topics:\r\n\r\n**Semantic languages**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\r\n*[[http://videolectures.net/training06_sure_stsw/|A short Tutorial on Semantic Web]]\r\n*[[http://videolectures.net/eswc09_tappolet_atre|Applied Temporal RDF: Ef?cient Temporal Querying of RDF Data with SPARQL]]\r\n*[[http://videolectures.net/eswc09_vennekens_faaeod|FO(ID) as an Extension of DL with Rules]]\r\n*[[http://videolectures.net/iswc08_perez_nsparql|NSPARQL: A Navigational Language for RDF]]\r\n*[[http://videolectures.net/iswc08_hausenblas_bwdwd|RDFa - Bridging the Web of Documents and the Web of Data]]\r\n\r\n**Knowledge formalisation  and  representation**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n*[[http://videolectures.net/akom08_krotzsch_fik|Formal and Informal knowledge representation]]\r\n*[[http://videolectures.net/iswc08_saggion_krebi|Knowledge Representation and Extraction for Business Intelligence]]\r\n\r\n**Reasoning and  probabilistic temporal models**\r\n*[[http://videolectures.net/iswc08_moller_itsr|Reasoning for Ontology Engineering and Usage]]\r\n*[[http://videolectures.net/ssll09_pagnucco_krr|Knowledge Representation and Reasoning]]\r\n*[[http://videolectures.net/bsciw08_schwaighofer_krrd|Knowledge Representation and Reasoning - Discussion]]\r\n\r\n**Knowledge structures**\r\n**Collaborative articulation of expressive knowledge**\r\n**Knowledge leveraging and repair models**\r\n**Knowledge-based adaptation**\r\n**Knowledge creation cycle**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/iswc08_hauer_asnrwpdehep|An architecture for semantic navigation and reasoning with patient data - experiences of the Health-e-Child project]]\r\n*[[http://videolectures.net/eswc08_blanco_sr|Semantic Reasoning: A Path To New Possibilities of Personalization]]\r\n*[[http://videolectures.net/akom08_krotzsch_fik/|Formal and Informal knowledge representation]]\r\n*[[http://videolectures.net/active09_ghani_rdekm/|Research Directions in Enterprise Knowledge Management]]\r\n\r\n ----\r\n ----\r\n\r\n == 3. Background Technologies\r\n\r\nThis course presents and explains core technologies from the area of knowledge technologies that ranges from the data driven methods to knowledge driven methods and are important for detecting, analysing and managing knowledge (tacit and explicit) in organisations. Recent developments in the particular areas are demonstrated through real software prototypes, successful market cases and real business implementations. The course provides many demos that are available as demonstrations online and could be supplemented with the hands-on session.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse3_BackgroundTechnologies.pdf|Background technologies - course]]\r\n\r\nCourse topics:\r\n\r\n**Context mining**\r\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\r\n*[[http://videolectures.net/um05_loosli_ccdoc|Context changes detection by one-class svms]]\r\n*[[http://videolectures.net/ice08_lukowicz_crw|Context recognition in the wearIT@work project]]\r\n*[[http://videolectures.net/kdd09_zhu_mrciws|Mining Rich Session Context to Improve Web Search]]\r\n*[[http://videolectures.net/samt08_santini_cnod|Context as a non-ontological determinant of semantics]]\r\n\r\n**Stream mining**\r\n*[[http://videolectures.net/ecml07_gama_sad|State of the Art in Data Stream Mining]]\r\n*[[http://videolectures.net/ecml07_mohamed_sad|State of the Art in Data Stream Mining]]\r\n*[[http://videolectures.net/ecml07_mohamed_acac|An architecture for context-aware adaptive data stream mining]]\r\n*[[http://videolectures.net/ecml07_mohamed_mqgr|A Model for Quality Guaranteed Resource-Aware Stream Mining]]\r\n\r\n**Anomaly detection**\r\n*[[http://videolectures.net/ecmlpkdd08_lazarevic_dmfa|Data Mining for Anomaly Detection]]\r\n*[[http://videolectures.net/mmdss07_tishby_itam|Information Theo-retic and Alge-braic Methods for Network Anomaly Detection]]\r\n*[[http://videolectures.net/kdd09_jermaine_alrtffsad|A LRT Framework for Fast Spacial Anomaly Detection]]\r\n\r\n**Social network analysis**\r\n*[[http://videolectures.net/semseach09_graves_srrdsn|Searching and ranking in RDF documents and social networks]]\r\n*[[http://videolectures.net/icwsm09_agarwal_siaifs|A Social Identity Approach to Identify Familiar Strangers in a Social Network]]\r\n*[[http://videolectures.net/kdd09_jermaine_alrtffsad|A LRT Framework for Fast Spacial Anomaly Detection]]\r\n*[[http://videolectures.net/iswc07_aasman_usn|Using Social Network Analysis, Geotemporal Reasoning and RDFS++ Reasoning for Business Intelligence]]\r\n\r\n**Social software and Web 2.0**\r\n*[[http://videolectures.net/active09_mulvany_cwsc|A Cabinet of Web 2.0 Scientific Curiositics]]\r\n*[[http://videolectures.net/eswc08_gomes_cs|Collective Semantics: Collective Intelligence & the Semantic Web - Flickring Our World]]\r\n*[[http://videolectures.net/eccs07_huberman_bwe|Beyond Web 2.0]]\r\n*[[http://videolectures.net/icwsm09_sun_gmctfnf|Gesundheit! Modeling Contagion Through Facebook News Feed]]\r\n*[[http://videolectures.net/eswc08_halpin_sw|Panel II: Social Network Portability: Is the Semantic Web Ready?]]\r\n*[[http://videolectures.net/cikm08_perisic_usnfsw|Using Social Networks for Social Work]]\r\n*[[http://videolectures.net/www09_baezayates_mtwbs|Mining the Web 2.0 for Better Search]]\r\n*[[http://videolectures.net/samt08_baumann_wai|WhoAmI - A Web2.0 Platform for Faceted Identity Management through Aggregation of Social Media]]\r\n\r\n**Adaptive and context-aware systems**\r\n*[[http://videolectures.net/samt08_rodriguez_doncel_smac|A Semantic Model for the Authorisation of Context-Aware Content Adaptation]]\r\n\r\n**Semantic technologies and content**\r\n**Social software and Web 2.0**\r\n**Knowledge filters**\r\n**Meta learning**\r\n**Forecasting**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/eccs07_huberman_bwe|Beyond Web 2.0]]\r\n*[[http://videolectures.net/kdd07_fayyad_fmtw|From Mining the Web to Inventing the New Sciences Underlying the Internet ]]\r\n*[[http://videolectures.net/ecml07_baeza_yates_mwq|Mining Queries]]\r\n*[[http://videolectures.net/estc08_zaragoza_isst|Improving Search with Semantic Technologies: Current Research Directions]]\r\n*[[http://videolectures.net/active09_grobelnik_tmlws|Text Mining and Light Weight Semantics]]\r\n\r\n ----\r\n ----\r\n\r\n == 4. ACTIVE Innovative Solutions\r\n\r\nThis is one of the main courses in ACTIVE training programmes. It is aimed at presenting ACTIVE innovative solutions that will be developed in the frame of the project. Training starts with innovative business and organisational models that are consequence of newly introduced technologies. The main focus is on the explanation and demonstration of technologies developed in ACTIVE, their use in the industry contexts and on the discussion of their implications to the traditional business environment. Course addresses in detail the methods for identifying knowledge processes, hidden knowledge in organisations as well as new technology research streams. Furthermore it explains and demonstrates the methods for contextualisation that spans over three orthogonal dimensions: content, social network and time. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse4_InnovativeSolutions.pdf|ACTIVE innovative solutions - course]]\r\n\r\nCourse topics:\r\n\r\n**Tools and methods for collaborative and expressive knowledge articulation paradigms**\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n\r\n**Ontology learning**\r\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\r\n*[[http://videolectures.net/training06_grobelnik_tmol|Text Mining for Ontology Learning]]\r\n*[[http://videolectures.net/koml04_grobelnik_olkds|Ontology Learning - Knowledge Discovery and the Semantic Web]]\r\n\r\n**Hybrid Web 2.0 - ontology infrastructure**\r\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\r\n*[[http://videolectures.net/eswc08_hess_cs|Collective Semantics: Collective Intelligence & the Semantic Web - From Web 2.0 to Semantic Web - A Semi-Automated Approach]]\r\n\r\n**Semi-automated process refactoring**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n**Optimization of knowledge models and pro-active support**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n**Delivery of contextualized information**\r\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\r\n\r\n**Visualization of temporal enterprise model**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n**Privacy preserving analysis of enterprise data**\r\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\r\n*[[http://videolectures.net/google_roughan_ppdm|Privacy Preserving DataMining]]\r\n\r\n**Inconsistency diagnosis and automatic repair of inconsistencies**\r\n**Complex rule interfaces**\r\n**Knowledge process mining**\r\n**Autonomous, context aware services for knowledge processes**\r\n**Dynamic adaptations of context-aware knowledge processes**\r\n**Security-aware knowledge processes**\r\n**Simultaneous analysis of multiple modalities**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/iswc08_witbrock_fsc|Free Semantic Content: Using OpenCyc in Semantic Web Applications]]\r\n*[[http://videolectures.net/iswc08_dellaValle_rswa|Realizing a Semantic Web Application]]\r\n*[[http://videolectures.net/active09_warren_kmcfl|KM at the Customer Front-Line: The BT Case Study in ACTIVE]]\r\n\r\n ----\r\n ----\r\n\r\n == 5. Management and Problem Solving\r\n\r\nThis course is aimed at providing knowledge about the models, structures and mechanisms for management, coordination and problem solving. The coordination mechanisms are basic mechanisms in any networked organisation and as such the focal point of interest for any distributed, knowledge focused organisation. The course will analyse and study the approaches for distributed and collaborative decision-making including organizational aspects in the context of informal and knowledge processes. Support with ACTIVE models and solutions for decision making processes in inter-enterprise and collaborative environment is the main focus.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse5_Management and problem solving.pdf|Management and problem solving - course]]\r\n\r\nCourse topics:\r\n\r\n**Context sensitive management**\r\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\r\n\r\n**Pro-active knowledge process support**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n ----\r\n ----\r\n\r\n == 6. Practical Examples and ACTIVE Prototypes\r\n\r\nIn this course the development process of the ACTIVE prototypes for three specific applications will be demonstrated. The development process and the applications with their specific benefits which are created by the ACTIVE research results will be shown. The course will be supplemented with a hands-on workshop to allow participants to deal with concrete examples from their work context. The focus will be on identifying areas of applications where the functionalities developed in the ACTIVE project can be applied.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse6_PracticalExamples.pdf|Practical Examples and ACTIVE Prototypes - course]]\r\n\r\nCourse topics:\r\n\r\n**Case studies and best practices**\r\n*[[http://videolectures.net/active09_warren_kmcfl|KM at the Customer Front-Line: The BT Case Study in ACTIVE]]\r\n*[[http://videolectures.net/coinactivess2010_thurlow_bcs|ACTIVE\u000b BT Case Study]]\r\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\r\n\r\n**Demonstrators, demos, prototypes**\r\n*[[http://videolectures.net/eswc08_berges_smw|Semantic Web Technology for Agent Communication Protocols]]\r\n*[[http://videolectures.net/active09_dolinsek_iak|Introduction to the ACTIVE Knowledge Workspace SDK]]\r\n\r\n**Use scenarios**\r\n\r\n ----\r\n ----\r\n\r\n == 9. ACTIVE project - Introduction\r\n\r\nThe aim of this course is to present the aims, goals, structure and expected results of ACTIVE project. In addition this course provides information about the future plans, development and operations of the business development that will follow the ACTIVE project. In that respect the future directions in the research areas will be presented, their use potentials, development scenarios and business scenarios in the forms of business plans. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse9_Introduction.pdf|ACTIVE project - Introduction - course]]\r\n\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/active09_mladenic_warren_oai|Opening and Introduction of the 1st ACTIVE Summer School]]\r\n*[[http://videolectures.net/coinactivess2010_warren_ai|ACTIVE Introduction]]\r\n*[[http://videolectures.net/coinactivess2010_jermol_wel|Welcome to the Summer School on Advanced Technologies for Knowledge Intensive Networked Organizations 2010 - Aachen ]]\r\n\r\n == 10. Using ACTIVE solution\r\n\r\nThe aim of this training module is to train the potential users/adopters/developers on the ACTIVE solutions. The course is organised as a blended learning module that combines traditional two days event with the self-learning courses in LC. The main learning goals for this module are to teach about basics of ACTIVE solutions and infrastructure, provide technical specifications, development environment and cases. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse10_UsingACTIVESolution.pdf|Using ACTIVE solution - course]]\r\n\r\nCourse topics:\r\n\r\n**ACTIVE prototypes, ACTIVE Knowledge Workspace Desktop, ACTIVE SDK, ACTIVE Integrated Platform**\r\n*[[http://videolectures.net/active09_dolinsek_iak|Introduction to the ACTIVE Knowledge Workspace SDK]]\r\n*[[http://videolectures.net/coinactivess2010_dolinsek_akw|Active Knowledge Work Space demonstration]]", "recorded": "2011-02-23T15:20:20", "title": "ACTIVE - Training programme for multipliers"}, {"url": "nib_krebs_biology", "desc": "Systems biology research is typically performed by multidisciplinary groups of scientists, often in large consortia and in distributed locations. The data generated in these projects tend to be heterogeneous and often involves high-throughput \"omics\" analyses. Models are developed iteratively from data generated in the projects and from the literature. Consequently, there is a growing requirement for exchanging experimental data, mathematical models, and scientific protocols between consortium members and a necessity to record and share the outcomes of experiments and the links between data and models.\r\n\r\nThe SEEK is an open-source, web-based platform for the management and exchange of Systems Biology data, models and processes. It was originally developed in the SysMO-DB project (http://www.sysmodb.org) for the pan-European SysMO consortia (Systems Biology of Micro Organisms). However, it is now also being adopted by a large number of other consortia across Europe, for example, the Virtual Liver, EviMalar and Unicellsys.   The SysMO-DB solution is being developed in close collaboration with the users, and with a very pragmatic approach, trying to adapt to the common procedures of users and combining this with methods and technologies that allow an effective dissemination, linkage and exchange of data and information. \r\n\r\nUnderlying the SEEK is the JERM (Just Enough Results Model), which is a minimum information model describing the structure and content of the SEEK assets and relationships between them. A JERM for any one type of data (i.e. microarray data, or metabolomic data) is the minimum data schema that SysMO projects agree to share. This is used to create JERM templates. SysMO-DB leverages these minimum models wherever possible, enabling easy export and publishing of SysMO data to public repositories. In addition, we have developed RightField (the Spreadsheet Ontology Annotation tool) to help researchers to develop templates for experimental data with embedded semantic descriptions. Data can then be consistently annotated with terms from appropriate ontologies and controlled vocabularies consistently. The SEEK provides an access control layer to enable researchers to restrict access to their data to collaborators and colleagues or to share it with the wider community. \r\n\r\nAvailability: SEEK code is open source and available for download http://code.google.com/p/sysmo-db/. For a demonstration of the SEEK capabilities, and to try out the  software, demo SEEK is available here https://demo.sysmo-db.org/. RightField download: http://www.sysmo-db.org/rightfield", "recorded": "2012-11-06T15:30:00", "title": "The SEEK: a platform for sharing data and models in systems biology"}, {"url": "coin_academia_training", "desc": "back to [[http://videolectures.net/coin|COIN training project ]]\n\n===These videolectures describe the technologies being used and developed in COIN, and some of the applications of those technologies in the project.  The lectures are given by COIN researchers and by other researchers working in the same and related fields. We also suggest that as a starting point you take a look at the [[http://videolectures.net/coin_videolectures_promo/|COIN promo video]].\n\n == 1. Motivation for the paradigm of EI/EC\n\nThis first unit aims at creating a motivation for the course through a brief presentation of application areas, illustrated by concrete examples in industry, services, government, etc. A brief historic overview of the industrial organizational paradigms leading to collaborative networks and their interoperability as well as a summary of current technological and organizational trends is presented. For each example an attempt to identify the main involved problems (e.g. organizational forms, processes, and cooperation and collaboration forms) is made, calling the attention for the potential contributes from other disciplines.\n\n * Collaboration and Interoperability\n * Practical examples of CNs\n * Practices of Interoperability\n * Historic overview.\n * Technological and organizational trends.\n * Discussion of the usefulness / benefits and current limitations\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course%201%20Motivation%20for%20the%20paradigm.pdf|Motivation for the paradigm - course]]\n\n||[[:ice09_martinez_ewbom]]||[[:ice08_martinez_future]]||[[:ice2011_schuh_production/]]||[[:ice08_prinz_web]]||[[:esocenet07_gusmeroli_csf]]||\n ----\n ----\n\n == 2. Basic concepts\n\nAfter the motivation phase, the base concepts are introduced. Considering the large variety of collaborative networks and interoperability modes, a categorization of the various forms is made and taxonomy is introduced in order to give students a global perspective of the area. At the same time the basic project concepts and  models are being addressed. The various innovative concepts and models developed in COIN.\n\n * COIN Basic Concepts\n * Fundamentals in CN\n * Fundamentals in Interoperability\n * COIN innovative concepts and models\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course%202%20Basic%20Concepts.pdf|Basic concepts - course]]\n\n||[[:ice08_gusmeroli_meta]]||[[||:iesa08_rossiter_lfi]]||[[||:coinactivess2010_gusmeroli_cica]]||[[||:coinactivess2010_sesana_cis]]||[[||:cgm09_gusmeroli_tccps]]\n\n ----\n ----\n\n == 3. Enterprise Interoperability\n\nAfter the motivation phase and the COIN basic concepts are introduced, the base concepts of Enterprise Interoperability are explained. After describing the overall goals and essential terms for the Interoperability of enterprises, principles, methods and benefits of enterprise Interoperability are explained. Here we show key issue, definitions and approaches in manufacturing and industrial\nenterprise generally and how Interoperability is the ability of a system or a product to work with other systems based on various architectures and platforms or products without special effort from the user.\n\n * Basic Concepts, Definitions and Approaches.\n * Enterprise Modelling for Interoperability\n * Ontology for Interoperability\n * Introduction to Architecture and Platforms for Enterprise system Interoperability\n * Business Interoperability (BI)\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course%203%20Enterprise%20Interoperability.pdf|Enterprise Interoperability - course]]\n\n ||[[:ice08_katranuschkov_aigevo]]||[[:ice09_olmo_aabc]]||[[:ice09_debate_qa]]||[[:iswc06_wache_irpto]]||[[:cgm09_taglino_eis]]||\n\n ----\n ----\n\n == 4. Virtual Organisations Breeding Environment\n\nCourse on the main elements of the VBE that are studied in COIN featuring theoretical and practical business examples from the field. The basic elements of Virtual Organizations Breeding Environment and its role in the context of CNO. Contents: Virtual Organization And Current Enterprises, Collaborative networked organization and business opportunities, Business ecosystems, VBE - Virtual Organization Breeding Environments, VBE - constituting elements and features, VBE - working and sharing principles, Value system and metrics for VBE.\n\n * Concept and examples.\n * Components, structure, actors and roles.\n * Competencies and assets.\n * Processes and governance principles.\n * VBE management system.\n * Trust and value systems.\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course%204%20Vo%20Breeding%20Environment.pdf|VO Breeding Environment - course]]\n\n ||[[:ess07_ferlez_mc]]||[[:akom08_grobelnik_ina]]||[[:brussels06_afsarmanesh_v]]||[[:ess07_jermol_evg]]|||[[:antwerpen04_blomqvist_ottbn]]||\n\n ----\n ----\n\n == 5. Virtual Organizations\n\nCourse on the concept and structure of Virtual Organizations creation rules and functionalities. Here we present the continuous life cycle of the Virtual Organization creation with its creation, formation, later approaching its breeding environment functionalities and ultimately its dissolution and incorporation into its next life cycle phase.\n\n * Concepts, organizational models and operational rules.\nLife cycle.\n * VO creation process and functionalities.\n * VO management functionalities and performance measurement.\n * VO dissolution and inheritance.\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course%205%20Virtual%20Organizations.pdf| Virtual Organizations - course]]\n\n ||[[:ess07_ollus_vom]]||[[:ess06_ollus_vrvp]]||[[:ess06_seifert_pmv]]||[[:ess07_slavik_vrv]]||||[[:ekom08_ollus_mcn]]\n\n ----\n ----\n\n == 6. Virtual Communities\n\nIn this course is shown the basic knowledge on Virtual Communities, the concept of Professional Virtual Communities that is being explored in COIN. A typology of VC is introduced and a particular attention is devoted to Professional Virtual Communities. The components, structure, and life cycle of PVCs are discussed and modeling options introduced in comparison with the VBE. Architectural options for a PVC management system and supporting functionalities are introduced. The creation of Virtual Teams within a PVC and their management are studied. Governance principles, main processes, intellectual property issues, and social computing issues are discussed.\n\n * Concepts and typology.\n * Components, structure, and life cycle.\n * Professional virtual communities (PVC).\n * PVC management system.\n * Virtual teams.\n * Governance principles and social computing.\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_6_Virtual_Communities_Academia.pdf|Virtual Communities - course]]\n\n ||[[:ess06_seifert_pmv]]||[[:esocenet07_santoro_ci]]||[[:brussels06_gusmeroli_i]]||[[:mitworld_baltimore_bac]]||[[:ess07_vorobey_ape]]||\n ** recomended lectures:**\n *[[http://videolectures.net/ess06_crave_pbct| PVC basic concepts & typologies]]\n *[[http://videolectures.net/ess07_crave_pca|PVC and cooperation from AI perspective]]\n *[[http://videolectures.net/ess06_picard_sppvc|Social protocols in Professional Virtual Communities]]\n *[[http://videolectures.net/eccs07_chavalarias_sma|Science mapping with asymmetric co-occurence analysis]]\n\n ----\n ----\n\n == 7. Architectures and Platforms\n\nFocusing on research coordination in the area of Architecture & Platforms. Show basic internet and computer technologies, ideas, and concepts for enterprise interoperability purposes and to continue on updating with state-of-the-art models, approaches and mechanisms.\n\n * Computer networks basics. Base Internet technologies.\n * Components of a communication infrastructure.\n * Introduction to Service Platforms, Service Oriented Architectures\n * Introduction to Distributed systems\n * Introduction to Platform virtualisation\n * Introduction to Service-Oriented Interoperability (SOI)\n * Introduction to Model-Driven Interoperability (MDI)\n * Security mechanisms and technologies.\n * Data Quality in Cooperative Information Systems\n * Emerging computing models and implementation approaches\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_7_Architectures_and_Platforms_Academia.pdf|Architectures and Platforms - course]]\n\n||[[:iesa08_gionis_aha]]||[[:iesa08_ullberg_eas]]||[[:ess07_negretto_ii]]||[[:ess07_hodik_atv]]||[[:ess06_nagellen_soa]]||\n\n ----\n ----\n\n == 8. Background Technologies\n\nThis course presents and explains core technologies from the area of knowledge technologies that ranges from the data driven methods to knowledge driven methods and are important for detecting, analyzing and managing knowledge (tacit and explicit) in enterprises, organisations or agents. Recent developments in the particular areas are demonstrated through real software prototypes, successful market cases and real business implementations. The course provides many demos and business cases that will be available as demonstrations online and could be supplemented with the hands-on session.\n\n * Traditional technologies\n * Semantic and knowledge technologies\n * Self awareness and cognitive systems\n * Agent technologies\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course%208%20Background%20Technologies.pdf| Background Technologies - course]]\n\n ||[[:kdd07_fayyad_dms]]||[[:ssll09_kotagiri_dami]]||[[:stanfordcs229f08_ng_lec01]]||[[:iswc08_hendler_ittsw]]||[[:ess07_jermol_ktno]]||\n**recomended lectures:**\n *[[http://videolectures.net/psm08_cristianini_ieb/|In the Eye of the Beholder? Another look at Cognitive Systems]]\n*[[http://videolectures.net/ijcai09_lesser_saitmao/|Scaling AI Through Multi-Agent Organizations]]\n*[[http://videolectures.net/ccss09_pietronero_soafse/|Self-Organization and Finite Size Effects in Agent Models for Financial Markets]]\n*[[http://videolectures.net/ccss09_steubing_atcf/|Assessing the Critical Factors that Determine the Availability of Wood Fuel in Switzerland with an Agent Based Model]]\n ----\n ----\n\n == 9. COIN Solution\n\nThis is one of the main courses in COIN training programmes. It is aimed at presenting COIN innovative  solutions that will be developed in the frame of the project. Training starts with innovative business and organisational models that are consequence of newly introduced technologies. The main focus is on the explanation and demonstration of technologies developed in COIN, their use in the industry contexts and on the discussion of their implications to the traditional business environment. Course addresses in detail the methods for identifying knowledge processes, knowledge (tacit and explicit) in organisations as well as new technology research streams. Furthermore it explains and demonstrates the methods for contextualisation that spans over three orthogonal dimensions: content, social network and time.\n\n * Basic architecture\n * Introduction to COIN Service platform\n * Transition from a Service Platform to an Utility Platform\n * Business-adaptive Service Platform:\n * Pervasive, Evolutionary and Scalable Service Platform\n * TSD-enabled service Platform for Networked Enterprises\n * Agent-based Business Knowledge Interoperability\n * Introduction to COIN Enterprise Interoperability services\n * Interoperability baseline\n * Information Interoperability Services\n * Knowledge Interoperability Services\n * Business Interoperability Services.\n * Introduction to COIN Enterprise Collaboration services\n * Collaboration baseline\n * Collaborative Product Development c-PD,\n * Collaborative Production Planning c-PP,\n * Collaborative Project Management c-PM\n * Collaborative Human Interaction c-HI.\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course%209%20COIN%20solution%20-%20Introduction.pdf| COIN solution - course]]\n\n||[[:coinactivess2010_jansson_ccs]]||[[:coinactivess2010_sitek_ure]]||[[:coinactivess2010_sesana_cpd]]||[[:coinactivess2010_fischer_cbs]]||[[:coinplanetdataschool2011_sesana_coin]]||\n\n ----\n ----\n\n == 10. Practical Examples and COIN prototypes\n\nIn this course the practical examples of COIN prototypes will be demonstrated and explained together with some applications that are related to the COIN research domain. The course will be supplemented with a hands-on workshop to allow participants to deal with concrete examples from their work context.\n\n * use scenarios,\n * case studies and best practices,\n * demonstrators, demos, prototypes\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_10_Practical_Examples_and_COIN_prototipes_Academia.pdf| Practical Examples and COIN prototypes - course]]\n\n ||[[:ice09_olmo_coincpds]]||[[:coinplanetdataschool2011_sesana_demos/]]||[[:ice09_canepa_isurf]]||[[:cgm09_komazec_cspwho]]||[[:coinplanetdataschool2011_oman_usage]]||\n\n ----\n ----\n\n == 11. Information Management\n\nCourse on competency/profile information management basics and preliminary prototypes. Contents: Introduction, Specification of main components and functions of PCMS, e-Catalogue features and key components.\n\n * Information management requirements.\n * Mechanisms for information sharing and exchange.\n * Access rights definition and enforcement.\n * Federated /distributed information management.\n\n ||[[:ict08_mladenic_rtip/]]||[[:wsdm08_garcia_molina_wim]]||[[:kdd09_cherkasova_assaeim]]||[[:samt08_gauthier_iim]]||[[:estc09_miller_lde]]||\n\n* [[http://www.thelondonconsulting.com/products/information-server|TLCG Information Server]]\n* [[http://www.managing-information.org.uk/summary.htm|Information Management Paper]]\n* [[http://www.imbok.org|Information Management Body of Knowledge]]\n* [[http://www.ipl.com/services/businessconsulting/resources/#businessconsulting-papers|Information Management papers from IPL]]\n ----\n ----\n\n == 12. Information Exchange Standards\n\nA number of standards particularly relevant for collaborative networks and enterprise interoperability are introduced and analyzed. Among them: EDI (Electronic Data Interchange), which in historical terms represents one of the first tools for cooperation among enterprises, is introduced and briefly characterized. The interaction between EDI and ERP. The EDIFACT standard is presented and current XML-based implementations mentioned. Support technologies as well as PDM systems are discussed. Other emerging standards for information and knowledge exchange are pointed out.\n\n * Importance of standards.\n * Interaction with legacy systems.\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_12_Information_Exchange_Standards_Academia.pdf| Information Exchange Standards - course]]\n\n||[[:efreight2011_rantasila_pilli_sihvola_logistics]]||[[:kdd2010_zheng_udmt]]||[[:ict08fr_nagy_rothengass_eiu]]||[[:ecml07_smyth_api]]||[[:forum2010_glenn_gcisd]]||\n\n ----\n ----\n\n == 13. Coordination Mechanisms\n\nThis course is aimed at providing knowledge about the models, structures and mechanisms for management, coordination and problem solving. The coordination mechanisms are basic mechanisms in any networked organisation and as such the focal point of interest for any distributed, knowledge focused organisation. The course will analyze and study the approaches for distributed and collaborative decision-making including organizational aspects in the context of informal and knowledge processes.\n\n * Collaboration modalities.\n * Concept of coordination.\n * Distributed-business process modeling and planning.\n * Distributed scheduling and re-scheduling.\n * Languages for business process modeling.\n * Workflow and process execution engines.\n * Challenges in flexible coordination.\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_13_Coordination_Mechanisms_Academia.pdf| Coordination Mechanisms - course]]\n\n ||[[:eccs07_stark_cpc]]||[[:eccs07_menczer_wcn]]||[[:eccs07_matteo_gld]]||[[:iesa08_wings_csit]]||\n\n ----\n ----\n\n == 14. Management of common Ontologies\n\nThis course is aimed at providing the base concepts of ontologies, especially in relation to the COIN common ontology, explore the potential of ontology-based techniques to tackle the problem of interoperability and to investigate how such techniques can be joined together with the other fundamental perspectives addressed in COIN.\n\n * The role of ontologies in collaboration\n * Ontology based support to Enterprise Interoperability\n * Introduction to Ontologies\n * Glossary and specification of base entities and concepts\n * COIN Core level common ontology\n * Ontology engineering approaches\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_14_Management_of_common_Ontologies_Academia.pdf| Management of common Ontologies - course]]\n\n ||[[:ess07_grobelnik_twdmI]]||[[:iesa08_dahlem_osm]]||[[:mmdss07_grobelnik_oml]]||[[:ess07_obitko_oswve]]||[[:tao08_bontcheva_tao]]||\n\n ----\n ----\n\n == 15. e-Commerce and e-Markets\n\nThis course will in particular investigate aspects related to the economics and the incentives behind Interoperability. Issues of costs and benefits associated to developing, deploying or maintaining architecture, platforms and systems at enterprise level will be presented and instruments to predict and use them for analytically describe knowledge creation processes which are important pre-requisites for their large-scale.\n\n * Concepts of e-Commerce and e-Market.\n * Relationships to CN and Interoperability.\n * Support institutions.\n * Support systems. Portals. Negotiation.\n * CRM. Logistics.\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_15_E-Commerce_and_E-Markets_Academia.pdf|E-commerce and E-markets - course]]\n\n ||[[:echallenges2010_li_intro]]||[[:ice09_canepa_isurf]]||[[:ice09_withalm_cdcp]]||[[:coinplanetdataschool2011_hristov_media]]||[[:echallenges2010_suttner_tnb]]||\n\n ----\n ----\n\n == 16. Non Technological Issues\n\nIn this unit social, ethical, legal, and organizational issues are discussed and current trends pointed out. New business models and their applicability are discussed, namely through the introduction of examples. Marketing and sustainability, intellectual property management, systems of incentives, etc. are other relevant issues.\n\n * Social, ethical, legal, and organizational issues.\n * Contractual issues.\n * New business models.\n * Sustainability mechanisms.\n * Intellectual property management.\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_18_Emerging_Collaborative_Forms_Academia.pdf|Non Technological Issues - course]]\n\n ||[[:antwerpen04_heath_tbmso]]||[[:coinplanetdataschool2011_hsuan_web]]||[[:eccs07_antonelli_fei]]||[[:rtd09_stres_coipp]]||[[:ess06_picard_sppvc]]||\n\n ----\n ----\n\n == 17. Organisation Modeling and Reference Models\n\nThe course topic is focusing on Organisation Modelling as a combination of a set of activities within an enterprise with a structure describing their logical order and dependence whose objective is to produce a desired result. Business Process modeling as an enabler of common understanding and analysis of a business process. The course will also descrivbe the main process modelling techniques.\n\n * Concept of reference model.\n * Modeling frameworks.\n * Examples of reference models.\n * Organisation Modelling\n * Business Process Modelling\n * Business Models Overview\n * Derivation and evolution methods.\n\n ||[[:eccs07_stark_cpc]]||[[:eccs07_menczer_wcn]]||[[:eccs07_matteo_gld]]||\n\n ----\n ----\n\n == 18. Emerging Collaborative Forms\n\nBrief summary of the various collaborative forms studied in previous units, a discussion of possible new models and generalizations is made. As a starting basis, new forms of collaborative e-government, e-science, Virtual institutes, Virtual laboratories, etc, are discussed. Other generalizations include: networks of sensors, networks of machines, etc.\n\n * Summary of studied collaborative forms and interoperability approaches.\n * New application examples: collaborative e-government, e-Science, Virtual institutes, Virtual Labs, etc.\n * Internet of Things: Networks of machines, networks of sensors.\n * Intelligent, self-aware enterprises, Symbiotic models\n * Other emerging cases.\n\n[[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_18_Emerging_Collaborative_Forms_Academia.pdf|Emerging Collaborative Forms - course]]\n\n ||[[:eccs07_newman_sdc]]||[[:eccs07_verschure_dac]]||[[:eccs07_stamatiou_dtc]]||[[:esocenet07_borjeson_enl]]||[[:coinactivess2010_kropp_sol]]||\n **recomended lectures:**\n *[[http://videolectures.net/eccs07_canright_smn|Self-mapping Networks]]\n *[[http://videolectures.net/porto05_cordeiro_sc|Semiotics in CNOs]]\n *[[http://videolectures.net/eccs07_damiani_irb|Interacting Random Boolean Networks]]\n *[[http://videolectures.net/eccs07_jiang_pba|Population-based adaptive Systems: An Implementation in NEW TIES]]", "recorded": "2010-01-31T18:31:10", "title": "COIN - Academia training section"}, {"url": "dataforum2012_damova_factforge", "desc": "Linked Open Data movement is maturing. Not only LOD cloud increases by billions of triples yearly, but also technologies and guidelines about how to produce LOD fast, how to assure their quality, and how to provide vertical oriented data services are being developed (LOD2, LATC, baseKB).  Little is said however about how to include reasoning in the LOD framework, and about how to cope with its diversity.  In this talk we will present FactForge, a reason-able view on the web of data, which comprise a segment of LOD cloud, e.g. DBPedia, Freebase, Geonames, Wordnet, NY Times, Musicbrainz, Lingvoj, Lexvo, CIAFactbook, loaded in a single repository (OWLIM), and forming a compound dataset,  on which inference is performed. This results in 40% increase of the knowledge available for querying to about 15 billion statements.\r\n\r\nThe diversity of LOD makes their use and querying extremely challenging, as one has to be intimately familiar with the schemata underlying each dataset. Initiatives and research projects like schema.org, UMBEL, BLOOMS+, ALOCUS which try to involve the notion of a golden standard at schema level to allow better interoperability of LOD and the WWW in general, are indicative for the search of a solution along these lines. The new version of FactForge which will be shown in this talk and in the making for several years now, aligns with these views. It is supplied with a reference layer of the upper-level ontology PROTON, which is mapped to the ontologies of the LOD datasets in FactForge, making their instances accessible via PROTON concepts and properties. This reference layer makes loading of the LOD ontologies unnecessary, optimizing the reasoning processes, and allows for quick and seamless data integration of new datasets with the entire LOD segment of FactForge.\r\n\r\nIt also ensures better interfacing with other components via SPARQL as the queries are more compact and easy to formulate, faster response times, because of less joins are employed, and a wealth of inferred knowledge across the datasets, which allows for real journey of knowledge discovery, and navigation from different stand points. FactForge is the largest body of general knowledge and LOD on which inference is performed. We will present applications which make use of FactForge and emphasize the role of inferred knowledge in them produced by the reason-able views, and will argue for a new paradigm of data services, based not only on linked data verticals but also on inferred knowledge.", "recorded": "2012-06-07T10:30:00", "title": "FactForge: Data Service and the Value of Inferred Knowledge"}, {"url": "active_course_syllabus", "desc": "back to [[http://videolectures.net/active|ACTIVE training project ]]\n\n===\nThe goal of training activities in ACTIVE is to achieve the transfer of knowledge and best practices within the project as well as (principally) outside the project. ACTIVE training program is aimed at training individuals and groups on the topics that are relevant to the ACTIVE project. Each training program covers a general topic and is generated from several training courses that are focused on specific topics. Furthermore, each training program combines different types and forms of learning: traditional, ICT supported or blended training event. For each training course we provide textual materials, references to the sources used for training module preparation, a list of the topic relevant ACTIVE deliverables, video tutorials and additional materials/suggested readings.\n\n== 1. Theoretical Foundations and Conceptual Models\n\nThis course starts with the theoretical foundations on the organisational and collaboration forms, business process modelling, management and collaboration mechanisms, knowledge management and current governance principles in organisations. In contrast it provides basic information about traditional and emerging technologies that influence traditional business organisation and management context. Then it gives motivation for the complete ACTIVE training programme by providing incentives, future trends and business potentials.\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse1_TheoreticalFoundations.pdf|Theoretical foundations and conceptual models - course]]\n\nCourse topics:\n\n**Collaboration and collaborative knowledge creation**\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\n*[[http://videolectures.net/semseach09_albakour_mcpse|Managing Collaboration Projects using Semantic Email]]\n*[[http://videolectures.net/iswc08_tudarache_scodp|Supporting Collaborative Ontology Development in Protege]]\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\n*[[http://videolectures.net/ice08_kristensen_pcik|Productivity in Collaboration-intensive Knowledge Work: The Collaboration Management Imperative]]\n*[[http://videolectures.net/nano07_gadlin_rsc|Re-thinking scientific teams: competition, conflict and collaboration]]\n*[[http://videolectures.net/iswc06_auer_otssc|In-Use 1: OntoWiki - A Tool for Social, Semantic Collaboration]]\n\n**Knowledge processes and tasks**\n*[[http://videolectures.net/active09_tilly_ikp|Informal Knowledge Processes: The Long Tail of Business Processes]]\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\n\n**Process modelling**\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\n\n**Knowledge management**\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\n*[[http://videolectures.net/training06_davies_ka|Knowledge Access]]\n*[[http://videolectures.net/iswc08_bhagdev_cauoswilno|Creating and Using Organisational Semantic Webs in Large Networked Organisations]]\n*[[http://videolectures.net/cikm08_feldman_ak|Automating Knowledge]]\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\n\n**Formalisms for (dynamic) aspects of knowledge worker context and enterprises**\n*[[http://videolectures.net/iswc06_grobelnik_cskrs|Context Sensitivity in Knowledge Rich Systems]]\n*[[http://videolectures.net/iswc06_witbrock_cskrs|Context Sensitivity in Knowledge Rich Systems]]\n*[[http://videolectures.net/iswc06_mozetic_cskrs|Context Sensitivity in Knowledge Rich Systems]]\n*[[http://videolectures.net/iswc06_haase_cop|Context Sensitivity in Knowledge Rich Systems - Contents of parts 2]]\n\n ----\n ----\n\n == 2. Knowledge Models and Structures\n\nThis course deals with the theoretical background on knowledge and semantic technologies and examines them from a technological, historical and scientific perspective. It starts with the basic facts about knowledge structures and models and their role in the knowledge formalisation, modelling, reasoning and adaptation. It provides comparison and contrasting of diverse knowledge models, structures and systems and understanding their participation in industry.\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse2_KnowledgeModels.pdf|Knowledge models and structures - course]]\n\nCourse topics:\n\n**Semantic languages**\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\n*[[http://videolectures.net/training06_sure_stsw/|A short Tutorial on Semantic Web]]\n*[[http://videolectures.net/eswc09_tappolet_atre|Applied Temporal RDF: Ef?cient Temporal Querying of RDF Data with SPARQL]]\n*[[http://videolectures.net/eswc09_vennekens_faaeod|FO(ID) as an Extension of DL with Rules]]\n*[[http://videolectures.net/iswc08_perez_nsparql|NSPARQL: A Navigational Language for RDF]]\n*[[http://videolectures.net/iswc08_hausenblas_bwdwd|RDFa - Bridging the Web of Documents and the Web of Data]]\n\n**Knowledge formalisation  and  representation**\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\n*[[http://videolectures.net/akom08_krotzsch_fik|Formal and Informal knowledge representation]]\n*[[http://videolectures.net/iswc08_saggion_krebi|Knowledge Representation and Extraction for Business Intelligence]]\n\n**Reasoning and  probabilistic temporal models**\n*[[http://videolectures.net/iswc08_moller_itsr|Reasoning for Ontology Engineering and Usage]]\n*[[http://videolectures.net/ssll09_pagnucco_krr|Knowledge Representation and Reasoning]]\n*[[http://videolectures.net/bsciw08_schwaighofer_krrd|Knowledge Representation and Reasoning - Discussion]]\n\n**Knowledge structures**\n**Collaborative articulation of expressive knowledge**\n**Knowledge leveraging and repair models**\n**Knowledge-based adaptation**\n**Knowledge creation cycle**\n\nRelated talks:\n*[[http://videolectures.net/iswc08_hauer_asnrwpdehep|An architecture for semantic navigation and reasoning with patient data - experiences of the Health-e-Child project]]\n*[[http://videolectures.net/eswc08_blanco_sr|Semantic Reasoning: A Path To New Possibilities of Personalization]]\n*[[http://videolectures.net/akom08_krotzsch_fik/|Formal and Informal knowledge representation]]\n*[[http://videolectures.net/active09_ghani_rdekm/|Research Directions in Enterprise Knowledge Management]]\n\n ----\n ----\n\n == 3. Background Technologies\n\nThis course presents and explains core technologies from the area of knowledge technologies that ranges from the data driven methods to knowledge driven methods and are important for detecting, analysing and managing knowledge (tacit and explicit) in organisations. Recent developments in the particular areas are demonstrated through real software prototypes, successful market cases and real business implementations. The course provides many demos that are available as demonstrations online and could be supplemented with the hands-on session.\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse3_BackgroundTechnologies.pdf|Background technologies - course]]\n\nCourse topics:\n\n**Context mining**\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\n*[[http://videolectures.net/um05_loosli_ccdoc|Context changes detection by one-class svms]]\n*[[http://videolectures.net/ice08_lukowicz_crw|Context recognition in the wearIT@work project]]\n*[[http://videolectures.net/kdd09_zhu_mrciws|Mining Rich Session Context to Improve Web Search]]\n*[[http://videolectures.net/samt08_santini_cnod|Context as a non-ontological determinant of semantics]]\n\n**Stream mining**\n*[[http://videolectures.net/ecml07_gama_sad|State of the Art in Data Stream Mining]]\n*[[http://videolectures.net/ecml07_mohamed_sad|State of the Art in Data Stream Mining]]\n*[[http://videolectures.net/ecml07_mohamed_acac|An architecture for context-aware adaptive data stream mining]]\n*[[http://videolectures.net/ecml07_mohamed_mqgr|A Model for Quality Guaranteed Resource-Aware Stream Mining]]\n\n**Anomaly detection**\n*[[http://videolectures.net/ecmlpkdd08_lazarevic_dmfa|Data Mining for Anomaly Detection]]\n*[[http://videolectures.net/mmdss07_tishby_itam|Information Theo-retic and Alge-braic Methods for Network Anomaly Detection]]\n*[[http://videolectures.net/kdd09_jermaine_alrtffsad|A LRT Framework for Fast Spacial Anomaly Detection]]\n\n**Social network analysis**\n*[[http://videolectures.net/semseach09_graves_srrdsn|Searching and ranking in RDF documents and social networks]]\n*[[http://videolectures.net/icwsm09_agarwal_siaifs|A Social Identity Approach to Identify Familiar Strangers in a Social Network]]\n*[[http://videolectures.net/kdd09_jermaine_alrtffsad|A LRT Framework for Fast Spacial Anomaly Detection]]\n*[[http://videolectures.net/iswc07_aasman_usn|Using Social Network Analysis, Geotemporal Reasoning and RDFS++ Reasoning for Business Intelligence]]\n\n**Social software and Web 2.0**\n*[[http://videolectures.net/active09_mulvany_cwsc|A Cabinet of Web 2.0 Scientific Curiositics]]\n*[[http://videolectures.net/eswc08_gomes_cs|Collective Semantics: Collective Intelligence & the Semantic Web - Flickring Our World]]\n*[[http://videolectures.net/eccs07_huberman_bwe|Beyond Web 2.0]]\n*[[http://videolectures.net/icwsm09_sun_gmctfnf|Gesundheit! Modeling Contagion Through Facebook News Feed]]\n*[[http://videolectures.net/eswc08_halpin_sw|Panel II: Social Network Portability: Is the Semantic Web Ready?]]\n*[[http://videolectures.net/cikm08_perisic_usnfsw|Using Social Networks for Social Work]]\n*[[http://videolectures.net/www09_baezayates_mtwbs|Mining the Web 2.0 for Better Search]]\n*[[http://videolectures.net/samt08_baumann_wai|WhoAmI - A Web2.0 Platform for Faceted Identity Management through Aggregation of Social Media]]\n\n**Adaptive and context-aware systems**\n*[[http://videolectures.net/samt08_rodriguez_doncel_smac|A Semantic Model for the Authorisation of Context-Aware Content Adaptation]]\n\n**Semantic technologies and content**\n**Social software and Web 2.0**\n**Knowledge filters**\n**Meta learning**\n**Forecasting**\n\nRelated talks:\n*[[http://videolectures.net/eccs07_huberman_bwe|Beyond Web 2.0]]\n*[[http://videolectures.net/kdd07_fayyad_fmtw|From Mining the Web to Inventing the New Sciences Underlying the Internet ]]\n*[[http://videolectures.net/ecml07_baeza_yates_mwq|Mining Queries]]\n*[[http://videolectures.net/estc08_zaragoza_isst|Improving Search with Semantic Technologies: Current Research Directions]]\n*[[http://videolectures.net/active09_grobelnik_tmlws|Text Mining and Light Weight Semantics]]\n\n ----\n ----\n\n == 4. ACTIVE Innovative Solutions\n\nThis is one of the main courses in ACTIVE training programmes. It is aimed at presenting ACTIVE innovative solutions that will be developed in the frame of the project. Training starts with innovative business and organisational models that are consequence of newly introduced technologies. The main focus is on the explanation and demonstration of technologies developed in ACTIVE, their use in the industry contexts and on the discussion of their implications to the traditional business environment. Course addresses in detail the methods for identifying knowledge processes, hidden knowledge in organisations as well as new technology research streams. Furthermore it explains and demonstrates the methods for contextualisation that spans over three orthogonal dimensions: content, social network and time. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse4_InnovativeSolutions.pdf|ACTIVE innovative solutions - course]]\n\nCourse topics:\n\n**Tools and methods for collaborative and expressive knowledge articulation paradigms**\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\n\n**Ontology learning**\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\n*[[http://videolectures.net/training06_grobelnik_tmol|Text Mining for Ontology Learning]]\n*[[http://videolectures.net/koml04_grobelnik_olkds|Ontology Learning - Knowledge Discovery and the Semantic Web]]\n\n**Hybrid Web 2.0 - ontology infrastructure**\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\n*[[http://videolectures.net/eswc08_hess_cs|Collective Semantics: Collective Intelligence & the Semantic Web - From Web 2.0 to Semantic Web - A Semi-Automated Approach]]\n\n**Semi-automated process refactoring**\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\n\n**Optimization of knowledge models and pro-active support**\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\n\n**Delivery of contextualized information**\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\n\n**Visualization of temporal enterprise model**\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\n\n**Privacy preserving analysis of enterprise data**\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\n*[[http://videolectures.net/google_roughan_ppdm|Privacy Preserving DataMining]]\n\n**Inconsistency diagnosis and automatic repair of inconsistencies**\n**Complex rule interfaces**\n**Knowledge process mining**\n**Autonomous, context aware services for knowledge processes**\n**Dynamic adaptations of context-aware knowledge processes**\n**Security-aware knowledge processes**\n**Simultaneous analysis of multiple modalities**\n\nRelated talks:\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\n*[[http://videolectures.net/iswc08_witbrock_fsc|Free Semantic Content: Using OpenCyc in Semantic Web Applications]]\n*[[http://videolectures.net/iswc08_dellaValle_rswa|Realizing a Semantic Web Application]]\n*[[http://videolectures.net/active09_warren_kmcfl|KM at the Customer Front-Line: The BT Case Study in ACTIVE]]\n\n ----\n ----\n\n == 5. Management and Problem Solving\n\nThis course is aimed at providing knowledge about the models, structures and mechanisms for management, coordination and problem solving. The coordination mechanisms are basic mechanisms in any networked organisation and as such the focal point of interest for any distributed, knowledge focused organisation. The course will analyse and study the approaches for distributed and collaborative decision-making including organizational aspects in the context of informal and knowledge processes. Support with ACTIVE models and solutions for decision making processes in inter-enterprise and collaborative environment is the main focus.\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse5_Management and problem solving.pdf|Management and problem solving - course]]\n\nCourse topics:\n\n**Context sensitive management**\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\n\n**Pro-active knowledge process support**\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\n\n ----\n ----\n\n == 6. Practical Examples and ACTIVE Prototypes\n\nIn this course the development process of the ACTIVE prototypes for three specific applications will be demonstrated. The development process and the applications with their specific benefits which are created by the ACTIVE research results will be shown. The course will be supplemented with a hands-on workshop to allow participants to deal with concrete examples from their work context. The focus will be on identifying areas of applications where the functionalities developed in the ACTIVE project can be applied.\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse6_PracticalExamples.pdf|Practical Examples and ACTIVE Prototypes - course]]\n\nCourse topics:\n\n**Case studies and best practices**\n*[[http://videolectures.net/active09_warren_kmcfl|KM at the Customer Front-Line: The BT Case Study in ACTIVE]]\n*[[http://videolectures.net/coinactivess2010_thurlow_bcs|ACTIVE\u000b BT Case Study]]\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\n\n**Demonstrators, demos, prototypes**\n*[[http://videolectures.net/eswc08_berges_smw|Semantic Web Technology for Agent Communication Protocols]]\n*[[http://videolectures.net/active09_dolinsek_iak|Introduction to the ACTIVE Knowledge Workspace SDK]]\n\n**Use scenarios**\n\n ----\n ----\n\n == 7. Economic Incentives for Web 2.0 and Semantic Applications\n\nThis course will in particular investigate aspects related to the economics and the incentives behind Web2.0 and semantic technologies. Issues of costs and benefits associated to developing, deploying or maintaining Web 2.0 and semantic systems at enterprise level will be presented. , and instruments to predict and use them for analytically describe knowledge creation processes are important pre-requisites for their large-scale. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse7_EconomicIncentives.pdf|Economic incentives for Web2.0 and semantic applications - course]]\n\nCourse topics:\n\n**Integration into management activities**\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\n\n**Cost-benefit methods**\n*[[http://videolectures.net//akom08_popov_cbi|Costs, benefits and incentives (of semantic techologies)]]\n\n**Economic measurements**\n**Comprehensive models and tooling for economic measurements**\n**Business practices in knowledge technologies and social software**\n**Recommendations for tool design**\n\n Related taks:\n*[[http://videolectures.net/active09_sundaresan_tre|Trust and Reputation in eCommerce]]\n*[[http://videolectures.net/akom08_popov_cbi/|Costs, benefits and incentives (of semantic techologies)]]\n*[[http://videolectures.net/webstart08_mcgough_buan/|Business Angel]]\n*[[http://videolectures.net/eswc08_shadbolt_gst|Garlik: Semantic Technology for the Consumer]]\n\n ----\n ----\n\n == 8. Social, Ethical, Legal And Organizational Issues Related To Novel Semantic Technologies And Context Aware Systems\n\nIn this unit social, ethical, legal, and organizational issues are discussed and current trends pointed out. New business models and their applicability are discussed, namely through the introduction of examples. Marketing and sustainability, intellectual property management, systems of incentives, etc. are other relevant issues.\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse8_SocialIssues.pdf|Social, ethical, legal and organizational issues related to novel semantic technologies - course]]\n\nCourse topics:\n\n**Privacy models**\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\n*[[http://videolectures.net/ssms08_boehme_cpiimi|Concerns about Privacy & Innovation in ICT and Media Industries]]\n*[[http://videolectures.net/kdd09_li_otbpud|On the Tradeoff Between Privacy and Utility in Data Publishing ]]\n\n**Knowledge sharing and collaboration incentives**\n\nRelated talks:\n*[[http://videolectures.net/active09_zwegers_ficc/|On Future Internet, Cloud Computing and Semantics - You Name It]]\n*[[http://videolectures.net/iswc08_giannandrea_fowdw/|Freebase: An Open, Writable Database of the World\u2019s Information|]]\n*[[http://videolectures.net/iswc08_decker_mib/|Message in a Bottle or: How can the Semantic Web Community be more convincing?]]\n\n == 9. ACTIVE project - Introduction\n\nThe aim of this course is to present the aims, goals, structure and expected results of ACTIVE project. In addition this course provides information about the future plans, development and operations of the business development that will follow the ACTIVE project. In that respect the future directions in the research areas will be presented, their use potentials, development scenarios and business scenarios in the forms of business plans. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse9_Introduction.pdf|ACTIVE project - Introduction - course]]\n\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\n*[[http://videolectures.net/active09_mladenic_warren_oai|Opening and Introduction of the 1st ACTIVE Summer School]]\n*[[http://videolectures.net/coinactivess2010_warren_ai|ACTIVE Introduction]]\n*[[http://videolectures.net/coinactivess2010_jermol_wel|Welcome to the Summer School on Advanced Technologies for Knowledge Intensive Networked Organizations 2010 - Aachen ]]\n\n == 10. Using ACTIVE solution\n\nThe aim of this training module is to train the potential users/adopters/developers on the ACTIVE solutions. The course is organised as a blended learning module that combines traditional two days event with the self-learning courses in LC. The main learning goals for this module are to teach about basics of ACTIVE solutions and infrastructure, provide technical specifications, development environment and cases. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse10_UsingACTIVESolution.pdf|Using ACTIVE solution - course]]\n\nCourse topics:\n\n**ACTIVE prototypes, ACTIVE Knowledge Workspace Desktop, ACTIVE SDK, ACTIVE Integrated Platform**\n*[[http://videolectures.net/active09_dolinsek_iak|Introduction to the ACTIVE Knowledge Workspace SDK]]\n*[[http://videolectures.net/coinactivess2010_dolinsek_akw|Active Knowledge Work Space demonstration]]", "recorded": "2009-01-23T15:04:44", "title": "The ACTIVE Project - Technologies and Application"}, {"url": "active_industry_training", "desc": "back to [[http://videolectures.net/active|ACTIVE training project ]]\r\n\r\n===\r\nThe goal of training activities in ACTIVE is to achieve the transfer of knowledge and best practices within the project as well as (principally) outside the project. ACTIVE training program is aimed at training individuals and groups on the topics that are relevant to the ACTIVE project. Each training program covers a general topic and is generated from several training courses that are focused on specific topics. Furthermore, each training program combines different types and forms of learning: traditional, ICT supported or blended training event. For each training course we provide textual materials, references to the sources used for training module preparation, a list of the topic relevant ACTIVE deliverables, video tutorials and additional materials/suggested readings.\r\n\r\n== 1. Theoretical Foundations and Conceptual Models\r\n\r\nThis course starts with the theoretical foundations on the organisational and collaboration forms, business process modelling, management and collaboration mechanisms, knowledge management and current governance principles in organisations. In contrast it provides basic information about traditional and emerging technologies that influence traditional business organisation and management context. Then it gives motivation for the complete ACTIVE training programme by providing incentives, future trends and business potentials.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse1_TheoreticalFoundations.pdf|Theoretical foundations and conceptual models - course]]\r\n\r\nCourse topics:\r\n\r\n**Collaboration and collaborative knowledge creation**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n*[[http://videolectures.net/semseach09_albakour_mcpse|Managing Collaboration Projects using Semantic Email]]\r\n*[[http://videolectures.net/iswc08_tudarache_scodp|Supporting Collaborative Ontology Development in Protege]]\r\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\r\n*[[http://videolectures.net/ice08_kristensen_pcik|Productivity in Collaboration-intensive Knowledge Work: The Collaboration Management Imperative]]\r\n*[[http://videolectures.net/nano07_gadlin_rsc|Re-thinking scientific teams: competition, conflict and collaboration]]\r\n*[[http://videolectures.net/iswc06_auer_otssc|In-Use 1: OntoWiki - A Tool for Social, Semantic Collaboration]]\r\n\r\n**Knowledge processes and tasks**\r\n*[[http://videolectures.net/active09_tilly_ikp|Informal Knowledge Processes: The Long Tail of Business Processes]]\r\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\r\n\r\n**Process modelling**\r\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\r\n\r\n**Knowledge management**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\r\n*[[http://videolectures.net/training06_davies_ka|Knowledge Access]]\r\n*[[http://videolectures.net/iswc08_bhagdev_cauoswilno|Creating and Using Organisational Semantic Webs in Large Networked Organisations]]\r\n*[[http://videolectures.net/cikm08_feldman_ak|Automating Knowledge]]\r\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\r\n\r\n**Formalisms for (dynamic) aspects of knowledge worker context and enterprises**\r\n*[[http://videolectures.net/iswc06_grobelnik_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_witbrock_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_mozetic_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_haase_cop|Context Sensitivity in Knowledge Rich Systems - Contents of parts 2]]\r\n\r\n ----\r\n ----\r\n\r\n == 2. Knowledge Models and Structures\r\n\r\nThis course deals with the theoretical background on knowledge and semantic technologies and examines them from a technological, historical and scientific perspective. It starts with the basic facts about knowledge structures and models and their role in the knowledge formalisation, modelling, reasoning and adaptation. It provides comparison and contrasting of diverse knowledge models, structures and systems and understanding their participation in industry.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse2_KnowledgeModels.pdf|Knowledge models and structures - course]]\r\n\r\nCourse topics:\r\n\r\n**Semantic languages**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\r\n*[[http://videolectures.net/training06_sure_stsw/|A short Tutorial on Semantic Web]]\r\n*[[http://videolectures.net/eswc09_tappolet_atre|Applied Temporal RDF: Ef?cient Temporal Querying of RDF Data with SPARQL]]\r\n*[[http://videolectures.net/eswc09_vennekens_faaeod|FO(ID) as an Extension of DL with Rules]]\r\n*[[http://videolectures.net/iswc08_perez_nsparql|NSPARQL: A Navigational Language for RDF]]\r\n*[[http://videolectures.net/iswc08_hausenblas_bwdwd|RDFa - Bridging the Web of Documents and the Web of Data]]\r\n\r\n**Knowledge formalisation  and  representation**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n*[[http://videolectures.net/akom08_krotzsch_fik|Formal and Informal knowledge representation]]\r\n*[[http://videolectures.net/iswc08_saggion_krebi|Knowledge Representation and Extraction for Business Intelligence]]\r\n\r\n**Reasoning and  probabilistic temporal models**\r\n*[[http://videolectures.net/iswc08_moller_itsr|Reasoning for Ontology Engineering and Usage]]\r\n*[[http://videolectures.net/ssll09_pagnucco_krr|Knowledge Representation and Reasoning]]\r\n*[[http://videolectures.net/bsciw08_schwaighofer_krrd|Knowledge Representation and Reasoning - Discussion]]\r\n\r\n**Knowledge structures**\r\n**Collaborative articulation of expressive knowledge**\r\n**Knowledge leveraging and repair models**\r\n**Knowledge-based adaptation**\r\n**Knowledge creation cycle**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/iswc08_hauer_asnrwpdehep|An architecture for semantic navigation and reasoning with patient data - experiences of the Health-e-Child project]]\r\n*[[http://videolectures.net/eswc08_blanco_sr|Semantic Reasoning: A Path To New Possibilities of Personalization]]\r\n*[[http://videolectures.net/akom08_krotzsch_fik/|Formal and Informal knowledge representation]]\r\n*[[http://videolectures.net/active09_ghani_rdekm/|Research Directions in Enterprise Knowledge Management]]\r\n\r\n ----\r\n ----\r\n\r\n == 3. Background Technologies\r\n\r\nThis course presents and explains core technologies from the area of knowledge technologies that ranges from the data driven methods to knowledge driven methods and are important for detecting, analysing and managing knowledge (tacit and explicit) in organisations. Recent developments in the particular areas are demonstrated through real software prototypes, successful market cases and real business implementations. The course provides many demos that are available as demonstrations online and could be supplemented with the hands-on session.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse3_BackgroundTechnologies.pdf|Background technologies - course]]\r\n\r\nCourse topics:\r\n\r\n**Context mining**\r\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\r\n*[[http://videolectures.net/um05_loosli_ccdoc|Context changes detection by one-class svms]]\r\n*[[http://videolectures.net/ice08_lukowicz_crw|Context recognition in the wearIT@work project]]\r\n*[[http://videolectures.net/kdd09_zhu_mrciws|Mining Rich Session Context to Improve Web Search]]\r\n*[[http://videolectures.net/samt08_santini_cnod|Context as a non-ontological determinant of semantics]]\r\n\r\n**Stream mining**\r\n*[[http://videolectures.net/ecml07_gama_sad|State of the Art in Data Stream Mining]]\r\n*[[http://videolectures.net/ecml07_mohamed_sad|State of the Art in Data Stream Mining]]\r\n*[[http://videolectures.net/ecml07_mohamed_acac|An architecture for context-aware adaptive data stream mining]]\r\n*[[http://videolectures.net/ecml07_mohamed_mqgr|A Model for Quality Guaranteed Resource-Aware Stream Mining]]\r\n\r\n**Anomaly detection**\r\n*[[http://videolectures.net/ecmlpkdd08_lazarevic_dmfa|Data Mining for Anomaly Detection]]\r\n*[[http://videolectures.net/mmdss07_tishby_itam|Information Theo-retic and Alge-braic Methods for Network Anomaly Detection]]\r\n*[[http://videolectures.net/kdd09_jermaine_alrtffsad|A LRT Framework for Fast Spacial Anomaly Detection]]\r\n\r\n**Social network analysis**\r\n*[[http://videolectures.net/semseach09_graves_srrdsn|Searching and ranking in RDF documents and social networks]]\r\n*[[http://videolectures.net/icwsm09_agarwal_siaifs|A Social Identity Approach to Identify Familiar Strangers in a Social Network]]\r\n*[[http://videolectures.net/kdd09_jermaine_alrtffsad|A LRT Framework for Fast Spacial Anomaly Detection]]\r\n*[[http://videolectures.net/iswc07_aasman_usn|Using Social Network Analysis, Geotemporal Reasoning and RDFS++ Reasoning for Business Intelligence]]\r\n\r\n**Social software and Web 2.0**\r\n*[[http://videolectures.net/active09_mulvany_cwsc|A Cabinet of Web 2.0 Scientific Curiositics]]\r\n*[[http://videolectures.net/eswc08_gomes_cs|Collective Semantics: Collective Intelligence & the Semantic Web - Flickring Our World]]\r\n*[[http://videolectures.net/eccs07_huberman_bwe|Beyond Web 2.0]]\r\n*[[http://videolectures.net/icwsm09_sun_gmctfnf|Gesundheit! Modeling Contagion Through Facebook News Feed]]\r\n*[[http://videolectures.net/eswc08_halpin_sw|Panel II: Social Network Portability: Is the Semantic Web Ready?]]\r\n*[[http://videolectures.net/cikm08_perisic_usnfsw|Using Social Networks for Social Work]]\r\n*[[http://videolectures.net/www09_baezayates_mtwbs|Mining the Web 2.0 for Better Search]]\r\n*[[http://videolectures.net/samt08_baumann_wai|WhoAmI - A Web2.0 Platform for Faceted Identity Management through Aggregation of Social Media]]\r\n\r\n**Adaptive and context-aware systems**\r\n*[[http://videolectures.net/samt08_rodriguez_doncel_smac|A Semantic Model for the Authorisation of Context-Aware Content Adaptation]]\r\n\r\n**Semantic technologies and content**\r\n**Social software and Web 2.0**\r\n**Knowledge filters**\r\n**Meta learning**\r\n**Forecasting**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/eccs07_huberman_bwe|Beyond Web 2.0]]\r\n*[[http://videolectures.net/kdd07_fayyad_fmtw|From Mining the Web to Inventing the New Sciences Underlying the Internet ]]\r\n*[[http://videolectures.net/ecml07_baeza_yates_mwq|Mining Queries]]\r\n*[[http://videolectures.net/estc08_zaragoza_isst|Improving Search with Semantic Technologies: Current Research Directions]]\r\n*[[http://videolectures.net/active09_grobelnik_tmlws|Text Mining and Light Weight Semantics]]\r\n\r\n ----\r\n ----\r\n\r\n == 4. ACTIVE Innovative Solutions\r\n\r\nThis is one of the main courses in ACTIVE training programmes. It is aimed at presenting ACTIVE innovative solutions that will be developed in the frame of the project. Training starts with innovative business and organisational models that are consequence of newly introduced technologies. The main focus is on the explanation and demonstration of technologies developed in ACTIVE, their use in the industry contexts and on the discussion of their implications to the traditional business environment. Course addresses in detail the methods for identifying knowledge processes, hidden knowledge in organisations as well as new technology research streams. Furthermore it explains and demonstrates the methods for contextualisation that spans over three orthogonal dimensions: content, social network and time. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse4_InnovativeSolutions.pdf|ACTIVE innovative solutions - course]]\r\n\r\nCourse topics:\r\n\r\n**Tools and methods for collaborative and expressive knowledge articulation paradigms**\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n\r\n**Ontology learning**\r\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\r\n*[[http://videolectures.net/training06_grobelnik_tmol|Text Mining for Ontology Learning]]\r\n*[[http://videolectures.net/koml04_grobelnik_olkds|Ontology Learning - Knowledge Discovery and the Semantic Web]]\r\n\r\n**Hybrid Web 2.0 - ontology infrastructure**\r\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\r\n*[[http://videolectures.net/eswc08_hess_cs|Collective Semantics: Collective Intelligence & the Semantic Web - From Web 2.0 to Semantic Web - A Semi-Automated Approach]]\r\n\r\n**Semi-automated process refactoring**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n**Optimization of knowledge models and pro-active support**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n**Delivery of contextualized information**\r\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\r\n\r\n**Visualization of temporal enterprise model**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n**Privacy preserving analysis of enterprise data**\r\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\r\n*[[http://videolectures.net/google_roughan_ppdm|Privacy Preserving DataMining]]\r\n\r\n**Inconsistency diagnosis and automatic repair of inconsistencies**\r\n**Complex rule interfaces**\r\n**Knowledge process mining**\r\n**Autonomous, context aware services for knowledge processes**\r\n**Dynamic adaptations of context-aware knowledge processes**\r\n**Security-aware knowledge processes**\r\n**Simultaneous analysis of multiple modalities**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/iswc08_witbrock_fsc|Free Semantic Content: Using OpenCyc in Semantic Web Applications]]\r\n*[[http://videolectures.net/iswc08_dellaValle_rswa|Realizing a Semantic Web Application]]\r\n*[[http://videolectures.net/active09_warren_kmcfl|KM at the Customer Front-Line: The BT Case Study in ACTIVE]]\r\n\r\n ----\r\n ----\r\n\r\n == 5. Management and Problem Solving\r\n\r\nThis course is aimed at providing knowledge about the models, structures and mechanisms for management, coordination and problem solving. The coordination mechanisms are basic mechanisms in any networked organisation and as such the focal point of interest for any distributed, knowledge focused organisation. The course will analyse and study the approaches for distributed and collaborative decision-making including organizational aspects in the context of informal and knowledge processes. Support with ACTIVE models and solutions for decision making processes in inter-enterprise and collaborative environment is the main focus.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse5_Management and problem solving.pdf|Management and problem solving - course]]\r\n\r\nCourse topics:\r\n\r\n**Context sensitive management**\r\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\r\n\r\n**Pro-active knowledge process support**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n ----\r\n ----\r\n\r\n == 6. Practical Examples and ACTIVE Prototypes\r\n\r\nIn this course the development process of the ACTIVE prototypes for three specific applications will be demonstrated. The development process and the applications with their specific benefits which are created by the ACTIVE research results will be shown. The course will be supplemented with a hands-on workshop to allow participants to deal with concrete examples from their work context. The focus will be on identifying areas of applications where the functionalities developed in the ACTIVE project can be applied.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse6_PracticalExamples.pdf|Practical Examples and ACTIVE Prototypes - course]]\r\n\r\nCourse topics:\r\n\r\n**Case studies and best practices**\r\n*[[http://videolectures.net/active09_warren_kmcfl|KM at the Customer Front-Line: The BT Case Study in ACTIVE]]\r\n*[[http://videolectures.net/coinactivess2010_thurlow_bcs|ACTIVE\u000b BT Case Study]]\r\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\r\n\r\n**Demonstrators, demos, prototypes**\r\n*[[http://videolectures.net/eswc08_berges_smw|Semantic Web Technology for Agent Communication Protocols]]\r\n*[[http://videolectures.net/active09_dolinsek_iak|Introduction to the ACTIVE Knowledge Workspace SDK]]\r\n\r\n**Use scenarios**\r\n\r\n ----\r\n ----\r\n\r\n == 7. Economic Incentives for Web 2.0 and Semantic Applications\r\n\r\nThis course will in particular investigate aspects related to the economics and the incentives behind Web2.0 and semantic technologies. Issues of costs and benefits associated to developing, deploying or maintaining Web 2.0 and semantic systems at enterprise level will be presented. , and instruments to predict and use them for analytically describe knowledge creation processes are important pre-requisites for their large-scale. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse7_EconomicIncentives.pdf|Economic incentives for Web2.0 and semantic applications - course]]\r\n\r\nCourse topics:\r\n\r\n**Integration into management activities**\r\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\r\n\r\n**Cost-benefit methods**\r\n*[[http://videolectures.net//akom08_popov_cbi|Costs, benefits and incentives (of semantic techologies)]]\r\n\r\n**Economic measurements**\r\n**Comprehensive models and tooling for economic measurements**\r\n**Business practices in knowledge technologies and social software**\r\n**Recommendations for tool design**\r\n\r\n Related taks:\r\n*[[http://videolectures.net/active09_sundaresan_tre|Trust and Reputation in eCommerce]]\r\n*[[http://videolectures.net/akom08_popov_cbi/|Costs, benefits and incentives (of semantic techologies)]]\r\n*[[http://videolectures.net/webstart08_mcgough_buan/|Business Angel]]\r\n*[[http://videolectures.net/eswc08_shadbolt_gst|Garlik: Semantic Technology for the Consumer]]\r\n\r\n ----\r\n ----\r\n\r\n == 8. Social, Ethical, Legal And Organizational Issues Related To Novel Semantic Technologies And Context Aware Systems\r\n\r\nIn this unit social, ethical, legal, and organizational issues are discussed and current trends pointed out. New business models and their applicability are discussed, namely through the introduction of examples. Marketing and sustainability, intellectual property management, systems of incentives, etc. are other relevant issues.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse8_SocialIssues.pdf|Social, ethical, legal and organizational issues related to novel semantic technologies - course]]\r\n\r\nCourse topics:\r\n\r\n**Privacy models**\r\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\r\n*[[http://videolectures.net/ssms08_boehme_cpiimi|Concerns about Privacy & Innovation in ICT and Media Industries]]\r\n*[[http://videolectures.net/kdd09_li_otbpud|On the Tradeoff Between Privacy and Utility in Data Publishing ]]\r\n\r\n**Knowledge sharing and collaboration incentives**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/active09_zwegers_ficc/|On Future Internet, Cloud Computing and Semantics - You Name It]]\r\n*[[http://videolectures.net/iswc08_giannandrea_fowdw/|Freebase: An Open, Writable Database of the World\u2019s Information|]]\r\n*[[http://videolectures.net/iswc08_decker_mib/|Message in a Bottle or: How can the Semantic Web Community be more convincing?]]\r\n\r\n == 9. ACTIVE project - Introduction\r\n\r\nThe aim of this course is to present the aims, goals, structure and expected results of ACTIVE project. In addition this course provides information about the future plans, development and operations of the business development that will follow the ACTIVE project. In that respect the future directions in the research areas will be presented, their use potentials, development scenarios and business scenarios in the forms of business plans. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse9_Introduction.pdf|ACTIVE project - Introduction - course]]\r\n\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/active09_mladenic_warren_oai|Opening and Introduction of the 1st ACTIVE Summer School]]\r\n*[[http://videolectures.net/coinactivess2010_warren_ai|ACTIVE Introduction]]\r\n*[[http://videolectures.net/coinactivess2010_jermol_wel|Welcome to the Summer School on Advanced Technologies for Knowledge Intensive Networked Organizations 2010 - Aachen ]]\r\n\r\n == 10. Using ACTIVE solution\r\n\r\nThe aim of this training module is to train the potential users/adopters/developers on the ACTIVE solutions. The course is organised as a blended learning module that combines traditional two days event with the self-learning courses in LC. The main learning goals for this module are to teach about basics of ACTIVE solutions and infrastructure, provide technical specifications, development environment and cases. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse10_UsingACTIVESolution.pdf|Using ACTIVE solution - course]]\r\n\r\nCourse topics:\r\n\r\n**ACTIVE prototypes, ACTIVE Knowledge Workspace Desktop, ACTIVE SDK, ACTIVE Integrated Platform**\r\n*[[http://videolectures.net/active09_dolinsek_iak|Introduction to the ACTIVE Knowledge Workspace SDK]]\r\n*[[http://videolectures.net/coinactivess2010_dolinsek_akw|Active Knowledge Work Space demonstration]]", "recorded": "2011-02-23T15:18:56", "title": "ACTIVE - Training programme for industries"}, {"url": "active_academia_training", "desc": "back to [[http://videolectures.net/active|ACTIVE training project ]]\r\n\r\n===\r\nThe goal of training activities in ACTIVE is to achieve the transfer of knowledge and best practices within the project as well as (principally) outside the project. ACTIVE training program is aimed at training individuals and groups on the topics that are relevant to the ACTIVE project. Each training program covers a general topic and is generated from several training courses that are focused on specific topics. Furthermore, each training program combines different types and forms of learning: traditional, ICT supported or blended training event. For each training course we provide textual materials, references to the sources used for training module preparation, a list of the topic relevant ACTIVE deliverables, video tutorials and additional materials/suggested readings.\r\n\r\n== 1. Theoretical Foundations and Conceptual Models\r\n\r\nThis course starts with the theoretical foundations on the organisational and collaboration forms, business process modelling, management and collaboration mechanisms, knowledge management and current governance principles in organisations. In contrast it provides basic information about traditional and emerging technologies that influence traditional business organisation and management context. Then it gives motivation for the complete ACTIVE training programme by providing incentives, future trends and business potentials.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse1_TheoreticalFoundations.pdf|Theoretical foundations and conceptual models - course]]\r\n\r\nCourse topics:\r\n\r\n**Collaboration and collaborative knowledge creation**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n*[[http://videolectures.net/semseach09_albakour_mcpse|Managing Collaboration Projects using Semantic Email]]\r\n*[[http://videolectures.net/iswc08_tudarache_scodp|Supporting Collaborative Ontology Development in Protege]]\r\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\r\n*[[http://videolectures.net/ice08_kristensen_pcik|Productivity in Collaboration-intensive Knowledge Work: The Collaboration Management Imperative]]\r\n*[[http://videolectures.net/nano07_gadlin_rsc|Re-thinking scientific teams: competition, conflict and collaboration]]\r\n*[[http://videolectures.net/iswc06_auer_otssc|In-Use 1: OntoWiki - A Tool for Social, Semantic Collaboration]]\r\n\r\n**Knowledge processes and tasks**\r\n*[[http://videolectures.net/active09_tilly_ikp|Informal Knowledge Processes: The Long Tail of Business Processes]]\r\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\r\n\r\n**Process modelling**\r\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\r\n\r\n**Knowledge management**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\r\n*[[http://videolectures.net/training06_davies_ka|Knowledge Access]]\r\n*[[http://videolectures.net/iswc08_bhagdev_cauoswilno|Creating and Using Organisational Semantic Webs in Large Networked Organisations]]\r\n*[[http://videolectures.net/cikm08_feldman_ak|Automating Knowledge]]\r\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\r\n\r\n**Formalisms for (dynamic) aspects of knowledge worker context and enterprises**\r\n*[[http://videolectures.net/iswc06_grobelnik_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_witbrock_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_mozetic_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_haase_cop|Context Sensitivity in Knowledge Rich Systems - Contents of parts 2]]\r\n\r\n ----\r\n ----\r\n\r\n == 2. Knowledge Models and Structures\r\n\r\nThis course deals with the theoretical background on knowledge and semantic technologies and examines them from a technological, historical and scientific perspective. It starts with the basic facts about knowledge structures and models and their role in the knowledge formalisation, modelling, reasoning and adaptation. It provides comparison and contrasting of diverse knowledge models, structures and systems and understanding their participation in industry.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse2_KnowledgeModels.pdf|Knowledge models and structures - course]]\r\n\r\nCourse topics:\r\n\r\n**Semantic languages**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\r\n*[[http://videolectures.net/training06_sure_stsw/|A short Tutorial on Semantic Web]]\r\n*[[http://videolectures.net/eswc09_tappolet_atre|Applied Temporal RDF: Ef?cient Temporal Querying of RDF Data with SPARQL]]\r\n*[[http://videolectures.net/eswc09_vennekens_faaeod|FO(ID) as an Extension of DL with Rules]]\r\n*[[http://videolectures.net/iswc08_perez_nsparql|NSPARQL: A Navigational Language for RDF]]\r\n*[[http://videolectures.net/iswc08_hausenblas_bwdwd|RDFa - Bridging the Web of Documents and the Web of Data]]\r\n\r\n**Knowledge formalisation  and  representation**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n*[[http://videolectures.net/akom08_krotzsch_fik|Formal and Informal knowledge representation]]\r\n*[[http://videolectures.net/iswc08_saggion_krebi|Knowledge Representation and Extraction for Business Intelligence]]\r\n\r\n**Reasoning and  probabilistic temporal models**\r\n*[[http://videolectures.net/iswc08_moller_itsr|Reasoning for Ontology Engineering and Usage]]\r\n*[[http://videolectures.net/ssll09_pagnucco_krr|Knowledge Representation and Reasoning]]\r\n*[[http://videolectures.net/bsciw08_schwaighofer_krrd|Knowledge Representation and Reasoning - Discussion]]\r\n\r\n**Knowledge structures**\r\n**Collaborative articulation of expressive knowledge**\r\n**Knowledge leveraging and repair models**\r\n**Knowledge-based adaptation**\r\n**Knowledge creation cycle**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/iswc08_hauer_asnrwpdehep|An architecture for semantic navigation and reasoning with patient data - experiences of the Health-e-Child project]]\r\n*[[http://videolectures.net/eswc08_blanco_sr|Semantic Reasoning: A Path To New Possibilities of Personalization]]\r\n*[[http://videolectures.net/akom08_krotzsch_fik/|Formal and Informal knowledge representation]]\r\n*[[http://videolectures.net/active09_ghani_rdekm/|Research Directions in Enterprise Knowledge Management]]\r\n\r\n ----\r\n ----\r\n\r\n == 3. Background Technologies\r\n\r\nThis course presents and explains core technologies from the area of knowledge technologies that ranges from the data driven methods to knowledge driven methods and are important for detecting, analysing and managing knowledge (tacit and explicit) in organisations. Recent developments in the particular areas are demonstrated through real software prototypes, successful market cases and real business implementations. The course provides many demos that are available as demonstrations online and could be supplemented with the hands-on session.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse3_BackgroundTechnologies.pdf|Background technologies - course]]\r\n\r\nCourse topics:\r\n\r\n**Context mining**\r\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\r\n*[[http://videolectures.net/um05_loosli_ccdoc|Context changes detection by one-class svms]]\r\n*[[http://videolectures.net/ice08_lukowicz_crw|Context recognition in the wearIT@work project]]\r\n*[[http://videolectures.net/kdd09_zhu_mrciws|Mining Rich Session Context to Improve Web Search]]\r\n*[[http://videolectures.net/samt08_santini_cnod|Context as a non-ontological determinant of semantics]]\r\n\r\n**Stream mining**\r\n*[[http://videolectures.net/ecml07_gama_sad|State of the Art in Data Stream Mining]]\r\n*[[http://videolectures.net/ecml07_mohamed_sad|State of the Art in Data Stream Mining]]\r\n*[[http://videolectures.net/ecml07_mohamed_acac|An architecture for context-aware adaptive data stream mining]]\r\n*[[http://videolectures.net/ecml07_mohamed_mqgr|A Model for Quality Guaranteed Resource-Aware Stream Mining]]\r\n\r\n**Anomaly detection**\r\n*[[http://videolectures.net/ecmlpkdd08_lazarevic_dmfa|Data Mining for Anomaly Detection]]\r\n*[[http://videolectures.net/mmdss07_tishby_itam|Information Theo-retic and Alge-braic Methods for Network Anomaly Detection]]\r\n*[[http://videolectures.net/kdd09_jermaine_alrtffsad|A LRT Framework for Fast Spacial Anomaly Detection]]\r\n\r\n**Social network analysis**\r\n*[[http://videolectures.net/semseach09_graves_srrdsn|Searching and ranking in RDF documents and social networks]]\r\n*[[http://videolectures.net/icwsm09_agarwal_siaifs|A Social Identity Approach to Identify Familiar Strangers in a Social Network]]\r\n*[[http://videolectures.net/kdd09_jermaine_alrtffsad|A LRT Framework for Fast Spacial Anomaly Detection]]\r\n*[[http://videolectures.net/iswc07_aasman_usn|Using Social Network Analysis, Geotemporal Reasoning and RDFS++ Reasoning for Business Intelligence]]\r\n\r\n**Social software and Web 2.0**\r\n*[[http://videolectures.net/active09_mulvany_cwsc|A Cabinet of Web 2.0 Scientific Curiositics]]\r\n*[[http://videolectures.net/eswc08_gomes_cs|Collective Semantics: Collective Intelligence & the Semantic Web - Flickring Our World]]\r\n*[[http://videolectures.net/eccs07_huberman_bwe|Beyond Web 2.0]]\r\n*[[http://videolectures.net/icwsm09_sun_gmctfnf|Gesundheit! Modeling Contagion Through Facebook News Feed]]\r\n*[[http://videolectures.net/eswc08_halpin_sw|Panel II: Social Network Portability: Is the Semantic Web Ready?]]\r\n*[[http://videolectures.net/cikm08_perisic_usnfsw|Using Social Networks for Social Work]]\r\n*[[http://videolectures.net/www09_baezayates_mtwbs|Mining the Web 2.0 for Better Search]]\r\n*[[http://videolectures.net/samt08_baumann_wai|WhoAmI - A Web2.0 Platform for Faceted Identity Management through Aggregation of Social Media]]\r\n\r\n**Adaptive and context-aware systems**\r\n*[[http://videolectures.net/samt08_rodriguez_doncel_smac|A Semantic Model for the Authorisation of Context-Aware Content Adaptation]]\r\n\r\n**Semantic technologies and content**\r\n**Social software and Web 2.0**\r\n**Knowledge filters**\r\n**Meta learning**\r\n**Forecasting**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/eccs07_huberman_bwe|Beyond Web 2.0]]\r\n*[[http://videolectures.net/kdd07_fayyad_fmtw|From Mining the Web to Inventing the New Sciences Underlying the Internet ]]\r\n*[[http://videolectures.net/ecml07_baeza_yates_mwq|Mining Queries]]\r\n*[[http://videolectures.net/estc08_zaragoza_isst|Improving Search with Semantic Technologies: Current Research Directions]]\r\n*[[http://videolectures.net/active09_grobelnik_tmlws|Text Mining and Light Weight Semantics]]\r\n\r\n ----\r\n ----\r\n\r\n == 4. ACTIVE Innovative Solutions\r\n\r\nThis is one of the main courses in ACTIVE training programmes. It is aimed at presenting ACTIVE innovative solutions that will be developed in the frame of the project. Training starts with innovative business and organisational models that are consequence of newly introduced technologies. The main focus is on the explanation and demonstration of technologies developed in ACTIVE, their use in the industry contexts and on the discussion of their implications to the traditional business environment. Course addresses in detail the methods for identifying knowledge processes, hidden knowledge in organisations as well as new technology research streams. Furthermore it explains and demonstrates the methods for contextualisation that spans over three orthogonal dimensions: content, social network and time. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse4_InnovativeSolutions.pdf|ACTIVE innovative solutions - course]]\r\n\r\nCourse topics:\r\n\r\n**Tools and methods for collaborative and expressive knowledge articulation paradigms**\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n\r\n**Ontology learning**\r\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\r\n*[[http://videolectures.net/training06_grobelnik_tmol|Text Mining for Ontology Learning]]\r\n*[[http://videolectures.net/koml04_grobelnik_olkds|Ontology Learning - Knowledge Discovery and the Semantic Web]]\r\n\r\n**Hybrid Web 2.0 - ontology infrastructure**\r\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\r\n*[[http://videolectures.net/eswc08_hess_cs|Collective Semantics: Collective Intelligence & the Semantic Web - From Web 2.0 to Semantic Web - A Semi-Automated Approach]]\r\n\r\n**Semi-automated process refactoring**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n**Optimization of knowledge models and pro-active support**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n**Delivery of contextualized information**\r\n*[[http://videolectures.net/coinactivess2010_grobelnik_bpm|Business Process Mining and Formalization]]\r\n\r\n**Visualization of temporal enterprise model**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n**Privacy preserving analysis of enterprise data**\r\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\r\n*[[http://videolectures.net/google_roughan_ppdm|Privacy Preserving DataMining]]\r\n\r\n**Inconsistency diagnosis and automatic repair of inconsistencies**\r\n**Complex rule interfaces**\r\n**Knowledge process mining**\r\n**Autonomous, context aware services for knowledge processes**\r\n**Dynamic adaptations of context-aware knowledge processes**\r\n**Security-aware knowledge processes**\r\n**Simultaneous analysis of multiple modalities**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/iswc08_witbrock_fsc|Free Semantic Content: Using OpenCyc in Semantic Web Applications]]\r\n*[[http://videolectures.net/iswc08_dellaValle_rswa|Realizing a Semantic Web Application]]\r\n*[[http://videolectures.net/active09_warren_kmcfl|KM at the Customer Front-Line: The BT Case Study in ACTIVE]]\r\n\r\n ----\r\n ----\r\n\r\n == 5. Management and Problem Solving\r\n\r\nThis course is aimed at providing knowledge about the models, structures and mechanisms for management, coordination and problem solving. The coordination mechanisms are basic mechanisms in any networked organisation and as such the focal point of interest for any distributed, knowledge focused organisation. The course will analyse and study the approaches for distributed and collaborative decision-making including organizational aspects in the context of informal and knowledge processes. Support with ACTIVE models and solutions for decision making processes in inter-enterprise and collaborative environment is the main focus.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse5_Management and problem solving.pdf|Management and problem solving - course]]\r\n\r\nCourse topics:\r\n\r\n**Context sensitive management**\r\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\r\n\r\n**Pro-active knowledge process support**\r\n*[[http://videolectures.net/coinactivess2010_ruiz_moreno_leban_pak|Pro-Active Knowledge Processes Support]]\r\n\r\n ----\r\n ----\r\n\r\n == 6. Practical Examples and ACTIVE Prototypes\r\n\r\nIn this course the development process of the ACTIVE prototypes for three specific applications will be demonstrated. The development process and the applications with their specific benefits which are created by the ACTIVE research results will be shown. The course will be supplemented with a hands-on workshop to allow participants to deal with concrete examples from their work context. The focus will be on identifying areas of applications where the functionalities developed in the ACTIVE project can be applied.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse6_PracticalExamples.pdf|Practical Examples and ACTIVE Prototypes - course]]\r\n\r\nCourse topics:\r\n\r\n**Case studies and best practices**\r\n*[[http://videolectures.net/active09_warren_kmcfl|KM at the Customer Front-Line: The BT Case Study in ACTIVE]]\r\n*[[http://videolectures.net/coinactivess2010_thurlow_bcs|ACTIVE\u000b BT Case Study]]\r\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\r\n\r\n**Demonstrators, demos, prototypes**\r\n*[[http://videolectures.net/eswc08_berges_smw|Semantic Web Technology for Agent Communication Protocols]]\r\n*[[http://videolectures.net/active09_dolinsek_iak|Introduction to the ACTIVE Knowledge Workspace SDK]]\r\n\r\n**Use scenarios**\r\n\r\n ----\r\n ----\r\n\r\n == 7. Economic Incentives for Web 2.0 and Semantic Applications\r\n\r\nThis course will in particular investigate aspects related to the economics and the incentives behind Web2.0 and semantic technologies. Issues of costs and benefits associated to developing, deploying or maintaining Web 2.0 and semantic systems at enterprise level will be presented. , and instruments to predict and use them for analytically describe knowledge creation processes are important pre-requisites for their large-scale. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse7_EconomicIncentives.pdf|Economic incentives for Web2.0 and semantic applications - course]]\r\n\r\nCourse topics:\r\n\r\n**Integration into management activities**\r\n*[[http://videolectures.net/coinactivess2010_imtiaz_aam|ACTIVE, Ali and More]]\r\n\r\n**Cost-benefit methods**\r\n*[[http://videolectures.net//akom08_popov_cbi|Costs, benefits and incentives (of semantic techologies)]]\r\n\r\n**Economic measurements**\r\n**Comprehensive models and tooling for economic measurements**\r\n**Business practices in knowledge technologies and social software**\r\n**Recommendations for tool design**\r\n\r\n Related taks:\r\n*[[http://videolectures.net/active09_sundaresan_tre|Trust and Reputation in eCommerce]]\r\n*[[http://videolectures.net/akom08_popov_cbi/|Costs, benefits and incentives (of semantic techologies)]]\r\n*[[http://videolectures.net/webstart08_mcgough_buan/|Business Angel]]\r\n*[[http://videolectures.net/eswc08_shadbolt_gst|Garlik: Semantic Technology for the Consumer]]\r\n\r\n ----\r\n ----\r\n\r\n == 8. Social, Ethical, Legal And Organizational Issues Related To Novel Semantic Technologies And Context Aware Systems\r\n\r\nIn this unit social, ethical, legal, and organizational issues are discussed and current trends pointed out. New business models and their applicability are discussed, namely through the introduction of examples. Marketing and sustainability, intellectual property management, systems of incentives, etc. are other relevant issues.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse8_SocialIssues.pdf|Social, ethical, legal and organizational issues related to novel semantic technologies - course]]\r\n\r\nCourse topics:\r\n\r\n**Privacy models**\r\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\r\n*[[http://videolectures.net/ssms08_boehme_cpiimi|Concerns about Privacy & Innovation in ICT and Media Industries]]\r\n*[[http://videolectures.net/kdd09_li_otbpud|On the Tradeoff Between Privacy and Utility in Data Publishing ]]\r\n\r\n**Knowledge sharing and collaboration incentives**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/active09_zwegers_ficc/|On Future Internet, Cloud Computing and Semantics - You Name It]]\r\n*[[http://videolectures.net/iswc08_giannandrea_fowdw/|Freebase: An Open, Writable Database of the World\u2019s Information|]]\r\n*[[http://videolectures.net/iswc08_decker_mib/|Message in a Bottle or: How can the Semantic Web Community be more convincing?]]\r\n\r\n == 9. ACTIVE project - Introduction\r\n\r\nThe aim of this course is to present the aims, goals, structure and expected results of ACTIVE project. In addition this course provides information about the future plans, development and operations of the business development that will follow the ACTIVE project. In that respect the future directions in the research areas will be presented, their use potentials, development scenarios and business scenarios in the forms of business plans. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse9_Introduction.pdf|ACTIVE project - Introduction - course]]\r\n\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/active09_mladenic_warren_oai|Opening and Introduction of the 1st ACTIVE Summer School]]\r\n*[[http://videolectures.net/coinactivess2010_warren_ai|ACTIVE Introduction]]\r\n*[[http://videolectures.net/coinactivess2010_jermol_wel|Welcome to the Summer School on Advanced Technologies for Knowledge Intensive Networked Organizations 2010 - Aachen ]]\r\n\r\n == 10. Using ACTIVE solution\r\n\r\nThe aim of this training module is to train the potential users/adopters/developers on the ACTIVE solutions. The course is organised as a blended learning module that combines traditional two days event with the self-learning courses in LC. The main learning goals for this module are to teach about basics of ACTIVE solutions and infrastructure, provide technical specifications, development environment and cases. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse10_UsingACTIVESolution.pdf|Using ACTIVE solution - course]]\r\n\r\nCourse topics:\r\n\r\n**ACTIVE prototypes, ACTIVE Knowledge Workspace Desktop, ACTIVE SDK, ACTIVE Integrated Platform**\r\n*[[http://videolectures.net/active09_dolinsek_iak|Introduction to the ACTIVE Knowledge Workspace SDK]]\r\n*[[http://videolectures.net/coinactivess2010_dolinsek_akw|Active Knowledge Work Space demonstration]]", "recorded": "2011-02-23T15:14:37", "title": "\u2022\tACTIVE - Training programme for academia"}, {"url": "first", "desc": "**[[http://project-first.eu/|FIRST project]]** addresses the extreme challenges of dealing in real-time with vast and constantly growing amounts of heterogeneous data and information in financial markets. The financial industry represents a role model for critical, information-bound domains. Especially the end-users of information as for instance financial analysts, investment managers, market regulators, financial advisors, and individual investors rely on their ability to quickly identify and interpret relevant information. By using this information these user groups try to identify dynamically evolving and potentially risk bearing situations (e.g. shocks and crashes). Relevant and correct information assists these users in staying ahead of the market to place their ideal investment decision, detect market manipulation, or simply to give advice to a client. The problem hereby evolves through the vast amounts of information opportunities which make it nearly impossible for a user to concentrate on the essential information.\r\n\r\nTherefore, FIRST develops and provides an Information and Communication Technology (ICT) infrastructure that will:\r\n\r\n# Collect and process massive amounts of heterogeneous, structured and unstructured data as for instance textual data, largely scattered web information from blogs, bulletin boards etc., or historical data from economic databases\r\n# Integrate this data into a financial knowledge base for further analysis\r\n# Exploit this data by developing and employing a range of highly scalable online event detection and prediction models, visualization models, and decision-support models that will deliver pertinent information to the decision maker.\r\n\r\nFIRST helps by opening up new before-the-fact information for earlier/better treatment of evolving conditions in advanced financial decision making.\r\n\r\n**Objectives**\r\n\r\nThe FIRST project aims to provide a large-scale information extraction and integration infrastructure supporting non-ICT skilled end users for on-demand financial information access and execution of financial market analyses. Innovations in FIRST are:\r\n\r\n# information extraction from unreliable semi-structured sources on a massive scale and in near real-time,\r\n# automatic reuse of existing ontologies, large-scale ontology learning, and\r\n# advanced decision models making use of high-level semantic features.\r\n\r\n**Methods and advancements**\r\n\r\nFIRST implements a systematic strategy for scaling its methods and software infrastructure to the processing of massive amounts of information in real-time by three steps during the timeline of the project:\r\n\r\n# Functional prototype\r\n# Scaling for non time-critical processing of massive historical data, and\r\n# Scaling for massive live streams of structured feeds, textual news wire feeds, as well as semi-structured Web information in real-time", "recorded": "2012-04-11T12:34:23", "title": "FIRST - large scale inFormation extraction and Intergration infRastructure for SupporTing financial decision making"}, {"url": "coin_industry_training", "desc": "back to [[http://videolectures.net/coin|COIN training project ]]\n\n===These videolectures describe the technologies being used and developed in COIN, and some of the applications of those technologies in the project.  The lectures are given by COIN researchers and by other researchers working in the same and related fields.\n\n == 1. Motivation for the paradigm - Industry training\n\n**Description:** This first unit aims at creating a motivation for the course through a brief presentation of application areas, illustrated by concrete examples in industry, services, government, etc. A brief historic overview of the industrial organizational paradigms leading to collaborative networks and their interoperability as well as a summary of current technological and organizational trends is presented. For each example an attempt to identify the main involved problems (e.g. organizational forms, processes, and cooperation and collaboration forms) is made, calling the attention for the potential contributes from other disciplines.\n\n**Key concepts:** Collaboration and Interoperability, Practical examples of CNs, Practices of Interoperability, Historic overview, Technological and organizational trends, Discussion of the usefulness/benefits and current limitations\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_1_Motivation_for_the_paradigm_SMEs.pdf|Motivation for the paradigm - course]]\n\n**Suggested video lectures:**: [[http://videolectures.net/ice09_martinez_ewbom|Everything will be on machines by Cristina Martinez ]], [[http://videolectures.net/ice08_martinez_future|The Future Internet: a vision from European Research by Cristina Martinez ]], [[http://videolectures.net/ice2011_schuh_production/|Developing a production engineering based theory of production by G\u00fcnther Schuh]], [[http://videolectures.net/ice08_prinz_web|Web 2.0 and Collaborative Working Environments: What can we learn? by Wolfgang Prinz]], [[http://videolectures.net/esocenet07_gusmeroli_csf|Current Solutions and Future Trends by Sergio Gusmeroli]]\n\n----\n----\n\n == 2. Basic concepts - Industry training\n\n**Description:** After the motivation phase, the base concepts are introduced. Considering the large variety of collaborative networks and interoperability modes, a categorization of the various forms is made and taxonomy is introduced in order to give students a global perspective of the area. At the same time the basic project concepts and  models are being addressed. The various innovative concepts and models developed in COIN.\n\n**Key concepts:** COIN Basic Concepts, Fundamentals in CN, Fundamentals in Interoperability, COIN innovative concepts and models\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_2_Basic_Concepts_SMEs.pdf|Basic concepts - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ice08_gusmeroli_meta|The COIN Metaphor for EU Industry by Sergio Gusmeroli]], [[http://videolectures.net/iesa08_rossiter_lfi|Logical Foundations for the Infrastructure of the Information Market by Nick Rossiter ]], [[http://videolectures.net/coinactivess2010_gusmeroli_cica|Collaboration and Interoperability \u2013 COIN Approach\nby Sergio Gusmeroli]], [[http://videolectures.net/coinactivess2010_sesana_cis|COIN Innovative Services\nby Michele Sesana]], [[http://videolectures.net/cgm09_gusmeroli_tccps|TCC plenary session\nby Sergio Gusmerol]]\n\n----\n----\n\n == 3. Enterprise Interoperability - Industry training\n\n**Description:** After the motivation phase and the COIN basic concepts are introduced, the base concepts of Enterprise Interoperability are explained. After describing the overall goals and essential terms for the Interoperability of enterprises, principles, methods and benefits of enterprise Interoperability are explained. Here we show key issue, definitions and approaches in manufacturing and industrial\nenterprise generally and how Interoperability is the ability of a system or a product to work with other systems based on various architectures and platforms or products without special effort from the user.\n\n**Key concepts:** Basic Concepts, Definitions and Approaches, Enterprise Modelling for Interoperability, Ontology for Interoperability, Introduction to Architecture and Platforms for Enterprise system Interoperability, Business Interoperability (BI)\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_3_Enterprise_Interoperability_SMEs.pdf|Enterprise Interoperability - course]]\n\n **Suggested video lectures:** [[http://videolectures.net/ice08_katranuschkov_aigevo|Achieving Interoperability in Grid-Enabled Virtual Organisation by Peter Katranuschkov]], [[http://videolectures.net/ice09_olmo_aabc|Business Cases for Enterprise Interoperability - The Andalusian Aeronautics Business Case\nAlberto Olmo]], [[http://videolectures.net/ice09_debate_qa|Debate on Business Cases for Enterprise Interoperability  by Sergio Gusmerol]], [[http://videolectures.net/iswc06_wache_irpto|Workshop: Improving the recruitment process through ontology-based querying by Holger Wache]], [[http://videolectures.net/cgm09_taglino_eis|Enterprise Interoperability Services by Francesco Taglino]]\n\n ----\n ----\n\n == 4. VO Breeding Environment - Industry training\n\n**Description:** Course on the main elements of the VBE that are studied in COIN featuring theoretical and practical business examples from the field. The basic elements of Virtual Organizations Breeding Environment and its role in the context of CNO. Contents: Virtual Organization And Current Enterprises, Collaborative networked organization and business opportunities, Business ecosystems, VBE - Virtual Organization Breeding Environments, VBE - constituting elements and features, VBE - working and sharing principles, Value system and metrics for VBE.\n\n**Key concepts:** Concept and examples, Components, structure, actors and roles, Competencies and assets, Processes and governance principles, VBE management system, Trust and value systems.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_4_Vo_Breeding_Environment_SMEs.pdf|VO Breeding Environment - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess07_ferlez_mc| Modelling competences by\nJure Ferle\u017e]], [[http://videolectures.net/akom08_grobelnik_ina|Introduction to Network Analysis\nby Marko Grobelnik, Dunja Mladeni\u0107]], [[http://videolectures.net/brussels06_afsarmanesh_v|Virtual organisations breeding environment by Hamideh Afsarmanesh]], [[http://videolectures.net/ess07_jermol_evg|Exploring Collaborative Networked Organisations in ECOLEAD by Mitja Jermol]], [[http://videolectures.net/antwerpen04_blomqvist_ottbn/|An overview of trust and trust building in networks\n by Kirsimarja Blomqvist]]\n\n ----\n ----\n\n == 5. Virtual Organizations - Industry training\n\n**Description:** Course on the concept and structure of Virtual Organizations creation rules and functionalities. Here we present the continuous life cycle of the Virtual Organization creation with its creation, formation, later approaching its breeding environment functionalities and ultimately its dissolution and incorporation into its next life cycle phase.\n\n**Key concepts:** Concepts, organizational models and operational rules, Life cycle,  VO creation process and functionalities, VO management functionalities and performance measurement, VO dissolution and inheritance.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_5_Virtual_Organizations_SMEs.pdf| Virtual Organizations - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess07_ollus_vom|Virtual organizations management by Martin Ollus]], [[http://videolectures.net/ess06_ollus_vrvp|VOM in relation to VBE & PVC by Martin Ollus]], [[http://videolectures.net/ess06_seifert_pmv|Performance Management in VOs by Marcus Seifert]], [[http://videolectures.net/ess07_slavik_vrv|Virtual reality for VE\nby Pavel Slav\u00edk]], [[http://videolectures.net/ekom08_ollus_mcn|Management of collaboration in networks\nby Martin Ollus]]\n\n ----\n ----\n\n== 6. Virtual Communities - Industry training\n\n**Description:**In this course is shown the basic knowledge on Virtual Communities, the concept of Professional Virtual Communities that is being explored in COIN. A typology of VC is introduced and a particular attention is devoted to Professional Virtual Communities. The components, structure, and life cycle of PVCs are discussed and modeling options introduced in comparison with the VBE. Architectural options for a PVC management system and supporting functionalities are introduced. The creation of Virtual Teams within a PVC and their management are studied. Governance principles, main processes, intellectual property issues, and social computing issues are discussed.\n\n**Key concepts:** Concepts and typology, Components, structure, and life cycle, Professional virtual communities (PVC), PVC management system, Virtual teams, Governance principles and social computing.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_academia/Course_6_Virtual_Communities_Academia.pdf|Virtual Communities - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess06_seifert_pmv|Performance Management in VOs\nby Marcus Seifert]], [[http://videolectures.net/esocenet07_santoro_ci|Concurrent Innovation \u2013 Vision 2020\nby Roberto Santoro]], [[http://videolectures.net/brussels06_gusmeroli_i|ICT-I by Sergio Gusmeroli]], [[http://videolectures.net/mitworld_baltimore_bac|Building a Community on Trust by David Baltimore]], [[http://videolectures.net/ess07_vorobey_ape|AIESEC PVC ECOLEAD case study by Volodja Vorobey]]\n\n**Additional video lectures:** [[http://videolectures.net/ess06_crave_pbct| PVC basic concepts & typologies]], [[http://videolectures.net/ess07_crave_pca|PVC and cooperation from AI perspective]], [[http://videolectures.net/ess06_picard_sppvc|Social protocols in Professional Virtual Communities]], [[http://videolectures.net/eccs07_chavalarias_sma|Science mapping with asymmetric co-occurence analysis]]\n\n ----\n ----\n\n == 7. Architectures and Platforms - Industry training\n\n**Description:**Focusing on research coordination in the area of Architecture & Platforms. Show basic internet and computer technologies, ideas, and concepts for enterprise interoperability purposes and to continue on updating with state-of-the-art models, approaches and mechanisms.\n\n**Key concepts:** Computer networks basics. Base Internet technologies, Components of a communication infrastructure, Introduction to Service Platforms, Service Oriented Architectures, Introduction to Distributed systems, Introduction to Platform virtualisation, Security mechanisms and technologies, Emerging computing models and implementation approaches\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_7_Architectures_and_Platforms_SMEs.pdf|Architectures and Platforms - course]]\n\n**Suggested video lectures:**  [[http://videolectures.net/iesa08_gionis_aha|The Advantages of Hybrid Architectural Approaches for the Integrating Middleware by George Gionis]], [[http://videolectures.net/iesa08_ullberg_eas|Enterprise Architecture: A Service Interoperability Analysis Framework by Johan Ullberg]], [[http://videolectures.net/ess07_negretto_ii|ICT infrastructure by\nUgo Negretto]], [[http://videolectures.net/ess07_hodik_atv|Agent technologies for VE + SW demonstrations: MAS Tutorial by Ji\u0159\u00ed Hod\u00edk]], [[http://videolectures.net/ess06_nagellen_soa|Service Oriented Architectures by Thierry Nagellen]]\n\n ----\n ----\n\n == 8. Background Technologies - Industry training\n\n**Description:** This course presents and explains core technologies from the area of knowledge technologies that ranges from the data driven methods to knowledge driven methods and are important for detecting, analyzing and managing knowledge (tacit and explicit) in enterprises, organisations or agents. Recent developments in the particular areas are demonstrated through real software prototypes, successful market cases and real business implementations. The course provides many demos and business cases that will be available as demonstrations online and could be supplemented with the hands-on session.\n\n**Key concepts:** Traditional technologies, Semantic and knowledge technologies\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_8_Background_Technologies_SMEs.pdf| Background Technologies - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/kdd07_fayyad_dms|A Data Miner\u2019s Story \u2013 Getting to Know the Grand Challenges by Usama Fayyad ]], [[http://videolectures.net/ssll09_kotagiri_dami|Data Mining by Rao Kotagiri]], [[http://videolectures.net/stanfordcs229f08_ng_lec01| Lecture 1 - The Motivation & Applications of Machine Learning by Andrew Ng]], [[http://videolectures.net/iswc08_hendler_ittsw|Introduction to the Semantic Web by Aldo Gangemi, Sean Bechhofer, Asunci\u00f3n G\u00f3mez-P\u00e9rez, Jim Hendler]], [[http://videolectures.net/ess07_jermol_ktno|Knowledge technologies for network organisations by Mitja Jermol]]\n\n**Additional video lectures:**[[http://videolectures.net/psm08_cristianini_ieb/|In the Eye of the Beholder? Another look at Cognitive Systems]], [[http://videolectures.net/ijcai09_lesser_saitmao/|Scaling AI Through Multi-Agent Organizations]], [[http://videolectures.net/ccss09_pietronero_soafse/|Self-Organization and Finite Size Effects in Agent Models for Financial Markets]], [[http://videolectures.net/ccss09_steubing_atcf/|Assessing the Critical Factors that Determine the Availability of Wood Fuel in Switzerland with an Agent Based Model]]\n----\n----\n\n == 9. COIN Solution - Industry training\n\n**Description:** This is one of the main courses in COIN training programmes. It is aimed at presenting COIN innovative  solutions that will be developed in the frame of the project. Training starts with innovative business and organisational models that are consequence of newly introduced technologies. The main focus is on the explanation and demonstration of technologies developed in COIN, their use in the industry contexts and on the discussion of their implications to the traditional business environment. Course addresses in detail the methods for identifying knowledge processes, knowledge (tacit and explicit) in organisations as well as new technology research streams. Furthermore it explains and demonstrates the methods for contextualisation that spans over three orthogonal dimensions: content, social network and time.\n\n**Key concepts:** Basic architecture, Introduction to COIN Service platform, Transition from a Service Platform to an Utility Platform, Business-adaptive Service Platform, Pervasive, Evolutionary and Scalable Service Platform, TSD-enabled service Platform for Networked Enterprises, Agent-based Business Knowledge Interoperability, Introduction to COIN Enterprise Interoperability services, Interoperability baseline, Information Interoperability Services, Knowledge Interoperability Services, Business Interoperability Services, Introduction to COIN Enterprise Collaboration services, Collaboration baseline, Collaborative Product Development c-PD, Collaborative Production Planning c-PP, Collaborative Project Management c-PM, Collaborative Human Interaction c-HI.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_9_COIN_solution_Introduction_SMEs.pdf| COIN solution - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/coinactivess2010_jansson_ccs|COIN Collaborative Services by Kim Jansson ]], [[http://videolectures.net/coinactivess2010_sitek_ure|User requirements elicitation adapting Serious Gaming approach by Patrick Sitek]], [[http://videolectures.net/coinactivess2010_sesana_cpd|COIN Platform Demonstration by Michele Sesana]], [[http://videolectures.net/coinactivess2010_fischer_cbs|COIN Baseline services and negotiation support by Klaus Fischer]], [[http://videolectures.net/coinplanetdataschool2011_sesana_coin/|Technical and Business Innovation\nby Michele Sesana]]\n\n ----\n ----\n\n== 10. Practical Examples and COIN prototypes - Industry training\n\n**Description:** In this course the practical examples of COIN prototypes will be demonstrated and explained together with some applications that are related to the COIN research domain. The course will be supplemented with a hands-on workshop to allow participants to deal with concrete examples from their work context.\n\n**Key concepts:** use scenarios, case studies and best practices, demonstrators, demos, prototypes\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_10_Practical_Examples_and_COIN_prototipes_SMEs.pdf| Practical Examples and COIN prototypes - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ice09_olmo_coincpds|COIN Collaborative Product Development Services by Alberto Olmo]], [[http://videolectures.net/coinplanetdataschool2011_sesana_demos/|COIN System Demos by Michele Sesana]], [[http://videolectures.net/ice09_canepa_isurf|iSURF \u2013 Piacenza Knitwear Business Case by Alessandro Canepa]], [[http://videolectures.net/cgm09_komazec_cspwho|COIN Service Platform with hands-on by Srdjan Komazec]], [[http://videolectures.net/coinplanetdataschool2011_oman_usage|Usage of Integrated Services in the industry by\nSimon Oman]]\n\n ----\n ----\n\n == 11. Information Management - Industry training\n\n**Description:** Course on competency/profile information management basics and preliminary prototypes. Contents: Introduction, Specification of main components and functions of PCMS, e-Catalogue features and key components.\n\n**Key concepts:** Information management requirements, Mechanisms for information sharing and exchange, Access rights definition and enforcement, Federated /distributed information management.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_10_Practical_Examples_and_COIN_prototipes_SMEs.pdf| Information Management - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ict08_mladenic_rtip/|Real-Time Information Processing Marko Grobelnik, Dunja Mladeni\u0107 ]], [[http://videolectures.net/wsdm08_garcia_molina_wim| Web Information Management: Past, Present and Future by Hector Garcia-Molina ]], [[http://videolectures.net/kdd09_cherkasova_assaeim|Applying Syntactic Similarity Algorithms for Enterprise Information Management\nby Ludmila Cherkasova]], [[http://videolectures.net/samt08_gauthier_iim|Intelligent Information Management\nby Albert Gauthier]], [[http://videolectures.net/estc09_miller_lde|Linked Data in the Enterprise: Is It just another Hype or Does It Have Real Added Value for Information Management]]\n\n**Additional material:**\n* [[http://www.thelondonconsulting.com/products/information-server|TLCG Information Server]]\n* [[http://www.managing-information.org.uk/summary.htm|Information Management Paper]]\n* [[http://www.imbok.org|Information Management Body of Knowledge]]\n* [[http://www.ipl.com/services/businessconsulting/resources/#businessconsulting-papers|Information Management papers from IPL]]\n\n ----\n ----\n\n == 12. Information Exchange Standards - Industry training\n\n**Description:** A number of standards particularly relevant for collaborative networks and enterprise interoperability are introduced and analyzed. Among them: EDI (Electronic Data Interchange), which in historical terms represents one of the first tools for cooperation among enterprises, is introduced and briefly characterized. The interaction between EDI and ERP. The EDIFACT standard is presented and current XML-based implementations mentioned. Support technologies as well as PDM systems are discussed. Other emerging standards for information and knowledge exchange are pointed out.\n\n**Key concepts:** Importance of standards, Interaction with legacy systems.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_12_Information_Exchange_Standards_SMEs.pdf| Information Exchange Standards - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/efreight2011_rantasila_pilli_sihvola_logistics|Logistics-related information exchange - international exchange - international efforts and Finnish developments by Karri Rantasila, Eetu Pilli-Sihvola]], [[http://videolectures.net/kdd2010_zheng_udmt|Using Data Mining Techniques to Address Critical Information Exchange Needs in Disaster Affected Public-Private Networks by Li Zheng]], [[http://videolectures.net/ict08fr_nagy_rothengass_eiu|The Expanding Information Universe: New Trends, New Forms, New Usages\nby Marta Nagy-Rothengass]], [[http://videolectures.net/ecml07_smyth_api|Adventures in Personalized Information Access by Barry Smyth]], [[http://videolectures.net/forum2010_glenn_gcisd|Global Challenges and Information Society Development by Jerome C. Glenn]]\n\n ----\n ----\n\n == 13. Coordination Mechanisms - Industry training\n\n**Description:** This course is aimed at providing knowledge about the models, structures and mechanisms for management, coordination and problem solving. The coordination mechanisms are basic mechanisms in any networked organisation and as such the focal point of interest for any distributed, knowledge focused organisation. The course will analyze and study the approaches for distributed and collaborative decision-making including organizational aspects in the context of informal and knowledge processes.\n\n**Key concepts:** Collaboration modalities, Concept of coordination, Distributed-business process modeling and planning, Distributed scheduling and re-scheduling, Challenges in flexible coordination.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_13_Coordination_Mechanisms_SMEs.pdf| Coordination Mechanisms - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/eccs07_stark_cpc|Combined Problems of Cooperation and Coordination by Hans-Ulrich Stark]], [[http://videolectures.net/eccs07_menczer_wcn|Web Click Network\nby Filippo Menczer]], [[http://videolectures.net/eccs07_matteo_gld|Global and Local Dynamics in Correlated Systems by Tiziana Di Matteo]], [[http://videolectures.net/iesa08_wings_csit|Challenges and Strategies for IT Services in Heterogeneous Enterprise Environments by Sujit Wings]]\n\n ----\n ----\n\n == 14. Management of common Ontologies - Industry training\n\n**Description:** This course is aimed at providing the base concepts of ontologies, especially in relation to the COIN common ontology, explore the potential of ontology-based techniques to tackle the problem of interoperability and to investigate how such techniques can be joined together with the other fundamental perspectives addressed in COIN.\n\n**Key concepts:** The role of ontologies in collaboration, Ontology based support to Enterprise, Interoperability, Introduction to Ontologies,  Glossary and specification of base entities and concepts, COIN Core level common ontology, Ontology engineering approaches\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_14_Management_of_common_Ontologies_SMEs.pdf| Management of common Ontologies - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess07_grobelnik_twdmI|Text and web data mining by Marko Grobelnik]], [[http://videolectures.net/iesa08_dahlem_osm|Ontology-driven Semantic Mapping by Nikolai Dahlem]], [[http://videolectures.net/mmdss07_grobelnik_oml|Ontologies and Machine Learning by Marko Grobelnik, Bla\u017e Fortuna]], [[http://videolectures.net/ess07_obitko_oswve|Ontologies, semantic web and VE by Marek Obitko]], [[http://videolectures.net/tao08_bontcheva_tao|Transitioning Applications to Ontologies by Kalina Bontcheva]]\n\n ----\n ----\n\n == 15. e-Commerce and e-Markets - Industry training\n\n**Description:** This course will in particular investigate aspects related to the economics and the incentives behind Interoperability. Issues of costs and benefits associated to developing, deploying or maintaining architecture, platforms and systems at enterprise level will be presented and instruments to predict and use them for analytically describe knowledge creation processes which are important pre-requisites for their large-scale.\n\n**Key concepts:** Concepts of e-Commerce and e-Market, Relationships to CN and Interoperability, Support institutions, Support systems. Portals. Negotiation, CRM. Logistics.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_15_E-Commerce_and_E-Markets_SMEs.pdf|E-commerce and E-markets - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/echallenges2010_li_intro|Business Models Background\nMan-Sze Li ]], [[http://videolectures.net/ice09_canepa_isurf|iSURF \u2013 Piacenza Knitwear Business Case\nby Alessandro Canepa]], [[http://videolectures.net/ice09_withalm_cdcp|Business Cases for Enterprise Interoperability Collaborative Demand Capacity Planning (CDCP) by Josef Withalm]], [[http://videolectures.net/coinplanetdataschool2011_hristov_media| Innovative collaboration in Media \u2013 \u000ba COIN case in EEU by Konstantin Hristov]], [[http://videolectures.net/echallenges2010_suttner_tnb|Towards New Business Models in the Energy Sector based on Software-as-a-Service-Utilities and Value-added Services\nby Hannes Suttner]]\n\n ----\n ----\n\n == 16. Non Technological Issues - Industry training\n\n**Description:** In this unit social, ethical, legal, and organizational issues are discussed and current trends pointed out. New business models and their applicability are discussed, namely through the introduction of examples. Marketing and sustainability, intellectual property management, systems of incentives, etc. are other relevant issues.\n\n**Key concepts:** Social, ethical, legal, and organizational issues, Contractual issues, New business models, Sustainability mechanisms, Intellectual property management.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_16_Non-Technological_Issues_SMES.pdf|Non Technological Issues - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/antwerpen04_heath_tbmso|Trust building models and self-organizing systems / complexity theory by Margeret Heath]], [[http://videolectures.net/coinplanetdataschool2011_hsuan_web|The Cognitive Dissonance of Living in a world of \"Big Data\" by Abraham B. Hsuan ]], [[http://videolectures.net/eccs07_antonelli_fei|The Foundations of the Economics of Innovation\nby Cristiano Antonelli]], [[http://videolectures.net/rtd09_stres_coipp|Contribution on Intellectual Property Promotion and Technology Innovation Management in South East Europe by \u0160pela Stres]], [[http://videolectures.net/ess06_picard_sppvc|Social protocols in Professional Virtual Communities by Willy Picard]]\n\n == 17. Organisation Modeling and Reference Models - Industry training\n\n**Description:** The course topic is focusing on Organisation Modelling as a combination of a set of activities within an enterprise with a structure describing their logical order and dependence whose objective is to produce a desired result. Business Process modeling as an enabler of common understanding and analysis of a business process. The course will also describe the main process modeling techniques.\n\n**Key concepts:** Concept of reference model, Organisation Modelling, Business Process Modelling, Business Models Overview\n\n**Download the course:**\n\n **Suggested video lectures:** [[http://videolectures.net/eccs07_stark_cpc|Combined Problems of Cooperation and Coordination by Hans-Ulrich Stark ]], [[http://videolectures.net/eccs07_menczer_wcn|Web Click Network by Filippo Menczer]], [[http://videolectures.net/eccs07_matteo_gld|Global and Local Dynamics in Correlated Systems by Tiziana Di Matteo]]\n\n ----\n ----\n\n == 18. Emerging Collaborative Forms - Industry training\n\n**Description:** Brief summary of the various collaborative forms studied in previous units, a discussion of possible new models and generalizations is made. As a starting basis, new forms of collaborative e-government, e-science, Virtual institutes, Virtual laboratories, etc, are discussed. Other generalizations include: networks of sensors, networks of machines, etc.\n\n**Key concepts:** Summary of studied collaborative forms and interoperability approaches, New application examples: collaborative e-government, e-Science, Virtual institutes, Virtual Labs, etc., Internet of Things: Networks of machines, networks of sensors., Intelligent, self-aware enterprises, Symbiotic models, Other emerging cases.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_sme/Course_18_Emerging_Collaborative_Forms_SMEs.pdf|Emerging Collaborative Forms - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/eccs07_newman_sdc|Structure and Dynamics in Complex Networks by Mark Newman ]], [[http://videolectures.net/eccs07_verschure_dac|Distributive Adaptive Control: A Real-world Cognitive Architecture applied to Robots, Spaces and Avatares by Paul Verschure]], [[http://videolectures.net/eccs07_stamatiou_dtc|The \"Digital Territory\" as a Complex System of Interacting Agents, Emergent Properties and Technologies by Yannis Stamatiou ]], [[http://videolectures.net/esocenet07_borjeson_enl|European Network of Livin Labs by Mikael B\u00f6rjeson]], [[http://videolectures.net/coinactivess2010_kropp_sol|Smart Objects Innovation Lab: Theory and practice - hand in hand by Sebastian Kropp]],\n\n **Additional video lectures:**\n *[[http://videolectures.net/eccs07_canright_smn|Self-mapping Networks]]\n *[[http://videolectures.net/porto05_cordeiro_sc|Semiotics in CNOs]]\n *[[http://videolectures.net/eccs07_damiani_irb|Interacting Random Boolean Networks]]\n *[[http://videolectures.net/eccs07_jiang_pba|Population-based adaptive Systems: An Implementation in NEW TIES]]", "recorded": "2010-01-31T18:32:50", "title": "COIN - Industry training section"}, {"url": "solomon_hardy_semantic", "desc": "A new paradigm of 21st century human-oriented safety testing approaches is now emerging based on a combination of in silico and in vitro approaches. The new predictive test systems developed from this growing \u201cgrand challenge\u201d effort will need to combine evidences from a great variety of data, protocols, and concepts. The combination of these sources of knowledge within an ontology-based mechanistic knowledge-oriented framework to produce reliable test systems demands the development of a semantic web for toxicology. The OpenTox Framework (1,2) has been developed to support the communication between toxicology resources, based on standard representations of data and metadata, the ability for distributed resources to exchange data and metadata, build and validate models, and generate reporting information relevant for research analysis or risk assessment. I will describe the design and semantic architecture of OpenTox and example applications it can currently enable including a) creation and validation of models addressing the regulatory requirements of the REACH legislation for chemical safety evaluation (3), b) application in drug discovery infrastructure development and weight-of-evidence library profiling of drug candidate molecules (4), c) infrastructure development for the interdisciplinary research activities of a large cluster of over 70 partners collaborating on the replacement of animal testing in the area of systemic toxicology (5,6), and d) relevance for ecosystem protection and biodiversity preservation, including sustainable development contexts in both Europe and Africa (7).\r\n\r\n(1) OpenTox - An Open Source Predictive Toxicology Framework, is funded under the EU Seventh Framework Program: HEALTH-2007-1.3-3 Promotion, development, validation, acceptance and implementation of QSARs (Quantitative Structure-Activity Relationships) for toxicology, Project Reference Number Health-F5-2008-200787 (2008-2011). More information at http://www.opentox.org\r\n\r\n(2) Collaborative Development of Predictive Toxicology Applications\r\nBarry Hardy, Nicki Douglas, Christoph Helma, Micha Rautenberg, Nina Jeliazkova, Vedrin Jeliazkov, Ivelina Nikolova, Romualdo Benigni, Olga Tcheremenskaia, Stefan Kramer, Tobias Girschick, Fabian Buchwald, Joerg Wicker, Andreas Karwath, Martin Gutlein, Andreas Maunz, Haralambos Sarimveis, Georgia Melagraki, Antreas Afantitis, Pantelis Sopasakis, David Gallagher, Vladimir Poroikov, Dmitry Filimonov, Alexey Zakharov, Alexey Lagunin, Tatyana Gloriozova, Sergey Novikov, Natalia Skvortsova, Dmitry Druzhilovsky, Sunil Chawla, Indira Ghosh, Surajit Ray, Hitesh Patel and Sylvia Escher\r\nJournal of Cheminformatics 2010, 2:7 (31 August 2010)\r\nFull text and supplementary information available in Open Access at:\r\nhttp://www.jcheminf.com/content/2/1/7\r\n\r\n(3) REACH, http://ec.europa.eu/environment/chemicals/reach/reach_intro.htm\r\n\r\n(4) Scientists Against Malaria, http://scientistsagainstmalaria.net/\r\n\r\n(5) SEURAT-1, http://www.seurat-1.eu/\r\n\r\n(6) ToxBank, http://www.toxbank.net/\r\n\r\n(7) SETAC Africa Conference, 2011, http://cameroon.setac.eu/", "recorded": "2011-08-30T13:00:00", "title": "OpenTox - the creation of a Semantic Web for Toxicology "}, {"url": "reasecs_gutierrez_swawc", "desc": "After the data and ontology layers of the Semantic Web stack have achieved considerable stability through standard recommendations such as RDF and OWL, the query layer is the next item to be completed on W3C's agenda. This layer is realized by the SPARQL Protocol and RDF Query Language (SPARQL) currently under development by W3C's Data Access working group (DAWG). Although the SPARQL specification is not yet 100% stable - it just dropped a step back from candidate recommendation to working draft - people are taking up this specification at tremendous pace, driven by the strong need for a long awaited standard in querying the Semantic Web and being able to make use of the advantages of RDF together with common metadata-vocabularies at large scale.\n\nThis is just the right moment to reflect on the current state of the language and its applications, which we aim to provide in the proposed tutorial. The contributions of this tutorial will be along two complementary streams: On the one hand we will provide a practical introduction to SPARQL for newcomers, giving examples from various application domains, providing formal underpinnings and guiding attendees through the jungle of existing implementations, including those which reach beyond the current specification to query more expressive semantic web languages than RDF alone. Thus, participants will get a clear sense of the language as it is specified and as it exists in implementations. On the other hand, we will go further into depth of theoretical foundations of SPARQL, presenting recent results of SPARQL's complexity, formal foundations in terms of database theory, as well as its exact semantic relation to the other building blocks in the SW stack, namely, RDF Schema, OWL and the upcoming rules layer. Finally, we aim to bring these two streams together, and will identify the current limitations and challenges around SPARQL, pointing to possible extensions and emerging application fields.\n\nThe presenters of this tutorial tackle the topic of Semantic Web querying and SPARQL from various, complementary viewpoints. Andy Seaborne co-chairs the Data Access working group (DAWG) which is responsible for the development of SPARQL. The group from the Center for Web Research - Chile1, Marcelo Arenas, Claudio Gutierrez, and Jorge P\ufffdrez, with their long-term experience and excellent record in database technologies for the Web and Semantic Web foundations, is main responsible for recent successes towards more formal backgrounds of SPARQL, and provided best-paper winning results on semantics and complexity of the language. Bijan Parsia was a long-term member of the DAWG and was also involved in the development of OWL. Axel Polleres has a strong background in deductive databases and rules and is a member of the Rules Interchange format (RIF) working group which currently works on the Semantic Web rules layer, the subsequent building block of the SW stack. \n\nThis full-day tutorial has been given at the European Semantic Web Conference (ESWC 2007) in Innsbruck, Austria on June 3rd, 2007.", "recorded": "2007-09-09T00:00:00", "title": "SPARQL - Where are we?  Current state, theory and practice"}, {"url": "coin_multipliers_training", "desc": "back to [[http://videolectures.net/coin|COIN training project ]]\n\n===These videolectures describe the technologies being used and developed in COIN, and some of the applications of those technologies in the project. The lectures are given by COIN researchers and by other researchers working in the same and related fields.\n\n**MUST SEE videos for Multipliers before taking the courses:**\n||[[:coin_videolectures_promo]]||[[:coinplanetdataschool2011_braccini_introduction]]||[[:coinplanetdataschool2011_hristov_media/]]||[[:coinplanetdataschool2011_scicluna_web/]]||[[:coinplanetdataschool2011_gaggioli_coin/]]||\n\n == 1. Motivation for the paradigm - Multiplier training\n\n**Description:** This first unit aims at creating a motivation for the course through a brief presentation of application areas, illustrated by concrete examples in industry, services, government, etc. A brief historic overview of the industrial organizational paradigms leading to collaborative networks and their interoperability as well as a summary of current technological and organizational trends is presented. For each example an attempt to identify the main involved problems (e.g. organizational forms, processes, and cooperation and collaboration forms) is made, calling the attention for the potential contributes from other disciplines.\n\n**Key concepts:** Collaboration and Interoperability, Practical examples of CNs, Practices of Interoperability, Historic overview, Technological and organizational trends, Discussion of the usefulness/benefits and current limitations\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_1_Motivation_for_the_paradigm_Multipliers.pdf|Motivation for the paradigm - course]]\n\n**Suggested video lectures:**: [[http://videolectures.net/ice09_martinez_ewbom|Everything will be on machines by Cristina Martinez ]], [[http://videolectures.net/ice08_martinez_future|The Future Internet: a vision from European Research by Cristina Martinez ]], [[http://videolectures.net/ice2011_schuh_production/|Developing a production engineering based theory of production by G\u00fcnther Schuh]], [[http://videolectures.net/ice08_prinz_web|Web 2.0 and Collaborative Working Environments: What can we learn? by Wolfgang Prinz]], [[http://videolectures.net/esocenet07_gusmeroli_csf|Current Solutions and Future Trends by Sergio Gusmeroli]]\n\n----\n----\n\n == 2. Basic concepts - Multiplier training\n\n**Description:** After the motivation phase, the base concepts are introduced. Considering the large variety of collaborative networks and interoperability modes, a categorization of the various forms is made and taxonomy is introduced in order to give students a global perspective of the area. At the same time the basic project concepts and  models are being addressed. The various innovative concepts and models developed in COIN.\n\n**Key concepts:** COIN Basic Concepts, Fundamentals in CN, Fundamentals in Interoperability, COIN innovative concepts and models\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_2_Basic_Concepts_Multipliers.pdf|Basic concepts - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ice08_gusmeroli_meta|The COIN Metaphor for EU Industry by Sergio Gusmeroli]], [[http://videolectures.net/iesa08_rossiter_lfi|Logical Foundations for the Infrastructure of the Information Market by Nick Rossiter ]], [[http://videolectures.net/coinactivess2010_gusmeroli_cica|Collaboration and Interoperability \u2013 COIN Approach\nby Sergio Gusmeroli]], [[http://videolectures.net/coinactivess2010_sesana_cis|COIN Innovative Services\nby Michele Sesana]], [[http://videolectures.net/cgm09_gusmeroli_tccps|TCC plenary session\nby Sergio Gusmerol]]\n\n----\n----\n\n == 3. Enterprise Interoperability - Multiplier training\n\n**Description:** After the motivation phase and the COIN basic concepts are introduced, the base concepts of Enterprise Interoperability are explained. After describing the overall goals and essential terms for the Interoperability of enterprises, principles, methods and benefits of enterprise Interoperability are explained.\n\n**Key concepts:** Basic Concepts, Definitions and Approaches, Enterprise Modelling for Interoperability,  Business Interoperability (BI)\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_3_Enterprise_Interoperability_Multipliers.pdf|Enterprise Interoperability - course]]\n\n **Suggested video lectures:** [[http://videolectures.net/ice08_katranuschkov_aigevo|Achieving Interoperability in Grid-Enabled Virtual Organisation by Peter Katranuschkov]], [[http://videolectures.net/ice09_olmo_aabc|Business Cases for Enterprise Interoperability - The Andalusian Aeronautics Business Case\nAlberto Olmo]], [[http://videolectures.net/ice09_debate_qa|Debate on Business Cases for Enterprise Interoperability  by Sergio Gusmerol]], [[http://videolectures.net/iswc06_wache_irpto|Workshop: Improving the recruitment process through ontology-based querying by Holger Wache]], [[http://videolectures.net/cgm09_taglino_eis|Enterprise Interoperability Services by Francesco Taglino]]\n\n ----\n ----\n\n == 4. VO Breeding Environment - Multiplier training\n\n**Description:** Course on the main elements of the VBE that are studied in COIN featuring theoretical and practical business examples from the field. The basic elements of Virtual Organizations Breeding Environment and its role in the context of CNO.\n\n**Key concepts:** Concept and examples, Components, structure, actors and roles\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_4_Vo_Breeding_Environment_Multipliers.pdf|VO Breeding Environment - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess07_ferlez_mc| Modelling competences by\nJure Ferle\u017e]], [[http://videolectures.net/akom08_grobelnik_ina|Introduction to Network Analysis\nby Marko Grobelnik, Dunja Mladeni\u0107]], [[http://videolectures.net/brussels06_afsarmanesh_v|Virtual organisations breeding environment by Hamideh Afsarmanesh]], [[http://videolectures.net/ess07_jermol_evg|Exploring Collaborative Networked Organisations in ECOLEAD by Mitja Jermol]], [[http://videolectures.net/antwerpen04_blomqvist_ottbn/|An overview of trust and trust building in networks\n by Kirsimarja Blomqvist]]\n\n ----\n ----\n\n == 5. Virtual Organizations - Multiplier training\n\n**Description:** Course on the concept and structure of Virtual Organizations creation rules and functionalities. Here we present the continuous life cycle of the Virtual Organization creation with its creation, formation, later approaching its breeding environment functionalities and ultimately its dissolution and incorporation into its next life cycle phase.\n\n**Key concepts:** Concepts, organizational models and operational rules, Life cycle\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_5_Virtual_Organizations_Multipliers.pdf| Virtual Organizations - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess07_ollus_vom|Virtual organizations management by Martin Ollus]], [[http://videolectures.net/ess06_ollus_vrvp|VOM in relation to VBE & PVC by Martin Ollus]], [[http://videolectures.net/ess06_seifert_pmv|Performance Management in VOs by Marcus Seifert]], [[http://videolectures.net/ess07_slavik_vrv|Virtual reality for VE\nby Pavel Slav\u00edk]], [[http://videolectures.net/ekom08_ollus_mcn|Management of collaboration in networks\nby Martin Ollus]]\n\n ----\n ----\n\n== 6. Virtual Communities - Multiplier training\n\n**Description:**In this course is shown the basic knowledge on Virtual Communities, the concept of Professional Virtual Communities that is being explored in COIN. A typology of VC is introduced and a particular attention is devoted to Professional Virtual Communities. The components, structure, and life cycle of PVCs are discussed.\n\n**Key concepts:** Concepts and typology, Components\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_6_Virtual_Communities_Multipliers.pdf|Virtual Communities - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess06_seifert_pmv|Performance Management in VOs\nby Marcus Seifert]], [[http://videolectures.net/esocenet07_santoro_ci|Concurrent Innovation \u2013 Vision 2020\nby Roberto Santoro]], [[http://videolectures.net/brussels06_gusmeroli_i|ICT-I by Sergio Gusmeroli]], [[http://videolectures.net/mitworld_baltimore_bac|Building a Community on Trust by David Baltimore]], [[http://videolectures.net/ess07_vorobey_ape|AIESEC PVC ECOLEAD case study by Volodja Vorobey]]\n\n**Additional video lectures:** [[http://videolectures.net/ess06_crave_pbct| PVC basic concepts & typologies]], [[http://videolectures.net/ess07_crave_pca|PVC and cooperation from AI perspective]], [[http://videolectures.net/ess06_picard_sppvc|Social protocols in Professional Virtual Communities]], [[http://videolectures.net/eccs07_chavalarias_sma|Science mapping with asymmetric co-occurence analysis]]\n\n ----\n ----\n\n == 7. Architectures and Platforms - Multiplier training\n\n**Description:**Focusing on research coordination in the area of Architecture & Platforms. Show basic internet and computer technologies, ideas, and concepts for enterprise interoperability purposes and to continue on updating with state-of-the-art models, approaches and mechanisms.\n\n**Key concepts:** Computer networks basics. Base Internet technologies, Emerging computing models and implementation approaches\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_7_Architectures_and_Platforms_Multipliers.pdf|Architectures and Platforms - course]]\n\n**Suggested video lectures:**  [[http://videolectures.net/iesa08_gionis_aha|The Advantages of Hybrid Architectural Approaches for the Integrating Middleware by George Gionis]], [[http://videolectures.net/iesa08_ullberg_eas|Enterprise Architecture: A Service Interoperability Analysis Framework by Johan Ullberg]], [[http://videolectures.net/ess07_negretto_ii|ICT infrastructure by\nUgo Negretto]], [[http://videolectures.net/ess07_hodik_atv|Agent technologies for VE + SW demonstrations: MAS Tutorial by Ji\u0159\u00ed Hod\u00edk]], [[http://videolectures.net/ess06_nagellen_soa|Service Oriented Architectures by Thierry Nagellen]]\n\n ----\n ----\n\n == 8. Background Technologies - Multiplier training\n\n**Description:** This course presents and explains core technologies from the area of knowledge technologies that ranges from the data driven methods to knowledge driven methods and are important for detecting, analyzing and managing knowledge (tacit and explicit) in enterprises, organisations or agents. Recent developments in the particular areas are demonstrated through real software prototypes, successful market cases and real business implementations.\n\n**Key concepts:** Traditional technologies\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_8_Background_Technologies_Multipliers.pdf| Background Technologies - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/kdd07_fayyad_dms|A Data Miner\u2019s Story \u2013 Getting to Know the Grand Challenges by Usama Fayyad ]], [[http://videolectures.net/ssll09_kotagiri_dami|Data Mining by Rao Kotagiri]], [[http://videolectures.net/stanfordcs229f08_ng_lec01| Lecture 1 - The Motivation & Applications of Machine Learning by Andrew Ng]], [[http://videolectures.net/iswc08_hendler_ittsw|Introduction to the Semantic Web by Aldo Gangemi, Sean Bechhofer, Asunci\u00f3n G\u00f3mez-P\u00e9rez, Jim Hendler]], [[http://videolectures.net/ess07_jermol_ktno|Knowledge technologies for network organisations by Mitja Jermol]]\n\n**Additional video lectures:**[[http://videolectures.net/psm08_cristianini_ieb/|In the Eye of the Beholder? Another look at Cognitive Systems]], [[http://videolectures.net/ijcai09_lesser_saitmao/|Scaling AI Through Multi-Agent Organizations]], [[http://videolectures.net/ccss09_pietronero_soafse/|Self-Organization and Finite Size Effects in Agent Models for Financial Markets]], [[http://videolectures.net/ccss09_steubing_atcf/|Assessing the Critical Factors that Determine the Availability of Wood Fuel in Switzerland with an Agent Based Model]]\n----\n----\n\n == 9. COIN Solution - Multiplier training\n\n**Description:** This is one of the main courses in COIN training programmes. It is aimed at presenting COIN innovative  solutions that will be developed in the frame of the project. The main focus is on the explanation and demonstration of technologies developed in COIN, their use in the industry contexts and on the discussion of their implications to the traditional business environment.\n\n**Key concepts:** Basic architecture, Introduction to COIN Service platform, Introduction to COIN Enterprise Interoperability services, Interoperability baseline, Introduction to COIN Enterprise Collaboration services, Collaboration baseline\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_9_COIN_solution_Introduction_Multipliers.pdf| COIN solution - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/coinactivess2010_jansson_ccs|COIN Collaborative Services by Kim Jansson ]], [[http://videolectures.net/coinactivess2010_sitek_ure|User requirements elicitation adapting Serious Gaming approach by Patrick Sitek]], [[http://videolectures.net/coinactivess2010_sesana_cpd|COIN Platform Demonstration by Michele Sesana]], [[http://videolectures.net/coinactivess2010_fischer_cbs|COIN Baseline services and negotiation support by Klaus Fischer]], [[http://videolectures.net/coinplanetdataschool2011_sesana_coin/|Technical and Business Innovation\nby Michele Sesana]]\n\n ----\n ----\n\n== 10. Practical Examples and COIN prototypes - Multiplier training\n\n**Description:** In this course the practical examples of COIN prototypes will be demonstrated and explained together with some applications that are related to the COIN research domain. The course will be supplemented with a hands-on workshop to allow participants to deal with concrete examples from their work context.\n\n**Key concepts:** use scenarios, case studies and best practices, demonstrators, demos, prototypes\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_10_Practical_Examples_and_COIN_prototipes_Multipliers.pdf|Practical Examples and COIN prototypes - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ice09_olmo_coincpds|COIN Collaborative Product Development Services by Alberto Olmo]], [[http://videolectures.net/coinplanetdataschool2011_sesana_demos/|COIN System Demos by Michele Sesana]], [[http://videolectures.net/ice09_canepa_isurf|iSURF \u2013 Piacenza Knitwear Business Case by Alessandro Canepa]], [[http://videolectures.net/cgm09_komazec_cspwho|COIN Service Platform with hands-on by Srdjan Komazec]], [[http://videolectures.net/coinplanetdataschool2011_oman_usage|Usage of Integrated Services in the industry by\nSimon Oman]]\n\n ----\n ----\n\n == 11. Information Management - N/A for Multipliers\n\n ----\n ----\n\n == 12. Information Exchange Standards - Multiplier training\n\n**Description:** A number of standards particularly relevant for collaborative networks and enterprise interoperability are introduced and analyzed. Among them: EDI (Electronic Data Interchange), which in historical terms represents one of the first tools for cooperation among enterprises, is introduced and briefly characterized.\n\n**Key concepts:** Importance of standards\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_12_Information_Exchange_Standards_Multipliers.pdf|Information Exchange Standards - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/efreight2011_rantasila_pilli_sihvola_logistics|Logistics-related information exchange - international exchange - international efforts and Finnish developments by Karri Rantasila, Eetu Pilli-Sihvola]], [[http://videolectures.net/kdd2010_zheng_udmt|Using Data Mining Techniques to Address Critical Information Exchange Needs in Disaster Affected Public-Private Networks by Li Zheng]], [[http://videolectures.net/ict08fr_nagy_rothengass_eiu|The Expanding Information Universe: New Trends, New Forms, New Usages\nby Marta Nagy-Rothengass]], [[http://videolectures.net/ecml07_smyth_api|Adventures in Personalized Information Access by Barry Smyth]], [[http://videolectures.net/forum2010_glenn_gcisd|Global Challenges and Information Society Development by Jerome C. Glenn]]\n\n ----\n ----\n\n == 13. Coordination Mechanisms - Multiplier training\n\n**Description:** This course is aimed at providing knowledge about the models, structures and mechanisms for management, coordination and problem solving. The coordination mechanisms are basic mechanisms in any networked organisation and as such the focal point of interest for any distributed, knowledge focused organisation.\n\n**Key concepts:** Collaboration modalities\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_13_Coordination_Mechanisms_Multipliers.pdf|Coordination Mechanisms - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/eccs07_stark_cpc|Combined Problems of Cooperation and Coordination by Hans-Ulrich Stark]], [[http://videolectures.net/eccs07_menczer_wcn|Web Click Network\nby Filippo Menczer]], [[http://videolectures.net/eccs07_matteo_gld|Global and Local Dynamics in Correlated Systems by Tiziana Di Matteo]], [[http://videolectures.net/iesa08_wings_csit|Challenges and Strategies for IT Services in Heterogeneous Enterprise Environments by Sujit Wings]]\n\n ----\n ----\n\n == 14. Management of common Ontologies - Multiplier training\n\n**Description:** This course is aimed at providing the base concepts of ontologies, especially in relation to the COIN common ontology, explore the potential of ontology-based techniques to tackle the problem of interoperability.\n\n**Key concepts:** The role of ontologies in collaboration, COIN Core level common ontology\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_14_Management_of_common_Ontologies_Multipliers.pdf|Management of common Ontologies - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess07_grobelnik_twdmI|Text and web data mining by Marko Grobelnik]], [[http://videolectures.net/iesa08_dahlem_osm|Ontology-driven Semantic Mapping by Nikolai Dahlem]], [[http://videolectures.net/mmdss07_grobelnik_oml|Ontologies and Machine Learning by Marko Grobelnik, Bla\u017e Fortuna]], [[http://videolectures.net/ess07_obitko_oswve|Ontologies, semantic web and VE by Marek Obitko]], [[http://videolectures.net/tao08_bontcheva_tao|Transitioning Applications to Ontologies by Kalina Bontcheva]]\n\n ----\n ----\n\n == 15. e-Commerce and e-Markets - Multiplier training\n\n**Description:** This course will in particular investigate aspects related to the economics and the incentives behind Interoperability.\n\n**Key concepts:** Concepts of e-Commerce and e-Market\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_15_E-Commerce_and_E-Markets_Multiplierss.pdf|E-commerce and E-markets - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/echallenges2010_li_intro|Business Models Background\nMan-Sze Li ]], [[http://videolectures.net/ice09_canepa_isurf|iSURF \u2013 Piacenza Knitwear Business Case\nby Alessandro Canepa]], [[http://videolectures.net/ice09_withalm_cdcp|Business Cases for Enterprise Interoperability Collaborative Demand Capacity Planning (CDCP) by Josef Withalm]], [[http://videolectures.net/coinplanetdataschool2011_hristov_media| Innovative collaboration in Media \u2013 \u000ba COIN case in EEU by Konstantin Hristov]], [[http://videolectures.net/echallenges2010_suttner_tnb|Towards New Business Models in the Energy Sector based on Software-as-a-Service-Utilities and Value-added Services\nby Hannes Suttner]]\n\n ----\n ----\n\n == 16. Non Technological Issues -  - N/A for Multipliers\n\n----\n----\n\n == 17. Organisation Modeling and Reference Models - Multiplier training\n\n**Description:** The course topic is focusing on Organisation Modelling as a combination of a set of activities within an enterprise with a structure describing their logical order and dependence whose objective is to produce a desired result. Business Process modeling as an enabler of common understanding and analysis of a business process. The course will also describe the main process modeling techniques.\n\n**Key concepts:** Concept of reference model\n\n**Download the course:**\n\n **Suggested video lectures:** [[http://videolectures.net/eccs07_stark_cpc|Combined Problems of Cooperation and Coordination by Hans-Ulrich Stark ]], [[http://videolectures.net/eccs07_menczer_wcn|Web Click Network by Filippo Menczer]], [[http://videolectures.net/eccs07_matteo_gld|Global and Local Dynamics in Correlated Systems by Tiziana Di Matteo]]\n\n ----\n ----\n\n == 18. Emerging Collaborative Forms - Multiplier training\n\n**Description:** Brief summary of the various collaborative forms studied in previous units, a discussion of possible new models and generalizations is made. As a starting basis, new forms of collaborative e-government, e-science, Virtual institutes, Virtual laboratories, etc, are discussed. Other generalizations include: networks of sensors, networks of machines, etc.\n\n**Key concepts:** Summary of studied collaborative forms and interoperability approaches, New application examples: collaborative e-government, e-Science, Virtual institutes, Virtual Labs, etc., Internet of Things: Networks of machines, networks of sensors., Intelligent, self-aware enterprises, Symbiotic models, Other emerging cases.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_multipliers/Course_18_Emerging_Collaborative_Forms_Multipliers.pdf|Emerging Collaborative Forms - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/eccs07_newman_sdc|Structure and Dynamics in Complex Networks by Mark Newman ]], [[http://videolectures.net/eccs07_verschure_dac|Distributive Adaptive Control: A Real-world Cognitive Architecture applied to Robots, Spaces and Avatares by Paul Verschure]], [[http://videolectures.net/eccs07_stamatiou_dtc|The \"Digital Territory\" as a Complex System of Interacting Agents, Emergent Properties and Technologies by Yannis Stamatiou ]], [[http://videolectures.net/esocenet07_borjeson_enl|European Network of Livin Labs by Mikael B\u00f6rjeson]], [[http://videolectures.net/coinactivess2010_kropp_sol|Smart Objects Innovation Lab: Theory and practice - hand in hand by Sebastian Kropp]],\n\n **Additional video lectures:**\n *[[http://videolectures.net/eccs07_canright_smn|Self-mapping Networks]]\n *[[http://videolectures.net/porto05_cordeiro_sc|Semiotics in CNOs]]\n *[[http://videolectures.net/eccs07_damiani_irb|Interacting Random Boolean Networks]]\n *[[http://videolectures.net/eccs07_jiang_pba|Population-based adaptive Systems: An Implementation in NEW TIES]]", "recorded": "2010-01-31T18:34:51", "title": "COIN - Potential multipliers and policy makers training section"}, {"url": "active_general_training", "desc": "back to [[http://videolectures.net/active|ACTIVE training project ]]\r\n\r\n===\r\nThe goal of training activities in ACTIVE is to achieve the transfer of knowledge and best practices within the project as well as (principally) outside the project. ACTIVE training program is aimed at training individuals and groups on the topics that are relevant to the ACTIVE project. Each training program covers a general topic and is generated from several training courses that are focused on specific topics. Furthermore, each training program combines different types and forms of learning: traditional, ICT supported or blended training event. For each training course we provide textual materials, references to the sources used for training module preparation, a list of the topic relevant ACTIVE deliverables, video tutorials and additional materials/suggested readings.\r\n\r\n== 1. Theoretical Foundations and Conceptual Models\r\n\r\nThis course starts with the theoretical foundations on the organisational and collaboration forms, business process modelling, management and collaboration mechanisms, knowledge management and current governance principles in organisations. In contrast it provides basic information about traditional and emerging technologies that influence traditional business organisation and management context. Then it gives motivation for the complete ACTIVE training programme by providing incentives, future trends and business potentials.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse1_TheoreticalFoundations.pdf|Theoretical foundations and conceptual models - course]]\r\n\r\nCourse topics:\r\n\r\n**Collaboration and collaborative knowledge creation**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n*[[http://videolectures.net/semseach09_albakour_mcpse|Managing Collaboration Projects using Semantic Email]]\r\n*[[http://videolectures.net/iswc08_tudarache_scodp|Supporting Collaborative Ontology Development in Protege]]\r\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\r\n*[[http://videolectures.net/ice08_kristensen_pcik|Productivity in Collaboration-intensive Knowledge Work: The Collaboration Management Imperative]]\r\n*[[http://videolectures.net/nano07_gadlin_rsc|Re-thinking scientific teams: competition, conflict and collaboration]]\r\n*[[http://videolectures.net/iswc06_auer_otssc|In-Use 1: OntoWiki - A Tool for Social, Semantic Collaboration]]\r\n\r\n**Knowledge processes and tasks**\r\n*[[http://videolectures.net/active09_tilly_ikp|Informal Knowledge Processes: The Long Tail of Business Processes]]\r\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\r\n\r\n**Process modelling**\r\n*[[http://videolectures.net/eswc08_feldcamp_sb|Workshop on Semantic Business Process Management - GoMoKIT- Towards an applicable goal-oriented Business Process Modelling approach for knowledge-intensive Tasks]]\r\n\r\n**Knowledge management**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\r\n*[[http://videolectures.net/training06_davies_ka|Knowledge Access]]\r\n*[[http://videolectures.net/iswc08_bhagdev_cauoswilno|Creating and Using Organisational Semantic Webs in Large Networked Organisations]]\r\n*[[http://videolectures.net/cikm08_feldman_ak|Automating Knowledge]]\r\n*[[http://videolectures.net/eswc08_schaffert_sw|Semantic Wikis - IkeWiki - A Semantic Wiki for Collaborative Knowledge Management]]\r\n\r\n**Formalisms for (dynamic) aspects of knowledge worker context and enterprises**\r\n*[[http://videolectures.net/iswc06_grobelnik_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_witbrock_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_mozetic_cskrs|Context Sensitivity in Knowledge Rich Systems]]\r\n*[[http://videolectures.net/iswc06_haase_cop|Context Sensitivity in Knowledge Rich Systems - Contents of parts 2]]\r\n\r\n ----\r\n ----\r\n\r\n == 2. Knowledge Models and Structures\r\n\r\nThis course deals with the theoretical background on knowledge and semantic technologies and examines them from a technological, historical and scientific perspective. It starts with the basic facts about knowledge structures and models and their role in the knowledge formalisation, modelling, reasoning and adaptation. It provides comparison and contrasting of diverse knowledge models, structures and systems and understanding their participation in industry.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse2_KnowledgeModels.pdf|Knowledge models and structures - course]]\r\n\r\nCourse topics:\r\n\r\n**Semantic languages**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm/|Semantic MediaWiki]]\r\n*[[http://videolectures.net/training06_sure_stsw/|A short Tutorial on Semantic Web]]\r\n*[[http://videolectures.net/eswc09_tappolet_atre|Applied Temporal RDF: Ef?cient Temporal Querying of RDF Data with SPARQL]]\r\n*[[http://videolectures.net/eswc09_vennekens_faaeod|FO(ID) as an Extension of DL with Rules]]\r\n*[[http://videolectures.net/iswc08_perez_nsparql|NSPARQL: A Navigational Language for RDF]]\r\n*[[http://videolectures.net/iswc08_hausenblas_bwdwd|RDFa - Bridging the Web of Documents and the Web of Data]]\r\n\r\n**Knowledge formalisation  and  representation**\r\n*[[http://videolectures.net/coinactivess2010_dengler_sm|Semantic MediaWiki]]\r\n*[[http://videolectures.net/akom08_krotzsch_fik|Formal and Informal knowledge representation]]\r\n*[[http://videolectures.net/iswc08_saggion_krebi|Knowledge Representation and Extraction for Business Intelligence]]\r\n\r\n**Reasoning and  probabilistic temporal models**\r\n*[[http://videolectures.net/iswc08_moller_itsr|Reasoning for Ontology Engineering and Usage]]\r\n*[[http://videolectures.net/ssll09_pagnucco_krr|Knowledge Representation and Reasoning]]\r\n*[[http://videolectures.net/bsciw08_schwaighofer_krrd|Knowledge Representation and Reasoning - Discussion]]\r\n\r\n**Knowledge structures**\r\n**Collaborative articulation of expressive knowledge**\r\n**Knowledge leveraging and repair models**\r\n**Knowledge-based adaptation**\r\n**Knowledge creation cycle**\r\n\r\nRelated talks:\r\n*[[http://videolectures.net/iswc08_hauer_asnrwpdehep|An architecture for semantic navigation and reasoning with patient data - experiences of the Health-e-Child project]]\r\n*[[http://videolectures.net/eswc08_blanco_sr|Semantic Reasoning: A Path To New Possibilities of Personalization]]\r\n*[[http://videolectures.net/akom08_krotzsch_fik/|Formal and Informal knowledge representation]]\r\n*[[http://videolectures.net/active09_ghani_rdekm/|Research Directions in Enterprise Knowledge Management]]\r\n\r\n ----\r\n ----\r\n\r\n == 6. Practical Examples and ACTIVE Prototypes\r\n\r\nIn this course the development process of the ACTIVE prototypes for three specific applications will be demonstrated. The development process and the applications with their specific benefits which are created by the ACTIVE research results will be shown. The course will be supplemented with a hands-on workshop to allow participants to deal with concrete examples from their work context. The focus will be on identifying areas of applications where the functionalities developed in the ACTIVE project can be applied.\r\n[[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse6_PracticalExamples.pdf|Practical Examples and ACTIVE Prototypes - course]]\r\n\r\nCourse topics:\r\n\r\n**Case studies and best practices**\r\n*[[http://videolectures.net/active09_warren_kmcfl|KM at the Customer Front-Line: The BT Case Study in ACTIVE]]\r\n*[[http://videolectures.net/coinactivess2010_thurlow_bcs|ACTIVE\u000b BT Case Study]]\r\n*[[http://videolectures.net/coinactivess2010_djordjevic_acs|Accenture Case Study: Enterprise Collaboration & Knowledge Management through Machine Learning and Semantic Technologies]]\r\n\r\n**Demonstrators, demos, prototypes**\r\n*[[http://videolectures.net/eswc08_berges_smw|Semantic Web Technology for Agent Communication Protocols]]\r\n*[[http://videolectures.net/active09_dolinsek_iak|Introduction to the ACTIVE Knowledge Workspace SDK]]\r\n\r\n**Use scenarios**\r\n\r\n ----\r\n ----\r\n\r\n == 9. ACTIVE project - Introduction\r\n\r\nThe aim of this course is to present the aims, goals, structure and expected results of ACTIVE project. In addition this course provides information about the future plans, development and operations of the business development that will follow the ACTIVE project. In that respect the future directions in the research areas will be presented, their use potentials, development scenarios and business scenarios in the forms of business plans. [[http://analytics.ijs.si/~mitja/Courses/Active_academia/TrainingCourse9_Introduction.pdf|ACTIVE project - Introduction - course]]\r\n\r\n*[[http://videolectures.net/akom08_warren_welcome|Welcome to the ACTIVE kick off meeting]]\r\n*[[http://videolectures.net/active09_mladenic_warren_oai|Opening and Introduction of the 1st ACTIVE Summer School]]\r\n*[[http://videolectures.net/coinactivess2010_warren_ai|ACTIVE Introduction]]\r\n*[[http://videolectures.net/coinactivess2010_jermol_wel|Welcome to the Summer School on Advanced Technologies for Knowledge Intensive Networked Organizations 2010 - Aachen ]]", "recorded": "2011-02-23T15:21:23", "title": "ACTIVE - Training/promotion programme for general public"}, {"url": "coin_general_public_training", "desc": "back to [[http://videolectures.net/coin|COIN training project ]]\n\n===These videolectures describe the technologies being used and developed in COIN, and some of the applications of those technologies in the project. The lectures are given by COIN researchers and by other researchers working in the same and related fields.\n\n == 1. Motivation for the paradigm - General public training\n\n**Description:** In this course the learner will get basic knowledge on the emerging scientific discipline \u2013 Collaborative Networked Organisations with emphasis on Interoperability. You will learn basic concepts, historical context and rationales for the new discipline.\n\n**Key concepts:** Collaboration and Interoperability, Practical examples of CNs, Practices of Interoperability, Historic overview, Technological and organizational trends, Discussion of the usefulness/benefits and current limitations\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_1_Motivation_for_the_paradigm_General.pdf|Motivation for the paradigm - course]]\n\n**Suggested video lectures:**: [[http://videolectures.net/ice09_martinez_ewbom|Everything will be on machines by Cristina Martinez ]], [[http://videolectures.net/ice08_martinez_future|The Future Internet: a vision from European Research by Cristina Martinez ]], [[http://videolectures.net/ice2011_schuh_production/|Developing a production engineering based theory of production by G\u00fcnther Schuh]], [[http://videolectures.net/ice08_prinz_web|Web 2.0 and Collaborative Working Environments: What can we learn? by Wolfgang Prinz]], [[http://videolectures.net/esocenet07_gusmeroli_csf|Current Solutions and Future Trends by Sergio Gusmeroli]]\n\n----\n----\n\n == 2. Basic concepts - General public training\n\n**Description:** In this course the learner will get basic knowledge on COIN Basic Concepts, Fundamentals in CN, Fundamentals in Interoperability, COIN innovative concepts and models. You will learn background knowledge for understanding the EC and EI challenges within COIN.\n\n**Key concepts:** COIN Basic Concepts, Fundamentals in CN, Fundamentals in Interoperability, COIN innovative concepts and models\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_2_Basic_Concepts_General.pdf|Basic concepts - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ice08_gusmeroli_meta|The COIN Metaphor for EU Industry by Sergio Gusmeroli]], [[http://videolectures.net/iesa08_rossiter_lfi|Logical Foundations for the Infrastructure of the Information Market by Nick Rossiter ]], [[http://videolectures.net/coinactivess2010_gusmeroli_cica|Collaboration and Interoperability \u2013 COIN Approach\nby Sergio Gusmeroli]], [[http://videolectures.net/coinactivess2010_sesana_cis|COIN Innovative Services\nby Michele Sesana]], [[http://videolectures.net/cgm09_gusmeroli_tccps|TCC plenary session\nby Sergio Gusmerol]]\n\n----\n----\n\n == 3. Enterprise Interoperability - General public training\n\n**Description:** In this course the learner will get basic knowledge on Enterprise Interoperability as an the emerging scientific discipline. You will learn basic modes of Interoperability.\n\n**Key concepts:** Basic Concepts, Definitions and Approaches\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_3_Enterprise_Interoperability_General.pdf|Enterprise Interoperability - course]]\n\n **Suggested video lectures:** [[http://videolectures.net/ice08_katranuschkov_aigevo|Achieving Interoperability in Grid-Enabled Virtual Organisation by Peter Katranuschkov]], [[http://videolectures.net/ice09_olmo_aabc|Business Cases for Enterprise Interoperability - The Andalusian Aeronautics Business Case\nAlberto Olmo]], [[http://videolectures.net/ice09_debate_qa|Debate on Business Cases for Enterprise Interoperability  by Sergio Gusmerol]], [[http://videolectures.net/iswc06_wache_irpto|Workshop: Improving the recruitment process through ontology-based querying by Holger Wache]], [[http://videolectures.net/cgm09_taglino_eis|Enterprise Interoperability Services by Francesco Taglino]]\n\n ----\n ----\n\n == 4. VO Breeding Environment - General public training\n\n**Description:** In this course the learner will get basic knowledge on the main elements of the VBE, the basic elements of Virtual Organizations Breeding Environment and its role in the context of CNO.\n\n**Key concepts:** Concept and examples\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_4_Vo_Breeding_Environment_General.pdf|VO Breeding Environment - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess07_ferlez_mc| Modelling competences by\nJure Ferle\u017e]], [[http://videolectures.net/akom08_grobelnik_ina|Introduction to Network Analysis\nby Marko Grobelnik, Dunja Mladeni\u0107]], [[http://videolectures.net/brussels06_afsarmanesh_v|Virtual organisations breeding environment by Hamideh Afsarmanesh]], [[http://videolectures.net/ess07_jermol_evg|Exploring Collaborative Networked Organisations in ECOLEAD by Mitja Jermol]], [[http://videolectures.net/antwerpen04_blomqvist_ottbn/|An overview of trust and trust building in networks\n by Kirsimarja Blomqvist]]\n\n ----\n ----\n\n == 5. Virtual Organizations - General public training\n\n**Description:** In this course the learner will get basic knowledge on Virtual Organizations creation rules and functionalities.\n\n**Key concepts:** Concepts, organizational models and operational rules\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_5_Virtual_Organizations_General.pdf|Virtual Organizations - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess07_ollus_vom|Virtual organizations management by Martin Ollus]], [[http://videolectures.net/ess06_ollus_vrvp|VOM in relation to VBE & PVC by Martin Ollus]], [[http://videolectures.net/ess06_seifert_pmv|Performance Management in VOs by Marcus Seifert]], [[http://videolectures.net/ess07_slavik_vrv|Virtual reality for VE\nby Pavel Slav\u00edk]], [[http://videolectures.net/ekom08_ollus_mcn|Management of collaboration in networks\nby Martin Ollus]]\n\n ----\n ----\n\n== 6. Virtual Communities - General public training\n\n**Description:**In this course is shown the basic knowledge on Virtual Communities, the concept of Professional Virtual Communities that is being explored in COIN.\n\n**Key concepts:** Concepts and typology\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_6_Virtual_Communities_General.pdf|Virtual Communities - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess06_seifert_pmv|Performance Management in VOs\nby Marcus Seifert]], [[http://videolectures.net/esocenet07_santoro_ci|Concurrent Innovation \u2013 Vision 2020\nby Roberto Santoro]], [[http://videolectures.net/brussels06_gusmeroli_i|ICT-I by Sergio Gusmeroli]], [[http://videolectures.net/mitworld_baltimore_bac|Building a Community on Trust by David Baltimore]], [[http://videolectures.net/ess07_vorobey_ape|AIESEC PVC ECOLEAD case study by Volodja Vorobey]]\n\n**Additional video lectures:** [[http://videolectures.net/ess06_crave_pbct| PVC basic concepts & typologies]], [[http://videolectures.net/ess07_crave_pca|PVC and cooperation from AI perspective]], [[http://videolectures.net/ess06_picard_sppvc|Social protocols in Professional Virtual Communities]], [[http://videolectures.net/eccs07_chavalarias_sma|Science mapping with asymmetric co-occurence analysis]]\n\n ----\n ----\n\n == 7. Architectures and Platforms - General public training\n\n**Description:**Focusing on research coordination in the area of Architecture & Platforms. Show basic internet and computer technologies, ideas, and concepts for enterprise interoperability purposes and to continue on updating with state-of-the-art models, approaches and mechanisms.\n\n**Key concepts:** Computer networks basics. Base Internet technologies, Emerging computing models and implementation approaches\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_7_Architectures_and_Platforms_General.pdf|Architectures and Platforms - course]]\n\n**Suggested video lectures:**  [[http://videolectures.net/iesa08_gionis_aha|The Advantages of Hybrid Architectural Approaches for the Integrating Middleware by George Gionis]], [[http://videolectures.net/iesa08_ullberg_eas|Enterprise Architecture: A Service Interoperability Analysis Framework by Johan Ullberg]], [[http://videolectures.net/ess07_negretto_ii|ICT infrastructure by\nUgo Negretto]], [[http://videolectures.net/ess07_hodik_atv|Agent technologies for VE + SW demonstrations: MAS Tutorial by Ji\u0159\u00ed Hod\u00edk]], [[http://videolectures.net/ess06_nagellen_soa|Service Oriented Architectures by Thierry Nagellen]]\n\n ----\n ----\n\n == 8. Background Technologies - General public training\n\n**Description:** This course presents and explains core technologies from the area of knowledge technologies that ranges from the data driven methods to knowledge driven methods and are important for detecting, analyzing and managing knowledge (tacit and explicit) in enterprises, organisations or agents.\n\n**Key concepts:** Traditional technologies\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_8_Background_Technologies_General.pdf| Background Technologies - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/kdd07_fayyad_dms|A Data Miner\u2019s Story \u2013 Getting to Know the Grand Challenges by Usama Fayyad ]], [[http://videolectures.net/ssll09_kotagiri_dami|Data Mining by Rao Kotagiri]], [[http://videolectures.net/stanfordcs229f08_ng_lec01| Lecture 1 - The Motivation & Applications of Machine Learning by Andrew Ng]], [[http://videolectures.net/iswc08_hendler_ittsw|Introduction to the Semantic Web by Aldo Gangemi, Sean Bechhofer, Asunci\u00f3n G\u00f3mez-P\u00e9rez, Jim Hendler]], [[http://videolectures.net/ess07_jermol_ktno|Knowledge technologies for network organisations by Mitja Jermol]]\n\n**Additional video lectures:**[[http://videolectures.net/psm08_cristianini_ieb/|In the Eye of the Beholder? Another look at Cognitive Systems]], [[http://videolectures.net/ijcai09_lesser_saitmao/|Scaling AI Through Multi-Agent Organizations]], [[http://videolectures.net/ccss09_pietronero_soafse/|Self-Organization and Finite Size Effects in Agent Models for Financial Markets]], [[http://videolectures.net/ccss09_steubing_atcf/|Assessing the Critical Factors that Determine the Availability of Wood Fuel in Switzerland with an Agent Based Model]]\n----\n----\n\n == 9. COIN Solution - General public training\n\n**Description:** This is one of the main courses in COIN training programmes. It is aimed at presenting COIN innovative  solutions that will be developed in the frame of the project. The main focus is on the explanation and demonstration of technologies developed in COIN.\n\n**Key concepts:** Basic architecture, Introduction to COIN Enterprise Interoperability services, Introduction to COIN Enterprise Collaboration services\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_9_COIN_solution_Introduction_General.pdf| COIN solution - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/coinactivess2010_jansson_ccs|COIN Collaborative Services by Kim Jansson ]], [[http://videolectures.net/coinactivess2010_sitek_ure|User requirements elicitation adapting Serious Gaming approach by Patrick Sitek]], [[http://videolectures.net/coinactivess2010_sesana_cpd|COIN Platform Demonstration by Michele Sesana]], [[http://videolectures.net/coinactivess2010_fischer_cbs|COIN Baseline services and negotiation support by Klaus Fischer]], [[http://videolectures.net/coinplanetdataschool2011_sesana_coin/|Technical and Business Innovation\nby Michele Sesana]]\n\n ----\n ----\n\n== 10. Practical Examples and COIN prototypes - General public training\n\n**Description:** In this course the practical examples of COIN prototypes will be demonstrated and explained together with some applications that are related to the COIN research domain. The course will be supplemented with videos at the COIN IP page to allow participants to deal with concrete examples from their work context.\n\n**Key concepts:** use scenarios, demonstrators, demos, prototypes\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_10_Practical_Examples_and_COIN_prototipes_General.pdf|Practical Examples and COIN prototypes - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ice09_olmo_coincpds|COIN Collaborative Product Development Services by Alberto Olmo]], [[http://videolectures.net/coinplanetdataschool2011_sesana_demos/|COIN System Demos by Michele Sesana]], [[http://videolectures.net/ice09_canepa_isurf|iSURF \u2013 Piacenza Knitwear Business Case by Alessandro Canepa]], [[http://videolectures.net/cgm09_komazec_cspwho|COIN Service Platform with hands-on by Srdjan Komazec]], [[http://videolectures.net/coinplanetdataschool2011_oman_usage|Usage of Integrated Services in the industry by\nSimon Oman]]\n\n ----\n ----\n\n == 11. Information Management - N/A for General public\n\n ----\n ----\n\n == 12. Information Exchange Standards - General public training\n\n**Description:** A number of standards particularly relevant for collaborative networks and enterprise interoperability are introduced and analyzed.\n\n**Key concepts:** Importance of standards\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_12_Information_Exchange_Standards_General.pdf|Information Exchange Standards - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/efreight2011_rantasila_pilli_sihvola_logistics|Logistics-related information exchange - international exchange - international efforts and Finnish developments by Karri Rantasila, Eetu Pilli-Sihvola]], [[http://videolectures.net/kdd2010_zheng_udmt|Using Data Mining Techniques to Address Critical Information Exchange Needs in Disaster Affected Public-Private Networks by Li Zheng]], [[http://videolectures.net/ict08fr_nagy_rothengass_eiu|The Expanding Information Universe: New Trends, New Forms, New Usages\nby Marta Nagy-Rothengass]], [[http://videolectures.net/ecml07_smyth_api|Adventures in Personalized Information Access by Barry Smyth]], [[http://videolectures.net/forum2010_glenn_gcisd|Global Challenges and Information Society Development by Jerome C. Glenn]]\n\n ----\n ----\n\n == 13. Coordination Mechanisms - General public training\n\n**Description:** This course is aimed at providing knowledge about the models, structures and mechanisms for management, coordination and problem solving. The coordination mechanisms are basic mechanisms in any networked organisation and as such the focal point of interest for any distributed, knowledge focused organisation.\n\n**Key concepts:** Collaboration modalities\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_13_Coordination_Mechanisms_General.pdf|Coordination Mechanisms - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/eccs07_stark_cpc|Combined Problems of Cooperation and Coordination by Hans-Ulrich Stark]], [[http://videolectures.net/eccs07_menczer_wcn|Web Click Network\nby Filippo Menczer]], [[http://videolectures.net/eccs07_matteo_gld|Global and Local Dynamics in Correlated Systems by Tiziana Di Matteo]], [[http://videolectures.net/iesa08_wings_csit|Challenges and Strategies for IT Services in Heterogeneous Enterprise Environments by Sujit Wings]]\n\n ----\n ----\n\n == 14. Management of common Ontologies - General public training\n\n**Description:** This course is aimed at providing the base concepts of ontologies, especially in relation to the COIN common ontology, explore the potential of ontology-based techniques to tackle the problem of interoperability.\n\n**Key concepts:** The role of ontologies in collaboration\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_14_Management_of_common_Ontologies_General.pdf|Management of common Ontologies - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/ess07_grobelnik_twdmI|Text and web data mining by Marko Grobelnik]], [[http://videolectures.net/iesa08_dahlem_osm|Ontology-driven Semantic Mapping by Nikolai Dahlem]], [[http://videolectures.net/mmdss07_grobelnik_oml|Ontologies and Machine Learning by Marko Grobelnik, Bla\u017e Fortuna]], [[http://videolectures.net/ess07_obitko_oswve|Ontologies, semantic web and VE by Marek Obitko]], [[http://videolectures.net/tao08_bontcheva_tao|Transitioning Applications to Ontologies by Kalina Bontcheva]]\n\n ----\n ----\n\n == 15. e-Commerce and e-Markets - General public training\n\n**Description:** This course will in particular investigate aspects related to the economics and the incentives behind Interoperability.\n\n**Key concepts:** Concepts of e-Commerce and e-Market\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_15_E-Commerce_and_E-Markets_General.pdf|E-commerce and E-markets - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/echallenges2010_li_intro|Business Models Background\nMan-Sze Li ]], [[http://videolectures.net/ice09_canepa_isurf|iSURF \u2013 Piacenza Knitwear Business Case\nby Alessandro Canepa]], [[http://videolectures.net/ice09_withalm_cdcp|Business Cases for Enterprise Interoperability Collaborative Demand Capacity Planning (CDCP) by Josef Withalm]], [[http://videolectures.net/coinplanetdataschool2011_hristov_media| Innovative collaboration in Media \u2013 \u000ba COIN case in EEU by Konstantin Hristov]], [[http://videolectures.net/echallenges2010_suttner_tnb|Towards New Business Models in the Energy Sector based on Software-as-a-Service-Utilities and Value-added Services\nby Hannes Suttner]]\n\n ----\n ----\n\n == 16. Non Technological Issues -  - N/A for General public\n\n----\n----\n\n == 17. Organisation Modeling and Reference Models - General public training\n\n**Description:** The course topic is focusing on Organisation Modelling as a combination of a set of activities within an enterprise with a structure describing their logical order and dependence whose objective is to produce a desired result. Business Process modeling as an enabler of common understanding and analysis of a business process. The course will also describe the main process modeling techniques.\n\n**Key concepts:** Concept of reference model\n\n**Download the course:**\n\n **Suggested video lectures:** [[http://videolectures.net/eccs07_stark_cpc|Combined Problems of Cooperation and Coordination by Hans-Ulrich Stark ]], [[http://videolectures.net/eccs07_menczer_wcn|Web Click Network by Filippo Menczer]], [[http://videolectures.net/eccs07_matteo_gld|Global and Local Dynamics in Correlated Systems by Tiziana Di Matteo]]\n\n ----\n ----\n\n == 18. Emerging Collaborative Forms - General public training\n\n**Description:** Brief summary of the various collaborative forms studied in previous units, a discussion of possible new models and generalizations is made. As a starting basis, new forms of collaborative e-government, e-science, Virtual institutes, Virtual laboratories, etc, are discussed. Other generalizations include: networks of sensors, networks of machines, etc.\n\n**Key concepts:** Summary of studied collaborative forms and interoperability approaches, New application examples: collaborative e-government, e-Science, Virtual institutes, Virtual Labs, etc., Internet of Things: Networks of machines, networks of sensors., Intelligent, self-aware enterprises, Symbiotic models, Other emerging cases.\n\n**Download the course:** [[http://analytics.ijs.si/~mitja/Courses/Coin_general/Course_18_Emerging_Collaborative_Forms_General.pdf|Emerging Collaborative Forms - course]]\n\n**Suggested video lectures:** [[http://videolectures.net/eccs07_newman_sdc|Structure and Dynamics in Complex Networks by Mark Newman ]], [[http://videolectures.net/eccs07_verschure_dac|Distributive Adaptive Control: A Real-world Cognitive Architecture applied to Robots, Spaces and Avatares by Paul Verschure]], [[http://videolectures.net/eccs07_stamatiou_dtc|The \"Digital Territory\" as a Complex System of Interacting Agents, Emergent Properties and Technologies by Yannis Stamatiou ]], [[http://videolectures.net/esocenet07_borjeson_enl|European Network of Livin Labs by Mikael B\u00f6rjeson]], [[http://videolectures.net/coinactivess2010_kropp_sol|Smart Objects Innovation Lab: Theory and practice - hand in hand by Sebastian Kropp]],\n\n **Additional video lectures:**\n *[[http://videolectures.net/eccs07_canright_smn|Self-mapping Networks]]\n *[[http://videolectures.net/porto05_cordeiro_sc|Semiotics in CNOs]]\n *[[http://videolectures.net/eccs07_damiani_irb|Interacting Random Boolean Networks]]\n *[[http://videolectures.net/eccs07_jiang_pba|Population-based adaptive Systems: An Implementation in NEW TIES]]", "recorded": "2010-01-31T18:35:34", "title": "COIN - General public training/promotion  section"}]