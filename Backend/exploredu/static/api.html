<html>
<head>
</head>
<body>
<a aria-hidden="true" href="#overview" class="anchor" id="user-content-overview"><span class="octicon octicon-link"></span></a>Overview</h2>

<p>ExplorEdu offers RESTful API access to integrated Open Educational data.
The api is available here: <a href="http://exploredu.ijs.si/api">http://exploredu.ijs.si/api</a>.
The demo of ExEdu: <a href="http://exploredu.ijs.si">http://exploredu.ijs.si</a></p>

<h2>
<a aria-hidden="true" href="#api-index" class="anchor" id="user-content-api-index"><span class="octicon octicon-link"></span></a>API index</h2>

<ul>
<li><a href="#researchers-search-by-keywords">Researchers search by keywords</a></li>
<li><a href="#projects-search-by-keywords">Projects search by keywords</a></li>
<li><a href="#organizations-search-by-keywords">Organizations search by keywords</a></li>
<li><a href="#projects-search-by-keywords">Videos search by keywords</a></li>
<li><a href="#joint-researchers,-projects-and-videos-search-by-keyword">Joint researchers, projects and videos search by keywords</a></li>
<li><a href="#researchers-keywords-search">Researchers-keywords-search</a></li>
<li><a href="#keywords-autocomplete">Keywords-autocomplete</a></li>
<li><a href="#keywords-related-by-researchers">Keywords-related-by-researchers</a></li>
<li><a href="#composition-of-classification-of-a-set-of-researchers-retrieved-by-a-keyword">Composition-of-classification-of-a-set-of-researchers-retrieved-by-a-keyword</a></li>
<li><a href="#event-registry-news">Event Registry news</a></li>
<li><a href="#sio-educationa-material">SIO Educational Material</a></li>
<li><a href="#sio-educationa-material-advaced-search">SIO Educational Material Advanced Search</a></li>
<li><a href="#sio-categories">SIO Categories</a></li>
<li><a href="#collaboration-network">Collaboration network</a></li>
<li><a href="#project-frequencies">Project frequencies</a></li>
<li><a href="#get-all-legislation">Get All Legislation</a></li>
<li><a href="#get-legislation">Get Legislation</a></li>
<li><a href="#get-ods">Get ODS</a></li>
<li><a href="#oer-commons">OER Commons</a></li>
</ul>

<h2>
<a aria-hidden="true" href="#api" class="anchor" id="user-content-api"><span class="octicon octicon-link"></span></a>API</h2>

<h3>
<a aria-hidden="true" href="#researchers-search-by-keywords" class="anchor" id="user-content-researchers-search-by-keywords"><span class="octicon octicon-link"></span></a>Researchers search by keywords</h3>

<p>Get researchers indexed by keywords describing their profile</p>

<h4>
<a aria-hidden="true" href="#call" class="anchor" id="user-content-call"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/rsr/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example" class="anchor" id="user-content-example"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/rsr/text%20mining">http://exploredu.ijs.si/api/rsr/text%20mining</a></p>

<h4>
<a aria-hidden="true" href="#result" class="anchor" id="user-content-result"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"scienceCode": "T", "science": "Engineering sciences and technologies", "subfield": "Intelligent systems - software", "lname": "Janez", "field": "Computer science and informatics", "mstid": "22278", "fname": "Brank", "id": "15188"}, {"scienceCode": "T", "science": "Engineering sciences and technologies", "subfield": "Intelligent systems - software", "lname": "Dunja", "field": "Computer science and informatics", "mstid": "12570", "fname": "Mladeni\u0107", "id": "7778"}]
</code></pre>

<h3>
<a aria-hidden="true" href="#projects-search-by-keywords" class="anchor" id="user-content-projects-search-by-keywords"><span class="octicon octicon-link"></span></a>Projects search by keywords</h3>

<p>Get projects indexed by keywords, abstract, world and domestic significance.</p>

<h4>
<a aria-hidden="true" href="#call-1" class="anchor" id="user-content-call-1"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/prj/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-1" class="anchor" id="user-content-example-1"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/prj/text%20mining">http://exploredu.ijs.si/api/prj/text%20mining</a></p>

<h4>
<a aria-hidden="true" href="#result-1" class="anchor" id="user-content-result-1"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"startdate": "1.8.2013", "mstid": "J2-5480", "enddate": "31.7.2016", "name": "Conquering the Curse of Dimensionality by Using Background Knowledge"}, {"startdate": "1.5.2010", "mstid": "J6-3600", "enddate": "30.4.2013", "name": "SLOVENIAN PROVERBS AS CULTURAL HERITAGE: CLASIFICATION AND CORPUS EDITING"}, {"startdate": "1.7.2011", "mstid": "L7-4119", "enddate": "30.6.2014", "name": "Co-authorship networks of slovenian scholars: Theoretical analysis and visualization user interface development"}, {"startdate": "1.5.2011", "mstid": "Z7-4083", "enddate": "31.7.2014", "name": "Language technologies for detecting the author's personal profile"}, {"startdate": "1.7.2014", "mstid": "J6-6842", "enddate": "30.6.2017", "name": "Resources, Tools and Methods for the Research of Nonstandard Internet Slovene"}, {"startdate": "1.8.2013", "mstid": "J5-5552", "enddate": "31.7.2016", "name": "Model for Domain-Specific Trend Prediction based on Semantic Enrichment of Unstructured Patterns"}]
</code></pre>

<h3>
<a aria-hidden="true" href="#organizations-search-by-keywords" class="anchor" id="user-content-organizations-search-by-keywords"><span class="octicon octicon-link"></span></a>Organizations search by keywords</h3>

<p>Get Organizations indexed by name.</p>

<h4>
<a aria-hidden="true" href="#call-2" class="anchor" id="user-content-call-2"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/org/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-2" class="anchor" id="user-content-example-2"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/org/chemistry">http://exploredu.ijs.si/api/org/chemistry</a></p>

<h4>
<a aria-hidden="true" href="#result-2" class="anchor" id="user-content-result-2"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"city": "Ljubljana", "name": "Center of excellence for integrated approaches in chemistry and biology of proteins, Ljubljana", "science": "Natural sciences and mathematics"}, {"city": "Ljubljana", "name": "National Institute of Chemistry", "science": "Natural sciences and mathematics"}, {"city": "Ljubljana", "name": "University of Ljubljana, Faculty of Chemistry and Chemical Technology", "science": "Natural sciences and mathematics"}, {"city": "Maribor", "name": "University of Maribor, Faculty of Chemistry and Chemical Engineering", "science": "Natural sciences and mathematics"}]
</code></pre>

<h3>
<a aria-hidden="true" href="#videos-search-by-keywords" class="anchor" id="user-content-videos-search-by-keywords"><span class="octicon octicon-link"></span></a>Videos search by keywords</h3>

<p>Get videos indexed by descriptions.</p>

<h4>
<a aria-hidden="true" href="#call-3" class="anchor" id="user-content-call-3"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/lec/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-3" class="anchor" id="user-content-example-3"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/lec/text%20mining">http://exploredu.ijs.si/api/lec/text%20mining</a></p>

<h4>
<a aria-hidden="true" href="#result-3" class="anchor" id="user-content-result-3"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"url": "is02_mladenic_ddsdm", "desc": "", "recorded": "2002-10-15T00:00:00", "title": "Describing Decision Support, Darta Mining, and Text/Web Mining Studies in SolEuNet"}, {"url": "acai05_grobelnik_tm", "desc": "", "recorded": "2005-07-02T11:00:00", "title": "Text mining"}, {"url": "acai05_mladenic_tm", "desc": "", "recorded": "2005-07-02T11:00:00", "title": "Text mining"}, {"url": "reasecs_maynard_tmsw", "desc": "This hour-long tutorial gives an introduction to text mining issues for the Semantic Web, covering topics such as what text mining is, an introduction to information extraction and how it can be adapted for the Semantic Web, evaluation and visualisation tools and techniques. It is intended primarily for undergraduate and postgraduate students, but could equally serve as a learning tool for researchers new to the area of Human Language Technology and the Semantic Web.\r\n\r\nDocuments:\r\n;[[Text_mining.ppt]]\r\n;[[Text_mining.pdf]]", "recorded": "2005-03-09T00:00:00", "title": "Text mining and the Semantic Web"}, {"url": "translingeu2010_ananiadou_bmtm", "desc": "", "recorded": "2010-06-04T18:00:00", "title": "Biomedical text mining"}, {"url": "mlss07_klinger_tmi", "desc": "", "recorded": "2007-08-24T14:30:58", "title": "Text Mining in Biological Texts"}, {"url": "sab04_grobelnik_tmol", "desc": "", "recorded": "2004-05-13T00:00:00", "title": "Text Mining for Ontology Learning"}, {"url": "training06_grobelnik_tmol", "desc": "", "recorded": "2004-01-21T12:00:00", "title": "Text Mining for Ontology Learning"}, {"url": "ess07_grobelnik_twdmI", "desc": "", "recorded": "2007-09-07T08:30:00", "title": "Text and web data mining"}, {"url": "active09_grobelnik_tmlws", "desc": "", "recorded": "2009-09-04T16:00:00", "title": "Text Mining and Light Weight Semantics"}, {"url": "psm08_ferlez_tms", "desc": "", "recorded": "2008-01-29T17:50:00", "title": "Text mining for semantically enabled social browsing"}, {"url": "basys04_bednar_jlstm", "desc": "", "recorded": "2004-09-01T12:00:00", "title": "Java library for support of text mining and retrieval"}, {"url": "ecmlpkdd2011_tsatsaronis_mining", "desc": "Due to the nature of textual data the application of association rule mining in text corpora\r\nhas attracted the focus of the research scientific community for years. In this paper we\r\ndemonstrate a system that can efficiently mine association rules from text. The system annotates\r\nterms using several annotators, and extracts text association rules between terms\r\nor categories of terms. An additional contribution of this work is the inclusion of novel\r\nunsupervised evaluation measures for weighting and ranking the importance of the text\r\nrules. We demonstrate the functionalities of our system with two text collections, a set of\r\nWikileaks documents, and one from TREC-7.", "recorded": "2011-09-05T19:50:00", "title": "TRUMIT: A Tool to Support Large-Scale Mining of Text Association Rules"}, {"url": "ascc2013_lavrac_discovery", "desc": "", "recorded": "2013-11-19T09:00:00", "title": "Text mining for Creative Cross-Domain Knowledge Discovery"}, {"url": "aibootcamp2011_grobelnik_tmla", "desc": "", "recorded": "2011-02-14T11:30:00", "title": "Text Mining and Link Analysis for Web and Semantic Web"}, {"url": "mlas06_murphy_cs", "desc": "", "recorded": "2006-09-26T00:00:00", "title": "Joint Mining of Biological Text and Images: Case Studies"}, {"url": "mlss06tw_zhang_pmtm", "desc": "I will give a general overview of using prediction methods in text mining applications, including text categorization, information extraction, summarization, and question answering. I will then discuss some of the more advanced issues encountered in real applications such as structured and complicated output classification, the use of unlabeled data, modeling link structures, collective inference and community effect, and transfer learning under changing environment, etc.", "recorded": "2006-07-26T00:00:00", "title": "Predictive methods for Text mining"}, {"url": "mlsb09_saeys_incu", "desc": "", "recorded": "2009-09-05T10:25:00", "title": "Integrated Network Construction Using\u000b Event Based Text Mining"}, {"url": "icml05_fortuna_tuo", "desc": "", "recorded": "2005-08-07T00:00:00", "title": "The use of machine translation tools for cross-lingual text-mining "}, {"url": "epacseminar2013_rakauskas_corruption", "desc": "", "recorded": "2013-10-28T16:00:00", "title": "Text mining techniques and methods used in tender, fraud and corruption cases"}, {"url": "kdd07_wang_mcbtp", "desc": "Previous work on text mining has almost exclusively focused on a single stream. However, we often have available multiple text streams indexed by the same set of time points (called coordinated text streams), which offer new opportunities for text mining. For example, when a major event happens, all the news articles published by different agencies in different languages tend to cover the same event for a certain period, exhibiting a correlated bursty topic pattern in all the news article streams. In general, mining correlated bursty topic patterns from coordinated text streams can reveal interesting latent associations or events behind these streams.\n\nIn this paper, we define and study this novel text mining problem. We propose a general probabilistic algorithm which can effectively discover correlated bursty patterns and their bursty periods across text streams even if the streams have completely different vocabularies (e.g., English vs Chinese). Evaluation of the proposed method on a news data set and a literature data set shows that it can effectively discover quite meaningful topic patterns from both data sets: the patterns discovered from the news data set accurately reveal the major common events covered in the two streams of news articles (in English and Chinese, respectively), while the patterns discovered from two database publication streams match well with the major research paradigm shifts in database research. Since the proposed method is general and does not require the streams to share vocabulary, it can be applied to any coordinated text streams to discover correlated topic patterns that burst in multiple streams in the same period.", "recorded": "2007-08-14T10:12:25", "title": "Mining Correlated Bursty Topic Patterns from Coordinated Text Streams "}, {"url": "cidu2011_khan_classification", "desc": "With the advent and expansion of social networking, the amount of generated text\r\ndata has seen a sharp increase. In order to handle such a huge volume of text data, new and\r\nimproved text mining techniques are a necessity. One of the characteristics of text data that makes text mining difficult, is multi-labelity. In order to build a robust and effective text classification method which is an integral part of text mining research, we must consider this property more closely. This kind of property is not unique to text data as it can be found in non-text (e.g., numeric) data as well. However, in text data, it is most prevalent. This property also puts the text classification problem in the domain of multi-label classification (MLC), where each instance is associated with a subset of class-labels instead of a single class, as in conventional classification. In this paper, we explore how the generation of pseudo labels (i.e., combinations of existing class labels) can help us in performing better text classification and under what kind of circumstances. During the classification, the high and sparse dimensionality of text data has also been considered. Although, here we are proposing and evaluating a text classification technique, our main focus is on the handling of the multi-labelity of text data while utilizing the correlation among multiple labels existing in the data set. Our text classification technique is called pseudo-LSC (pseudo-Label Based Subspace Clustering). It is a subspace clustering algorithm that considers the high and sparse dimensionality as well as the correlation among different class labels during the classification process to provide better performance than existing approaches. Results on three real world multi-label data sets provide us insight into how the multi-labelity is handled in our classification process\r\nand shows the effectiveness of our approach.", "recorded": "2011-10-20T13:50:00", "title": "Pseudo-Label Generation for Multi-Label Text Classification"}, {"url": "ijcai09_mladenic_grobelnik_tmala", "desc": "The tutorial on Text Mining and Link Analysis for Web Data will focus on two main analytical approaches when analyzing web data: text mining and link analysis for the purpose of analyzing web documents and their linkage. First, the tutorial will cover some basic steps and problems when dealing with the textual and network (graph) data showing what is possible to achieve without very sophisticated technology. The idea of this first part is to present the nature of unstructured and semi-structured data. Next, in the second part, more sophisticated methods for solving more difficult and challenging problems will be shown. In the last part, some of the current open research issues will be presented and some practical pointers on the available tolls for solving previously mentioned problems will be provided.", "recorded": "2009-07-12T14:00:00", "title": "Text Mining and Link Analysis"}, {"url": "kdd07_grobelnik_tmala", "desc": "The tutorial on Text Mining and Link Analysis for Web Data will focus on two main analytical approaches when analyzing web data: text mining and link analysis for the purpose of analyzing web documents and their linkage. First, the tutorial will cover some basic steps and problems when dealing with the textual and network (graph) data showing what is possible to achieve without very sophisticated technology. The idea of this first part is to present the nature of un-structured and semi-structured data. Next, in the second part, more sophisticated methods for solving more difficult and challenging problems will be shown. In the last part, some of the current open research issues will be presented and some practical pointers on the available tolls for solving previously mentioned problems will be provided. \r\n \r\n ", "recorded": "2007-08-12T14:00:00", "title": "Text Mining and Link Analysis for Web and Semantic Web"}, {"url": "kdd07_fortuna_tmla", "desc": "The tutorial on Text Mining and Link Analysis for Web Data will focus on two main analytical approaches when analyzing web data: text mining and link analysis for the purpose of analyzing web documents and their linkage. First, the tutorial will cover some basic steps and problems when dealing with the textual and network (graph) data showing what is possible to achieve without very sophisticated technology. The idea of this first part is to present the nature of un-structured and semi-structured data. Next, in the second part, more sophisticated methods for solving more difficult and challenging problems will be shown. In the last part, some of the current open research issues will be presented and some practical pointers on the available tolls for solving previously mentioned problems will be provided. ", "recorded": "2007-08-13T17:00:00", "title": "Text Mining and Link Analysis for Web and Semantic Web - Ontogen Demo"}, {"url": "mlss04_hofmann_irtm", "desc": "This four hour course will provide an overview of applications of machine learning and statistics to problems in information retrieval and text mining. More specifically, it will cover tasks like document categorization, concept-based information retrieval, question-answering, topic detection and document clustering, information extraction, and recommender systems. The emphasis is on showing how machine learning techniques can help to automatically organize content and to provide efficient access to information in textual form.", "recorded": "2004-09-14T00:00:00", "title": "Information Retrieval and Text Mining"}, {"url": "mlss06au_hofmann_irtm", "desc": "This four hour course will provide an overview of applications of machine\r learning and statistics to problems in information retrieval and text\r mining. More specifically, it will cover tasks like document categorization,\r concept-based information retrieval, question-answering, topic detection and\r document clustering, information extraction, and recommender systems. The\r emphasis is on showing how machine learning techniques can help to\r automatically organize content and to provide efficient access to\r information in textual form.", "recorded": "2006-02-16T00:00:00", "title": "Information Retrieval and Text Mining"}, {"url": "iswc06_sumida_cires", "desc": "", "recorded": "2006-11-06T00:00:00", "title": "Web Content Mining with Human Language Technologies: Concept-Instance Relation Extraction from Simple Noun Sequences Using a Full-Text Search Engine"}, {"url": "kdd2014_han_wang_el_kishky_structure_text", "desc": "Mining phrases, entity concepts, topics, and hierarchies from massive text corpus is an essential problem in the age of big data. Text data in electronic forms are ubiquitous, ranging from scientific articles to social networks, enterprise logs, news articles, social media and general web pages. It is highly desirable but challenging to bring structure to unstructured text data, uncover underlying hierarchies, relationships, patterns and trends, and gain knowledge from such data. In this tutorial, we provide a comprehensive survey on the state-of-the art of data-driven methods that automatically mine phrases, extract and infer latent structures from text corpus, and construct multi-granularity topical groupings and hierarchies of the underlying themes. We study their principles, methodologies, algorithms and applications using several real datasets including research papers and news articles and demonstrate how these methods work and how the uncovered latent entity structures may help text understanding, knowledge discovery and management.", "recorded": "2014-08-24T09:00:00", "title": "Bringing Structure to Text: Mining Phrases, Entity Concepts, Topics, and Hierarchies"}, {"url": "kdd2010_elder_tmft", "desc": "If your health and finances are sufficiently poor, the Social Security Administration will send you taxpayer dollars to help out. But, applying and qualifying can be a long and frustrating process - sometimes taking up to two years! In the meantime, your health and finances are undoubtedly worsening. (Likely the reason half of those appealing a rejection eventually get approved; the lack of timely help ensures their deterioration.) Yet, by mining the important text of the applications, the SSA can identify those most likely to be approved upon analyst review, and put them in a much more efficient fast track - helping all applicants. The solution involves text extraction, token collocation, Bayesian inference, and a new way to combine evidence.", "recorded": "2010-07-26T14:45:00", "title": "Text Mining to Fast-Track Deserving Disability Applicants"}, {"url": "ecmlpkdd2010_baeza_yates_wm", "desc": "The Web continues to grow and evolve very fast, changing our daily lives. This activity represents the collaborative work of the millions of institutions and people that contribute content to the Web as well as the one billion people that use it. In this ocean of hyperlinked data there is explicit and implicit information and knowledge. Web Mining is the task of analyzing this data and extracting information and knowledge for many different purposes. The data comes in three main flavors: content (text, images, etc.), structure (hyperlinks) and usage (navigation, queries, etc.), implying different techniques such as text, graph or log mining. Each case reflects the wisdom of some group of people that can be used to make the Web better. For example, user generated tags in Web 2.0 sites. The tutorial covers (a) the main concepts behind Web mining, the different data that is found in the Web and typical applications; (b) the mining process: data recollection, data cleaning, data warehousing and data analysis, including crawling in the case of content mining, and privacy issues in the case of usage mining; (c) the main techniques used for the different data types; and (d) use cases of the three types: content, structure and usage mining, ranging from Web site design to search engines.", "recorded": "2010-09-24T10:30:00", "title": "Web mining"}, {"url": "russir2010_baeza_yates_wdm", "desc": "The Web continues to grow and evolve very fast, changing our daily lives. This activity represents the collaborative work of the millions of institutions and people that contribute content to the Web as well as the one billion people that use it. In this ocean of hyperlinked data there is explicit and implicit information and knowledge.\\\\\r\nWeb Mining is the task of analyzing this data and extracting information and knowledge for many different purposes. The data comes in three main flavors: content (text, images, etc.), structure (hyperlinks) and usage (navigation, queries, etc.), implying different techniques such as text, graph or log mining. Each case reflects the wisdom of some group of people that can be used to make the Web better. For example, user generated tags in Web 2.0 sites.\\\\\r\nThe tutorial covers (a) the main concepts behind Web mining, the different data that is found in the Web and typical applications; (b) the mining process: data recollection, data cleaning, data warehousing and data analysis, including crawling in the case of content mining, and privacy issues in the case of usage mining; (c) the main techniques used for the different data types; and (d) use cases of the three types: content, structure and usage mining, ranging from Web site design to search engines. ", "recorded": "2010-09-14T11:00:00", "title": "Web Data Mining"}, {"url": "ijcai2011_t16_mining", "desc": "The Web continues to grow and evolve very fast, changing our daily lives. This activity represents the collaborative work of the millions of institutions and people that contribute content to the Web as well as the one billion people that use it. In this ocean of hyperlinked data there is explicit and implicit information and knowledge. Web Mining is the task of analyzing this data and extracting information and knowledge for many different purposes. The data comes in three main flavors: content (text, images, etc.), structure (hyperlinks) and usage (navigation, queries, etc.), implying different techniques such as text, graph or log mining. Each case reflects the wisdom of some group of people that can be used to make the Web better, for example, user generated tags in Web 2.0 sites. In this tutorial we will walk through the mining process and will show several applications, ranging from Web site design to search engines. The main goal is to introduce AI researchers to the myriad of challenges in Web mining, where other AI techniques, in addition to machine learning, might be applicable.", "recorded": "2011-07-17T00:00:00", "title": "Web Mining"}, {"url": "ecmlpkdd09_ikeda_mpcfsstdubt", "desc": "We consider mining unusual patterns from text T. Unlike existing methods which assume probabilistic models and use simple estimation methods, we employ a set B of background text in addition to T and compositions w=xy of x and y as patterns. A string w is peculiar if there exist x and y such that w=xy, each of x and y is more frequent in B than in T, and conversely w=xy is more frequent in T. The frequency of xy in T is very small since x and y are infrequent in T, but xy is relatively abundant in T compared to xy in B. Despite these complex conditions for peculiar compositions, we develop a fast algorithm to find peculiar compositions using the suffix tree. Experiments using DNA sequences show scalability of our algorithm due to our pruning techniques and the superiority of the concept of the peculiar composition.", "recorded": "2009-09-09T11:50:00", "title": "Mining Peculiar Compositions of Frequent Substrings from Sparse Text Data Using Background Texts"}, {"url": "wsdm2011_kotov_mne", "desc": "In this work, we study a new text mining problem of discovering named entities with temporally correlated bursts of mention counts in multiple multilingual Web news streams. Mining named entities with temporally correlated bursts of mention counts in multilingual text streams has many interesting and important applications, such as identification of the latent events, attracting the attention of on-line media in different countries, and valuable linguistic knowledge in the form of transliterations. While mining \"bursty\" terms in a single text stream has been studied before, the problem of detecting terms with temporally correlated bursts in multilingual Web streams raises two new challenges: (i) correlated terms in multiple streams may have bursts that are of different orders of magnitude in their intensity and (ii) bursts of correlated terms may be separated by time gaps. We propose a two-stage method for mining items with temporally correlated bursts from multiple data streams, which addresses both challenges. In the first stage of the method, the temporal behavior of different entities is normalized by modeling them with the Markov-Modulated Poisson Process. In the second stage, a dynamic programming algorithm is used to discover correlated bursts of different items, that can be potentially separated by time gaps. We evaluated our method with the task of discovering transliterations of named entities from multilingual Web news streams. Experimental results indicate that our method can not only effectively discover named entities with correlated bursts in multilingual Web news streams, but also outperforms two state-of-the-art baseline methods for unsupervised discovery of transliterations in static text collections.", "recorded": "2011-02-12T11:00:00", "title": "Mining Named Entities with Temporally Correlated Bursts from Multilingual Web News Streams"}, {"url": "cidu2011_malin_annotation", "desc": "Text analysis is important for effective information retrieval from databases where the critical information is embedded in text fields. Aerospace safety depends on effective retrieval of relevant and related problem reports for the purpose of trend analysis. The complex text syntax in problem descriptions has limited statistical text mining of problem reports. This presentation describes an intelligent tagging approach that applies syntactic and then semantic analysis to overcome this problem. The tags identify types of problems and equipment that are embedded in the text descriptions. The power of these tags is illustrated in a faceted searching and browsing interface for problem report trending that combines automatically generated tags with database code fields and temporal information.", "recorded": "2011-10-19T14:00:00", "title": "Semantic Annotation of Complex Text Structures in Problem Reports"}, {"url": "kdd09_chen_edcf", "desc": "One common predictive modeling challenge occurs in text mining problems is that the training data and the operational (testing) data are drawn from different underlying distributions. This poses a great difficulty for many statistical learning methods. However, when the distribution in the source domain and the target domain are not identical but related, there may exist a shared concept space to preserve the relation. Consequently a good feature representation can encode this concept space and minimize the distribution gap. To formalize this intuition, we propose a domain adaptation method that parameterizes this concept space by linear transformation under which we explicitly minimize the distribution difference between the source domain with sufficient labeled data and target domains with only unlabeled data, while at the same time minimizing the empirical loss on the labeled data in the source domain. Another characteristic of our method is its capability for considering multiple classes and their interactions simultaneously. We have conducted extensive experiments on two common text mining problems, namely, information extraction and document classification to demonstrate the effectiveness of our proposed method.\r\n", "recorded": "2009-06-29T17:16:00", "title": "Extracting Discriminative Concepts for Domain Adaptation in Text Mining"}, {"url": "kdd2014_etzioni_data_mining", "desc": "Deep learning has catapulted to the front page of the New York Times, formed the core of the so-called 'Google brain', and achieved impressive results in vision, speech recognition, and elsewhere. Yet researchers have offered simple conundrums that deep learning doesn't address. For example, consider the sentence: 'The large ball crashed right through the table because it was made of Styrofoam.' What was made of Styrofoam? The large ball? Or the table? The answer is obviously 'the table', but if we change the word 'Styrofoam' to 'steel', the answer is clearly 'the large ball'. To automatically answer this type of question, our computers require an extensive body of knowledge. We believe that text mining can provide the requisite body of knowledge. My talk will describe work at the new Allen Institute for AI towards building the next-generation of text-mining systems.", "recorded": "2014-08-25T09:00:00", "title": "The Battle for the Future of Data Mining"}, {"url": "mmdss07_feldman_latm", "desc": "The information age has made it easy to store large amounts of\r data.The proliferation of documents available on the Web, on corporate\r intranets, on news wires, and elsewhere is overwhelming. However, while the\r amount of data available to us is constantly increasing, our ability to absorb and\r process this information remains constant. Search engines only exacerbate the\r problem by making more and more documents available in a matter of a few\r key strokes. Link Analysis is a new and exciting research area that tries to solve\r the information overload problem by using techniques from data mining,\r machine learning, Information Extraction, Text Categorization, Visualization\r and Knowledge Management.", "recorded": "2007-09-18T09:15:52", "title": "Link Analysis and Text Mining : Current State of the Art and Applications for Counter Terrorism"}, {"url": "coinactivess2010_grobelnik_bpm", "desc": "Part 1. Context Computing.\r\nContext is used as a term for packaging information for a particular need. A criterion for selecting or prioritization information from a broader pool of information could be called contextual model. Search can be contextual: http://searchpoint.ijs.si. The relevance of Context in computing seems to be growing. Many application areas see an opportunity in extending its value by introducing \"context sensitivity\". More details do to be found in ISWC2006 Tutorial on \"context sensitivity\": http://videolectures.net/iswc06_athens_ga/\r\n\r\nPart 2. Text Mining &amp; Light Weight Semantics.\r\nVideolectures discusses the following topics:\r\n;- levels of text representations\r\n;- modeling the data (Support Vector Machine)\r\n;- classification into large taxonomies (DMoz)\r\n;- visual &amp; contextual search (Search Point)\r\n;- multilingual search\r\n;- news bias, news visualization\r\n;- text enrichment (Enrycher)\r\n;- knowledge based summarization\r\n;- question answering (AnswerArt)\r\n;- Cyc knowledge base and reasoning", "recorded": "2010-10-18T14:00:00", "title": "Business Process Mining and Formalization"}, {"url": "sssw05_maynard_lt", "desc": "This tutorial covers the use of Human Language Technologies for the Semantic Web and Web Services. It includes sections on HLT and Text Mining for the Semantic Web, various forms of Information Extraction, Ontology Population and Semantic Metadata Creation, and Evaluation.\r\n \r\n The tutorial begins with an introduction to Human Language Technology, looking at both its background and development, and then situating it within the context of text mining and other tasks involving knowledge discovery from large collections of unstructured text, which are necessary for the development of the semantic web. The second section concerns information extraction, a major component of text mining. Information extraction involves extracting facts and structured information from unstructured data. We contrast this with Information retrieval, which concerns extracting documents from large text collections, and with data mining, which concerns discoveing patterns in structured data. We introduce GATE, and architecture for language engineering, and its resources for information extraction, and then expand the idea of traditional information extraction to focus on semantic web-enabled technology such as ontology population and semantic metadata creation, both of which involve the use of information extraction based on ontologies. We look at some current state-of-the-art semantic annotation systems such as KIM, Magpie, MnM and OntoMat. In the third section, we discuss evaluation methods for such technology, based on the idea that traditional methods are insufficient when applied to semantic web technology, due to the presence of hierarchical (ontological) information rather than flat structures. We also take a brief look at usability issues of annotation systems. Finally, the tutorial gives demonstrations of two examples of HLT in use for the semantic web. First we present RichNews, which aims to automate the annotation of news programs, segmenting, describing and classifying news broadcasts from transcripts. Second, we present work on ontology-based and mixed initiative information extraction carried out in the context of SEKT.\r\n ", "recorded": "2005-07-06T15:00:00", "title": "Language Technologies"}, {"url": "is2012_mladenic_grobelnik_text_data", "desc": "Text is one of the traditional ways of communication between people. With the growing availability of text data in electronic form, handling and analysis of text by means of computers gained popularity. Handling text data with machine learning methods brought interesting challenges to the area that got further extended by incorporation of some natural language specifics. As the methods were capable of addressing more complex problems related to text data, the expectations got bigger calling for a combination of methods from different research areas including information retrieval,\r\nmachine learning, statistical data analysis, data mining, natural language processing, semantic technologies. Nowadays automatic text analysis is an integral part of many systems, pushing boundaries of research capabilities towards artificial intelligence dream on never ending learning from\r\ntext aiming at mimicking ways of human learning. The paper presents development of text analysis research in Slovenian that we have been personally involved in, pointing out interesting research problems that have been and are still addressed by the research, example tasks that have been addressed and some challenges on the way.", "recorded": "2012-10-11T12:20:15", "title": "Artificial Intelligence Handling Text Data"}, {"url": "machine_rupnik_document_analysis", "desc": "We present a summary of our work on cross-lingual (CL) document analysis. We\r\nfocused on learning CL similarity functions and learning language independent\r\ndocument representations. Solutions to either of the two tasks enable us to solve\r\nCL text mining tasks (e.g. CL classification, CL retrieval, CL clustering) by using\r\nthe tools of monolingual text mining. We approached the problems using non-\r\nprobabilistic methods (typically based on numerical linear algebra) with a special\r\nemphasis on scalability. Special attention was devoted to language pairs for which\r\ndirect training data (translation pairs or comparable documents) was scarce or\r\nnonexistent. We showed how to exploit indirect training data through a major\r\n(hub) language, such as English.", "recorded": "2013-04-11T15:10:00", "title": "Cross-Lingual Document Analysis"}, {"url": "ida07_klopotek_tawm", "desc": "We present a novel approach to the growing neural gas (GNG)\r based clustering of the high-dimensional text data. We enhance our Contextual\r GNG models (proposed previously to shift the majority of calculations\r to context-sensitive, local sub-graphs and local sub-spaces and so to\r reduce computational complexity) by developing a new, histogram-based\r method for incremental model adaptation and evaluation of its stability.", "recorded": "2007-09-06T17:00:00", "title": "Towards Adaptive Web Mining: Histograms and Contexts in Text Data Clustering"}, {"url": "podpecan_zakova_iawco", "desc": "Framework for integration and its main functionalities:\r\n * storing semantic annotations of manually created workflows,\r\n * support for annotation of new algorithms,\r\n * execution of automatically planned workflows in Orange4WS\r\n - use cases: text mining (LATINO), bioinformatics (SEGS + Biomine)\r\n", "recorded": "2010-02-11T15:15:00", "title": "Integrating Annotations and Automated workflow Construction into Orange4WS"}, {"url": "reasecs_schroeder_otmbs", "desc": "Introduction into how rules, reasoning, ontologies and the web are used in bioinformatics.\nThere are three parts: introdcution to bioinformatics incl. overview over some relevant tools and systems, alignment of ontologies, and finally biomedical literature search with ontologies.", "recorded": "2006-08-31T00:00:00", "title": "Ontologies and Text Mining as a Basis for a Semantic Web for the Life Sciences"}, {"url": "kdd2010_papadimitriou_sun_yan_lsdm", "desc": "Data are becoming available in unprecedented volumes. This difference in scale is difference in kind, presenting new opportunities. Map-reduce has drawn a lot of attention recent years for large-scale data processing and mining. In this tutorial, we introduce Map-reduce and its application and research in data mining. In particular, we want to answer the following questions: \r\n\r\n\r\n\u2022What is Map-reduce and why do we need it for data mining?\r\n\u2022What mining applications need Map-reduce?\r\n\u2022What are the advantages and limitations using Map-Reduce?\r\n\u2022How do you use Map-reduce?\r\n\u2022What are other tools out there for large-scale data processing and mining?\r\nMore specifically, this tutorial is organized into three parts: \r\n\r\n1.MapReduce basic includes MapReduce programming model, system architecture, its OpenSource implementation Hadoop and its extensions such as HBase, Pig, Cascading, Hive.\r\n\r\n2.MapReduce algorithms cover MapReduce implementation of standard data mining algorithms such as clustering (K-means), classification (k-NN, naive Bayes), graph mining (page rank).\r\n\r\n3.MapReduce applications present the general applications of MapReduce that are beyond data mining, which include text processing, data warehousing.", "recorded": "2010-07-25T09:00:00", "title": " Large-scale Data Mining: MapReduce and Beyond"}, {"url": "kdd2010_li_mpn", "desc": "It is a big challenge to guarantee the quality of discovered relevance features in text documents for describing user preferences because of the large number of terms, patterns, and noise. Most existing popular text mining and classification methods have adopted term-based approaches. However, they have all suffered from the problems of polysemy and synonymy. Over the years, people have often held the hypothesis that pattern-based methods should perform better than term-based ones in describing user preferences, but many experiments do not support this hypothesis. The innovative technique presented in paper makes a breakthrough for this difficulty. This technique discovers both positive and negative patterns in text documents as higher level features in order to accurately weight low-level features (terms) based on their specificity and their distributions in the higher level features. Substantial experiments using this technique on Reuters Corpus Volume 1 and TREC topics show that the proposed approach significantly outperforms both the state-of-the-art term-based methods underpinned by Okapi BM25, Rocchio or Support Vector Machine and pattern based methods on precision, recall and F measures.\r\n", "recorded": "2010-07-27T11:00:00", "title": "Mining Positive and Negative Patterns for Relevance Feature Discovery"}, {"url": "kdd2010_zhang_ehdpm", "desc": "Mining cluster evolution from multiple correlated time-varying text corpora is important in exploratory text analytics. In this paper, we propose an approach called evolutionary hierarchical Dirichlet processes~(EvoHDP) to discover interesting cluster evolution patterns from such text data. We formulate the EvoHDP as a series of hierarchical Dirichlet processes~(HDP) by adding time dependencies to the adjacent epochs, and propose a cascaded Gibbs sampling scheme to infer the model. This approach can discover different evolving patterns of clusters, including emergence, disappearance, evolution within a corpus and across different corpora. Experiments over synthetic and real-world multiple correlated time-varying data sets illustrate the effectiveness of EvoHDP on discovering cluster evolution patterns.\r\n", "recorded": "2010-07-28T10:48:00", "title": "Evolutionary Hierarchical Dirichlet Processes for Multiple Correlated Time-varying Corpora"}, {"url": "brownbag_ijs", "desc": "The BrownBag seminar is held every week at the Department of Knowledge Technologies at the Jo\u017eef Stefan Institute. The goal is to advance cutting-edge research and applications of knowledge technologies, including data, text and web mining, machine learning, decision support, language technologies, knowledge management, and other information technologies that support the acquisition, management, modelling and use of knowledge and data.", "recorded": "2010-01-11T09:46:43", "title": "IJS BrownBag Seminar"}, {"url": "kdd2014_kannan_text_snippets", "desc": "Images are often used to convey many different concepts or illustrate many different stories. We propose an algorithm to mine multiple diverse, relevant, and interesting text snippets for images on the web. Our algorithm scales to all images on the web. For each image, all webpages that contain it are considered. The top-K text snippet selection problem is posed as combinatorial subset selection with the goal of choosing an optimal set of snippets that maximizes a combination of relevancy, interestingness, and diversity. The relevancy and interestingness are scored by machine learned models. Our algorithm is run at scale on the entire image index of a major search engine resulting in the construction of a database of images with their corresponding text snippets. We validate the quality of the database through a large-scale comparative study. We showcase the utility of the database through two web-scale applications: (a) augmentation of images on the web as webpages are browsed and (b)~an image browsing experience (similar in spirit to web browsing) that is enabled by interconnecting semantically related images (which may not be visually related) through shared concepts in their corresponding text snippets.", "recorded": "2014-08-27T10:45:00", "title": "Mining Text Snippets for Images on the Web"}, {"url": "samt08_campedel_pim", "desc": "Satellite images are numerous and weakly exploited: it is urgent to develop an efficient and fast indexing/retrieval system to easy their access. Content-based image retrieval systems (CBIR) are known to provide an efficient framework. We thus propose to associate a CBIR approach with text-based queries to adapt to these big (12000$\\times$12000 pixels) and semantically rich images. The presented system relies on a multimedia data mining system called PLATO able to adapt to any kind of multimedia data. Moreover state-of-the-art relevance feedback strategy is introduced to provide interactive learning and auto annotation.", "recorded": "2008-12-05T10:15:00", "title": "PLATO for Information Mining in Satellite Imagery"}, {"url": "sikdd2014_rei_large_scale", "desc": "We present a semi-automatic data exploration and \r\norganization tool. The system integrates machine learning \r\nand text mining algorithms into an simple user interface and \r\na Client/Server architecture. The main features of the \r\nsystems include unsupervised and supervised methods for \r\nconcept suggestion, visualization and ability to make both \r\ndata and methods available to other applications as a \r\nservice. ", "recorded": "2014-10-06T10:50:00", "title": "A System For Large Scale Data Exploration and Organization"}, {"url": "mmdss07_tanev_les", "desc": "Automatic Event Extraction from texts emerges as an im-\r portant and complex text mining task. Its goal is to detect description\r of events of a speci\u00afc type described in the text. For each event the\r Event Extraction system is expected to \u00afnd the time, the location, the\r participants in this event and their roles, as well as other related circum-\r stances. In this talk we present a Machine Learning approach for learning\r of information extraction patterns, a method for semi-automatic lexical\r acquisition, and an information aggregation strategy implemented in a\r working prototype nexus which detects automatically security related\r events in clusters of news articles.", "recorded": "2007-09-20T16:15:00", "title": "Learning to Extract Security-related Event Information from Large News Collections"}, {"url": "xlike_kickoff2012_grobelnik_introduction", "desc": "The goal of the **[[http://www.xlike.org/|XLike project]]** is to develop technology to monitor and aggregate knowledge that is currently spread across mainstream and social media, and to enable cross-lingual services for publishers, media monitoring and business intelligence.\n\nThe aim is to combine scientific insights from several scientific areas to contribute in the area of cross-lingual text understanding. By combining modern computational linguistics, machine learning, text mining and semantic technologies we plan to deal with the following two key open research problems:\n\n * to extract and integrate formal knowledge from multilingual texts with cross-lingual knowledge bases, and\n * to adapt linguistic techniques and crowdsourcing to deal with irregularities in informal language used primarily in social media.", "recorded": "2012-01-18T09:00:00", "title": "Introduction to FP7 XLike project"}, {"url": "ecmlpkdd09_segond_bngutd", "desc": "According to Koestler, the notion of a bisociation denotes\r\na connection between pieces of information from habitually separated\r\ndomains or categories. In this paper, we consider a methodology to \ffind\r\nsuch bisociations using a network representation of knowledge, which is\r\ncalled a BisoNet, because it promises to contain bisociations. In a fi\frst\r\nstep, we consider how to create BisoNets from several textual databases\r\ntaken from di\u000bfferent domains using simple text-mining techniques. To\r\nachieve this, we introduce a procedure to link nodes of a BisoNet and\r\nto endow such links with weights, which is based on a new measure for\r\ncomparing text frequency vectors. In a second step, we try to rediscover\r\nknown bisociations, which were originally found by a human domain\r\nexpert, namely indirect relations between migraine and magnesium as\r\nthey are hidden in medical research articles published before 1987. We\r\nobserve that these bisociations are easily rediscovered by simply following the strongest links. Future work includes extending our methods to\r\nnon-textual data, improving the similarity measure, and applying more\r\nsophisticated graph mining methods.", "recorded": "2009-09-11T16:07:00", "title": "\"BisoNet\" Generation Using Textual Data"}, {"url": "kdd2010_wang_lar", "desc": "In this paper, we define and study a new opinionated text data analysis problem called Latent Aspect Rating Analysis (LARA), which aims at analyzing opinions expressed about an entity in an online review at the level of topical aspects to discover each individual reviewer's latent opinion on each aspect as well as the relative emphasis on different aspects when forming the overall judgment of the entity. We propose a novel probabilistic rating regression model to solve this new text mining problem in a general way. Empirical experiments on a hotel review data set show that the proposed latent rating regression model can effectively solve the problem of LARA, and that the detailed analysis of opinions at the level of topical aspects enabled by the proposed model can support a wide range of application tasks, such as aspect opinion summarization, entity ranking based on aspect ratings, and analysis of reviewers rating behavior.\r\n", "recorded": "2010-07-27T11:30:00", "title": "Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach"}, {"url": "kdd09_zaiane_mobasher_spiliopoulou_nasraoui_aimtw", "desc": "The Web has changed our way of life and the Web 2.0 has changed our way of perceiving and using the Web. Data analysis is now required in a plethora of applications that aim to enrich the experience of people with the Web. We first discuss data mining for the social Web. We elaborate on social network analysis and focus on community mining, then go over to recommendation engines and personalization. We discuss the challenges that emerged through the shift from the traditional Web to Web 2.0. We then focus on two issues - the need to protect Web applications from manipulation and the need to make them adaptive towards change. We first discuss manipulations/attacks in recommender systems and present counter-measures. We then elaborate on how changes/concept drifts can be dealt with in applications that analyze clickstream data, monitor topics in news and blogs, or monitor communities and their evolution.\r\n\r\nThis tutorial is aimed at novice researchers that have general background in data mining and are interested in understanding the potential and challenges pertinent to the social Web. The participants should have a basic understanding of recommendation engines, personalization and text modeling for mining (vector space models). They will learn how basic techniques are extended and new techniques are designed for mining the Web, especially the social Web. They will also learn about issues that are still open and require further research - research that the tutorial participants may decide to perform themselves.", "recorded": "2009-06-28T14:00:00", "title": "Advances in Mining the Web"}, {"url": "kdd07_yuan_ffitsm", "desc": "Data mining techniques that are successful in transaction and text data may not be simply applied to image data that contain high-dimensional features and have spatial structures. It is not a trivial task to discover meaningful visual patterns in image databases, because the content variations and spatial dependency in the visual data greatly challenge most existing methods.\n\nThis paper presents a novel approach to coping with these difficulties for mining meaningful visual patterns. Specifically, the novelty of this work lies in the following new contributions:\n\n(1) a principled solution to the discovery of meaningful itemsets based on frequent itemset mining;\n\n(2) a self-supervised clustering scheme of the high-dimensional visual features by feeding back discovered patterns to tune the similarity measure through metric learning; and\n\n(3) a pattern summarization method that deals with the measurement noises brought by the image data.\n\nThe experimental results in the real images show that our method can discover semantically meaningful patterns efficiently and effectively.", "recorded": "2007-08-14T09:58:53", "title": "From frequent itemsets to semantically meaningful visual patterns "}, {"url": "kdd2010_banerjee_igmdm", "desc": "Graphical models for large scale data mining constitute an exciting development in statistical data analysis which has gained significant momentum in the past decade. Unlike traditional statistical models which often make `i.i.d.' assumptions, graphical models acknowledge dependencies among variables of interest and investigate inference/prediction while taking into account such dependencies. In recent years, latent variable Bayesian networks, such as latent Dirichlet allocation, stochastic block models, Bayesian co-clustering, and probabilistic matrix factorization techniques have achieved unprecedented success in a variety of application domains including topic modeling and text mining, recommendation systems, multi-relational data analysis, etc. The tutorial will give a broad overview of graphical models, and discuss recent developments in the context of mixed-membership models, matrix analysis models, and their generalizations. The tutorial will present a balanced mix of models, inference/learning methods, and applications. ", "recorded": "2010-07-25T14:00:00", "title": "Introduction to Graphical Models for Data Mining"}, {"url": "kdd2014_spangler_lichtarge_scientific_literature", "desc": "Keeping up with the ever-expanding flow of data and publications is untenable and poses a fundamental bottleneck to scientific progress. Current search technologies typically find many relevant documents, but they do not extract and organize the information content of these documents or suggest new scientific hypotheses based on this organized content. We present an initial case study on KnIT, a prototype system that mines the information contained in the scientific literature, represents it explicitly in a queriable network, and then further reasons upon these data to generate novel and experimentally testable hypotheses. KnIT combines entity detection with neighbor-text feature analysis and with graph-based diffusion of information to identify potential new properties of entities that are strongly implied by existing relationships. We discuss a successful application of our approach that mines the published literature to identify new protein kinases that phosphorylate the protein tumor suppressor p53. Retrospective analysis demonstrates the accuracy of this approach and ongoing laboratory experiments suggest that kinases identified by our system may indeed phosphorylate p53. These results establish proof of principle for automated hypothesis generation and discovery based on text mining of the scientific literature.", "recorded": "2014-08-27T11:45:00", "title": "Automated Hypothesis Generation Based on Mining Scientific Literature"}, {"url": "reasecs_tablan_pahlt", "desc": "This 4-hour tutorial presented at the ACAI -05 Advanced Course in Knowledge Technologies SEKT Summer School covers the use of Human Language Technologies for the Semantic Web and Web Services, focusing particularly on practical applications. It gives some introduction to text mining and Information Extraction, and aims to show how such core technologies can be adapted to deal with the needs of the Semantic Web, by means of real-life examples and applications.\r\n\r\nDocuments:\r\n;[[Practical_Applications.pdf]]\r\n;[[Practical_Applications.ppt]]", "recorded": "2005-06-16T00:00:00", "title": "Practical Applications of Human Language Technologies for the Semantic Web"}, {"url": "kdd07_mei_alm", "desc": "Multinomial distributions over words are frequently used to model topics in text collections. A common, major challenge in applying all such topic models to any text mining problem is to label a multinomial topic model accurately so that a user can interpret the discovered topic. So far, such labels have been generated manually in a subjective way. In this paper, we propose probabilistic approaches to automatically labeling multinomial topic models in an objective way. We cast this labeling problem as an optimization problem involving minimizing Kullback-Leibler divergence between word distributions and maximizing mutual information between a label and a topic model. Experiments with user study have been done on two text data sets with different genres. The results show that the proposed labeling methods are quite effective to generate labels that are meaningful and useful for interpreting the discovered topic models. Our methods are general and can be applied to labeling topics learned through all kinds of topic models such as PLSA, LDA, and their variations.", "recorded": "2007-08-14T14:30:53", "title": "Automatic Labeling of Multinomial Topic Models"}, {"url": "aop09_cagliari", "desc": "Modern society is increasingly reliant on our capability to automatically detect patterns in vast masses of data. This is affecting not only the way we do business and run our industries, but also is changing the very nature of the scientific method. Every science now has an e-version (computational biology, computational chemistry, etc) and in many cases this involves automatisation of both the production and the analysis of experimental data. The use of computer simulations increases our reliance on automatic analysis of data even further. This process is accelerating.\r\n\r\nThe distinct scientific communities that are working on various aspects of automatic analysis of data include Combinatorial Pattern Matching, Data Mining, Computational Statistics, Network Analysis, Text Mining, Image Processing, Syntactical Pattern Recognition, Machine Learning, Statistical Pattern Recognition, Computer Vision, and many others.\r\n\r\nA unified understanding of the challenges and opportunities ahead is essential for further progress, and is the purpose of this series of workshops / summer-schools: to promote a unified understanding of all the technical and conceptual issues relating to the automatic discovery and exploitation of patterns in data.\r\n\r\nThe previous 2 editions of this event took place in Erice, 2005 and Bertinoro, 2007. The videos of all lectures are available online.\r\n\r\nINTENDED AUDIENCE: The school is intended for PhD students, postdocs, and researchers (both academic and industrial), working in any of the disciplines involved in \"the analysis of patterns\" and hence including: bioinformatics, data mining, text analysis, machine learning, statistics, optimization, computer vision, stringology, network analysis, etc.\r\n\r\n----\r\nThe event homepage can be found at http://www.analysis-of-patterns.net/\r\n----", "recorded": "2009-09-28T09:00:00", "title": "The Analysis of Patterns, Cagliari 2009"}, {"url": "ecmlpkdd09_shaparenko_iocdlm", "desc": "One major goal of text mining is to provide automatic methods to help humans grasp the key ideas in ever-increasing text corpora. To this effect, we propose a statistically well-founded method for identifying the original ideas that a document contributes to a corpus, focusing on self-referential diachronic corpora such as research publications, blogs, email, and news articles. Our statistical model of passage impact defines (interesting) original content through a combination of impact and novelty, and the model is used to identify each document\u2019s most original passages. Unlike heuristic approaches, the statistical model is extensible and open to analysis. We evaluate the approach both on synthetic data and on real data in the domains of research publications and news, showing that the passage impact model outperforms a heuristic baseline method.", "recorded": "2009-09-10T15:27:00", "title": "Identifying the Original Contribution of a Document via Language Modeling"}, {"url": "ecmlpkdd2011_turney_10years", "desc": "In 2001, ECML PKDD published my paper, Mining the Web for Synonyms. In 2011, they chose this paper for their 10 Year Award for \"the paper that was published 10 years ago in the proceedings of ECML PKDD and proved to be important in terms of scientific or other impact\". They asked me to speak about my \"experience in the 10 years of scientific endeavor\" from 2001 to 2011. The 2001 paper was my first publication on a theme that has subsequently dominated my research: How can we use huge amounts of text, gathered from the Web, to figure out what words mean? Briefly, in the last decade, my research has gone from Mining the Web for Synonyms to Mining the Web for Meaning. This area of research is known as Statistical Semantics, Distributional Semantics, or Geometrical Semantics, and it is a topic of several new conferences and workshops (e.g., DISCO, GEMS, IWCS, RELMS). The scope and ambition of the research has expanded from synonyms to antonyms, meronyms, hypernyms, analogies, sentiment, emotion, semantic relations, abstraction, and metaphor. The focus has expanded from words to phrases and sentences. Many in the field believe that Statistical Semantics has the potential to cover all aspects of meaning of natural language. We believe that Statistical Semantics will enable computers to understand human language.", "recorded": "2011-09-07T19:00:00", "title": "Mining the Web for Meaning"}, {"url": "sikdd08_ljubljana", "desc": "Data handling technologies have significantly progressed in the last ten years. The first phases mainly dealing with storing and efficiently accessing the data, resulted in the development of industry delivering tools for handling large databases, standardization of related processes, queering languages, etc. When the data storage was not a primary problem any more the need for improving the database organization resulted in the databases supporting not only transactions but also analytical views of the data.\r\n\r\nAt this point data warehousing with OLAP (On-Line-Analytical-Processing) entered as a usual part of a company information system. The OLAP paradigme stil requires from the user to set well defined questions which is not always easy and possible. This led to the development of Data Mining offering automatic data analysis trying to obtain some new information from the existing data and enabling the user some new insights in the data. Further development of methods for Text Mining enables handling textual data in addition to well structured data in databases. Large amount of data and activities on the Web is further addressed in Web Mining where in addition to content of the Web documents, the structure of the Web and Web log-files are analysed.\r\n\r\nLink to the Conference Page - http://kt.ijs.si/Dunja/SiKDD2008/", "recorded": "2008-10-17T09:00:00", "title": "Slovenian KDD Conference on Data Mining and Data Warehouses (SiKDD), Ljubljana 2008"}, {"url": "russir08_moens_tmife", "desc": "communities (medical informatics, security, blog and news analysis, business information analysis, legal informatics, etc.). ?Still, today it is a somewhat fragmented subfield of human language technologies and information retrieval where the themes of (often forgotten) old-style pattern-based IE and more recent machine learning techniques, as applied in medical informatics, opinion mining and blog extraction, are scattered in various conferences and sessions (computational linguistics, artificial intelligence, machine learning, Web technologies, semantic computing).\r\nThe aim of this tutorial is to explain important technologies from handcrafted patterns to learning, and especially focus on how they blend together in order to suit the needs of current information systems that retrieve or mine information, or that make decisions and solve problems based on the extracted information. This unified perspective also entails valuable insights into the role of traditional pipelined system architectures and more recent probabilistic inference techniques.\r\nProbabilistic extraction, by which text is translated into a variety of semantic labels, pe\"../slides/rfectly integrates with probabilistic retrieval models that naturally combine surface text features and semantic labels in ranking computations, among which are the popular language retrieval models. Finally, information extraction alleviates the knowledge acquisition bottleneck in expert and question answering systems technology that operate in more restricted subject domains.\r\nWe conclude with some pointers to new challenges among which are the recognition of complex semantic concepts (e.g., narrative scripts, or issues such as medical malpractice or competitiveness) in texts.\r\nBecause of the reconciling aspects of the many techniques and application domains, the tutorial will attract students and researchers with different backgrounds. ", "recorded": "2008-09-01T09:00:00", "title": "Text Mining, Information and Fact Extraction (TMIFE)"}, {"url": "sssw05_buitelaar_hltsw", "desc": "In this talk I will present an overview of Human Language Technology\r\n (HLT) and its use in Semantic Web development. HLT is concerned with automatic linguistic processing towards the semantic analysis and extraction of information from textual data. In the context of the Semantic Web the use of HLT is in knowledge markup of web documents for ontology population and text mining for ontology evolution (extension and modification of ontology models). The talk will include examples of both as currently developed in the context of the SmartWeb project on \"Mobile Broadband Access to the Semantic Web\" - http://www.smartweb-projekt.de/", "recorded": "2005-06-30T11:00:00", "title": "Human Language technology for the Semantic Web"}, {"url": "emergingtrends2012_ljubljana", "desc": "The main goal of this one day event is to clarify how emerging technologies based on machine learning, machine translation, text mining, semantic web, open access, academic video journals, free video libraries, open lecture capture systems, OER and more can change and help co-create emerging publishing, curriculum, designation, filtration, validation and research trends in Academia in Europe and in general. For more information please visit the [[http://ct3.ijs.si/emerging_trends2012/|Emerging Trends Workshop website]].", "recorded": "2012-11-07T09:00:00", "title": "Workshop on Co-creation of Emerging Trends in Academia, Ljubljana 2012"}, {"url": "sikdd2011_leban_duplicates", "desc": "Bug tracking systems (BTS) are systems that allow users of some software to report to developers bugs they encountered while using it. Common problem of BTS are duplicated reports of the same bug. Since identifying bug duplicates is a time consuming task we show in this paper an approach to automatically identifying duplicates using text-mining methods. We demonstrate the usability of our method on KDE Bugzilla BTS which contains 249,083 bug reports of which 47,093 are duplicates.", "recorded": "2011-10-10T16:00:00", "title": "Analysis and prediction of bug duplicates in KDE bug tracking system"}, {"url": "eswc2010_hazucha_ikftc", "desc": "Descriptive data mining only brings its fruits when the results are provided\r\nto the end user in a palatable form. The vehicle for end-user delivery of mining\r\nresults (and associated information such as data schema, task settings, and domain background knowledge) are so-called analytical reports. In order to manage\r\na huge number of reports referring to different mining sessions, we designed a\r\ndata mining web portal based on a content management system, together called\r\nSEWEBAR-CMS.1 One of the requirements on the CMS was the ability to interact with semantic knowledge sources and other structured data, see [1].\r\nThe data analyst who authors an analytical report in the CMS has different\r\npossibilities of (semi-)automatically entering structured data into the text.\r\nFirst, for locally stored data such as mining task/result/data descriptions\r\nexported from mining tools in PMML (Predictive Model Mark-Up Language), a\r\nCMS plugin can pick marked segments of HTML code, produced from PMML\r\nusing XSLT, and insert them into the report as indicated by the analyst.\r\nSecond, sophisticated support for remote data/knowledge has been newly\r\nadded. The infrastructure for this functionality allows to persistently specify\r\n\u2013 Links to queriable resources\r\n\u2013 Template queries for these resources (which can be paramatrized by the\r\nend-user at runtime)\r\n\u2013 XSLT transformations allowing to insert the results of queries as HTML\r\nfragments, either static or dynamically updated from the resources.\r\nCurrently we experiment with queriable resources in the form of native XML\r\ndatabase (Berkeley, queried via XQuery), which stores PMML data, and semantic knowledge bases both in the form of SPARQL endpoint and Ontopia Knowledge Suite (a Topic Maps tool, queried via a Prolog-like language called tolog).\r\nInclusion of further types of resources such as Lucene indices is in progress.\r\n", "recorded": "2010-05-31T16:44:00", "title": "Importing Knowledge Fragments to CMS-Enabled Data Mining Analytical Reports"}, {"url": "ocwc2014_grobelnik_x_like", "desc": "The goal of the XLike project is to develop technology to monitor and aggregate knowledge that is currently spread across mainstream and social media, and to enable cross-lingual services for publishers, media monitoring and business intelligence. The aim is to combine scientific insights from several scientific areas to contribute in the area of cross-lingual text understanding. By combining modern computational linguistics, machine learning, text mining and semantic technologies we plan to deal with the following two key open research problems:\r\n\r\nto extract and integrate formal knowledge from multilingual texts with cross-lingual knowledge bases, and\r\nto adapt linguistic techniques and crowdsourcing to deal with irregularities in informal language used primarily in social media.\r\nThe developed technology will be language-agnostic, while within the project we will specifically address English, German, Spanish, Chinese and Hindi as major world languages and Catalan and Slovenian as minority languages.", "recorded": "2014-04-25T10:30:00", "title": "x-like \u2013 Cross-lingual knowledge extraction"}, {"url": "bsciw08_burges_osafp", "desc": "Search engine companies are gathering treasure troves of user-generated data. It has already been shown that such data can be used to directly improve the user's online experience. I will discuss some ideas as to what online search and advertising might look like a few years hence, in light of the algorithms and data we have now. Moving from future to present, I will outline some recent work done by researchers in the Text Mining, Search and Navigation team at Microsoft Research; the work in TMSN touches many aspects of online search and advertising.", "recorded": "2008-12-13T07:30:00", "title": "Online Search and Advertising, Future and Present"}, {"url": "is2012_perovsek_hierarchical_clustering", "desc": "This paper presents a browser-based semi-automatic taxonomy construction tool Vd-chuck which is able to incorporate text and data mining algorithms into a userfriendly interface. The presented system is browserbased. Its unsupervised learning for concept suggestion and different visualization techniques assist the user with textual and numerical data analysis. We tested the Vd-chuck system on a real-world domain: a corpus of documents taken from Slovenian Language technologies conferences. The results show that with our system similar taxonomies as with other taxonomy editors can be constructed.", "recorded": "2012-10-08T12:25:58", "title": "Visual Divisive Hierarchical Clustering Using k-Means"}, {"url": "kdd09_ahmed_sctm", "desc": "A major source of information (often the most crucial and informative part) in scholarly articles from scientific journals, proceedings and books are the figures that directly provide images and other graphical illustrations of key experimental results and other scientific contents. In biological articles, a typical figure often comprises multiple panels, accompanied by either scoped or global captioned text. Moreover, the text in the caption contains important semantic entities such as protein names, gene ontology, tissues labels, etc., relevant to the images in the figure. Due to the avalanche of biological literature in recent years, and increasing popularity of various bio-imaging techniques, automatic retrieval and summarization of biological information from literature figures has emerged as a major unsolved challenge in computational knowledge extraction and management in the life science. We present a new structured probabilistic topic model built on a realistic figure generation scheme to model the structurally annotated biological figures, and we derive an efficient inference algorithm based on collapsed Gibbs sampling for information retrieval and visualization. The resulting program constitutes one of the key IR engines in our SLIF system that has recently entered the final round (4 out 70 competing systems) of the Elsevier Grand Challenge on Knowledge Enhancement in the Life Science. Here we present various evaluations on a number of data mining tasks to illustrate our method.", "recorded": "2009-06-29T16:18:00", "title": "Structured Correspondence Topic Models for Mining Captioned Figures in Biological Literature"}, {"url": "mmdss07_gazzada", "desc": "This Workshop brings together scientists and engineers interested in recent developments in exploiting Massive Data Sets. Emphasis is placed on available techniques and their application to security-critical applications.\r \\\\ \r Today our world is awash in data and we live in an Information Society where every action leaves a trace, generating massive amounts of data. Recent scientific developments provide technologies to exploit these huge amounts of data and extract from it critical information. Used today in many commercial applications (marketing campaigns, user profiling and recommendations on e-commerce sites, web search,users communitiee...), these technologies can also be used for security-critical applications (fraud detection and money laundering, intrusions detection, intelligence gathering, terrorist networks detection, Web surveillance...).\r \r It is the purpose of this workshop to review the various technologies available (data mining algorithms, social networks, crawling and indexing, text-mining, search engines, data streams) in the context of very large data sets.\r \r The workshop will provide survey presentations &amp; posters to help building a scientific community aware of security issues and techniques to solve them.", "recorded": "2007-09-10T00:09:00", "title": "NATO Advanced Study Institute on Mining Massive Data Sets for Security"}, {"url": "eswc2015_knowalod", "desc": "Knowledge discovery is an well-established field with a large community investigating methods for the discovery of patterns and regularities in large data sets, including relational databases and unstructured text. Research in this field has led to the development of practically relevant and scalable approaches such as association rule mining, subgroup discovery, graph mining or clustering. At the same time, the Web of Data has grown to one of the largest publicly available collections of structured, cross-domain data sets. While the growing success of Linked Data and its use in applications, e.g., in the e-Government area, has provided numerous novel opportunities, its scale and heterogeneity are posing challenges to knowledge discovery and data mining:\r\n\r\n*The extraction and discovery of knowledge from very large data sets;\r\n*The maintenance of high quality data and provenance information; \r\n*The scalability of processing and mining the distributed Web of Data; and \r\n*The discovery of novel links, both on the instance and the schema level.\r\n\r\nContributions from the knowledge discovery field may help foster the future growth of Linked Open Data. Some recent works on statistical schema induction, mapping, and link mining have already shown that there is a fruitful intersection of both fields. With the proposed workshop, we want to investigate possible synergies between the Linked Data and Knowledge Discovery communities, and to explore novel directions for joint research. On the one hand, we wish to stimulate a discussion about how state-of-the-art algorithms for knowledge discovery and data mining can be adapted to fit the characteristics of Linked Data, such as its distributed nature, incompleteness (incl. absence of negative examples), and identify concrete use cases and applications. On the other hand, we hope to show that Linked Data can support traditional knowledge discovery tasks (e.g., as a source of additional background knowledge and of predictive features) for mining from existing, not natively linked data like, for instance, in business intelligence settings.\r\n\r\nThe workshop addresses researchers and practitioners from the fields of knowledge discovery in databases and data mining, as well as researchers from the Semantic Web community applying such techniques to Linked Data. The goal of the workshop is to provide a platform for knowledge exchange between the different research communities, and to foster future collaborations.\r\n\r\nFor more information about the workshop please visit the [[http://knowalod2015.informatik.uni-mannheim.de/en/home/|Know@LOD 2015 website]].", "recorded": "2015-05-31T09:00:00", "title": "4th Workshop on Knowledge Discovery and Data Mining Meets Linked Open Data (Know@LOD)"}, {"url": "sikdd2014_ljubljana", "desc": "Data handling technologies are significantly progressing. The first phases mainly dealing with storing and efficiently accessing the data, resulted in the development of industry delivering tools for handling large databases, standardization of related processes, queering languages, etc. When the data storage was not a primary problem any more the need for improving the database organization resulted in the databases supporting not only transactions but also analytical views of the data. At this point data warehousing with OLAP (On-Line-Analytical-Processing) entered as a usual part of a company information system. The OLAP paradigme stil requires from the user to set well defined questions which is not always easy and possible. This led to the development of Data Mining offering automatic data analysis trying to obtain some new information from the existing data and enabling the user some new insights in the data. Further development of methods for Text and Multimedia Mining enables handling textual, video and audio data in addition to well structured data in databases. Large amount of data and activities on the Web is further addressed in Web Mining where in addition to content of the Web documents, the structure of the Web and Web log-files are analysed. Structure of interconnected data objects is also in focus of Link Detection and Link Analysis, as for instance in Social Network Analysis.\r\n\r\nTo find out more please visit **[[http://ailab.ijs.si/dunja/SiKDD2014/|SiKDD 2014 website]]**.", "recorded": "2014-10-06T09:00:00", "title": "Slovenian KDD Conference on Data Mining and Data Warehouses (SiKDD), Ljubljana 2014"}, {"url": "sikdd2013_ljubljana", "desc": "Data handling technologies are significantly progressing. The first phases mainly dealing with storing and efficiently accessing the data, resulted in the development of industry delivering tools for handling large databases, standardization of related processes, queering languages, etc. When the data storage was not a primary problem any more the need for improving the database organization resulted in the databases supporting not only transactions but also analytical views of the data. At this point data warehousing with OLAP (On-Line-Analytical-Processing) entered as a usual part of a company information system. The OLAP paradigme stil requires from the user to set well defined questions which is not always easy and possible. This led to the development of Data Mining offering automatic data analysis trying to obtain some new information from the existing data and enabling the user some new insights in the data. Further development of methods for Text and Multimedia Mining enables handling textual, video and audio data in addition to well structured data in databases. Large amount of data and activities on the Web is further addressed in Web Mining where in addition to content of the Web documents, the structure of the Web and Web log-files are analysed. Structure of interconnected data objects is also in focus of Link Detection and Link Analysis, as for instance in Social Network Analysis.\r\n\r\nTo find out more please visit **[[http://ailab.ijs.si/dunja/SiKDD2013/|SiKDD 2013 website]]**.", "recorded": "2013-10-07T09:00:00", "title": "Slovenian KDD Conference on Data Mining and Data Warehouses (SiKDD), Ljubljana 2013"}, {"url": "sikdd2011_ljubljana", "desc": "Data handling technologies are significantly progressing. The first phases mainly dealing with storing and efficiently accessing the data, resulted in the development of industry delivering tools for handling large databases, standardization of related processes, queering languages, etc. When the data storage was not a primary problem any more the need for improving the database organization resulted in the databases supporting not only transactions but also analytical views of the data. At this point data warehousing with OLAP (On-Line-Analytical-Processing) entered as a usual part of a company information system. The OLAP paradigme stil requires from the user to set well defined questions which is not always easy and possible. This led to the development of Data Mining offering automatic data analysis trying to obtain some new information from the existing data and enabling the user some new insights in the data. Further development of methods for Text and Multimedia Mining enables handling textual, video and audio data in addition to well structured data in databases. Large amount of data and activities on the Web is further addressed in Web Mining where in addition to content of the Web documents, the structure of the Web and Web log-files are analysed. Structure of interconnected data objects is also in focus of Link Detection and Link Analysis, as for instance in Social Network Analysis. \r\n\r\nDetailed information can be found at [[http://ailab.ijs.si/dunja/SiKDD2011/|Slovenian KDD conference 2011]].", "recorded": "2011-10-10T09:15:00", "title": "Slovenian KDD Conference on Data Mining and Data Warehouses (SiKDD), Ljubljana 2011"}, {"url": "is2012_sikdd2012", "desc": "Data handling technologies are significantly progressing. The first phases mainly dealing with storing and efficiently accessing the data, resulted in the development of industry delivering tools for handling large databases, standardization of related processes, queering languages, etc. When the data storage was not a primary problem any more the need for improving the database organization resulted in the databases supporting not only transactions but also analytical views of the data.\\\\\r\nAt this point data warehousing with OLAP (On-Line-Analytical-Processing) entered as a usual part of a company information system. The OLAP paradigme stil requires from the user to set well defined questions which is not always easy and possible. This led to the development of Data Mining offering automatic data analysis trying to obtain some new information from the existing data and enabling the user some new insights in the data.\\\\\r\nFurther development of methods for Text and Multimedia Mining enables handling textual, video and audio data in addition to well structured data in databases. Large amount of data and activities on the Web is further addressed in Web Mining where in addition to content of the Web documents, the structure of the Web and Web log-files are analysed. Structure of interconnected data objects is also in focus of Link Detection and Link Analysis, as for instance in Social Network Analysis.\r\n\r\nTo find out more please visit **[[http://ailab.ijs.si/dunja/SiKDD2012/|SiKDD 2012 website]]**.", "recorded": "2012-10-08T09:00:00", "title": "Slovenian KDD Conference on Data Mining and Data Warehouses (SiKDD) 2012"}, {"url": "sikdd2012_ljubljana", "desc": "Data handling technologies are significantly progressing. The first phases mainly dealing with storing and efficiently accessing the data, resulted in the development of industry delivering tools for handling large databases, standardization of related processes, queering languages, etc. When the data storage was not a primary problem any more the need for improving the database organization resulted in the databases supporting not only transactions but also analytical views of the data. At this point data warehousing with OLAP (On-Line-Analytical-Processing) entered as a usual part of a company information system. The OLAP paradigme stil requires from the user to set well defined questions which is not always easy and possible. This led to the development of Data Mining offering automatic data analysis trying to obtain some new information from the existing data and enabling the user some new insights in the data. Further development of methods for Text and Multimedia Mining enables handling textual, video and audio data in addition to well structured data in databases. Large amount of data and activities on the Web is further addressed in Web Mining where in addition to content of the Web documents, the structure of the Web and Web log-files are analysed. Structure of interconnected data objects is also in focus of Link Detection and Link Analysis, as for instance in Social Network Analysis.\r\n\r\nDetailed information can be found at [[http://ailab.ijs.si/dunja/SiKDD2012/|Slovenian KDD conference 2012]].", "recorded": "2012-10-08T09:15:00", "title": "Slovenian KDD Conference on Data Mining and Data Warehouses (SiKDD), Ljubljana 2012"}, {"url": "kdd2013_melville_text_analytics", "desc": "U-report is an open-source SMS platform operated by UNICEF Uganda, designed to give community members a voice on issues that impact them. Data received by the system are either SMS responses to a poll conducted by UNICEF, or unsolicited reports of a problem occurring within the community. There are currently 200,000 U-report participants, and they send up to 10,000 unsolicited text messages a week. The objective of the program in Uganda is to understand the data in real-time, and have issues addressed by the appropriate department in UNICEF in a timely manner. Given the high volume and velocity of the data streams, manual inspection of all messages is no longer sustainable. This paper describes an automated message-understanding and routing system deployed by IBM at UNICEF. We employ recent advances in data mining to get the most out of labeled training data, while incorporating domain knowledge from experts. We discuss the trade-offs, design choices and challenges in applying such techniques in a real-world deployment.", "recorded": "2013-08-14T14:39:46", "title": "Amplifying the Voice of Youth in Africa via Text Analytics"}, {"url": "ecmlpkdd09_steinberger_hmna", "desc": "The publicly accessible Europe Media Monitor (EMM) family of applications (http://press.jrc.it/overview.html) gather and analyse an average of 80,000 to 100,000 online news articles per day in up to 43 languages. Through the extraction of meta-information in these articles, they provide an aggregated view of the news, they allow to monitor trends and to navigate the news over time and even across languages. EMM-NewsExplorer additionally collects historical information about persons and organisations from the multilingual news, generates co-occurrence and quotation-based social networks, and more. All EMM applications were entirely developed at, and are being maintained by, the European Commission\u2019s Joint Research Centre (JRC) in Ispra, Italy.\r\n\r\nThe applications make combined use of a variety of text analysis tools, including clustering, multi-label document classification, named entity recognition, name variant matching across languages and writing systems, topic detection and tracking, event scenario template filling, and more. Due to the high number of languages covered, linguistics-poor methods were used for the development of these text mining components. See the site http://langtech.jrc.it/ for technical details and a list of publications.\r\n\r\nThe speaker will give an overview of the various applications and will then explain the workings of selected text analysis components.", "recorded": "2009-09-09T09:05:00", "title": "Highly Multilingual News Analysis Applications"}, {"url": "clsp_cortes_kernels", "desc": "Kernel methods are widely used in statistical learning techniques due to their excellent performance and their computational efficiency in high-dimensional feature space. However, text or speech data cannot always be represented by the fixed-length vectors that the traditional kernels handle. In this talk, we introduce a general framework, Rational Kernels, that extends kernel techniques to deal with variable-length sequences and more generally to deal with large sets of weighted alternative sequences represented by weighted automata. Far from being abstract and computationally complex objects, rational kernels can be readily implemented using general weighted automata algorithms that have been extensively used in text and speech processing and that we will briefly review. Rational kernels provide a general framework for the definition and design of similarity measures between word or phone lattices particularly useful in speech mining applications. Viewed as a similarity measure, they can also be used in Support Vector Machines and significantly improve the spoken-dialog classification performance in difficult tasks such as the AT&amp;T 'How May I Help You' (HMIHY) system. We present several examples of rational kernels to illustrate these applications. We finally show that many string kernels commonly considered in computational biology applications are specific instances of rational kernels.", "recorded": "2007-08-15T15:15:14", "title": "Rational Kernels: A General Machine Learning Framework for the Analysis of Text, Speech and Biological Sequences"}, {"url": "ecmlpkdd08_zavrel_mlce", "desc": "Machine learning methods are widely used as a heuristic knowledge acquisition method for building commercial text mining and document understanding systems, even though learning from data inherently delivers imperfect results. In this talk I will look at the practical value of imperfect solutions in document understanding systems, and at how machine learning is effective in this context, in particular in domains which are transaction oriented. We will point out practical issues from an industrial perspective, illustrated by cases from our practice at Textkernel. Machine Learning is proving to be a viable commercial methodology for knowledge acquisition and offers a principled way towards progress in systems engineering for Language Technology.", "recorded": "2008-09-16T14:00:00", "title": " \tMachine Learning Considered Effective for Commercial Document Understanding Systems"}, {"url": "eswc2013_aimashup", "desc": "The AI mashup challenge accepts and awards mashups that use AI technology, including but not restricted to machine learning and data mining, machine vision, natural language processing, reasoning, ontologies in the context of the semantic web. Imagine for example:\r\n\r\n*Information extraction or automatic text summarization to create a task-oriented overview mashup for mobile devices\r\n*Semantic Web technology and data sources adapting to user and task-specific configurations\r\n*Semantic background knowledge (such as ontologies, WordNet, Freebase or Cyc) to improve search and content combination\r\n*Machine translation for mashups that cross-language borders\r\n*Machine vision technology for novel ways of aggregating images, for instance mixing real and virtual environments\r\n*Intelligent agents taking over simple household planning tasks\r\n*Text-to-speech technology creating speech mashups with intelligent and emotional intonation\r\n*Speech-to-text technology for interactive speech mashups and multimodal services\r\n*The display of Pub Med articles on a map based on geographic entity detection referring to diseases or health centers\r\n*The integration of enterprise data - see Open Mashup Alliance.\r\n\r\nThe emphasis is not on providing and consuming semantic markup, but rather on using intelligence to mashup these resources in a more powerful way. For more ideas have a look at [[http://aimashup.org/aimashup13/doku.php?id=results|AI Mashup Challenge 2013 website]].", "recorded": "2013-05-28T17:00:00", "title": "AI Mashup Challenge 2013"}, {"url": "eswc09_nenadic_msdob", "desc": "A number of projects (myGrid, BioMOBY, etc.) have been initiated to organise emerging bioinformatics Web Services and provide their semantic descriptions. They typically rely on manual curation efforts. In this paper we focus on a semi-automated approach to mine semantic descriptions from the bioinformatics literature. The method combines terminological processing and dependency parsing of journal articles, and applies information extraction techniques to profile Web services using informative textual passages, related ontological annotations and service descriptors. Service descriptors are terminological phrases reflecting specific roles (e.g. input, output, etc.) of the related semantic classes (e.g. algorithm, database, etc.). They can be used to facilitate subsequent manual description of services, but also for providing a semantic synopsis of a service that can be used to locate related services. We present a case-study involving a subset of full text articles from the BMC Bioinformatics journal. We illustrate the potential of natural language processing not only for mining descriptions of known services, but also for discovering new services that have been described in the literature.", "recorded": "2009-06-02T14:30:45", "title": "Mining Semantic Descriptions of Bioinformatics Web Services from the Literature"}, {"url": "kdd2010_rao_mmdi", "desc": "The last century has seen a massive increase in the accuracy and sensitivity of diagnostic tests: from observing external symptoms, to precise laboratory panels, to complex imaging methods for non-invasive internal examinations, to, in the very near future, the use of genomic and molecular analysis at the bedside. This improved diagnostic accuracy has resulted in an exponential increase in the patient data available to the physician. Furthermore, medical knowledge is continuously growing, with physicians being flooded with an expanding array of new tests, updated clinical guidelines on how to diagnose and treat patients, and evidence-based results from clinical trials. Both these trends \u2013 the increase in patient data and medical knowledge \u2013 will only intensify, as healthcare transforms into the practice of increasingly personalized medicine.\r\n\r\nThere is a tremendous opportunity for data mining methods to assist the physician, improve patient care, control costs, and ultimately to save lives. In this talk we will provide an overview of the special challenges faced in launching new healthcare data mining products, and identify a few key take aways for entrepreneurs who want to create new businesses in this domain. We begin by analyzing the clinical need for products to mine medical images to enable radiologists to identify cancers and other medical conditions in asymptomatic patients, and thus begin treatment as early as possible. The next step is personalized therapy selection, which requires data mining methods to mine different patient data sources, including images, free text, labs, pharmacy, molecular &amp; genomic data. We discuss how to determine the scope and market size for products such as these, and identify the key methodological issues we have tackled. We focus on the clinical, regulatory and marketing challenges that we have had to solve over the last decade, as we have gone from concepts, to deployed products that are used today in thousands of patient encounters worldwide. We conclude by highlighting results that demonstrate the impact of data mining on patient care and improved outcomes.\r\n", "recorded": "2010-07-26T10:30:00", "title": "Mining Medical Data to Improve Patient Outcomes"}, {"url": "kdd2010_mei_dripd", "desc": "Information networks are widely used to characterize the relationships between data items such as text documents. Many important retrieval and mining tasks rely on ranking the data items based on their centrality or prestige in the network. Beyond prestige, diversity has been recognized as a crucial objective in ranking, aiming at providing a non-redundant and high coverage piece of information in the top ranked results. Nevertheless, existing network-based ranking approaches either disregard the concern of diversity, or handle it with non-optimized heuristics, usually based on greedy vertex selection. \r\nWe propose a novel ranking algorithm, DivRank, based on a reinforced random walk in an information network. This model automatically balances the prestige and the diversity of the top ranked vertices in a principled way. DivRank not only has a clear optimization explanation, but also well connects to classical models in mathematics and network science. We evaluate DivRank using empirical experiments on three different networks as well as a text summarization task. DivRank outperforms existing network-based ranking methods in terms of enhancing diversity in prestige. ", "recorded": "2010-07-27T17:50:00", "title": "DivRank: the Interplay of Prestige and Diversity in Information Networks"}, {"url": "mmdss07_fogelman_mmds", "desc": "Today, the amount of data coming from all possible sources is\r enormous and growing at a fast pace due, in large part, to the ubiquitous Web\r and its increasing presence in our everyday life; but also to emails, cell phones,\r credit cards, retail, finance ... These data serve all sorts of functions : from\r query and search, to extracting information, providing services as well as\r managing security. Many fields are involved : statistics, data mining, text\r mining, data streams, search, social networks ... There is no lack of\r sophisticated techniques produced by academic activity, where challenges\r mostly deal with novelty, accuracy, and scalability of algorithms. However, in\r real-world applications, challenges are quite different : scalability (usually one\r or two orders of magnitude more than in academic publications), ease-of-use\r and capability to integrate efficient techniques into working systems in a\r transparent way, while always producing value for the customer. Real-world\r solutions are complex and usually need to integrate many technical\r components, from the various fields mentioned before: it thus becomes\r important to assess how these fields can complement one another.\r In the first part of the talk, I will present the challenges of real-world data\r mining applications. I will introduce the general Statistical Learning Theory\r framework and discuss some of the technical issues involved (large dimension\r data sets, missing data, outliers, non-i.i.d. structured data, unlabelled data ...) In\r the second part, I will show, taking examples from the implementation in\r KXEN and applications developed, how a theoretical framework (Structural\r Risk Minimization [1]) can be used to solve some of the challenges met in the\r real-world. I will finally describe some open practical issues which will require\r further theoretical investigation.", "recorded": "2007-09-10T09:31:20", "title": "Mining Massive Data Sets "}, {"url": "ecmlpkdd08_naudts_suiar", "desc": "MDC Partners is based in Belgium and delivers business and market intelligence to pharma and medical device companies. As heterogenous public databases and the internet are our main data sources, semantic unification of concepts is the necessary driving force behind our data gathering en data storage platforms. In this talk we discuss a number of design philosophies and technical challenges in building a semantic data gathering, mining and reporting engine. Specifically on the semantic unification side, we will discuss alternative schemes for semantisizing text fragments, based on bootstrapped probabilistic grammars, reference ontologies and factual semantic data. The impact on the total semantic engine, from incoming data to reported queries, of alternative approaches will be discussed.", "recorded": "2008-09-16T14:40:00", "title": " \tSemantic Unification in a Real-World Data Flow for Delivering Business Intelligence"}, {"url": "mmdss07_gallinari_lsd", "desc": "We focus on the prediction of structured outputs. A classical example\r is sequence labeling with applications in speech, vision, natural language or\r biology. Beyond sequences, the prediction of structured data, like trees, lattices\r or graphs also occurs in many domains. Structured prediction is usually considered\r as an extension of multi-class classification. It is considered as a challenging\r problem since the size of the output space increases drastically with the number\r of potential dependencies between output variables. Several methods have been\r recently proposed in the ML community in order to overcome this complexity and\r the domain is still largely open. We will provide a review of these methods and\r discuss there potential and limitations. These different ideas will be illustrated\r with Natural language processing and text mining applications.", "recorded": "2007-09-14T09:15:03", "title": "Learning with structured data - structured outputs"}, {"url": "icwsm2011_lin_twitter", "desc": "Twitter provides amazing opportunities for the emerging field of data science. From the perspective of data science as algorithms and systems for mining insights from large datasets, it provides a rich playground for text, graph, and stream processing as well as distributed systems. From the perspective of data science as data-driven scientific inquiry (i.e., \"the fourth paradigm\"), Twitter provides unprecedented access to the workings of human social groups, driving much work in computational social science. Nevertheless, both pursuits are fraught with challenges, ranging from data acquisition to scalable algorithms. In this talk, Lin will share some observations from the perspective of someone who has navigated academia as well as built production systems used by millions daily. He'll point out interesting directions for research and reflect on the question of impact, hopefully paving the way for an even more vibrant Twitter ecosystem.", "recorded": "2011-07-19T09:00:45", "title": "Twitter and Data Science"}, {"url": "cmuseminars_mladenic_media_monitoring", "desc": "Global media monitoring in real-time assumes handling large amount of textual data across different languages. We propose using text mining methods together with semantic processing to identify events from media and track the media reporting on them. We will demonstrate the proposed approach on operational media monitoring system that involves a large number of data streams in multiple languages. The system comprises a Cross-lingual Global Media Monitoring platform http://EventRegistry.org for (a) collecting media information from 300,000 news and social media sources, (b) performing linguistic and semantic processing in multiple languages, (c) forming events and event sequences, (d) streaming information about events in open data formats, (e) rich visualizations, and (f) search with complex queries for analysing global social dynamics. Challenges and technical solutions were discussed.", "recorded": "2015-02-10T14:30:00", "title": "Cross-lingual Global Media Monitoring"}, {"url": "icwsm2013_schulz_multi_indicator", "desc": "Real-time information from microblogs like Twitter is useful for different applications such as market research, opinion mining, and crisis management. For many of those messages, location information is required to derive useful insights. Today, however, only around 1% of all tweets are explicitly geotagged. We propose the first multi-indicator method for determining (1) the location where a tweet was created as well as (2) the location of the user's residence. Our method is based on various weighted indicators, including the names of places that appear in the text message, dedicated location entries, and additional information from the user profile. An evaluation shows that our method is capable of locating 92% of all tweets with a median accuracy of below 30km, as well as predicting the user's residence with a median accuracy of below 5.1km. With that level of accuracy, our approach significantly outperforms existing work.", "recorded": "2013-07-08T14:49:00", "title": "A Multi-Indicator Approach for Geolocalization of Tweets"}, {"url": "waw09_barcelona", "desc": "The World Wide Web has become part of our everyday life, and information retrieval and data mining on the Web are now of enormous practical interest. The algorithms supporting these activities combine the view of the Web as a text repository and as a graph, induced in various ways by links among pages, links among hosts, or other similar networks. We also witness an increasing role of the second generation Web-based applications Web 2.0 such as social networking sites and wiki sites.\r\n\r\nThe aim of the 6-th Workshop on Algorithms and Models for the Web Graph (WAW2009) is to further the understanding of the Web and Web 2.0 graphs, and stimulate the development of high-performance algorithms and applications for Web and Web 2.0. The workshop will also welcome the researchers who are working on graph-theoretic and algorithmic aspects of citation networks, social networks, biological networks, molecular networks, and Internet.", "recorded": "2009-02-12T15:00:00", "title": "The 6th Workshop on Algorithms and Models for the Web Graph (WAW2009)"}, {"url": "acmwebsci2011_flock_diversity", "desc": "Wikipedia is a top-ten Web site providing a free encyclopedia created\r\nby an open community of volunteer contributors. As investigated\r\nin various studies over the past years, contributors have different\r\nbackgrounds, mindsets and biases; however, the effects - positive\r\nand negative - of this diversity on the quality of the Wikipedia\r\ncontent, and on the sustainability of the overall project are yet only\r\npartially understood. In this paper we discuss these effects through\r\nan analysis of existing scholarly literature in the area and identify\r\ndirections for future research and development; we also present an\r\napproach for diversity-minded content management within Wikipedia\r\nthat combines techniques from semantic technologies, data and text\r\nmining and quantitative social dynamics analysis to create greater\r\nawareness of diversity-related issues within the Wikipedia community,\r\ngive readers access to indicators and metrics to understand\r\nbiases and their impact on the quality of Wikipedia articles, and\r\nsupport editors in achieving balanced versions of these articles that\r\nleverage the wealth of knowledge and perspectives inherent to large scale\r\ncollaboration.", "recorded": "2011-06-15T17:00:33", "title": "Towards a diversity-minded Wikipedia"}, {"url": "icwsm2011_livne_election", "desc": "In this work, we study the use of Twitter by House, Senate\r\nand gubernatorial candidates during the midterm (2010)\r\nelections in the U.S. Our data includes almost 700\r\ncandidates and over 690k documents that they produced and\r\ncited in the 3.5 years leading to the elections. We utilize\r\ngraph and text mining techniques to analyze differences\r\nbetween Democrats, Republicans and Tea Party candidates,\r\nand suggest a novel use of language modeling for estimating\r\ncontent cohesiveness. Our findings show significant\r\ndifferences in the usage patterns of social media, and\r\nsuggest conservative candidates used this medium more\r\neffectively, conveying a coherent message and maintaining\r\na dense graph of connections. Despite the lack of party\r\nleadership, we find Tea Party members display both\r\nstructural and language-based cohesiveness. Finally, we\r\ninvestigate the relation between network structure, content\r\nand election results by creating a proof-of-concept model\r\nthat predicts candidate victory with an accuracy of 88.0%.", "recorded": "2011-07-19T10:55:00", "title": "The Party Is Over Here: Structure and Content in the 2010 Election"}, {"url": "solomon_buntine_topic_models", "desc": "This talk will cover some of our recent work in extended topic models to serve as tools in text mining and NLP (and hopefully, later, in IR) when some semantic analysis is required. In some sense our goals are akin to the use of Latent Semantic Analysis. The basic theoretical/algorithmic tool we have for this is non-parametric Bayesian methods for reasoning on hierarchies of probability vectors.\r\n\r\nThe concepts will be introduced but not the statistical detail. Then I'll present some of our KDD 2014 paper (Experiments with Non-parametric Topic Models), and some extended work such as \"Bibliographic Analysis with the Citation Network Topic Model\" (ACML 2014) and \"Topic Segmentation with a Structured Topic Model\" (NAACL 2013). Various valuations and comparisons will be made. The fully non-parametric topic model with burstiness is currently the best performing published model by a number of measures and is only a small factor slower in speed (and small factor larger in memory) than standard LDA implementations.", "recorded": "2015-01-14T13:00:00", "title": "Experiments with Non-parametric Topic Models"}, {"url": "mmdss07_best_osi", "desc": "Open Source Intelligence can be defined as the retrieval, extraction and analysis of information from publicly available sources. Each of these three processes is the subject of ongoing research resulting in specialised techniques. Today the largest source of open source information is the Internet. Most newspapers and news agencies have web sites with live updates on unfolding events, opinions and perspectives on world events are published. Most governments monitor news reports to feel the pulse of public opinion, and for early warning and current awareness of emerging crises. The phenomenal growth in knowledge, data and opinions published on the Internet requires advanced software tools which allow analysts to cope with the overflow of information. Malicious use of the Internet has also grown rapidly particularly on-line fraud, illegal content, virtual stalking, and various scams. These are all creating major challenges to security and law enforcement agencies. The alarming increase in the use of the Internet by extremist and Terrorist groups has emerged. The number of terrorist linked websites has grown from about 15 in 1998 to some 4500 today. These sites use slick multimedia to distil propaganda whose main purpose is to 1) enthuse and stir up rebellion in embedded communities 2) instill fear in the \u201cenemy\u201d and fight psychological warfare. Anonymous communication between terrorist cells via bulletin boards, chat rooms and email is also prevalent.\r The Joint Research Centre has developed significant experience in Internet content monitoring through its work on media monitoring (EMM) for the European Commission. EMM forms the core of the Commissions daily press monitoring service, and has also been adopted by the European Council Situation Centre for their ODIN system. A new research topic at the JRC is Web mining and open source intelligence. This applies EMM technology to the wider Internet and not just to news sites. This applies advanced multi-lingual search techniques to identify potential web resources and the extraction and download of all the textual content. This is then followed by automatic change detection, the recognition of places, names and relationships, and further analysis of the resultant large bodies of text. These tools help analysts to process large amounts of documents and derive structured data easier to analyse.\r \r This talk will review 4 main topics:\r \r \u2022 Internet trends and the rapid rise of Web 2.0 user generated content\r \u2022 Information retrieval: Live content monitoring of multilingual news reports. Web scraping &amp; RSS feed generation, Web Mining and content monitoring\r \u2022 Information Extraction: Topic filtering, Topic Clustering, multilingual named entity extraction, geocoding and geolocating text, event extraction, opinion mining.\r \u2022 Information Analysis: Social Network derivation, geospatial indexing and analysis, incident tracking databases, statistical trend analysis, threat monitoring and assessment.", "recorded": "2007-09-20T09:15:00", "title": "Open Source Intelligence"}, {"url": "xlike", "desc": "The goal of the **[[http://www.xlike.org/|X-LIKE project]]** is to develop technology to monitor and aggregate knowledge that is currently spread across global mainstream and social media, and to enable cross-lingual services for publishers, media monitoring and business intelligence.\r\n\r\nIn terms of research contributions, the aim is to combine scientific insights from several scientific areas to contribute in the area of cross-lingual text understanding. By combining modern computational linguistics, machine learning, text mining and semantic technologies we plan to deal with the following two key open research problems:\r\n#to extract and integrate formal knowledge from multilingual texts with cross-lingual knowledge bases, and\r\n#to adapt linguistic techniques and crowdsourcing to deal with irregularities in informal language used primarily in social media.\r\n\r\nAs an interlingua, knowledge resources from Linked Open Data cloud (http://linkeddata.org) will be used with special focus on general common sense knowledge base CycKB (http://www.cyc.com). For the languages where no required linguistic resources will be available, we will use a probabilistic interlingua representation trained from a comparable corpus drawn from the Wikipedia.\r\n\r\nThe solution will be applied on two case studies, both from the area of news. For the Bloomberg case study the domain will be financial news, while for the Slovenian Press Agency we will deal with general news. The technology developed in the project will be used to introduce cross-lingual and information from social media in services for publishers and end-users in the area of summarization, contextualization, personalization, and plagiarism detection. Special attention will be paid to analysing news reporting bias from multilingual sources.\r\n\r\nThe developed technology will be language-agnostic, while within the project we will specifically address English, German, Spanish, and Chinese as major world languages and Catalan and Slovenian as minority languages.", "recorded": "2012-01-30T15:42:54", "title": "XLike"}, {"url": "wapa2011_sudhahar_quantitative", "desc": "We present a working system for large scale quantitative narrative analysis (QNA) of news corpora, which includes various recent ideas from text mining and pattern analysis in order to solve a problem arising in computational social sciences. The task is that of identifying the key actors in a body of news, and the actions they perform, so that further analysis can be carried out. This step is normally performed by hand and is very labour intensive. We then characterise the actors by: studying their position in the overall network of actors and actions; studying the time series associated with some of their properties; generating scatter plots describing the subject/object bias of each actor; and investigating the types of actions each actor is most associated with. The system is demonstrated on a set of 100,000 articles about crime appeared on the New York Times between 1987 and 2007. As an example, we find that Men were most commonly responsible for crimes against the person, while Women and Children were most often victims of those crimes.", "recorded": "2011-10-21T12:00:00", "title": "Automating Quantitative Narrative Analysis of News Data "}, {"url": "icml2015_ghoshdastidar_tensor_spectral_method", "desc": "Matrix spectral methods play an important role in statistics and machine learning, and most often the word `matrix\u2019 is dropped as, by default, one assumes that similarities or affinities are measured between two points, thereby resulting in similarity matrices. However, recent challenges in computer vision and text mining have necessitated the use of multi-way affinities in the learning methods, and this has led to a considerable interest in hypergraph partitioning methods in machine learning community. A plethora of \u201chigher-order\u201d algorithms have been proposed in the past decade, but their theoretical guarantees are not well-studied. In this paper, we develop a unified approach for partitioning uniform hypergraphs by means of a tensor trace optimization problem involving the affinity tensor, and a number of existing higher-order methods turn out to be special cases of the proposed formulation. We further propose an algorithm to solve the proposed trace optimization problem, and prove that it is consistent under a planted hypergraph model. We also provide experimental results to validate our theoretical findings.", "recorded": "2015-07-09T14:46:53", "title": "A Provable Generalized Tensor Spectral Method for Uniform Hypergraph Partitioning"}, {"url": "kdd07_zhu_erne", "desc": "Expense reimbursement is a time-consuming and labor-intensive process across organizations. In this talk, we present an automated expense reimbursement system developed at IBM Almaden Research Center. Our complete solution involves (1) an electronic document management infrastructure that provides multi-channel image capture, transport and storage of paper documents, such as receipts; (2) an unconstrained data mining approach to extracting relevant named entities from un-structured document images; (3) automation of manual auditing procedures using extracted metadata. The main focus of this presentation is our approach to automatically extracting important metadata, once we aggregate documents through such a scalable infrastructure. Extracting relevant named entities robustly from document images with unconstrained layouts and diverse formatting is a fundamental technical challenge to image-based data mining, question answering, and other information retrieval tasks. In many applications that require such capability, applying traditional language modeling techniques to the stream of OCR text does not give satisfactory result due to the absence of linguistic contexts, such as language constructs and punctuation. We present a novel approach for extracting relevant named entities from document images by learning the statistical dependencies between page layout and language features collectively from the sequence of geometrically decomposed regions on a document using a discriminative conditional random fields (CRFs) framework. We integrate this named entity extraction engine into our expense reimbursement solution and evaluate the system performance on large collections of real world receipt images provided by IBM World Wide Reimbursement Center.\\\\", "recorded": "2007-08-13T11:00:00", "title": "Extracting Relevant Named Entities for Automated Expense Reimbursement "}, {"url": "dataforum2012_tzoumas_big_data", "desc": "Linking and Analyzing Big Data Summary of the presentation: In this talk, I will provide an overview of two projects at TU Berlin, and the research and innovation challenges in their intersection. Stratosphere (www.stratosphere.eu, funded by the German Research Foundation) is an open platform for Big Data Analytics. It features a cloud-enabled execution engine with flexible fault tolerance schemes, a novel programming model centered around second-order functions that extends MapReduce, and a cost-based query optimizer. Stratosphere is validated by several use-case scenarios, including climate data analysis, text mining in the Bioinformatics, and data cleansing on Linked Open Data. DOPA (an FP7 STREP project) focuses on linking large Data Pools of both structured and unstructured data using data supply chains. The goal is to multiply the utility of each individual service while simultaneously sharing the costs between them. This way DOPA lowers the barrier of entry for SMEs that need to perform advanced analytics across multiple data pools since the required input data as well as the processing environment do not have to be provided by the SME itself.", "recorded": "2012-06-07T10:30:00", "title": "Analyzing and Linking Big Data with Stratosphere"}, {"url": "kdd2014_fader_knowledge_bases", "desc": "We consider the problem of open-domain question answering (Open QA) over massive knowledge bases (KBs). Existing approaches use either manually curated KBs like Freebase or KBs automatically extracted from unstructured text. In this paper, we present OQA, the first approach to leverage both curated and extracted KBs.\r\n\r\nA key technical challenge is designing systems that are robust to the high variability in both natural language questions and massive KBs. OQA achieves robustness by decomposing the full Open QA problem into smaller sub-problems including question paraphrasing and query reformulation. OQA solves these sub-problems by mining millions of rules from an unlabeled question corpus and across multiple KBs. OQA then learns to integrate these rules by performing discriminative training on question-answer pairs using a latent-variable structured perceptron algorithm. We evaluate OQA on three benchmark question sets and demonstrate that it achieves up to twice the precision and recall of a state-of-the-art Open QA system.", "recorded": "2014-08-25T12:00:00", "title": "Open Question Answering Over Curated and Extracted Knowledge Bases"}, {"url": "icml2015_ubaru_coding_matrices", "desc": "Low-rank matrix approximation is an integral component of tools such as principal component analysis (PCA), as well as is an important instrument used in applications like web search models, text mining and computer vision, e.g., face recognition. Recently, randomized algorithms were proposed to effectively construct low rank approximations of large matrices. In this paper, we show how matrices from error correcting codes can be used to find such low rank approximations. The benefits of using these code matrices are the following: (i) They are easy to generate and they reduce randomness significantly. (ii) Code matrices have low coherence and have a better chance of preserving the geometry of an entire subspace of vectors; (iii) Unlike Fourier transforms or Hadamard matrices, which require sampling O(klogk) columns for a rank-k approximation, the log factor is not necessary in the case of code matrices. (iv) Under certain conditions, the approximation errors can be better and the singular values obtained can be more accurate, than those obtained using Gaussian random matrices and other structured random matrices.", "recorded": "2015-07-08T14:46:53", "title": "Low Rank Approximation using Error Correcting Coding Matrices"}, {"url": "xlike_kickoff2012_bled", "desc": "The goal of the X-LIKE project is to develop technology to monitor and aggregate knowledge that is currently spread across global mainstream and social media, and to enable cross-lingual services for publishers, media monitoring and business intelligence.\r\n\r\nIn terms of research contributions, the aim is to combine scientific insights from several scientific areas to contribute in the area of cross-lingual text understanding. By combining modern computational linguistics, machine learning, text mining and semantic technologies we plan to deal with the following two key open research problems: - to extract and integrate formal knowledge from multilingual texts with cross-lingual knowledge bases, and - to adapt linguistic techniques and crowdsourcing to deal with\r\nirregularities in informal language used primarily in social media.\r\n\r\nAs an interlingua, knowledge resources from [[http://linkeddata.org/|Linked Open Data]] cloud will be used with special focus on general common sense knowledge base [[http://www.cyc.com/|CycKB]]. For the languages where no required linguistic resources will be available, we will use a probabilistic\r\ninterlingua representation trained from a comparable corpus drawn from the Wikipedia. The solution will be applied on two case\r\nstudies, both from the area of news. For the Bloomberg case study the domain will be financial news, while for the Slovenian Press\r\nAgency we will deal with general news. The technology developed in the project will be used to introduce cross-lingual and\r\ninformation from social media in services for publishers and end-users in the area of summarization, contextualization,\r\npersonalization, and plagiarism detection. Special attention will be paid to analysing news reporting bias from multilingual sources.\r\nThe developed technology will be language-agnostic, while within the project we will specifically address English, German,\r\nSpanish, and Chinese as major world languages and Catalan and Slovenian as minority languages.\r\n\r\nDetailed information about the project can be found at http://www.xlike.org.", "recorded": "2012-01-18T10:00:00", "title": "XLike - Cross-Lingual Knowledge Extraction Kickoff Meeting, Bled 2012"}, {"url": "ecmlpkdd2011_bauckhage_kersting_matrices", "desc": "Low-rank approximations of data matrices have become an important tool in machine learning and data mining. They allow for embedding high dimensional data in lower dimensional spaces and can therefore mitigate effects due to noise, uncover latent relations, or facilitate further processing. These properties have been proven successful in many applications areas such as bio-informatics, computer vision, text process ing, recommender systems, social network analysis, among others. Present day technologies are characterized by exponentially growing amounts of data. Recent advances in sensor technology, Internet applications, and communication networks call for methods that scale to very large and/or growing data matrices. In this tutorial, we discuss basic characteristics of matrix factorization and introduce several recent approaches that scale to modern massive data analysis problems.\r\n\r\nThe tutorial aims at a wide audience as it reviews both machine learning and data mining techniques. It is intended for PhD students, practitioners, and researchers who are interested in large scale machine learning and data analysis.\r\n\r\nThe tutorial is divided into three parts:\r\n\r\n * Part I: Matrix Factorization \u2014 Traditional Optimization Approaches and Statistical Foundations: In this block, we will discuss foundations and multi-linear extensions of traditional methods such as SVD, PCA, K-Means, and Vector Quantization.\r\n * Part II: Constraint Matrix Factorization Many real-world applications of matrix factorization impose constraints on the factorization problem. For instance, matrix factors need to be non-negative, convex combinations of existing data, or compact binary codes. Among others, we discuss techniques such as Spectral Hashing, NMF, Archetypal Analysis, CNMF, and CH-NMF.\r\n * Part III: Data-driven Matrix Factorization Techniques: The first and second part of the tutorial consider norm minimization problems to obtain suitable matrix factors. Recent approaches that extend matrix factorization towards massive data assume a different point of view: they attempt to maximize the volume of a selection of rows and columns of a given data matrix. In this final part of the tutorial, we present and review approaches such as FastMap, CUR, CMD, and SiVM.\r\n\r\nIn each of the parts, we present practical applications from fields such as image processing, computer vision, robotics, web mining, and social media analysis.", "recorded": "2011-09-05T14:00:00", "title": "Factorizing Gigantic Matrices"}, {"url": "ijcai2011_t5_semantic", "desc": "The advent of knowledge-sharing communities such as Wikipedia and the progress in scalable information extraction from Web sources has enabled the automatic construction of large knowledge bases. Recent endeavors of this kind include academic research projects such as DBpedia, EntityCube, KnowItAll, ReadTheWeb, and YAGO-NAGA, as well as industrial ones such as Freebase and Trueknowledge. These projects provide automatically-constructed, large and rich knowledge bases of facts about named entities, their semantic classes, and their mutual relations. This 1-day tutorial will discuss a) the content, organization, and potential of these Web-induced knowledge bases, b) state-of-the-art methods for constructing them from semistructured and textual Web sources, c) recent approaches to maintaining and extending them, which includes introducing a temporal dimension of knowledge, d) use cases of knowledge bases, including semantic search, reasoning for question answering, and entity linking and disambiguation. It is likely to interest a broad audience of AI researchers because it bridges the areas of data and text mining, knowledge extraction, knowledge-based search, and uncertain data management. It will also point out open problems and research opportunities on this spectrum of issues.", "recorded": "2011-07-18T00:00:00", "title": "Semantic Knowledge Bases from Web Sources"}, {"url": "eswc2012_kolcz_twitter", "desc": "Twitter represents a large complex network of users with diverse and continuously evolving interests. Discussions and interactions range from very small to very large groups of people and most of them occur in the public. Interests are both long and short term and are expressed by the content generated by the users as well as via the Twitter follow graph, i.e. who is following whose content. Understanding user interests is crucial to providing good Twitter experience by helping users to connect to others, find relevant information and interesting information sources. The manner in which information is spread over the network and communication attempts are made can also help in identifying spammers and other service abuses. Understanding users and their preferences is also a very challenging problem due to the very large volume information, the fast rate of change and the short nature of the tweets. \r\nLarge scale machine learning as well as graph and text mining have been helping us to tackle these problems and create new opportunities to better understand our users. In the talk I will describe a number of challenging modeling problems addressed by the Twitter team as well as our approach to creating frameworks and infrastructure to make learning at scale possible.", "recorded": "2012-05-31T14:00:00", "title": "Large Scale Learning at Twitter"}, {"url": "www2011_sheth_velmurugan_csd", "desc": "With the rapid rise in the popularity of social media (500M+ Facebook users, 100M+ twitter users), and near ubiquitous mobile access (4.1 billion actively-used mobile phones), the sharing of observations and opinions has become common-place (nearly 100M tweets a day, 1.8 trillion SMSs in US last year). This has given us an unprecedented access to the pulse of a populace and the ability to perform analytics on social data to support a variety of socially intelligent applications -- be it towards targeted online content delivery, crisis management, organizing revolutions or promoting social development in underdeveloped and developing countries.\r\nThis tutorial will address challenges and techniques for building applications that support a broad variety of users and types of social media. This tutorial will focus on social intelligence applications for social development, and cover the following research efforts in sufficient depth: 1) understanding and analysis of informal text, esp. microblogs (e.g., issues of cultural entity extraction and role of semantic/background knowledge enhanced techniques), and 2) building social media analytics platforms. Technical insights will be coupled with identification of computational techniques and real-world examples.\r\n", "recorded": "2011-03-28T08:30:00", "title": "Citizen Sensor Data Mining, Social Media Analytics and Development Centric Web Applications"}, {"url": "sokt08_ljubljana", "desc": "**Integration of data sources and tools, and performing computations on them is one of the key problems for using the data from experimental biology today** (see e.g. CFP of the Workshop on Service Oriented Technologies for Biological Databases and Tools (SOBDAT 2007), **held in conjunction with ICWS/SCC 2007 9-13 July 2007, Salt Lake City, [[http://www.cs.gsu.edu/~hipc/sobdat07/|Utah]])**. These resources are highly diverse in nature in terms of representation, data formats, and computer systems and are distributed across the network. Although this broad spectrum of information is accessible over the Web, each data source comes with its own structure, semantics, data formats, names, concepts, and access methods. Currently, the burden falls on the scientist to manually (via programs) convert between the data formats, resolve conflicts, integrate data, and interpret results in order to make viable use of this information.\r\n\r\n**This workshop intends to bring together JSI and Leiden researches** with the intention to elaborate a joint service oriented approach to information fusion, for the needs of exploratory data analysis in the framework of inductive databases, enriched with ontology and text information available from the web. The goal of this workshop is to:\r\n\r\n-\t//Present subgroup discovery, as a methodology for exploratory/explanatory data analysis in biomedical applications;//\r\n\r\n-\t//Present an architecture for inductive databases, and an approach to extending this architecture to a service oriented architectures (SoA);//\r\n\r\n-\t//Present details of the background data mining technologies: subgroup discovery and propositionalization approach to relational data mining;//\r\n\r\n-\t//Enable ample brainstorming time on how to implement the SOKT architecture. SEGS workflow in a SoA framework, as a step in a more ambitious SoA approach to implementing workflows for exploratory data analysis;///\r\n\r\n-\t//Presentation of the proposed architecture for the future Service Oriented Knowledge Technologies (SOKT) toolbox;//\r\n\r\n-\t//Wrap-up session: Summary of achievements and plans for future work.//", "recorded": "2008-01-19T09:00:00", "title": "Workshop on Service Oriented Knowledge Technologies "}]
</code></pre>

<h3>
<a aria-hidden="true" href="#researchers-keywords-search" class="anchor" id="user-content-researchers-keywords-search"><span class="octicon octicon-link"></span></a>Researcher's keywords search</h3>

<p>Get keywords assigned to researchers. The call returns the keyword <code>keyws</code> and <code>freq</code>. Freq indicates how many times the keywords in the dataset.</p>

<h4>
<a aria-hidden="true" href="#call-4" class="anchor" id="user-content-call-4"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/rsrkeyws/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-4" class="anchor" id="user-content-example-4"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/rsrkeyws/machine">http://exploredu.ijs.si/api/rsrkeyws/machine</a></p>

<h4>
<a aria-hidden="true" href="#result-4" class="anchor" id="user-content-result-4"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"freq": 1, "keyws": "machine design"}, {"freq": 6, "keyws": "machine parts"}, {"freq": 34, "keyws": "machine learning"}, {"freq": 1, "keyws": "machine elements"}, {"freq": 1, "keyws": "machine physics"}, {"freq": 1, "keyws": "machine ports"}, {"freq": 1, "keyws": "milking machine"}, {"freq": 1, "keyws": "machine control"}, {"freq": 3, "keyws": "machine vision"}, {"freq": 3, "keyws": "sewing machine"}, {"freq": 2, "keyws": "specialising in machine design"}, {"freq": 1, "keyws": "cnc machine tools"}, {"freq": 1, "keyws": "statistical machine translation"}, {"freq": 1, "keyws": "man-machine communication"}, {"freq": 1, "keyws": "computerized machine control"}, {"freq": 1, "keyws": "human machine interfaces"}, {"freq": 1, "keyws": "human - machine communication"}, {"freq": 1, "keyws": "human-machine systems"}, {"freq": 1, "keyws": "wear of machine elements"}, {"freq": 1, "keyws": "machine component and preparing"}, {"freq": 2, "keyws": "electric machine noise"}, {"freq": 1, "keyws": "man - machine communication"}, {"freq": 1, "keyws": "man-machine communications"}, {"freq": 1, "keyws": "machine tools design"}, {"freq": 1, "keyws": "specilaising in machine design"}, {"freq": 1, "keyws": "machine-building industry"}, {"freq": 1, "keyws": "man-machine interaction"}, {"freq": 1, "keyws": "ultra sound welaning machine"}, {"freq": 2, "keyws": "permanent-magnet synchronous machine"}, {"freq": 1, "keyws": "hybrid approaches to machine learning"}, {"freq": 1, "keyws": "cnc machine tool software"}, {"freq": 1, "keyws": "artifical intelligence and machine learning"}]
</code></pre>

<h3>
<a aria-hidden="true" href="#keywords-autocomplete" class="anchor" id="user-content-keywords-autocomplete"><span class="octicon octicon-link"></span></a>Keywords Autocomplete</h3>

<p>Get keywords syntactically related to the input, from the set of keywords assigned to researchers. The call returns an array of keywords.</p>

<h4>
<a aria-hidden="true" href="#call-5" class="anchor" id="user-content-call-5"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/autocomplete/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-5" class="anchor" id="user-content-example-5"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/autocomplete/machine">http://exploredu.ijs.si/api/autocomplete/machine</a></p>

<h4>
<a aria-hidden="true" href="#result-5" class="anchor" id="user-content-result-5"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>["machinebility", "machinery", "forest machinery/cut and split machines", "machines", "machinery noise", "tods and machinery", "agricultural machinery", "hidraulic machinery", "answering machines", "machines and mechanisms", "forming machines", "machines development", "hydraulic machines", "electrical machines", "thermoenergetic machines", "design of machines", "electrica machines", "electric machines", "machines design", "machine design", "machine parts", "machine learning", "machine elements", "machine physics", "machine ports", "milking machine", "machine control", "machine vision", "sewing machine", "forestry machinery and equipment", "forest machinery and equipment", "woodworking machinery construction", "heat machinery and devices", "dynamics of machines and structures", "measurement of electrical machines and", "design of special machines", "mechanics of machines and constructions", "design of electric machines", "coordinate measuting machines", "specialising in machine design", "cnc machine tools", "statistical machine translation", "man-machine communication", "computerized machine control", "human machine interfaces", "human - machine communication", "human-machine systems", "wear of machine elements", "machine component and preparing", "electric machine noise", "man - machine communication", "man-machine communications", "machine tools design", "specilaising in machine design", "machine-building industry", "man-machine interaction", "exitation systems of sinhronus machines", "modeling and design of electrical machines", "linear and rotation electric machines", "linear and rotation electrical machines", "projecting of machines and equipment for bakery", "safety in work with farm machines", "control design of electrical machines", "hydravlic machines - design and construction", "hidravlic machinery: hydravlic transient phenomena", "ultra sound welaning machine", "permanent-magnet synchronous machine", "hybrid approaches to machine learning", "cnc machine tool software", "artifical intelligence and machine learning", "conventional design and cad of electric machines", "numerical flow simulation through the hydravlic machines", "investigation quality al alloy for forging nad alloy for processing on automatic machines"]
</code></pre>

<h3>
<a aria-hidden="true" href="#keywords-related-by-researchers" class="anchor" id="user-content-keywords-related-by-researchers"><span class="octicon octicon-link"></span></a>Keywords related by researchers</h3>

<p>Get a set of related researchers. Keywords are related if they appear as keywords assigned to the researchers in the set</p>

<h4>
<a aria-hidden="true" href="#call-6" class="anchor" id="user-content-call-6"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/keyws/relrsr/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-6" class="anchor" id="user-content-example-6"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/keyws/relrsr/machine%20learning">http://exploredu.ijs.si/api/keyws/relrsr/machine%20learning</a></p>

<h4>
<a aria-hidden="true" href="#result-6" class="anchor" id="user-content-result-6"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"freq": 34, "rank": 1, "keyws": "machine learning"}, {"freq": 19, "rank": 2, "keyws": "artificial intelligence"}, {"freq": 8, "rank": 3, "keyws": "data mining"}, {"freq": 8, "rank": 4, "keyws": "intelligent systems"}, {"freq": 7, "rank": 5, "keyws": "computer science"}, {"freq": 4, "rank": 6, "keyws": "expert systems"}, {"freq": 3, "rank": 7, "keyws": "decision support systems"}, {"freq": 3, "rank": 8, "keyws": "medical informatics"}, {"freq": 3, "rank": 9, "keyws": "intelligent data analysis"}, {"freq": 3, "rank": 10, "keyws": "artifical intelligence"}, {"freq": 3, "rank": 11, "keyws": "inductive logic programming"}, {"freq": 3, "rank": 12, "keyws": "information systems"}, {"freq": 2, "rank": 13, "keyws": "intelligent agents"}, {"freq": 2, "rank": 14, "keyws": "biomechanics"}, {"freq": 2, "rank": 15, "keyws": "data analysis"}, {"freq": 2, "rank": 16, "keyws": "biomedical engineering"}, {"freq": 2, "rank": 17, "keyws": "combining classifiers"}, {"freq": 2, "rank": 18, "keyws": "genetic algorithms"}, {"freq": 2, "rank": 19, "keyws": "cognitive science"}, {"freq": 2, "rank": 20, "keyws": "decision trees"}, {"freq": 1, "rank": 21, "keyws": "hybrid approaches to machine learning"}, {"freq": 1, "rank": 22, "keyws": "knowledge discovery in databases"}, {"freq": 1, "rank": 23, "keyws": "medical imaging"}, {"freq": 1, "rank": 24, "keyws": "knowledge-based systems"}, {"freq": 1, "rank": 25, "keyws": "automated model-based reasoning and diagnosis"}, {"freq": 1, "rank": 26, "keyws": "evolutionary computation"}, {"freq": 1, "rank": 27, "keyws": "learning from language resources"}, {"freq": 1, "rank": 28, "keyws": "bone traction methods"}, {"freq": 1, "rank": 29, "keyws": "signal processing"}, {"freq": 1, "rank": 30, "keyws": "hip joint"}, {"freq": 1, "rank": 31, "keyws": "use of these methods in practise"}, {"freq": 1, "rank": 32, "keyws": "analysis of environmental data"}, {"freq": 1, "rank": 33, "keyws": "meta learning"}, {"freq": 1, "rank": 34, "keyws": "meta - learning"}, {"freq": 1, "rank": 35, "keyws": "clothing engineering"}, {"freq": 1, "rank": 36, "keyws": "fibre blend optimisation"}, {"freq": 1, "rank": 37, "keyws": "formal self-reference"}, {"freq": 1, "rank": 38, "keyws": "bioelectromagnetic field"}, {"freq": 1, "rank": 39, "keyws": "reinforlement learning"}, {"freq": 1, "rank": 40, "keyws": "evalutionary algorithms"}, {"freq": 1, "rank": 41, "keyws": "decision support"}, {"freq": 1, "rank": 42, "keyws": "computer programming"}, {"freq": 1, "rank": 43, "keyws": "study of mechanical properties of fabric and threads"}, {"freq": 1, "rank": 44, "keyws": "heuristic algorithms"}, {"freq": 1, "rank": 45, "keyws": "surgery"}, {"freq": 1, "rank": 46, "keyws": "artificial intelligence in medicine"}, {"freq": 1, "rank": 47, "keyws": "computational learning theory"}, {"freq": 1, "rank": 48, "keyws": "technology of spinning"}, {"freq": 1, "rank": 49, "keyws": "fusing process"}, {"freq": 1, "rank": 50, "keyws": "reconstruction"}, {"freq": 1, "rank": 51, "keyws": "cost sensitive learning"}, {"freq": 1, "rank": 52, "keyws": "segmentation"}, {"freq": 1, "rank": 53, "keyws": "objecti"}, {"freq": 1, "rank": 54, "keyws": "knowledge transfer"}, {"freq": 1, "rank": 55, "keyws": "applications of artificial intelligence in medicine"}, {"freq": 1, "rank": 56, "keyws": "medical applications"}, {"freq": 1, "rank": 57, "keyws": "computational reflection"}, {"freq": 1, "rank": 58, "keyws": "data visualization"}, {"freq": 1, "rank": 59, "keyws": "text-mining"}, {"freq": 1, "rank": 60, "keyws": "modelling of skile"}, {"freq": 1, "rank": 61, "keyws": "roc analysis"}, {"freq": 1, "rank": 62, "keyws": "neuron networks"}, {"freq": 1, "rank": 63, "keyws": "sewing process"}, {"freq": 1, "rank": 64, "keyws": "cogutive science"}, {"freq": 1, "rank": 65, "keyws": "neural networks"}, {"freq": 1, "rank": 66, "keyws": "fabrice model"}, {"freq": 1, "rank": 67, "keyws": "mathematical logic"}, {"freq": 1, "rank": 68, "keyws": "equation discovery"}, {"freq": 1, "rank": 69, "keyws": "image processing"}, {"freq": 1, "rank": 70, "keyws": "biomedicine"}, {"freq": 1, "rank": 71, "keyws": "applications of artificial intelligence"}, {"freq": 1, "rank": 72, "keyws": "learning from the web"}, {"freq": 1, "rank": 73, "keyws": "konwledge disvocery"}, {"freq": 1, "rank": 74, "keyws": "text mining"}, {"freq": 1, "rank": 75, "keyws": "datamining"}, {"freq": 1, "rank": 76, "keyws": "environmental applications"}, {"freq": 1, "rank": 77, "keyws": "pattern recognition"}, {"freq": 1, "rank": 78, "keyws": "data warehouses"}, {"freq": 1, "rank": 79, "keyws": "classification constructive"}, {"freq": 1, "rank": 80, "keyws": "dynamics system control"}, {"freq": 1, "rank": 81, "keyws": "optimisation"}, {"freq": 1, "rank": 82, "keyws": "artifical intelligence and machine learning"}, {"freq": 1, "rank": 83, "keyws": "scheduling"}, {"freq": 1, "rank": 84, "keyws": "comutational logic"}, {"freq": 1, "rank": 85, "keyws": "regression"}, {"freq": 1, "rank": 86, "keyws": "computer scinece"}, {"freq": 1, "rank": 87, "keyws": "data mining and knowledge dicsovery from data bases"}, {"freq": 1, "rank": 88, "keyws": "computer graphics"}, {"freq": 1, "rank": 89, "keyws": "logic programming"}, {"freq": 1, "rank": 90, "keyws": "computer vision"}, {"freq": 1, "rank": 91, "keyws": "thread model"}, {"freq": 1, "rank": 92, "keyws": "multi-attribute decision making"}, {"freq": 1, "rank": 93, "keyws": "prediction of spun yarn properties"}, {"freq": 1, "rank": 94, "keyws": "artificial inteligence"}, {"freq": 1, "rank": 95, "keyws": "reliability of classifiers"}, {"freq": 1, "rank": 96, "keyws": "computer-based infromation systems for textile industries"}, {"freq": 1, "rank": 97, "keyws": "qualitative modelling"}, {"freq": 1, "rank": 98, "keyws": "hand"}, {"freq": 1, "rank": 99, "keyws": "bioinformatics"}, {"freq": 1, "rank": 100, "keyws": "texstiles"}, {"freq": 1, "rank": 101, "keyws": "hip endoprosthesis"}, {"freq": 1, "rank": 102, "keyws": "digital image processing"}, {"freq": 1, "rank": 103, "keyws": "data-mining"}, {"freq": 1, "rank": 104, "keyws": "dinamic systems control"}, {"freq": 1, "rank": 105, "keyws": "materials"}, {"freq": 1, "rank": 106, "keyws": "algorithms"}, {"freq": 1, "rank": 107, "keyws": "hip-join"}]
</code></pre>

<h3>
<a aria-hidden="true" href="#composition-of-classification-of-a-set-of-researchers-retrieved-by-a-keyword" class="anchor" id="user-content-composition-of-classification-of-a-set-of-researchers-retrieved-by-a-keyword"><span class="octicon octicon-link"></span></a>Composition of classification of a set of researchers retrieved by a keyword</h3>

<p>Get the composition of classification of a set of researchers retrieved by a keyword</p>

<h4>
<a aria-hidden="true" href="#call-7" class="anchor" id="user-content-call-7"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/class/relrsr/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-7" class="anchor" id="user-content-example-7"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/class/relrsr/machine%20learning">http://exploredu.ijs.si/api/class/relrsr/machine%20learning</a></p>

<h4>
<a aria-hidden="true" href="#result-7" class="anchor" id="user-content-result-7"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>{"sciences": [{"science": "Engineering sciences and technologies", "freq": 33.0, "rel": 0.9428571428571428, "rank": 1}, {"science": "Natural sciences and mathematics", "freq": 1.0, "rel": 0.02857142857142857, "rank": 2}, {"science": "Medical sciences", "freq": 1.0, "rel": 0.02857142857142857, "rank": 3}], "subfields": [{"science": "Natural sciences and mathematics", "subfield": "Algorithms", "rank": 1, "field": "Computer intensive methods and applications", "rel": 0.14285714285714285, "freq": 1.0}, {"science": "Engineering sciences and technologies", "subfield": "Textile-mechanical processes", "rank": 2, "field": "Textile and leather", "rel": 0.14285714285714285, "freq": 1.0}, {"science": "Engineering sciences and technologies", "subfield": "Biomedical technics", "rank": 3, "field": "Systems and cybernetics", "rel": 0.14285714285714285, "freq": 1.0}, {"science": "Engineering sciences and technologies", "subfield": "Intelligent systems - software", "rank": 4, "field": "Computer science and informatics", "rel": 0.14285714285714285, "freq": 1.0}, {"science": "Engineering sciences and technologies", "subfield": "Computer integrated construction of objects", "rank": 5, "field": "Civil engineering", "rel": 0.14285714285714285, "freq": 1.0}, {"science": "Engineering sciences and technologies", "subfield": "Programming technologies - software", "rank": 6, "field": "Computer science and informatics", "rel": 0.14285714285714285, "freq": 1.0}, {"science": "Engineering sciences and technologies", "subfield": "Metallic materials", "rank": 7, "field": "Materials science and technology", "rel": 0.14285714285714285, "freq": 1.0}], "fields": [{"science": "Engineering sciences and technologies", "freq": 1.0, "rel": 0.14285714285714285, "rank": 1, "field": "Materials science and technology"}, {"science": "Engineering sciences and technologies", "freq": 1.0, "rel": 0.14285714285714285, "rank": 2, "field": "Civil engineering"}, {"science": "Engineering sciences and technologies", "freq": 1.0, "rel": 0.14285714285714285, "rank": 3, "field": "Systems and cybernetics"}, {"science": "Engineering sciences and technologies", "freq": 1.0, "rel": 0.14285714285714285, "rank": 4, "field": "Computer science and informatics"}, {"science": "Natural sciences and mathematics", "freq": 1.0, "rel": 0.14285714285714285, "rank": 5, "field": "Computer intensive methods and applications"}, {"science": "Engineering sciences and technologies", "freq": 1.0, "rel": 0.14285714285714285, "rank": 6, "field": "Textile and leather"}, {"science": "Medical sciences", "freq": 1.0, "rel": 0.14285714285714285, "rank": 7, "field": "Neurobiology"}]}
</code></pre>

<h3>
<a aria-hidden="true" href="#event-registry-news" class="anchor" id="user-content-event-registry-news"><span class="octicon octicon-link"></span></a>Event Registry News</h3>

<p>Get news articles from Event-Registry related to education</p>

<h4>
<a aria-hidden="true" href="#call-8" class="anchor" id="user-content-call-8"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/er/news</code></p>

<h4>
<a aria-hidden="true" href="#example-8" class="anchor" id="user-content-example-8"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/er/news">http://exploredu.ijs.si/api/er/news</a></p>

<h4>
<a aria-hidden="true" href="#result-8" class="anchor" id="user-content-result-8"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>{"articles": {"resultCount": 121772, "results": [{"lang": "eng", "body": "What's inside? Here are the questions answered in today's reader mailbag, boiled down to five word summaries. Click on the number to jump straight down to the question.\n\n1. Replacing an old credit card\n\n2. Handling wants without spending\n\n3. Diverging financial perspectives from husband\n\n4. Guilty ...", "title": "Questions About Freezer Bags, iTunes, Work Boredom, Old Debt Guilt and More!", "url": "http://www.thesimpledollar.com/questions-about-freezer-bags-itunes-work-boredom-old-debt-guilt-and-more/", "uri": "333595664", "isDuplicate": false, "source": {"uri": "www.thesimpledollar.com", "title": "The Simple Dollar"}, "time": "14:00:00", "date": "2015-11-16", "wgt": 5, "id": "55636062", "sim": 0}, {"lang": "eng", "body": "STUNG by the low proficiency in English of many of the educators who teach the language, the education ministry has decided for the first time to impose a standard curriculum for teacher-training courses in universities.\n\nTo date, teacher training classes in higher education were non-standardized, ...", "title": "Nationwide curriculum to end free-for-all in Japan English teacher training", "url": "http://www.manilatimes.net/nationwide-curriculum-to-end-free-for-all-in-japan-english-teacher-training/229587/", "uri": "333594810", "isDuplicate": false, "source": {"uri": "www.manilatimes.net", "title": "The Manila Times Online"}, "time": "13:54:00", "date": "2015-11-16", "wgt": 10, "id": "55635930", "sim": 0}, {"lang": "eng", "body": "The Ministry and Department of Education have again, for the second year, shown their appreciation and gratitude to educators - at the Government-run schools in recognition of their challenging work and contribution - by honouring seven outstanding teachers. The colourful event was held at Flavours ...", "title": "SEVEN EDUCATORS GET \"TEACHER OF THE YEAR AWARD\"", "url": "http://theanguillian.com/2015/11/seven-educators-get-teacher-of-the-year-award/", "uri": "333584664", "isDuplicate": false, "source": {"uri": "theanguillian.com", "title": "theanguillian.com"}, "time": "13:15:00", "date": "2015-11-16", "wgt": 11, "id": "55633219", "sim": 0}, {"lang": "eng", "body": "Ethiopia is in a dire need for specialized and intensive research on areas of its development priorities, particularly in science and technology, argues Ayenachew Aseffa Woldegiyorgis.\n\nIn the second Growth and Transformation Plan (GTP II) Ethiopia is set to build eleven new universities. This is ...", "title": "Ethiopia: Focus More On Differentiation Than Expansion of Higher Education", "url": "http://allafrica.com/stories/201511162217.html", "uri": "333593141", "isDuplicate": false, "source": {"uri": "allafrica.com", "title": "allafrica.com"}, "time": "13:08:00", "date": "2015-11-16", "wgt": 16, "id": "55635602", "sim": 0}, {"lang": "eng", "body": "Director of Basic Education in the Ministry of Education Science and Technology, Dr Joseph Chimombo has urged stakeholders in the education sector to enhance strong bond of partnership in order to achieve quality of education.\n\nDr Chimombo and officials in the ministry of education taking porridge ...", "title": "Malawi: Ministry Calls for Partnership Approach in Improving Quality of Education", "url": "http://allafrica.com/stories/201511162061.html", "uri": "333591922", "isDuplicate": true, "source": {"uri": "allafrica.com", "title": "allafrica.com"}, "time": "13:08:00", "date": "2015-11-16", "wgt": 18, "id": "55635152", "sim": 0}, {"lang": "eng", "body": "Last week, Mike Tokars of the Christian Science Monitor reported that:\n\nNew York state's attorney general, Eric Schneiderman, and US Rep. Ted Lieu (D) of California are both looking into whether the world's largest publicly traded oil and gas company intentionally misled the public and company ...", "title": "ExxonMobil and the Distortion of Climate Science", "url": "http://www.huffingtonpost.com/steven-cohen/exxonmobil-and-the-distor_b_8574304.html", "uri": "333585701", "isDuplicate": false, "source": {"uri": "www.huffingtonpost.com", "title": "Huffington Post"}, "time": "13:05:00", "date": "2015-11-16", "wgt": 2, "id": "55633517", "sim": 0}, {"lang": "eng", "body": "The Los Angeles Unified School District is seeking a new superintendent, who will oversee a system with a $12.6-billion budget, 650,000 students, 90,000 employees and many challenges. Below, education experts, parents, teachers, students and others discuss what the district's priorities should ...", "title": "How to solve the LAUSD puzzle", "url": "http://www.latimes.com/opinion/op-ed/la-oe-1116-fixing-la-schools-20151112-html-htmlstory.html", "uri": "333584977", "eventUri": "3253925", "isDuplicate": false, "source": {"uri": "www.latimes.com", "title": "latimes.com"}, "time": "13:00:00", "date": "2015-11-16", "wgt": 13, "id": "55633291", "sim": 0.6027}, {"lang": "eng", "body": "Today's elementary students have spent their entire lives surrounded by information in a variety of mediums. Studies have shown a positive impact on learning when students are required to engage in inquiry, analyze content, construct knowledge and effectively communicate their learning.\n\nCoyote ...", "title": "Coyote Springs Elementary ensures 21st century learners", "url": "http://dcourier.com/Main.asp?SectionID=1&amp;SubSectionID=1&amp;ArticleID=152016", "uri": "333584023", "isDuplicate": false, "source": {"uri": "dcourier.com", "title": "dcourier.com"}, "time": "13:00:00", "date": "2015-11-16", "wgt": 4, "id": "55633115", "sim": 0}, {"lang": "eng", "body": "PEN Afrikaans eis meertaligheid en moedertaalonderrig as uitgangspunte vir onderwys in Suid-Afrika asook 'n heroorweging van die US-taalbeleid\n\n[The English version of this declaration follows the Afrikaans below.]\n\nDie openbare reaksie van skok op die voorgestelde afskaffing van Afrikaans as een ...", "title": "PEN Afrikaans eis meertaligheid en moedertaalonderrig as uitgangspunte vir onderwys in Suid-Afrika", "url": "http://bookslive.co.za/blog/2015/11/16/pen-afrikaans-eis-meertaligheid-en-moedertaalonderrig-as-uitgangspunte-vir-onderwys-in-suid-afrika/?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%253A%2BBOOKSA%2B%2528Books%2BLIVE%2529", "uri": "333589582", "isDuplicate": false, "source": {"uri": "bookslive.co.za", "title": "Books LIVE @ Books LIVE"}, "time": "12:40:00", "date": "2015-11-16", "wgt": 7, "id": "55634514", "sim": 0}, {"lang": "eng", "body": "Starting from Oct. 27, 1991, Turkmenistan celebrates one of its major holidays - the Day of Independence. The 24th Anniversary of Independence of neutral Turkmenistan is the remarkable date in the glorious history of the sovereign country.\n\nThe democratic state proclaims an individual the highest ...", "title": "Turkmen economy continues strong ...", "url": "http://www.koreatimes.co.kr/www/news/nation/2015/11/634_191126.html", "uri": "333577181", "isDuplicate": false, "source": {"uri": "www.koreatimes.co.kr", "title": "koreatimes"}, "time": "12:34:00", "date": "2015-11-16", "wgt": 3, "id": "55631565", "sim": 0}, {"lang": "eng", "body": "No doubt, Ethiopia is currently being one of the five fastest economies in the world having maintained a double digit growth rate for more than over 12 consecutive years. It has become a largest economy in East Africa. This tremendous economic growth is by and large attributed to the development ...", "title": "Ethiopia: Science and Technology - Feasible Tool for Transformation", "url": "http://allafrica.com/stories/201511161936.html", "uri": "333572152", "isDuplicate": false, "source": {"uri": "allafrica.com", "title": "allafrica.com"}, "time": "12:08:00", "date": "2015-11-16", "wgt": 4, "id": "55630196", "sim": 0}, {"lang": "eng", "body": "A beacon for the right to an education for children everywhere: Malala Yousafzai\n\nIf the tragic events in Paris have taught us anything it is that we now more than ever need to have a better understanding of the world we are in. Education ought to be the greatest equaliser of them all, writes John ...", "title": "Education is the greatest equaliser", "url": "https://www.siliconrepublic.com/portfolio/2015/11/16/education-the-greatest-equaliser", "uri": "333572179", "isDuplicate": false, "source": {"uri": "www.siliconrepublic.com", "title": "Silicon Republic"}, "time": "11:38:00", "date": "2015-11-16", "wgt": 10, "id": "55630187", "sim": 0}, {"lang": "eng", "body": "As the toll of the six attacks in Paris on Friday rises to at least 129 dead and 350 wounded, including 99 in critical condition, the French and the world are asking very basic questions: Who did it, why, and how can future attacks be prevented?\n\nThe planning of this attack was significant. \"This ...", "title": "Why Paris Was the Target of the ISIS Massacre", "url": "http://news.yahoo.com/why-paris-target-isis-massacre-111500791.html", "uri": "333565097", "eventUri": "3253885", "isDuplicate": false, "source": {"uri": "news.yahoo.com", "title": "Yahoo News"}, "time": "11:32:00", "date": "2015-11-16", "wgt": 6, "id": "55628415", "sim": 0.5497}, {"lang": "eng", "body": "The University of Adelaide is offering scholarship program for commencing international students undertaking undergraduate study. The International Student Centre (ISC) offers support to all international students throughout their stay in Adelaide. The International Student Centre is a support ...", "title": "Adelaide International Undergraduate Scholarships", "url": "https://www.fundsforngos.org/scholarships-2/adelaide-international-undergraduate-scholarships/", "uri": "333559742", "isDuplicate": false, "source": {"uri": "www.fundsforngos.org", "title": "Funds for NGOs"}, "time": "10:59:00", "date": "2015-11-16", "wgt": 2, "id": "55626988", "sim": 0}, {"lang": "eng", "body": "TALLAHASSEE | Michelle Lipton, an Ormond Beach native, decided to become an anesthesiologist because of its short but critical role in patient care.\n\n\"You only get 5 to 10 minutes to help a patient feel comfortable when they are going into surgery,\" she said.\n\nLipton is in her second year of a ...", "title": "Florida's medical residency funding grows but can't meet demand", "url": "http://jacksonville.com/news/florida/2015-11-16/story/state-lawmakers-spend-millions-keep-residents-florida-demand-still", "uri": "333559547", "isDuplicate": false, "source": {"uri": "jacksonville.com", "title": "jacksonville.com"}, "time": "10:26:00", "date": "2015-11-16", "wgt": 3, "id": "55626963", "sim": 0}, {"lang": "fra", "body": "This is not a UNHCR publication. UNHCR is not responsible for, nor does it necessarily endorse, its content. Any views expressed are solely those of the author or publisher and do not necessarily reflect those of UNHCR, the United Nations or its Member States.\n\nDes sources signalent que la MGF est ...", "title": "Refworld | Nig\u00e9ria : information sur la fr\u00e9quence de la mutilation g\u00e9nitale des femmes (MGF) chez les Urhobos, y compris les cons\u00e9quences du refus de se soumettre \u00e0 cette pratique, particuli\u00e8rement pour les femmes enceintes; la protection offerte par l'\u00c9tat (2014-mars 2015)", "url": "http://www.refworld.org/docid/56498d144.html", "uri": "333555270", "isDuplicate": false, "source": {"uri": "www.refworld.org", "title": "Refworld"}, "time": "09:51:00", "date": "2015-11-16", "wgt": 2, "id": "55625766", "sim": 0}, {"lang": "eng", "body": "This is not a UNHCR publication. UNHCR is not responsible for, nor does it necessarily endorse, its content. Any views expressed are solely those of the author or publisher and do not necessarily reflect those of UNHCR, the United Nations or its Member States.\n\nSources state that FGM continues to be ...", "title": "Nigeria : Prevalence of female genital mutilation (FGM) among the Urhobo, including the consequences for refusing to undergo this procedure, particularly pregnant women; state protection available (2014-March 2015)", "url": "http://www.refworld.org/docid/56498d834.html", "uri": "333545184", "isDuplicate": false, "source": {"uri": "www.refworld.org", "title": "Refworld"}, "time": "09:51:00", "date": "2015-11-16", "wgt": 4, "id": "55623240", "sim": 0}, {"lang": "eng", "body": "Academic Vice President of Addis Ababa University, Dr. Jeilu Oumer signed a Memorandum of understanding (MoU) with the Vice Chancellor of the University of Sk\u00f6vde , Professor Sigbritt Karlsson on November 9, 2015. The aim of the MoU is to expand and promote cooperation between the two institutions ...", "title": "Ethiopia: Addis Ababa University Signs an MoU With Sk\u00c3\u00b6vde University, Sweden", "url": "http://allafrica.com/stories/201511160818.html", "uri": "333545195", "isDuplicate": false, "source": {"uri": "allafrica.com", "title": "allafrica.com"}, "time": "09:32:00", "date": "2015-11-16", "wgt": 4, "id": "55623238", "sim": 0}, {"lang": "eng", "body": "NEW YORK, Nov. 13 /CSRwire/ - Schwarzman Scholars today announces the appointment of Albert Chau as Associate Dean of Student Life for Schwarzman Scholars at Tsinghua University in Beijing. Chau is currently the Dean of Student Affairs and the Director of General Education at The University of Hong ...", "title": "Schwarzman Scholars Appoints Associate Dean of Student Life", "url": "http://www.csrwire.com/press_releases/38470-Schwarzman-Scholars-Appoints-Associate-Dean-of-Student-Life?tracking_source=rss&amp;utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%253A%2Bcsrwire%252FPRfeed%2B%2528CSRwire.com%2529&amp;utm_content=FeedBurner", "uri": "333538133", "isDuplicate": false, "source": {"uri": "www.csrwire.com", "title": "www.csrwire.com"}, "time": "09:11:00", "date": "2015-11-16", "wgt": 2, "id": "55621414", "sim": 0}, {"lang": "eng", "body": "The chair of COAG's Education Council and Queensland Education Minister, Kate Jones. Photo: Bradley Kanaris\n\nThey may appear permanently glued to their smart phones and tablets, but Australian students are less able to navigate basic computer tasks now than three years ago.\n\nAnd the greatest ...", "title": "Students smart on phones but going backwards in computer literacy", "url": "http://www.theage.com.au/act-news/students-smart-on-phones-but-going-backwards-in-computer-literacy-20151116-gkzwjd.html", "uri": "333575710", "isDuplicate": false, "source": {"uri": "www.theage.com.au", "title": "The Age"}, "time": "09:02:00", "date": "2015-11-16", "wgt": 8, "id": "55630962", "sim": 0}, {"lang": "eng", "body": "With Intuitive's innovative approach, we have been able to bring our EvaSys Insight and MBE Module Benchmarking products to life\n\nUniversities and colleges now have vital performance insight and UK-wide benchmarking data at their fingertips\n\nA strategic partnership between EvaSys Survey Automation ...", "title": "Electric Paper partners with Intuitive for real-time performance insight", "url": "http://www.sourcewire.com/news/89149/electric-paper-partners-with-intuitive-for-real-time-performance-insight", "uri": "333541010", "isDuplicate": false, "source": {"uri": "www.sourcewire.com", "title": "SourceWire"}, "time": "09:00:00", "date": "2015-11-16", "wgt": 6, "id": "55622166", "sim": 0}, {"lang": "eng", "body": "Union Minister of Agriculture and Farmers Welfare, Shri Radha Mohan Singh laid the Foundation Stone of Acharya N.G.Ranga Agricultural University in Andhra Pradesh today. Shri Singh on the occasion said that \u00e2\u20ac\u0153there are still large productivity gaps in the potential and the realized farm output ...", "title": "Technological Progress in Agriculture is Crucial for the Overall Economic Development of the Country- Radha Mohan Singh", "url": "http://pib.nic.in/newsite/PrintRelease.aspx?relid=130514", "uri": "333532336", "isDuplicate": false, "source": {"uri": "pib.nic.in", "title": "pib.nic.in"}, "time": "08:42:00", "date": "2015-11-16", "wgt": 8, "id": "55619919", "sim": 0}, {"lang": "eng", "body": "It began with 10 successfully incubated eggs and the only thing left about 60 days later was a duck wing and some feathers.\n\nDylan Pepin, 11, who is part of a farming family, decided he would ask the Eaglet Lake Farmers Institute (ELFI) to support him in hatching a flock of ducks to raise.\n\nThe ...", "title": "Young farmer inspires program", "url": "http://www.princegeorgecitizen.com/news/local-news/young-farmer-inspires-program-1.2111704", "uri": "333530196", "isDuplicate": false, "source": {"uri": "www.princegeorgecitizen.com", "title": "Prince George Citizen"}, "time": "07:05:00", "date": "2015-11-16", "wgt": 3, "id": "55619261", "sim": 0}, {"lang": "eng", "body": "Pupils visiting Braiswick Primary School site ahead of its opening this year\n\nCOLCHESTER'S newest primary school has had to take on an extra 30 pupils nine months sooner than planned.\n\nBraiswick Primary School opened in September and initially took in 60 four-year-olds for two reception ...", "title": "Swelling population forces school into emergency admissions", "url": "http://www.halsteadgazette.co.uk/news/north_essex_news/14030983.Swelling_population_forces_school_into_emergency_admissions/?ref=rss", "uri": "333514911", "isDuplicate": false, "source": {"uri": "www.halsteadgazette.co.uk", "title": "Halstead Gazette"}, "time": "06:30:00", "date": "2015-11-16", "wgt": 4, "id": "55615400", "sim": 0}, {"lang": "eng", "body": "In Alva, registered nurse Dixie Meyer took a job teaching science. In Clinton, day care owner Heather Davis jumped at the chance to teach prekindergarten. In Oklahoma City, Sage Perry decided he would rather be a teacher then a physical therapist.\n\nMeyer, Davis and Perry were not certified as ...", "title": "Oklahoma City school district requests bulk of emergency teacher certifications", "url": "http://newsok.com/oklahoma-city-school-district-requests-bulk-of-emergency-teacher-certifications/article/5460725?custom_click=rss", "uri": "333510703", "isDuplicate": false, "source": {"uri": "newsok.com", "title": "NewsOK.com"}, "time": "05:44:00", "date": "2015-11-16", "wgt": 11, "id": "55614366", "sim": 0}, {"lang": "eng", "body": "In a tent in Lebanon's Bekaa Valley, Sanaa al-Absi extracts a condom from its wrapper in front of a group of giggling Syrian refugee women and begins explaining its use.\n\nIt is the first time some of the women have seen the contraceptive, which they are learning about as part of a rare programme ...", "title": "Lebanon: Futures unclear, Syrian refugees in Lebanon start family planning", "url": "http://reliefweb.int/report/lebanon/futures-unclear-syrian-refugees-lebanon-start-family-planning", "uri": "333506957", "isDuplicate": false, "source": {"uri": "reliefweb.int", "title": "ReliefWeb"}, "time": "05:32:00", "date": "2015-11-16", "wgt": 2, "id": "55613377", "sim": 0}, {"lang": "eng", "body": "DOWNTOWN: The Allegheny County Sanitary Authority will hold a public meeting from 5 to 7 p.m. in the Gold Room of the Allegheny County Courthouse on Grant Streetto hear citizens' views and ideas on a customer assistance program for low-income ratepayers in the ALCOSAN service territory. Call ...", "title": "City Calendar: Nov. 16-22", "url": "http://www.post-gazette.com/local/city/2015/11/16/City-Calendar-Nov-16-22/stories/201511160003", "uri": "333504571", "isDuplicate": false, "source": {"uri": "www.post-gazette.com", "title": "Pittsburgh Post-Gazette"}, "time": "05:05:00", "date": "2015-11-16", "wgt": 3, "id": "55612788", "sim": 0}, {"lang": "eng", "body": "Open Stellenbosch, a movement of mostly black students and staff, wants the university to investigate the activities of staff and guest lecturers during apartheid.\n\nThe call was made in the wake of revelations that apartheid-era chemical warfare expert Wouter Basson tutored Stellenbosch University ...", "title": "Storm over Basson tutoring", "url": "http://www.timeslive.co.za/thetimes/2015/11/16/Storm-over-Basson-tutoring", "uri": "333504333", "isDuplicate": false, "source": {"uri": "www.timeslive.co.za", "title": "Times LIVE"}, "time": "05:05:00", "date": "2015-11-16", "wgt": 3, "id": "55612722", "sim": 0}, {"lang": "eng", "body": "Senate President Pro Tem Phil Berger sure knows how to improve the morale of the folks working hard every day to help students and teachers across North Carolina.\n\nBerger recently told a meeting of the education group BEST N.C. that the 15,000 state-funded and low-paid teacher assistants who are now ...", "title": "Berger\u2019s 6 misleading minutes about TAs, teachers, public schools", "url": "http://courier-tribune.com/opinion/staff-columns/berger-s-6-misleading-minutes-about-tas-teachers-public-schools", "uri": "333509356", "isDuplicate": false, "source": {"uri": "courier-tribune.com", "title": "The Courier-Tribune"}, "time": "05:01:00", "date": "2015-11-16", "wgt": 7, "id": "55614048", "sim": 0}, {"lang": "eng", "body": "'The professional world is an incredibly competitive place and there is an ever growing community of brilliantly qualified graduates so it is important to become a more interesting adult who is versatile and engaging. Creativity is among the top five applied skills sought by business leaders and ...", "title": "Art vital part of child's education - Creativity among top five applied skills sought by companies", "url": "http://www.arabtimesonline.com/news/art-vital-part-of-childs-education-creativity-among-top-five-applied-skills-sought-by-companies/", "uri": "333517522", "isDuplicate": false, "source": {"uri": "www.arabtimesonline.com", "title": "ARAB TIMES"}, "time": "04:41:00", "date": "2015-11-16", "wgt": 17, "id": "55616013", "sim": 0}]}}
</code></pre>

<h3>
<a aria-hidden="true" href="#sio-educational-material" class="anchor" id="user-content-sio-educational-material"><span class="octicon octicon-link"></span></a>SIO Educational Material</h3>

<p>Get news educational material from SIO</p>

<h4>
<a aria-hidden="true" href="#call-9" class="anchor" id="user-content-call-9"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/sio/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-9" class="anchor" id="user-content-example-9"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/sio/human%20culture">http://exploredu.ijs.si/api/sio/human%20culture</a></p>

<h4>
<a aria-hidden="true" href="#result-9" class="anchor" id="user-content-result-9"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"grade": "-1", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/strojnistvo/strojni_gim.htm", "name": "culture and religion", "subject": "strojnistvo"}, {"grade": "1", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/vik/vik1.htm", "name": "culture and religion", "subject": "vik"}, {"grade": "2", "level": "gimnazija", "link": "/skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/vik/vik2.htm", "name": "culture and religion", "subject": "vik"}, {"grade": "3", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/vik/vik3.htm", "name": "culture and religion", "subject": "vik"}, {"grade": "4", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/vik/vik4.htm", "name": "culture and religion", "subject": "vik"}, {"grade": "4", "level": "osnovnasola", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/osnovnasola/druzba/druzba4r.htm", "name": "society", "subject": "druzba"}, {"grade": "5", "level": "osnovnasola", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/osnovnasola/druzba/druzba5r.htm", "name": "society", "subject": "druzba"}, {"grade": "6", "level": "osnovnasola", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/osnovnasola/druzba/druzba6r.htm", "name": "society", "subject": "druzba"}, {"grade": "7", "level": "osnovnasola", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/osnovnasola/druzba/druzba7r.htm", "name": "society", "subject": "druzba"}, {"grade": "8", "level": "osnovnasola", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/osnovnasola/druzba/druzba8r.htm", "name": "society", "subject": "druzba"}, {"grade": "9", "level": "osnovnasola", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/osnovnasola/druzba/druzba9r.htm", "name": "society", "subject": "druzba"}, {"grade": "-1", "level": "vrtec", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/vrtec/druzba_vrt.htm", "name": "society", "subject": "druzba_vrt.htm"}, {"grade": "7", "level": "osnovnasola", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/osnovnasola/zgodovina/zgodovina7r.htm", "name": "history", "subject": "zgodovina"}, {"grade": "8", "level": "osnovnasola", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/osnovnasola/zgodovina/zgodovina8r.htm", "name": "history", "subject": "zgodovina"}, {"grade": "9", "level": "osnovnasola", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/osnovnasola/zgodovina/zgodovina9r.htm", "name": "history", "subject": "zgodovina"}, {"grade": "1", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/zgodovina/zgodovina1l.htm", "name": "history", "subject": "zgodovina"}, {"grade": "2", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/zgodovina/zgodovina2l.htm", "name": "history", "subject": "zgodovina"}, {"grade": "3", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/zgodovina/zgodovina3l.htm", "name": "history", "subject": "zgodovina"}, {"grade": "4", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/zgodovina/zgodovina4l.htm", "name": "history", "subject": "zgodovina"}]
</code></pre>

<h3>
<a aria-hidden="true" href="#sio-educational-material-advanced-search" class="anchor" id="user-content-sio-educational-material-advanced-search"><span class="octicon octicon-link"></span></a>SIO Educational Material Advanced Search</h3>

<p>Get news educational material from SIO searched by different fields</p>

<h4>
<a aria-hidden="true" href="#call-10" class="anchor" id="user-content-call-10"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/sio/adv/&lt;search_json&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-10" class="anchor" id="user-content-example-10"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/sio/adv/%7B%22grade%22:%224">http://exploredu.ijs.si/api/sio/adv/{"grade":"4</a>", "text":"biology", "name":"chemistry", "level":"gimnazija"}</p>

<h4>
<a aria-hidden="true" href="#result-10" class="anchor" id="user-content-result-10"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"grade": "4", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/biologija_gim/biologija4l.htm", "name": "biology", "subject": "biologija_gim"}, {"grade": "4", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/kemija/kemija4l.htm", "name": "chemistry", "subject": "kemija"}, {"grade": "4", "level": "gimnazija", "link": "http://skupnost.sio.si/egradiva/seznam_projektov/pages/gimnazija/fizika/fizika4l.htm", "name": "physics", "subject": "fizika"}]
</code></pre>

<h3>
<a aria-hidden="true" href="#get-sio-uniq-categories" class="anchor" id="user-content-get-sio-uniq-categories"><span class="octicon octicon-link"></span></a>Get SIO uniq categories</h3>

<h4>
<a aria-hidden="true" href="#call-11" class="anchor" id="user-content-call-11"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/sio/categories</code></p>

<h4>
<a aria-hidden="true" href="#example-11" class="anchor" id="user-content-example-11"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/sio/categories">http://exploredu.ijs.si/api/sio/categories</a></p>

<h4>
<a aria-hidden="true" href="#result-11" class="anchor" id="user-content-result-11"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>{"grades": ["-1", "1", "3", "2", "5", "4", "7", "6", "9", "8"], "levels": ["gimnazija", "strokovne", "osnovnasola", "poklicna", "visjesolska", "vrtec"], "names": ["natural science", "art", "history", "russian", "society", "engineering", "sport", "technology", "culture and religion", "geography", "sociology", "film and media", "business communication", "music", "economy", "german language", "math", "carpentry", "householding", "biology", "theatre", "nature", "entrepreneurship", "craft", "electro engineering", "informatics", "law", "farming", "textile processing", "slovene language", "english language", "slovenian language", "machinery", "medical care", "computer science", "chemistry", "physics", "hairdressing"]}
</code></pre>

<h3>
<a aria-hidden="true" href="#collaboration-network" class="anchor" id="user-content-collaboration-network"><span class="octicon octicon-link"></span></a>Collaboration Network</h3>

<p>Get graph of researcher collaboration based on research projects</p>

<h4>
<a aria-hidden="true" href="#call-12" class="anchor" id="user-content-call-12"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/graph/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-12" class="anchor" id="user-content-example-12"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/graph/data%20mining">http://exploredu.ijs.si/api/graph/data%20mining</a></p>

<h4>
<a aria-hidden="true" href="#result-12" class="anchor" id="user-content-result-12"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>{"graph": {"nodes": [{"name": "Zevnik Andrej", "degree": 1, "color": "", "science": "", "y": 28, "x": 35, "id": "21193"}, {"name": "Welzer Dru\u017eovec Tatjana", "degree": 1, "color": "I", "science": "Interdisciplinary research", "y": 62, "x": 85, "id": "5907"}, {"name": "Brumen Bo\u0161tjan", "degree": 1, "color": "T", "science": "Engineering sciences and technologies", "y": 24, "x": 82, "id": "10952"}, {"name": "Mladeni\u0107 Dunja", "degree": 3, "color": "T", "science": "Engineering sciences and technologies", "y": 8, "x": 30, "id": "7778"}, {"name": "Podgorelec Vili", "degree": 1, "color": "T", "science": "Engineering sciences and technologies", "y": 85, "x": 91, "id": "9364"}, {"name": "Brank Janez", "degree": 2, "color": "T", "science": "Engineering sciences and technologies", "y": 60, "x": 11, "id": "15188"}, {"name": "\u0160krjanc Maja", "degree": 2, "color": "T", "science": "Engineering sciences and technologies", "y": 93, "x": 1, "id": "13263"}, {"name": "Robnik \u0160ikonja Marko", "degree": 4, "color": "T", "science": "Engineering sciences and technologies", "y": 3, "x": 69, "id": "8741"}, {"name": "Curk Toma\u017e", "degree": 2, "color": "T", "science": "Engineering sciences and technologies", "y": 96, "x": 6, "id": "16561"}, {"name": "Dem\u0161ar Janez", "degree": 5, "color": "T", "science": "Engineering sciences and technologies", "y": 39, "x": 71, "id": "9383"}, {"name": "Povalej Br\u017ean Petra", "degree": 1, "color": "T", "science": "Engineering sciences and technologies", "y": 93, "x": 62, "id": "15449"}, {"name": "Zrimec Tatjana", "degree": 4, "color": "T", "science": "Engineering sciences and technologies", "y": 68, "x": 3, "id": "5163"}, {"name": "Vidmar Gaj", "degree": 1, "color": "T", "science": "Engineering sciences and technologies", "y": 63, "x": 77, "id": "10115"}, {"name": "Hristovski Dimitar", "degree": 1, "color": "M", "science": "Medical sciences", "y": 41, "x": 92, "id": "7344"}, {"name": "Zupan Bla\u017e", "degree": 6, "color": "T", "science": "Engineering sciences and technologies", "y": 69, "x": 41, "id": "7764"}, {"name": "Kukar Matja\u017e", "degree": 1, "color": "T", "science": "Engineering sciences and technologies", "y": 99, "x": 90, "id": "8453"}, {"name": "D\u017eeroski Sa\u0161o", "degree": 5, "color": "T", "science": "Engineering sciences and technologies", "y": 54, "x": 35, "id": "7251"}, {"name": "Zav\u0161ek Simon", "degree": 1, "color": "N", "science": "Natural sciences and mathematics", "y": 34, "x": 55, "id": "6385"}], "edges": [{"rsrid1": "5907", "rsrid2": "10952"}, {"rsrid1": "7778", "rsrid2": "15188"}, {"rsrid1": "7778", "rsrid2": "13263"}, {"rsrid1": "7778", "rsrid2": "7251"}, {"rsrid1": "15188", "rsrid2": "13263"}, {"rsrid1": "8741", "rsrid2": "9383"}, {"rsrid1": "8741", "rsrid2": "5163"}, {"rsrid1": "8741", "rsrid2": "7764"}, {"rsrid1": "8741", "rsrid2": "7251"}, {"rsrid1": "16561", "rsrid2": "9383"}, {"rsrid1": "16561", "rsrid2": "7764"}, {"rsrid1": "9383", "rsrid2": "5163"}, {"rsrid1": "9383", "rsrid2": "7764"}, {"rsrid1": "9383", "rsrid2": "7251"}, {"rsrid1": "5163", "rsrid2": "7764"}, {"rsrid1": "5163", "rsrid2": "7251"}, {"rsrid1": "10115", "rsrid2": "7344"}, {"rsrid1": "7764", "rsrid2": "8453"}, {"rsrid1": "7764", "rsrid2": "7251"}]}}
</code></pre>

<h3>
<a aria-hidden="true" href="#project-frequencies" class="anchor" id="user-content-project-frequencies"><span class="octicon octicon-link"></span></a>Project frequencies</h3>

<p>Get frequencies of projects over years</p>

<h4>
<a aria-hidden="true" href="#call-13" class="anchor" id="user-content-call-13"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/prj/hist/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-13" class="anchor" id="user-content-example-13"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/prj/hist/language">http://exploredu.ijs.si/api/prj/hist/language</a></p>

<h4>
<a aria-hidden="true" href="#result-13" class="anchor" id="user-content-result-13"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>{"1995": 1, "1997": 15, "1996": 5, "1999": 5, "1998": 9, "2002": 0, "2003": 7, "2000": 2, "2001": 11, "2006": 1, "2007": 16, "2004": 22, "2005": 3, "2014": 10, "2008": 23, "2009": 11, "2011": 20, "2010": 12, "2013": 15, "2012": 2}
</code></pre>

<h3>
<a aria-hidden="true" href="#get-all-legislation" class="anchor" id="user-content-get-all-legislation"><span class="octicon octicon-link"></span></a>Get All Legislation</h3>

<p>Get all legislation</p>

<h4>
<a aria-hidden="true" href="#call-14" class="anchor" id="user-content-call-14"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/zakoni/all</code></p>

<h4>
<a aria-hidden="true" href="#example-14" class="anchor" id="user-content-example-14"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/zakoni/all">http://exploredu.ijs.si/api/zakoni/all</a></p>

<h4>
<a aria-hidden="true" href="#result-14" class="anchor" id="user-content-result-14"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code></code></pre>
<h3>
<a aria-hidden="true" href="#get-legislation" class="anchor" id="user-content-get-legislation"><span class="octicon octicon-link"></span></a>Get Legislation</h3>

<p>Get top N latest legislation</p>

<h4>
<a aria-hidden="true" href="#call-15" class="anchor" id="user-content-call-15"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>[GET] http://exploredu.ijs.si/api/zakoni/&lt;num&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-15" class="anchor" id="user-content-example-15"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/zakoni/2">http://exploredu.ijs.si/api/zakoni/2</a></p>

<h4>
<a aria-hidden="true" href="#result-15" class="anchor" id="user-content-result-15"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"idPredpisa": "PRAV12516", "npbNum": "4", "idPredpisaBase": "PRAV10943", "SNIPPET": [{"text": "1. \u010dlen", "type": "CLEN"}, {"text": "Ta pravilnik dolo\u010da izobrazbo, ki jo morajo imeti u\u010ditelji, laboranti, svetovalni delavci, knji\u017eni\u010darji in drugi strokovni delavci v izobra\u017eevalnem programu osnovne \u0161ole.", "type": "text"}], "POLNI_NASLOV": "PRAVILNIK o izobrazbi u\u010diteljev in drugih strokovnih delavcev v izobra\u017eevalnem programu osnovne \u0161ole", "link": "http://pisrs.si/Pis.web/pregledNpb?idPredpisa=PRAV12516&amp;idPredpisaChng=PRAV10943", "sopPredpisa": "2015-01-2935", "datumZacetkaVelj": "2015-10-23 00:00:00", "OPOZORILO": "Opozorilo: Neuradno pre\u010di\u0161\u010deno besedilo predpisa predstavlja zgolj informativni delovni pripomo\u010dek, glede katerega organ ne jam\u010di od\u0161kodninsko ali kako druga\u010de.", "path": "/2015/29/2015-01-2935-2011-01-4943-npb4", "NPB": "(neuradno pre\u010di\u0161\u010deno besedilo \u0161t. 4)", "cleni": "9", "id": "562159e8c65bc8304b65d21f", "NASLOV": "o izobrazbi u\u010diteljev in drugih strokovnih delavcev v izobra\u017eevalnem programu osnovne \u0161ole", "sopPredpisaChng": "2011-01-4943", "PREHODNE": "Pravilnik o izobrazbi u\u010diteljev in drugih strokovnih delavcev v izobra\u017eevalnem programu osnovne \u0161ole (Uradni list RS, \u0161t.109/11) vsebuje naslednjo prehodno in kon\u010dni dolo\u010dbi: / Pravilnik o dopolnitvi Pravilnika o izobrazbi u\u010diteljev in drugih strokovnih delavcev v izobra\u017eevalnem programu osnovne \u0161ole (Uradni list RS, \u0161t.10/12) vsebuje naslednjo kon\u010dno dolo\u010dbo: / Pravilnik o spremembah in dopolnitvah Pravilnika o izobrazbi u\u010diteljev in drugih strokovnih delavcev v izobra\u017eevalnem programu osnovne \u0161ole (Uradni list RS, \u0161t.92/12) vsebuje naslednjo kon\u010dno dolo\u010dbo: / Pravilnik o spremembah in dopolnitvah Pravilnika o izobrazbi u\u010diteljev in drugih strokovnih delavcev v izobra\u017eevalnem programu osnovne \u0161ole (Uradni list RS, \u0161t.49/13) vsebuje naslednjo kon\u010dno dolo\u010dbo: / Pravilnik o spremembah in dopolnitvah Pravilnika o izobrazbi u\u010diteljev in drugih strokovnih delavcev v izobra\u017eevalnem programu osnovne \u0161ole (Uradni list RS, \u0161t.75/15) vsebuje naslednjo kon\u010dno dolo\u010dbo:", "cleni_predefined_not_found": "9", "idPredpisaChng": "PRAV10943", "letoPredpisa": "2015", "VRSTA": "PRAVILNIK"}, {"PODPISNIK_IME": "dr. Maja Makovec Bren\u010di\u010d l.r.", "POPISNIK_NAZIV": "Ministrica / za izobra\u017eevanje, / znanost in \u0161port", "idPredpisa": "PRAV12514", "EVA": "EVA 2015-3330-0034", "npbNum": "0", "PODLAGA": "Na podlagi \u0161estega odstavka 92. \u010dlena Zakona o organizaciji in financiranju vzgoje in izobra\u017eevanja (Uradni list RS, \u0161t. 16/07 \u2013 uradno pre\u010di\u0161\u010deno besedilo, 36/08, 58/09, 64/09 \u2013 popr., 65/09 \u2013 popr., 20/11, 40/12 \u2013 ZUJF, 57/12 \u2013 ZPCP-2D in 47/15) ministrica za izobra\u017eevanje, znanost in \u0161port izdaja", "idPredpisaBase": "PRAV12514", "SNIPPET": [{"text": "1. \u010dlen", "type": "CLEN"}, {"text": "(vsebina pravilnika)", "type": "CLEN_NASLOV"}, {"text": "Ta pravilnik dolo\u010da izobrazbo, ki jo morajo imeti u\u010ditelji, laboranti, svetovalni delavci, knji\u017eni\u010darji in drugi strokovni delavci v izobra\u017eevalnih programih gimnazije.", "type": "text"}], "link": "http://pisrs.si/Pis.web/pregledPredpisa?id=PRAV12514", "sopPredpisa": "2015-01-2929", "datumZacetkaVelj": "2015-10-23 00:00:00", "POLNI_NASLOV": "PRAVILNIK o izobrazbi u\u010diteljev in drugih strokovnih delavcev v izobra\u017eevalnih programih gimnazije", "path": "/2015/29/2015-01-2929", "cleni": "161", "id": "561eb6cbc65bc8304b65d215", "NASLOV": "o izobrazbi u\u010diteljev in drugih strokovnih delavcev v izobra\u017eevalnih programih gimnazije", "VRSTA": "PRAVILNIK", "DATUM": "Ljubljana, dne 25. septembra 2015", "cleni_predefined_not_found": "161", "letoPredpisa": "2015", "STEVILKA": "\u0160t. 0070-48/2015"}]
</code></pre>

<h3>
<a aria-hidden="true" href="#get-ods" class="anchor" id="user-content-get-ods"><span class="octicon octicon-link"></span></a>Get ODS</h3>

<p>Open Discovery Space data.</p>

<h4>
<a aria-hidden="true" href="#call-16" class="anchor" id="user-content-call-16"><span class="octicon octicon-link"></span></a>Call</h4>

<p><code>http://exploredu.ijs.si/api/ods/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-16" class="anchor" id="user-content-example-16"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/ods/mathematics">http://exploredu.ijs.si/api/ods/mathematics</a></p>

<h4>
<a aria-hidden="true" href="#result-16" class="anchor" id="user-content-result-16"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"content": "kernlab is an extensible package for kernel-based machine learning methods in R. It takes advantage of R's new S4 object model and provides a framework for creating and using kernel-based algorithms. The package contains dot product primitives (kernels), implementations of support vector machines and the relevance vector machine, Gaussian processes, a ranking algorithm, kernel PCA, kernel CCA, and a spectral clustering algorithm. Moreover it provides a general purpose quadratic programming solver, and an incomplete Cholesky decomposition method. (author's abstract) ; Series: Research Report Series / Department of Statistics and Mathematics", "link": "http://epub.wu.ac.at/1048/1/document.pdf"}, {"content": "SNA provides a wide range of tools that allow examination of telecommunications graphs. Those graphs contain vertices representing cell phone users and lines standing for established connections. Many sna tools do not incorporate the intensity of interaction. This may lead to wrong conclusions because the difference between best friends and random contacts can be defined by the accumulated duration of talks. To solve this problem, we propose a closeness centrality measure (ewc) that incorporates line values and compare it to Freeman's closeness. Small exemplary networks will demonstrate the characteristics of the weighted closeness compared to other centrality measures. Finally, the ewc will be tested on a real-world telecommunications graph provided by a large Austrian mobile service provider and the advantages of the ewc will be discussed. (author\u00b4s abstract) ; Series: Research Report Series / Department of Statistics and Mathematics", "link": "http://epub.wu.ac.at/708/1/document.pdf"}, {"content": "In this paper we discuss an algorithm for the construction of D-optimal experimental designs for the parameters in a regression model when the errors have a correlation structure. We show that design points can collapse under the presence of some covariance structures and a so called nugget can be employed in a natural way. We also show that the information of equidistant design on covariance parameter is increasing with the number of design points under exponential variogram, however these designs are not D-optimal. Also in higher dimensions the exponential structure without nugget leads to collapsing of the D-optimal design when also parameters of covariance structure are of interest. However, if only trend parameters are of interest, the designs covering uniformly the whole design space are very efficient. For illustration some numerical examples are also included. (author's abstract) ; Series: Research Report Series / Department of Statistics and Mathematics", "link": "http://epub.wu.ac.at/994/1/document.pdf"}, {"content": "We propose a method to deal simultaneously with model uncertainty and correlated regressors in linear regression models by combining elastic net specifications with a spike and slab prior. The estimation method nests ridge regression and the LASSO estimator and thus allows for a more flexible modelling framework than existing model averaging procedures. In particular, the proposed technique has clear advantages when dealing with datasets of (potentially highly) correlated regressors, a pervasive characteristic of the model averaging datasets used hitherto in the econometric literature. We apply our method to the dataset of economic growth determinants by Sala-i-Martin et al. (Sala-i-Martin, X., Doppelhofer, G., and Miller, R. I. (2004). Determinants of Long-Term Growth: A Bayesian Averaging of Classical Estimates (BACE) Approach. American Economic Review, 94: 813-835) and show that our procedure has superior out-of-sample predictive abilities as compared to the standard Bayesian model averaging methods currently used in the literature. (author's abstract) ; Series: Research Report Series / Department of Statistics and Mathematics", "link": "http://epub.wu.ac.at/3213/1/Report113.pdf"}]
</code></pre>

<h3>
<a aria-hidden="true" href="#oer-commons-data" class="anchor" id="user-content-oer-commons-data"><span class="octicon octicon-link"></span></a>OER commons data</h3>

<p>Get OER commons Open Educational Data resources. Search by keywords.#### Call
<code>[GET] http://exploredu.ijs.si/api/oer/&lt;keyword&gt;</code></p>

<h4>
<a aria-hidden="true" href="#example-17" class="anchor" id="user-content-example-17"><span class="octicon octicon-link"></span></a>Example</h4>

<p><a href="http://exploredu.ijs.si/api/oer/artificial%20intelligence">http://exploredu.ijs.si/api/oer/artificial%20intelligence</a></p>

<h4>
<a aria-hidden="true" href="#result-17" class="anchor" id="user-content-result-17"><span class="octicon octicon-link"></span></a>Result</h4>

<pre><code>[{"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/3f/ea/3fea13e24d9732346f0079e12dece0a8.jpg", "desc": "This course will present advanced topics in Artificial Intelligence (AI), including inquiries ...", "meta": "Subject:Computer SciencePhilosophyScience and TechnologyMaterial Type:AssessmentsAudio LecturesFull CourseLecture NotesReadingsSyllabiVideo LecturesProvider:The Saylor Foundation", "link": "https://www.oercommons.org/courses/advanced-artificial-intelligence", "title": "Advanced Artificial Intelligence"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/20/bd/20bd5cca10701bddc1b0ed657fca9f06.jpg", "desc": "Artificial Intelligence : Course lectures, hours 42. There are 11 pdf files, ...", "meta": "Subject:Computer ScienceScience and TechnologyMaterial Type:Full CourseLecture NotesProvider:Jaypee Institute of Engineering and Technology (JIET)Provider Set:Individual AuthorsAuthor:RC Chakraborty", "link": "https://www.oercommons.org/courses/artificial-intelligence", "title": "Courseware : Artificial Intelligence"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/e8/2c/e82cf32b993c9c906f3279dab6b00d7b.jpg", "desc": "A graduate-level introduction to artificial intelligence. Topics include: representation and inference in ...", "meta": "Subject:Computer ScienceScience and TechnologyMaterial Type:AssessmentsFull CourseHomework and AssignmentsLecture NotesSyllabiProvider:M.I.T.Provider Set:M.I.T. OpenCourseWareAuthor:Kaelbling, Leslie Pack", "link": "https://www.oercommons.org/courses/6-825-techniques-in-artificial-intelligence-sma-5504-fall-2002", "title": "Techniques in Artificial Intelligence (SMA 5504), Fall 2002"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/1f/0f/1f0f5b960d34667804fb0a182cd4de27.jpg", "desc": "Artificial Intelligence and heuristic methods are extremely important for the present and ...", "meta": "Subject:Computer ScienceComputing and InformationMaterial Type:Instructional MaterialProvider:ShodorProvider Set:CSERD: Computational Science Education Reference DeskAuthor:Paolo Frasconi (University of Florence) Ron Shamir (Tel Aviv University)", "link": "https://www.oercommons.org/courses/artificial-intelligence-and-heuristic", "title": "Artificial Intelligence and Heuristic"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/4b/10/4b10b4884b935226db54968e16ef7909.jpg", "desc": "An introduction to the main techniques of Artifical Intelligence: state-space search methods, ...", "meta": "Subject:Computer ScienceScience and TechnologyMaterial Type:Full CourseHomework and AssignmentsSyllabiProvider:UMass BostonProvider Set:UMass Boston OpenCourseWareAuthor:Ph.D.Professor Wei Ding", "link": "https://www.oercommons.org/courses/artificial-intelligence-fall-2008", "title": "Artificial Intelligence, Fall 2008"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/1a/ed/1aede1569446df944a9e08aa13b690bb.jpg", "desc": "This course includes materials on AI programming, logic, search, game playing, machine ...", "meta": "Subject:Computer ScienceScience and TechnologyMaterial Type:Full CourseReadingsSyllabiTextbooksProvider:The Saylor Foundation", "link": "https://www.oercommons.org/courses/artificial-intelligence-3", "title": "Artificial Intelligence"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/81/e3/81e3637aa0df663464a6c059dd22876e.jpg", "desc": "Manuela Velosa is an artificial intelligence researcher from Carnegie Mellon University who ...", "meta": "Subject:EngineeringPhysicsMaterial Type:ReferenceProvider:Twin Cities Public TelevisionProvider Set:DragonflyTVAuthor:Dragonfly TV", "link": "https://www.oercommons.org/courses/manuela-velosa", "title": "Manuela Velosa"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/8f/a2/8fa29cb6ea5ee3b2a31bb4c203485fa0.jpg", "desc": "An quick overview of AI from both the technical and the philosophical ...", "meta": "Subject:Computer ScienceScience and TechnologyMaterial Type:Full CourseHomework and AssignmentsReadingsSyllabiVideo LecturesOtherProvider:ArsDigita UniversityProvider Set:ArsDigita UniversityAuthor:Patrick Winston", "link": "https://www.oercommons.org/courses/artificial-intelligence-2", "title": "Artificial Intelligence"}, {"img_url": "https://www.oercommons.org/static/newdesign/images/materials/default-thumbnail-index.png", "desc": "A \"inspirational\" web site. \"At MIT\u013a\u0150s Artificial Intelligence Lab, James McLurkin is ...", "meta": "Subject:EducationProvider:Fun WorksProvider Set:Fun Works . . . for Careers You Never Knew Existed", "link": "https://www.oercommons.org/courses/james-mclurkin-robotic-ants", "title": "James McLurkin - Robotic Ants"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/5e/b8/5eb883eed09f1a11ac9aa01f0ad7d70f.jpg", "desc": "This course introduces students to the basic knowledge representation, problem solving, and ...", "meta": "Subject:Computer ScienceInformation ScienceScience and TechnologyMaterial Type:AssessmentsHomework and AssignmentsReadingsSyllabiProvider:M.I.T.Provider Set:M.I.T. OpenCourseWareAuthor:Winston, Patrick Henry", "link": "https://www.oercommons.org/courses/artificial-intelligence-fall-2010", "title": "Artificial Intelligence, Fall 2010"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/a2/35/a235fb0725e2af03a6fcb6d9397e257c.jpg", "desc": "Presents the main concepts of decision analysis, artificial intelligence, and predictive model ...", "meta": "Subject:Computer ScienceScience and TechnologyMaterial Type:Activities and LabsFull CourseLecture NotesSyllabiProvider:M.I.T.Provider Set:M.I.T. OpenCourseWare", "link": "https://www.oercommons.org/courses/medical-decision-support-fall-2005", "title": "Medical Decision Support, Fall 2005"}, {"img_url": "https://www.oercommons.org/static/newdesign/images/materials/default-thumbnail-index.png", "desc": "Introduces representations, techniques, and architectures used to build applied systems and to ...", "meta": "Subject:Architecture and DesignComputer ScienceScience and TechnologyMaterial Type:Activities and LabsAssessmentsFull CourseHomework and AssignmentsLecture NotesSyllabiProvider:M.I.T.Provider Set:M.I.T. OpenCourseWareAuthor:Lozano-P\u011a\u0160rez, Tom\u011a\u00c1s", "link": "https://www.oercommons.org/courses/artificial-intelligence-spring-2005", "title": "Artificial Intelligence, Spring 2005"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/f0/ed/f0ed7d6e52f60f3f131e79d59bc9dcb2.jpg", "desc": "Introduces representations, techniques, and architectures used to build applied systems and to ...", "meta": "Subject:Health, Medicine and NursingMaterial Type:Activities and LabsAssessmentsFull CourseHomework and AssignmentsLecture NotesSyllabiProvider:M.I.T.Provider Set:M.I.T. OpenCourseWareAuthor:Szolovits, Peter", "link": "https://www.oercommons.org/courses/hst-947-medical-artificial-intelligence-spring-2005", "title": "Medical Artificial Intelligence, Spring 2005"}, {"img_url": "https://www.oercommons.org/static/newdesign/images/materials/default-thumbnail-index.png", "desc": "Presents the main concepts of decision analysis, artificial intelligence, and predictive model ...", "meta": "Subject:Computer ScienceScience and TechnologyMaterial Type:AssessmentsFull CourseHomework and AssignmentsLecture NotesSyllabiProvider:M.I.T.Provider Set:M.I.T. OpenCourseWareAuthor:Ohno-Machado, Lucila", "link": "https://www.oercommons.org/courses/hst-951j-medical-decision-support-spring-2003", "title": "Medical Decision Support, Spring 2003"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/98/8c/988c6a6878baea24c423d7255a4ab289.jpg", "desc": "This case study analyzes the reasoning processes and types of information that ...", "meta": "Subject:Computer ScienceComputing and InformationLinguisticsSocial SciencesMaterial Type:Case StudyInstructional MaterialProvider:National Center for Case Study Teaching in ScienceProvider Set:Case Study CollectionAuthor:Stephanie E. August", "link": "https://www.oercommons.org/courses/the-living-room-a-case-study-in-artificial-intelligence-collaborative-systems-and-language-understanding", "title": "The \"Living\" Room A Case Study in Artificial Intelligence, Collaborative Systems, and Language Understanding"}, {"img_url": "https://oercommons.s3.amazonaws.com/media/thumbnails/81/04/8104e769a5e08500a05445e294424064.jpg", "desc": "This activity explores what it means for a computer to be intelligent ...", "meta": "Subject:Computer ScienceComputing and InformationEngineeringTechnologyEducationLife ScienceMathematicsMathematics and StatisticsScience and TechnologyPsychologySocial SciencesMaterial Type:Activities and LabsGamesInstructional MaterialLesson PlansSimulationsProvider:Computer Science UnpluggedScience and Math Informal Learning Educators (SMILE)Provider Set:Computer Science UnpluggedSMILE Pathway: Science and Math Activities in One SearchAuthor:Brian Mason Scientific and Technical TrustComputer Science UnpluggedGoogle Inc.Paul Curzon", "link": "https://www.oercommons.org/courses/artificial-intelligence-4", "title": "Artificial Intelligence"}]
</code></pre>

      </div>

  </div>
  </div>
</body>
</html>
